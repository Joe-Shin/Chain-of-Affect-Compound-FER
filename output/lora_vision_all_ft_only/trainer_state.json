{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.995698924731183,
  "eval_steps": 500,
  "global_step": 5810,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0017204301075268817,
      "grad_norm": 6.398373876854907,
      "learning_rate": 1.142857142857143e-06,
      "loss": 5.1775,
      "step": 1
    },
    {
      "epoch": 0.0034408602150537634,
      "grad_norm": 5.671365033566476,
      "learning_rate": 2.285714285714286e-06,
      "loss": 5.4266,
      "step": 2
    },
    {
      "epoch": 0.005161290322580645,
      "grad_norm": 5.798535863878864,
      "learning_rate": 3.428571428571429e-06,
      "loss": 5.3603,
      "step": 3
    },
    {
      "epoch": 0.006881720430107527,
      "grad_norm": 6.674697420970945,
      "learning_rate": 4.571428571428572e-06,
      "loss": 5.3107,
      "step": 4
    },
    {
      "epoch": 0.008602150537634409,
      "grad_norm": 5.816599414205571,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 5.2838,
      "step": 5
    },
    {
      "epoch": 0.01032258064516129,
      "grad_norm": 7.988304925764885,
      "learning_rate": 6.857142857142858e-06,
      "loss": 5.2191,
      "step": 6
    },
    {
      "epoch": 0.012043010752688172,
      "grad_norm": 13.877271827916129,
      "learning_rate": 8.000000000000001e-06,
      "loss": 5.3049,
      "step": 7
    },
    {
      "epoch": 0.013763440860215054,
      "grad_norm": 6.303065814164223,
      "learning_rate": 9.142857142857144e-06,
      "loss": 5.2024,
      "step": 8
    },
    {
      "epoch": 0.015483870967741935,
      "grad_norm": 6.985338132057083,
      "learning_rate": 1.0285714285714286e-05,
      "loss": 5.2637,
      "step": 9
    },
    {
      "epoch": 0.017204301075268817,
      "grad_norm": 6.360505324861129,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 5.0352,
      "step": 10
    },
    {
      "epoch": 0.0189247311827957,
      "grad_norm": 7.020156277887024,
      "learning_rate": 1.2571428571428573e-05,
      "loss": 5.3719,
      "step": 11
    },
    {
      "epoch": 0.02064516129032258,
      "grad_norm": 8.267635160394788,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 5.1208,
      "step": 12
    },
    {
      "epoch": 0.022365591397849462,
      "grad_norm": 6.046189592686294,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 5.0588,
      "step": 13
    },
    {
      "epoch": 0.024086021505376344,
      "grad_norm": 5.841130347241154,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 5.0795,
      "step": 14
    },
    {
      "epoch": 0.025806451612903226,
      "grad_norm": 5.998407678050526,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 4.8968,
      "step": 15
    },
    {
      "epoch": 0.027526881720430108,
      "grad_norm": 6.385539131153773,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 4.9649,
      "step": 16
    },
    {
      "epoch": 0.02924731182795699,
      "grad_norm": 7.225088199022413,
      "learning_rate": 1.942857142857143e-05,
      "loss": 4.897,
      "step": 17
    },
    {
      "epoch": 0.03096774193548387,
      "grad_norm": 6.179096839726578,
      "learning_rate": 2.0571428571428573e-05,
      "loss": 4.9483,
      "step": 18
    },
    {
      "epoch": 0.032688172043010756,
      "grad_norm": 7.203286781532126,
      "learning_rate": 2.1714285714285715e-05,
      "loss": 4.7348,
      "step": 19
    },
    {
      "epoch": 0.034408602150537634,
      "grad_norm": 7.6479233936208155,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 4.7443,
      "step": 20
    },
    {
      "epoch": 0.03612903225806452,
      "grad_norm": 6.088257426455156,
      "learning_rate": 2.4e-05,
      "loss": 4.4502,
      "step": 21
    },
    {
      "epoch": 0.0378494623655914,
      "grad_norm": 6.995414469813813,
      "learning_rate": 2.5142857142857147e-05,
      "loss": 4.2129,
      "step": 22
    },
    {
      "epoch": 0.03956989247311828,
      "grad_norm": 10.338229901401862,
      "learning_rate": 2.6285714285714286e-05,
      "loss": 4.0419,
      "step": 23
    },
    {
      "epoch": 0.04129032258064516,
      "grad_norm": 6.886430991406633,
      "learning_rate": 2.742857142857143e-05,
      "loss": 3.6438,
      "step": 24
    },
    {
      "epoch": 0.043010752688172046,
      "grad_norm": 6.8285891912527825,
      "learning_rate": 2.857142857142857e-05,
      "loss": 3.423,
      "step": 25
    },
    {
      "epoch": 0.044731182795698925,
      "grad_norm": 6.078889754593265,
      "learning_rate": 2.9714285714285717e-05,
      "loss": 2.795,
      "step": 26
    },
    {
      "epoch": 0.04645161290322581,
      "grad_norm": 5.738068643469313,
      "learning_rate": 3.0857142857142856e-05,
      "loss": 2.4089,
      "step": 27
    },
    {
      "epoch": 0.04817204301075269,
      "grad_norm": 7.65857517993254,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 2.021,
      "step": 28
    },
    {
      "epoch": 0.04989247311827957,
      "grad_norm": 5.177439721751895,
      "learning_rate": 3.314285714285714e-05,
      "loss": 1.6019,
      "step": 29
    },
    {
      "epoch": 0.05161290322580645,
      "grad_norm": 5.491348353810103,
      "learning_rate": 3.428571428571429e-05,
      "loss": 1.0247,
      "step": 30
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 3.6968461660908627,
      "learning_rate": 3.5428571428571426e-05,
      "loss": 0.7065,
      "step": 31
    },
    {
      "epoch": 0.055053763440860215,
      "grad_norm": 2.3951005049749536,
      "learning_rate": 3.6571428571428576e-05,
      "loss": 0.4736,
      "step": 32
    },
    {
      "epoch": 0.0567741935483871,
      "grad_norm": 2.1469226832197146,
      "learning_rate": 3.771428571428572e-05,
      "loss": 0.3027,
      "step": 33
    },
    {
      "epoch": 0.05849462365591398,
      "grad_norm": 1.1166820010304608,
      "learning_rate": 3.885714285714286e-05,
      "loss": 0.2294,
      "step": 34
    },
    {
      "epoch": 0.060215053763440864,
      "grad_norm": 1.1497746647940839,
      "learning_rate": 4e-05,
      "loss": 0.2665,
      "step": 35
    },
    {
      "epoch": 0.06193548387096774,
      "grad_norm": 1.325292368595335,
      "learning_rate": 4.1142857142857146e-05,
      "loss": 0.2723,
      "step": 36
    },
    {
      "epoch": 0.06365591397849463,
      "grad_norm": 1.4287458167846387,
      "learning_rate": 4.228571428571429e-05,
      "loss": 0.2639,
      "step": 37
    },
    {
      "epoch": 0.06537634408602151,
      "grad_norm": 1.0688882538888045,
      "learning_rate": 4.342857142857143e-05,
      "loss": 0.245,
      "step": 38
    },
    {
      "epoch": 0.06709677419354838,
      "grad_norm": 0.9989085991300497,
      "learning_rate": 4.4571428571428574e-05,
      "loss": 0.2132,
      "step": 39
    },
    {
      "epoch": 0.06881720430107527,
      "grad_norm": 0.8940862759165646,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.145,
      "step": 40
    },
    {
      "epoch": 0.07053763440860215,
      "grad_norm": 1.372117648288275,
      "learning_rate": 4.685714285714286e-05,
      "loss": 0.2181,
      "step": 41
    },
    {
      "epoch": 0.07225806451612904,
      "grad_norm": 1.015623348966547,
      "learning_rate": 4.8e-05,
      "loss": 0.2173,
      "step": 42
    },
    {
      "epoch": 0.07397849462365591,
      "grad_norm": 0.8503807699299957,
      "learning_rate": 4.9142857142857144e-05,
      "loss": 0.1513,
      "step": 43
    },
    {
      "epoch": 0.0756989247311828,
      "grad_norm": 0.8786882872052653,
      "learning_rate": 5.028571428571429e-05,
      "loss": 0.1969,
      "step": 44
    },
    {
      "epoch": 0.07741935483870968,
      "grad_norm": 1.0273563342750194,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.2066,
      "step": 45
    },
    {
      "epoch": 0.07913978494623657,
      "grad_norm": 1.0595765343548433,
      "learning_rate": 5.257142857142857e-05,
      "loss": 0.2162,
      "step": 46
    },
    {
      "epoch": 0.08086021505376344,
      "grad_norm": 0.8418755398757264,
      "learning_rate": 5.3714285714285714e-05,
      "loss": 0.1842,
      "step": 47
    },
    {
      "epoch": 0.08258064516129032,
      "grad_norm": 1.0188394318493865,
      "learning_rate": 5.485714285714286e-05,
      "loss": 0.1349,
      "step": 48
    },
    {
      "epoch": 0.08430107526881721,
      "grad_norm": 0.9083138280113892,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 0.1427,
      "step": 49
    },
    {
      "epoch": 0.08602150537634409,
      "grad_norm": 0.8506500899488859,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.1714,
      "step": 50
    },
    {
      "epoch": 0.08774193548387096,
      "grad_norm": 1.449743368516623,
      "learning_rate": 5.828571428571429e-05,
      "loss": 0.1664,
      "step": 51
    },
    {
      "epoch": 0.08946236559139785,
      "grad_norm": 0.7271478895608784,
      "learning_rate": 5.9428571428571434e-05,
      "loss": 0.1287,
      "step": 52
    },
    {
      "epoch": 0.09118279569892473,
      "grad_norm": 1.0838288683701243,
      "learning_rate": 6.0571428571428576e-05,
      "loss": 0.2251,
      "step": 53
    },
    {
      "epoch": 0.09290322580645162,
      "grad_norm": 0.6067400974510586,
      "learning_rate": 6.171428571428571e-05,
      "loss": 0.1208,
      "step": 54
    },
    {
      "epoch": 0.09462365591397849,
      "grad_norm": 1.300627788544437,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.1226,
      "step": 55
    },
    {
      "epoch": 0.09634408602150538,
      "grad_norm": 0.8172052241210683,
      "learning_rate": 6.400000000000001e-05,
      "loss": 0.1518,
      "step": 56
    },
    {
      "epoch": 0.09806451612903226,
      "grad_norm": 0.8656586056590979,
      "learning_rate": 6.514285714285715e-05,
      "loss": 0.1668,
      "step": 57
    },
    {
      "epoch": 0.09978494623655915,
      "grad_norm": 0.837708233355476,
      "learning_rate": 6.628571428571428e-05,
      "loss": 0.1208,
      "step": 58
    },
    {
      "epoch": 0.10150537634408602,
      "grad_norm": 0.7255252259817828,
      "learning_rate": 6.742857142857143e-05,
      "loss": 0.1632,
      "step": 59
    },
    {
      "epoch": 0.1032258064516129,
      "grad_norm": 1.0155662218727883,
      "learning_rate": 6.857142857142858e-05,
      "loss": 0.1801,
      "step": 60
    },
    {
      "epoch": 0.10494623655913979,
      "grad_norm": 0.9069426999221443,
      "learning_rate": 6.971428571428572e-05,
      "loss": 0.1318,
      "step": 61
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.12239321351679,
      "learning_rate": 7.085714285714285e-05,
      "loss": 0.1413,
      "step": 62
    },
    {
      "epoch": 0.10838709677419354,
      "grad_norm": 0.7642603722668174,
      "learning_rate": 7.2e-05,
      "loss": 0.1047,
      "step": 63
    },
    {
      "epoch": 0.11010752688172043,
      "grad_norm": 1.3270102214713835,
      "learning_rate": 7.314285714285715e-05,
      "loss": 0.1302,
      "step": 64
    },
    {
      "epoch": 0.11182795698924732,
      "grad_norm": 0.7604852592617509,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.1219,
      "step": 65
    },
    {
      "epoch": 0.1135483870967742,
      "grad_norm": 1.035428143219634,
      "learning_rate": 7.542857142857144e-05,
      "loss": 0.1378,
      "step": 66
    },
    {
      "epoch": 0.11526881720430107,
      "grad_norm": 2.163793016358659,
      "learning_rate": 7.657142857142857e-05,
      "loss": 0.1314,
      "step": 67
    },
    {
      "epoch": 0.11698924731182796,
      "grad_norm": 1.2949829403842776,
      "learning_rate": 7.771428571428572e-05,
      "loss": 0.1834,
      "step": 68
    },
    {
      "epoch": 0.11870967741935484,
      "grad_norm": 1.4591458749380333,
      "learning_rate": 7.885714285714286e-05,
      "loss": 0.1899,
      "step": 69
    },
    {
      "epoch": 0.12043010752688173,
      "grad_norm": 1.6375580068889406,
      "learning_rate": 8e-05,
      "loss": 0.1498,
      "step": 70
    },
    {
      "epoch": 0.1221505376344086,
      "grad_norm": 1.5628829305501026,
      "learning_rate": 8.114285714285714e-05,
      "loss": 0.1549,
      "step": 71
    },
    {
      "epoch": 0.12387096774193548,
      "grad_norm": 1.6490167918532963,
      "learning_rate": 8.228571428571429e-05,
      "loss": 0.1569,
      "step": 72
    },
    {
      "epoch": 0.12559139784946236,
      "grad_norm": 1.252445018254199,
      "learning_rate": 8.342857142857143e-05,
      "loss": 0.1732,
      "step": 73
    },
    {
      "epoch": 0.12731182795698925,
      "grad_norm": 0.8514784402023827,
      "learning_rate": 8.457142857142858e-05,
      "loss": 0.1418,
      "step": 74
    },
    {
      "epoch": 0.12903225806451613,
      "grad_norm": 1.1844693588756077,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.1277,
      "step": 75
    },
    {
      "epoch": 0.13075268817204302,
      "grad_norm": 1.9217749141940492,
      "learning_rate": 8.685714285714286e-05,
      "loss": 0.2247,
      "step": 76
    },
    {
      "epoch": 0.1324731182795699,
      "grad_norm": 0.7947656650930373,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.1326,
      "step": 77
    },
    {
      "epoch": 0.13419354838709677,
      "grad_norm": 3.540860812067319,
      "learning_rate": 8.914285714285715e-05,
      "loss": 0.1435,
      "step": 78
    },
    {
      "epoch": 0.13591397849462367,
      "grad_norm": 1.2126085780152873,
      "learning_rate": 9.028571428571428e-05,
      "loss": 0.1159,
      "step": 79
    },
    {
      "epoch": 0.13763440860215054,
      "grad_norm": 1.0403601510291534,
      "learning_rate": 9.142857142857143e-05,
      "loss": 0.1327,
      "step": 80
    },
    {
      "epoch": 0.1393548387096774,
      "grad_norm": 1.2223519734012458,
      "learning_rate": 9.257142857142858e-05,
      "loss": 0.1454,
      "step": 81
    },
    {
      "epoch": 0.1410752688172043,
      "grad_norm": 0.8122935432885311,
      "learning_rate": 9.371428571428572e-05,
      "loss": 0.0919,
      "step": 82
    },
    {
      "epoch": 0.14279569892473118,
      "grad_norm": 0.9327269090407359,
      "learning_rate": 9.485714285714287e-05,
      "loss": 0.1323,
      "step": 83
    },
    {
      "epoch": 0.14451612903225808,
      "grad_norm": 1.0516078225040508,
      "learning_rate": 9.6e-05,
      "loss": 0.1402,
      "step": 84
    },
    {
      "epoch": 0.14623655913978495,
      "grad_norm": 0.827955449091864,
      "learning_rate": 9.714285714285715e-05,
      "loss": 0.1117,
      "step": 85
    },
    {
      "epoch": 0.14795698924731182,
      "grad_norm": 0.7963954736479844,
      "learning_rate": 9.828571428571429e-05,
      "loss": 0.1134,
      "step": 86
    },
    {
      "epoch": 0.14967741935483872,
      "grad_norm": 1.282961336888973,
      "learning_rate": 9.942857142857144e-05,
      "loss": 0.1349,
      "step": 87
    },
    {
      "epoch": 0.1513978494623656,
      "grad_norm": 0.7523656582196778,
      "learning_rate": 0.00010057142857142859,
      "loss": 0.0721,
      "step": 88
    },
    {
      "epoch": 0.15311827956989246,
      "grad_norm": 1.1367345172924646,
      "learning_rate": 0.00010171428571428572,
      "loss": 0.1377,
      "step": 89
    },
    {
      "epoch": 0.15483870967741936,
      "grad_norm": 0.9722505448218558,
      "learning_rate": 0.00010285714285714286,
      "loss": 0.1592,
      "step": 90
    },
    {
      "epoch": 0.15655913978494623,
      "grad_norm": 0.945581864154726,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.131,
      "step": 91
    },
    {
      "epoch": 0.15827956989247313,
      "grad_norm": 0.8971407828442776,
      "learning_rate": 0.00010514285714285714,
      "loss": 0.139,
      "step": 92
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0296786808338267,
      "learning_rate": 0.0001062857142857143,
      "loss": 0.1231,
      "step": 93
    },
    {
      "epoch": 0.16172043010752687,
      "grad_norm": 0.7394920193165669,
      "learning_rate": 0.00010742857142857143,
      "loss": 0.1199,
      "step": 94
    },
    {
      "epoch": 0.16344086021505377,
      "grad_norm": 1.129307624895207,
      "learning_rate": 0.00010857142857142856,
      "loss": 0.1298,
      "step": 95
    },
    {
      "epoch": 0.16516129032258065,
      "grad_norm": 0.8246729302433047,
      "learning_rate": 0.00010971428571428573,
      "loss": 0.0652,
      "step": 96
    },
    {
      "epoch": 0.16688172043010752,
      "grad_norm": 0.7585316192553162,
      "learning_rate": 0.00011085714285714286,
      "loss": 0.1048,
      "step": 97
    },
    {
      "epoch": 0.16860215053763442,
      "grad_norm": 0.8203771584273482,
      "learning_rate": 0.00011200000000000001,
      "loss": 0.1058,
      "step": 98
    },
    {
      "epoch": 0.1703225806451613,
      "grad_norm": 1.0395066858175308,
      "learning_rate": 0.00011314285714285715,
      "loss": 0.1003,
      "step": 99
    },
    {
      "epoch": 0.17204301075268819,
      "grad_norm": 1.2224685371982975,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.1614,
      "step": 100
    },
    {
      "epoch": 0.17376344086021506,
      "grad_norm": 0.8564737827286073,
      "learning_rate": 0.00011542857142857145,
      "loss": 0.1029,
      "step": 101
    },
    {
      "epoch": 0.17548387096774193,
      "grad_norm": 1.0847050651480843,
      "learning_rate": 0.00011657142857142858,
      "loss": 0.1441,
      "step": 102
    },
    {
      "epoch": 0.17720430107526883,
      "grad_norm": 1.1055170925479192,
      "learning_rate": 0.0001177142857142857,
      "loss": 0.1126,
      "step": 103
    },
    {
      "epoch": 0.1789247311827957,
      "grad_norm": 0.7448301774815075,
      "learning_rate": 0.00011885714285714287,
      "loss": 0.0949,
      "step": 104
    },
    {
      "epoch": 0.18064516129032257,
      "grad_norm": 0.896187776187886,
      "learning_rate": 0.00012,
      "loss": 0.084,
      "step": 105
    },
    {
      "epoch": 0.18236559139784947,
      "grad_norm": 1.0593115805762015,
      "learning_rate": 0.00012114285714285715,
      "loss": 0.0927,
      "step": 106
    },
    {
      "epoch": 0.18408602150537634,
      "grad_norm": 0.8142245909804108,
      "learning_rate": 0.0001222857142857143,
      "loss": 0.1088,
      "step": 107
    },
    {
      "epoch": 0.18580645161290324,
      "grad_norm": 0.6748629424174378,
      "learning_rate": 0.00012342857142857142,
      "loss": 0.0851,
      "step": 108
    },
    {
      "epoch": 0.1875268817204301,
      "grad_norm": 0.7087174420183305,
      "learning_rate": 0.0001245714285714286,
      "loss": 0.0955,
      "step": 109
    },
    {
      "epoch": 0.18924731182795698,
      "grad_norm": 0.6667597340692222,
      "learning_rate": 0.00012571428571428572,
      "loss": 0.0846,
      "step": 110
    },
    {
      "epoch": 0.19096774193548388,
      "grad_norm": 0.992614974085464,
      "learning_rate": 0.00012685714285714286,
      "loss": 0.1139,
      "step": 111
    },
    {
      "epoch": 0.19268817204301075,
      "grad_norm": 1.0808297516468763,
      "learning_rate": 0.00012800000000000002,
      "loss": 0.0804,
      "step": 112
    },
    {
      "epoch": 0.19440860215053762,
      "grad_norm": 1.1004881492689385,
      "learning_rate": 0.00012914285714285713,
      "loss": 0.1924,
      "step": 113
    },
    {
      "epoch": 0.19612903225806452,
      "grad_norm": 1.498559341162331,
      "learning_rate": 0.0001302857142857143,
      "loss": 0.1282,
      "step": 114
    },
    {
      "epoch": 0.1978494623655914,
      "grad_norm": 1.1341921942971445,
      "learning_rate": 0.00013142857142857143,
      "loss": 0.1383,
      "step": 115
    },
    {
      "epoch": 0.1995698924731183,
      "grad_norm": 1.006441980420799,
      "learning_rate": 0.00013257142857142856,
      "loss": 0.144,
      "step": 116
    },
    {
      "epoch": 0.20129032258064516,
      "grad_norm": 0.971249256833835,
      "learning_rate": 0.00013371428571428573,
      "loss": 0.1056,
      "step": 117
    },
    {
      "epoch": 0.20301075268817204,
      "grad_norm": 1.2903931123809802,
      "learning_rate": 0.00013485714285714286,
      "loss": 0.0958,
      "step": 118
    },
    {
      "epoch": 0.20473118279569893,
      "grad_norm": 0.9577197059551178,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.1446,
      "step": 119
    },
    {
      "epoch": 0.2064516129032258,
      "grad_norm": 0.8258801675948008,
      "learning_rate": 0.00013714285714285716,
      "loss": 0.1041,
      "step": 120
    },
    {
      "epoch": 0.20817204301075268,
      "grad_norm": 0.9268216545601755,
      "learning_rate": 0.0001382857142857143,
      "loss": 0.1347,
      "step": 121
    },
    {
      "epoch": 0.20989247311827958,
      "grad_norm": 0.8302232746916749,
      "learning_rate": 0.00013942857142857143,
      "loss": 0.1101,
      "step": 122
    },
    {
      "epoch": 0.21161290322580645,
      "grad_norm": 0.7730497131640326,
      "learning_rate": 0.00014057142857142857,
      "loss": 0.1044,
      "step": 123
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 1.237424069112319,
      "learning_rate": 0.0001417142857142857,
      "loss": 0.1307,
      "step": 124
    },
    {
      "epoch": 0.21505376344086022,
      "grad_norm": 0.9033957852886475,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.095,
      "step": 125
    },
    {
      "epoch": 0.2167741935483871,
      "grad_norm": 0.618600554545099,
      "learning_rate": 0.000144,
      "loss": 0.0685,
      "step": 126
    },
    {
      "epoch": 0.218494623655914,
      "grad_norm": 0.72581305130086,
      "learning_rate": 0.00014514285714285717,
      "loss": 0.0919,
      "step": 127
    },
    {
      "epoch": 0.22021505376344086,
      "grad_norm": 0.9587532722667284,
      "learning_rate": 0.0001462857142857143,
      "loss": 0.0979,
      "step": 128
    },
    {
      "epoch": 0.22193548387096773,
      "grad_norm": 0.7168470182265312,
      "learning_rate": 0.00014742857142857144,
      "loss": 0.0745,
      "step": 129
    },
    {
      "epoch": 0.22365591397849463,
      "grad_norm": 1.43967880444092,
      "learning_rate": 0.00014857142857142857,
      "loss": 0.1286,
      "step": 130
    },
    {
      "epoch": 0.2253763440860215,
      "grad_norm": 1.1197393733070031,
      "learning_rate": 0.0001497142857142857,
      "loss": 0.122,
      "step": 131
    },
    {
      "epoch": 0.2270967741935484,
      "grad_norm": 1.173897317778574,
      "learning_rate": 0.00015085714285714287,
      "loss": 0.1228,
      "step": 132
    },
    {
      "epoch": 0.22881720430107527,
      "grad_norm": 1.323614812496525,
      "learning_rate": 0.000152,
      "loss": 0.0926,
      "step": 133
    },
    {
      "epoch": 0.23053763440860214,
      "grad_norm": 1.1971793558242696,
      "learning_rate": 0.00015314285714285714,
      "loss": 0.0592,
      "step": 134
    },
    {
      "epoch": 0.23225806451612904,
      "grad_norm": 0.7954344303835006,
      "learning_rate": 0.0001542857142857143,
      "loss": 0.086,
      "step": 135
    },
    {
      "epoch": 0.2339784946236559,
      "grad_norm": 1.2729640506294027,
      "learning_rate": 0.00015542857142857144,
      "loss": 0.1248,
      "step": 136
    },
    {
      "epoch": 0.23569892473118279,
      "grad_norm": 0.7857191498003195,
      "learning_rate": 0.00015657142857142858,
      "loss": 0.0662,
      "step": 137
    },
    {
      "epoch": 0.23741935483870968,
      "grad_norm": 1.1221399284307112,
      "learning_rate": 0.00015771428571428571,
      "loss": 0.1522,
      "step": 138
    },
    {
      "epoch": 0.23913978494623656,
      "grad_norm": 0.7658008830405252,
      "learning_rate": 0.00015885714285714285,
      "loss": 0.1029,
      "step": 139
    },
    {
      "epoch": 0.24086021505376345,
      "grad_norm": 0.800492882243766,
      "learning_rate": 0.00016,
      "loss": 0.0855,
      "step": 140
    },
    {
      "epoch": 0.24258064516129033,
      "grad_norm": 0.5830622710866874,
      "learning_rate": 0.00016114285714285715,
      "loss": 0.0535,
      "step": 141
    },
    {
      "epoch": 0.2443010752688172,
      "grad_norm": 0.8834240020518167,
      "learning_rate": 0.00016228571428571428,
      "loss": 0.1137,
      "step": 142
    },
    {
      "epoch": 0.2460215053763441,
      "grad_norm": 0.9264232040919806,
      "learning_rate": 0.00016342857142857145,
      "loss": 0.0725,
      "step": 143
    },
    {
      "epoch": 0.24774193548387097,
      "grad_norm": 0.92670692923415,
      "learning_rate": 0.00016457142857142858,
      "loss": 0.0898,
      "step": 144
    },
    {
      "epoch": 0.24946236559139784,
      "grad_norm": 0.8305510661446963,
      "learning_rate": 0.00016571428571428575,
      "loss": 0.0979,
      "step": 145
    },
    {
      "epoch": 0.2511827956989247,
      "grad_norm": 0.7873389195659478,
      "learning_rate": 0.00016685714285714285,
      "loss": 0.1038,
      "step": 146
    },
    {
      "epoch": 0.25290322580645164,
      "grad_norm": 1.3167692420129196,
      "learning_rate": 0.000168,
      "loss": 0.1164,
      "step": 147
    },
    {
      "epoch": 0.2546236559139785,
      "grad_norm": 0.8096966381710151,
      "learning_rate": 0.00016914285714285715,
      "loss": 0.076,
      "step": 148
    },
    {
      "epoch": 0.2563440860215054,
      "grad_norm": 0.853328602129078,
      "learning_rate": 0.0001702857142857143,
      "loss": 0.0982,
      "step": 149
    },
    {
      "epoch": 0.25806451612903225,
      "grad_norm": 0.5535647685807982,
      "learning_rate": 0.00017142857142857143,
      "loss": 0.0562,
      "step": 150
    },
    {
      "epoch": 0.2597849462365591,
      "grad_norm": 0.7507834976938943,
      "learning_rate": 0.0001725714285714286,
      "loss": 0.1063,
      "step": 151
    },
    {
      "epoch": 0.26150537634408605,
      "grad_norm": 0.7729614835694858,
      "learning_rate": 0.00017371428571428572,
      "loss": 0.0867,
      "step": 152
    },
    {
      "epoch": 0.2632258064516129,
      "grad_norm": 0.9846275999895379,
      "learning_rate": 0.0001748571428571429,
      "loss": 0.0874,
      "step": 153
    },
    {
      "epoch": 0.2649462365591398,
      "grad_norm": 0.6318677306961608,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.0507,
      "step": 154
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.7248709872877279,
      "learning_rate": 0.00017714285714285713,
      "loss": 0.0619,
      "step": 155
    },
    {
      "epoch": 0.26838709677419353,
      "grad_norm": 0.7874254475311626,
      "learning_rate": 0.0001782857142857143,
      "loss": 0.0827,
      "step": 156
    },
    {
      "epoch": 0.2701075268817204,
      "grad_norm": 0.9353970282755456,
      "learning_rate": 0.00017942857142857143,
      "loss": 0.0906,
      "step": 157
    },
    {
      "epoch": 0.27182795698924733,
      "grad_norm": 1.3513948501738995,
      "learning_rate": 0.00018057142857142857,
      "loss": 0.1139,
      "step": 158
    },
    {
      "epoch": 0.2735483870967742,
      "grad_norm": 0.8938774110828337,
      "learning_rate": 0.00018171428571428573,
      "loss": 0.0846,
      "step": 159
    },
    {
      "epoch": 0.2752688172043011,
      "grad_norm": 1.3156921299688924,
      "learning_rate": 0.00018285714285714286,
      "loss": 0.1471,
      "step": 160
    },
    {
      "epoch": 0.27698924731182795,
      "grad_norm": 0.7665523319106499,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.0969,
      "step": 161
    },
    {
      "epoch": 0.2787096774193548,
      "grad_norm": 0.9072115135045284,
      "learning_rate": 0.00018514285714285716,
      "loss": 0.0958,
      "step": 162
    },
    {
      "epoch": 0.28043010752688174,
      "grad_norm": 0.9919807072605572,
      "learning_rate": 0.0001862857142857143,
      "loss": 0.0861,
      "step": 163
    },
    {
      "epoch": 0.2821505376344086,
      "grad_norm": 0.9229739918990703,
      "learning_rate": 0.00018742857142857143,
      "loss": 0.1522,
      "step": 164
    },
    {
      "epoch": 0.2838709677419355,
      "grad_norm": 0.7857160585273741,
      "learning_rate": 0.00018857142857142857,
      "loss": 0.0945,
      "step": 165
    },
    {
      "epoch": 0.28559139784946236,
      "grad_norm": 1.210510783847379,
      "learning_rate": 0.00018971428571428573,
      "loss": 0.1336,
      "step": 166
    },
    {
      "epoch": 0.28731182795698923,
      "grad_norm": 0.8339703955592906,
      "learning_rate": 0.00019085714285714287,
      "loss": 0.1225,
      "step": 167
    },
    {
      "epoch": 0.28903225806451616,
      "grad_norm": 0.7683798957562796,
      "learning_rate": 0.000192,
      "loss": 0.0899,
      "step": 168
    },
    {
      "epoch": 0.29075268817204303,
      "grad_norm": 1.2248917166432962,
      "learning_rate": 0.00019314285714285717,
      "loss": 0.1318,
      "step": 169
    },
    {
      "epoch": 0.2924731182795699,
      "grad_norm": 0.7377929904502395,
      "learning_rate": 0.0001942857142857143,
      "loss": 0.0664,
      "step": 170
    },
    {
      "epoch": 0.29419354838709677,
      "grad_norm": 0.6840727526753546,
      "learning_rate": 0.00019542857142857144,
      "loss": 0.0951,
      "step": 171
    },
    {
      "epoch": 0.29591397849462364,
      "grad_norm": 0.9027952133473672,
      "learning_rate": 0.00019657142857142858,
      "loss": 0.1389,
      "step": 172
    },
    {
      "epoch": 0.2976344086021505,
      "grad_norm": 0.4913101288115619,
      "learning_rate": 0.0001977142857142857,
      "loss": 0.0811,
      "step": 173
    },
    {
      "epoch": 0.29935483870967744,
      "grad_norm": 0.41270611570442983,
      "learning_rate": 0.00019885714285714287,
      "loss": 0.0812,
      "step": 174
    },
    {
      "epoch": 0.3010752688172043,
      "grad_norm": 0.8160093700139749,
      "learning_rate": 0.0002,
      "loss": 0.117,
      "step": 175
    },
    {
      "epoch": 0.3027956989247312,
      "grad_norm": 0.8527130236726315,
      "learning_rate": 0.0001999999844588949,
      "loss": 0.1153,
      "step": 176
    },
    {
      "epoch": 0.30451612903225805,
      "grad_norm": 0.6675986507742738,
      "learning_rate": 0.00019999993783558439,
      "loss": 0.1277,
      "step": 177
    },
    {
      "epoch": 0.3062365591397849,
      "grad_norm": 0.6236336864674168,
      "learning_rate": 0.00019999986013008304,
      "loss": 0.0847,
      "step": 178
    },
    {
      "epoch": 0.30795698924731185,
      "grad_norm": 0.8397869659863672,
      "learning_rate": 0.00019999975134241487,
      "loss": 0.1163,
      "step": 179
    },
    {
      "epoch": 0.3096774193548387,
      "grad_norm": 0.5851319689074413,
      "learning_rate": 0.0001999996114726138,
      "loss": 0.0676,
      "step": 180
    },
    {
      "epoch": 0.3113978494623656,
      "grad_norm": 0.7561223850538665,
      "learning_rate": 0.00019999944052072327,
      "loss": 0.0637,
      "step": 181
    },
    {
      "epoch": 0.31311827956989247,
      "grad_norm": 0.7168673909089012,
      "learning_rate": 0.00019999923848679644,
      "loss": 0.0866,
      "step": 182
    },
    {
      "epoch": 0.31483870967741934,
      "grad_norm": 0.48024961600527594,
      "learning_rate": 0.00019999900537089608,
      "loss": 0.0425,
      "step": 183
    },
    {
      "epoch": 0.31655913978494626,
      "grad_norm": 0.9202176537834117,
      "learning_rate": 0.00019999874117309466,
      "loss": 0.0998,
      "step": 184
    },
    {
      "epoch": 0.31827956989247314,
      "grad_norm": 0.7261372864712633,
      "learning_rate": 0.0001999984458934743,
      "loss": 0.1231,
      "step": 185
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9022199308679764,
      "learning_rate": 0.00019999811953212674,
      "loss": 0.0958,
      "step": 186
    },
    {
      "epoch": 0.3217204301075269,
      "grad_norm": 1.1080850353158662,
      "learning_rate": 0.0001999977620891535,
      "loss": 0.0967,
      "step": 187
    },
    {
      "epoch": 0.32344086021505375,
      "grad_norm": 0.5619676068301911,
      "learning_rate": 0.0001999973735646656,
      "loss": 0.041,
      "step": 188
    },
    {
      "epoch": 0.3251612903225806,
      "grad_norm": 1.3217373314793013,
      "learning_rate": 0.00019999695395878382,
      "loss": 0.0914,
      "step": 189
    },
    {
      "epoch": 0.32688172043010755,
      "grad_norm": 1.4518483965964708,
      "learning_rate": 0.00019999650327163864,
      "loss": 0.1492,
      "step": 190
    },
    {
      "epoch": 0.3286021505376344,
      "grad_norm": 1.2908344916149643,
      "learning_rate": 0.0001999960215033701,
      "loss": 0.1099,
      "step": 191
    },
    {
      "epoch": 0.3303225806451613,
      "grad_norm": 0.9673002802166781,
      "learning_rate": 0.00019999550865412792,
      "loss": 0.1149,
      "step": 192
    },
    {
      "epoch": 0.33204301075268816,
      "grad_norm": 1.487121070965373,
      "learning_rate": 0.00019999496472407154,
      "loss": 0.0972,
      "step": 193
    },
    {
      "epoch": 0.33376344086021503,
      "grad_norm": 1.0491709814293257,
      "learning_rate": 0.00019999438971337002,
      "loss": 0.0939,
      "step": 194
    },
    {
      "epoch": 0.33548387096774196,
      "grad_norm": 0.7832551513793514,
      "learning_rate": 0.00019999378362220207,
      "loss": 0.0574,
      "step": 195
    },
    {
      "epoch": 0.33720430107526883,
      "grad_norm": 0.6130113049390375,
      "learning_rate": 0.0001999931464507561,
      "loss": 0.0398,
      "step": 196
    },
    {
      "epoch": 0.3389247311827957,
      "grad_norm": 1.0708882430270805,
      "learning_rate": 0.00019999247819923018,
      "loss": 0.0974,
      "step": 197
    },
    {
      "epoch": 0.3406451612903226,
      "grad_norm": 0.9653400839571831,
      "learning_rate": 0.00019999177886783194,
      "loss": 0.1214,
      "step": 198
    },
    {
      "epoch": 0.34236559139784944,
      "grad_norm": 1.152599921737416,
      "learning_rate": 0.0001999910484567788,
      "loss": 0.1229,
      "step": 199
    },
    {
      "epoch": 0.34408602150537637,
      "grad_norm": 0.6734726248079032,
      "learning_rate": 0.00019999028696629777,
      "loss": 0.0704,
      "step": 200
    },
    {
      "epoch": 0.34580645161290324,
      "grad_norm": 1.2059797249171207,
      "learning_rate": 0.00019998949439662558,
      "loss": 0.1079,
      "step": 201
    },
    {
      "epoch": 0.3475268817204301,
      "grad_norm": 0.7349406945232663,
      "learning_rate": 0.00019998867074800852,
      "loss": 0.0517,
      "step": 202
    },
    {
      "epoch": 0.349247311827957,
      "grad_norm": 1.0823039158092742,
      "learning_rate": 0.00019998781602070264,
      "loss": 0.1061,
      "step": 203
    },
    {
      "epoch": 0.35096774193548386,
      "grad_norm": 0.751119699901316,
      "learning_rate": 0.00019998693021497358,
      "loss": 0.0902,
      "step": 204
    },
    {
      "epoch": 0.35268817204301073,
      "grad_norm": 0.9683030117018163,
      "learning_rate": 0.00019998601333109668,
      "loss": 0.0853,
      "step": 205
    },
    {
      "epoch": 0.35440860215053765,
      "grad_norm": 0.9836780144128401,
      "learning_rate": 0.00019998506536935694,
      "loss": 0.1255,
      "step": 206
    },
    {
      "epoch": 0.3561290322580645,
      "grad_norm": 0.8384512212832828,
      "learning_rate": 0.000199984086330049,
      "loss": 0.0763,
      "step": 207
    },
    {
      "epoch": 0.3578494623655914,
      "grad_norm": 0.9532206891318825,
      "learning_rate": 0.00019998307621347717,
      "loss": 0.1129,
      "step": 208
    },
    {
      "epoch": 0.35956989247311827,
      "grad_norm": 0.5347942697376664,
      "learning_rate": 0.00019998203501995536,
      "loss": 0.0451,
      "step": 209
    },
    {
      "epoch": 0.36129032258064514,
      "grad_norm": 0.7167852405392764,
      "learning_rate": 0.00019998096274980728,
      "loss": 0.0697,
      "step": 210
    },
    {
      "epoch": 0.36301075268817207,
      "grad_norm": 1.14978909666268,
      "learning_rate": 0.00019997985940336616,
      "loss": 0.0937,
      "step": 211
    },
    {
      "epoch": 0.36473118279569894,
      "grad_norm": 0.8597022561142836,
      "learning_rate": 0.00019997872498097498,
      "loss": 0.0733,
      "step": 212
    },
    {
      "epoch": 0.3664516129032258,
      "grad_norm": 0.8179000787253334,
      "learning_rate": 0.00019997755948298633,
      "loss": 0.1202,
      "step": 213
    },
    {
      "epoch": 0.3681720430107527,
      "grad_norm": 0.6156932164310346,
      "learning_rate": 0.0001999763629097625,
      "loss": 0.07,
      "step": 214
    },
    {
      "epoch": 0.36989247311827955,
      "grad_norm": 0.8095744272783681,
      "learning_rate": 0.00019997513526167536,
      "loss": 0.0569,
      "step": 215
    },
    {
      "epoch": 0.3716129032258065,
      "grad_norm": 0.6857762525704524,
      "learning_rate": 0.00019997387653910648,
      "loss": 0.0777,
      "step": 216
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.789427428862275,
      "learning_rate": 0.00019997258674244717,
      "loss": 0.1308,
      "step": 217
    },
    {
      "epoch": 0.3750537634408602,
      "grad_norm": 0.9346309954390305,
      "learning_rate": 0.00019997126587209825,
      "loss": 0.0709,
      "step": 218
    },
    {
      "epoch": 0.3767741935483871,
      "grad_norm": 1.028304288644844,
      "learning_rate": 0.00019996991392847035,
      "loss": 0.1143,
      "step": 219
    },
    {
      "epoch": 0.37849462365591396,
      "grad_norm": 0.7917510450916527,
      "learning_rate": 0.00019996853091198364,
      "loss": 0.0938,
      "step": 220
    },
    {
      "epoch": 0.38021505376344084,
      "grad_norm": 1.1918431277871113,
      "learning_rate": 0.000199967116823068,
      "loss": 0.0907,
      "step": 221
    },
    {
      "epoch": 0.38193548387096776,
      "grad_norm": 0.9308271490398586,
      "learning_rate": 0.00019996567166216295,
      "loss": 0.1185,
      "step": 222
    },
    {
      "epoch": 0.38365591397849463,
      "grad_norm": 0.7795412604620906,
      "learning_rate": 0.0001999641954297177,
      "loss": 0.0941,
      "step": 223
    },
    {
      "epoch": 0.3853763440860215,
      "grad_norm": 0.8596783351880503,
      "learning_rate": 0.00019996268812619107,
      "loss": 0.0698,
      "step": 224
    },
    {
      "epoch": 0.3870967741935484,
      "grad_norm": 0.847857987285469,
      "learning_rate": 0.00019996114975205157,
      "loss": 0.0781,
      "step": 225
    },
    {
      "epoch": 0.38881720430107525,
      "grad_norm": 0.6710464856895779,
      "learning_rate": 0.0001999595803077774,
      "loss": 0.0594,
      "step": 226
    },
    {
      "epoch": 0.3905376344086022,
      "grad_norm": 1.3586912555779578,
      "learning_rate": 0.00019995797979385633,
      "loss": 0.1179,
      "step": 227
    },
    {
      "epoch": 0.39225806451612905,
      "grad_norm": 0.7190634547966333,
      "learning_rate": 0.00019995634821078586,
      "loss": 0.0713,
      "step": 228
    },
    {
      "epoch": 0.3939784946236559,
      "grad_norm": 1.1736207043064362,
      "learning_rate": 0.0001999546855590731,
      "loss": 0.0889,
      "step": 229
    },
    {
      "epoch": 0.3956989247311828,
      "grad_norm": 0.8629982042031774,
      "learning_rate": 0.00019995299183923483,
      "loss": 0.0746,
      "step": 230
    },
    {
      "epoch": 0.39741935483870966,
      "grad_norm": 0.8045724212334489,
      "learning_rate": 0.00019995126705179756,
      "loss": 0.0602,
      "step": 231
    },
    {
      "epoch": 0.3991397849462366,
      "grad_norm": 0.6585619435409217,
      "learning_rate": 0.00019994951119729735,
      "loss": 0.0758,
      "step": 232
    },
    {
      "epoch": 0.40086021505376346,
      "grad_norm": 0.6821138446951028,
      "learning_rate": 0.00019994772427627994,
      "loss": 0.0632,
      "step": 233
    },
    {
      "epoch": 0.40258064516129033,
      "grad_norm": 1.180947732359119,
      "learning_rate": 0.00019994590628930078,
      "loss": 0.1087,
      "step": 234
    },
    {
      "epoch": 0.4043010752688172,
      "grad_norm": 1.140871966136942,
      "learning_rate": 0.00019994405723692488,
      "loss": 0.0954,
      "step": 235
    },
    {
      "epoch": 0.40602150537634407,
      "grad_norm": 0.962522827136008,
      "learning_rate": 0.00019994217711972705,
      "loss": 0.0834,
      "step": 236
    },
    {
      "epoch": 0.40774193548387094,
      "grad_norm": 0.938458665033275,
      "learning_rate": 0.0001999402659382916,
      "loss": 0.0811,
      "step": 237
    },
    {
      "epoch": 0.40946236559139787,
      "grad_norm": 0.7030876861916511,
      "learning_rate": 0.00019993832369321262,
      "loss": 0.0626,
      "step": 238
    },
    {
      "epoch": 0.41118279569892474,
      "grad_norm": 0.9803603636734144,
      "learning_rate": 0.00019993635038509377,
      "loss": 0.076,
      "step": 239
    },
    {
      "epoch": 0.4129032258064516,
      "grad_norm": 1.0037584542936955,
      "learning_rate": 0.00019993434601454842,
      "loss": 0.0657,
      "step": 240
    },
    {
      "epoch": 0.4146236559139785,
      "grad_norm": 1.1174817184328898,
      "learning_rate": 0.00019993231058219958,
      "loss": 0.0978,
      "step": 241
    },
    {
      "epoch": 0.41634408602150536,
      "grad_norm": 1.0927287884807142,
      "learning_rate": 0.00019993024408867984,
      "loss": 0.0851,
      "step": 242
    },
    {
      "epoch": 0.4180645161290323,
      "grad_norm": 0.8608024786975388,
      "learning_rate": 0.0001999281465346316,
      "loss": 0.0693,
      "step": 243
    },
    {
      "epoch": 0.41978494623655915,
      "grad_norm": 1.5494970544017437,
      "learning_rate": 0.00019992601792070679,
      "loss": 0.1166,
      "step": 244
    },
    {
      "epoch": 0.421505376344086,
      "grad_norm": 1.026023549608845,
      "learning_rate": 0.000199923858247567,
      "loss": 0.0866,
      "step": 245
    },
    {
      "epoch": 0.4232258064516129,
      "grad_norm": 0.8678650788425419,
      "learning_rate": 0.00019992166751588354,
      "loss": 0.0714,
      "step": 246
    },
    {
      "epoch": 0.42494623655913977,
      "grad_norm": 0.8839794940989709,
      "learning_rate": 0.00019991944572633733,
      "loss": 0.0608,
      "step": 247
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.7477279709121063,
      "learning_rate": 0.00019991719287961896,
      "loss": 0.082,
      "step": 248
    },
    {
      "epoch": 0.42838709677419357,
      "grad_norm": 0.9709581822284415,
      "learning_rate": 0.00019991490897642864,
      "loss": 0.0614,
      "step": 249
    },
    {
      "epoch": 0.43010752688172044,
      "grad_norm": 0.7601275111474702,
      "learning_rate": 0.00019991259401747627,
      "loss": 0.0486,
      "step": 250
    },
    {
      "epoch": 0.4318279569892473,
      "grad_norm": 1.0435268134483384,
      "learning_rate": 0.00019991024800348144,
      "loss": 0.0735,
      "step": 251
    },
    {
      "epoch": 0.4335483870967742,
      "grad_norm": 0.7961931170441497,
      "learning_rate": 0.00019990787093517325,
      "loss": 0.0896,
      "step": 252
    },
    {
      "epoch": 0.43526881720430105,
      "grad_norm": 1.1502723721820236,
      "learning_rate": 0.0001999054628132906,
      "loss": 0.0983,
      "step": 253
    },
    {
      "epoch": 0.436989247311828,
      "grad_norm": 0.7772758739542103,
      "learning_rate": 0.000199903023638582,
      "loss": 0.0826,
      "step": 254
    },
    {
      "epoch": 0.43870967741935485,
      "grad_norm": 0.8359362258707809,
      "learning_rate": 0.00019990055341180557,
      "loss": 0.0818,
      "step": 255
    },
    {
      "epoch": 0.4404301075268817,
      "grad_norm": 1.0945705026772603,
      "learning_rate": 0.0001998980521337291,
      "loss": 0.1522,
      "step": 256
    },
    {
      "epoch": 0.4421505376344086,
      "grad_norm": 0.9725687669546861,
      "learning_rate": 0.00019989551980513007,
      "loss": 0.0623,
      "step": 257
    },
    {
      "epoch": 0.44387096774193546,
      "grad_norm": 1.1149282587184128,
      "learning_rate": 0.0001998929564267956,
      "loss": 0.1126,
      "step": 258
    },
    {
      "epoch": 0.4455913978494624,
      "grad_norm": 0.796184280822778,
      "learning_rate": 0.0001998903619995224,
      "loss": 0.0853,
      "step": 259
    },
    {
      "epoch": 0.44731182795698926,
      "grad_norm": 1.0582043960692626,
      "learning_rate": 0.0001998877365241169,
      "loss": 0.1001,
      "step": 260
    },
    {
      "epoch": 0.44903225806451613,
      "grad_norm": 1.1972940671744894,
      "learning_rate": 0.00019988508000139514,
      "loss": 0.1066,
      "step": 261
    },
    {
      "epoch": 0.450752688172043,
      "grad_norm": 0.8803082137252989,
      "learning_rate": 0.00019988239243218285,
      "loss": 0.0792,
      "step": 262
    },
    {
      "epoch": 0.4524731182795699,
      "grad_norm": 0.8077470757792532,
      "learning_rate": 0.0001998796738173154,
      "loss": 0.0804,
      "step": 263
    },
    {
      "epoch": 0.4541935483870968,
      "grad_norm": 0.8296369603785336,
      "learning_rate": 0.0001998769241576377,
      "loss": 0.0758,
      "step": 264
    },
    {
      "epoch": 0.4559139784946237,
      "grad_norm": 0.9197273663707289,
      "learning_rate": 0.0001998741434540045,
      "loss": 0.1032,
      "step": 265
    },
    {
      "epoch": 0.45763440860215054,
      "grad_norm": 0.7692161784910893,
      "learning_rate": 0.00019987133170728012,
      "loss": 0.0887,
      "step": 266
    },
    {
      "epoch": 0.4593548387096774,
      "grad_norm": 0.8541723045568017,
      "learning_rate": 0.00019986848891833845,
      "loss": 0.0819,
      "step": 267
    },
    {
      "epoch": 0.4610752688172043,
      "grad_norm": 0.9936891179093482,
      "learning_rate": 0.0001998656150880631,
      "loss": 0.0614,
      "step": 268
    },
    {
      "epoch": 0.46279569892473116,
      "grad_norm": 0.701088788649214,
      "learning_rate": 0.0001998627102173473,
      "loss": 0.0804,
      "step": 269
    },
    {
      "epoch": 0.4645161290322581,
      "grad_norm": 0.6617544203640636,
      "learning_rate": 0.00019985977430709407,
      "loss": 0.0804,
      "step": 270
    },
    {
      "epoch": 0.46623655913978496,
      "grad_norm": 0.9538076201524596,
      "learning_rate": 0.0001998568073582158,
      "loss": 0.0733,
      "step": 271
    },
    {
      "epoch": 0.4679569892473118,
      "grad_norm": 0.8417182665422152,
      "learning_rate": 0.0001998538093716348,
      "loss": 0.0758,
      "step": 272
    },
    {
      "epoch": 0.4696774193548387,
      "grad_norm": 0.6509897814374129,
      "learning_rate": 0.0001998507803482828,
      "loss": 0.0513,
      "step": 273
    },
    {
      "epoch": 0.47139784946236557,
      "grad_norm": 0.6370369292358283,
      "learning_rate": 0.00019984772028910138,
      "loss": 0.0654,
      "step": 274
    },
    {
      "epoch": 0.4731182795698925,
      "grad_norm": 0.8160014624193652,
      "learning_rate": 0.00019984462919504163,
      "loss": 0.0741,
      "step": 275
    },
    {
      "epoch": 0.47483870967741937,
      "grad_norm": 1.0568054832562634,
      "learning_rate": 0.00019984150706706436,
      "loss": 0.0693,
      "step": 276
    },
    {
      "epoch": 0.47655913978494624,
      "grad_norm": 0.6767862389145658,
      "learning_rate": 0.00019983835390613997,
      "loss": 0.0559,
      "step": 277
    },
    {
      "epoch": 0.4782795698924731,
      "grad_norm": 1.1942206310769266,
      "learning_rate": 0.00019983516971324857,
      "loss": 0.0893,
      "step": 278
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5796557061188079,
      "learning_rate": 0.0001998319544893798,
      "loss": 0.0637,
      "step": 279
    },
    {
      "epoch": 0.4817204301075269,
      "grad_norm": 0.7566541168660185,
      "learning_rate": 0.00019982870823553308,
      "loss": 0.0838,
      "step": 280
    },
    {
      "epoch": 0.4834408602150538,
      "grad_norm": 1.0135880326695748,
      "learning_rate": 0.0001998254309527174,
      "loss": 0.098,
      "step": 281
    },
    {
      "epoch": 0.48516129032258065,
      "grad_norm": 0.5743949435769279,
      "learning_rate": 0.00019982212264195147,
      "loss": 0.0364,
      "step": 282
    },
    {
      "epoch": 0.4868817204301075,
      "grad_norm": 1.3134387071088869,
      "learning_rate": 0.00019981878330426348,
      "loss": 0.0704,
      "step": 283
    },
    {
      "epoch": 0.4886021505376344,
      "grad_norm": 0.6986499200681648,
      "learning_rate": 0.00019981541294069146,
      "loss": 0.0878,
      "step": 284
    },
    {
      "epoch": 0.49032258064516127,
      "grad_norm": 0.9651028347454803,
      "learning_rate": 0.00019981201155228298,
      "loss": 0.0327,
      "step": 285
    },
    {
      "epoch": 0.4920430107526882,
      "grad_norm": 1.0698182289225076,
      "learning_rate": 0.0001998085791400952,
      "loss": 0.0919,
      "step": 286
    },
    {
      "epoch": 0.49376344086021506,
      "grad_norm": 1.0973972226488935,
      "learning_rate": 0.00019980511570519505,
      "loss": 0.1284,
      "step": 287
    },
    {
      "epoch": 0.49548387096774194,
      "grad_norm": 0.8692431972606434,
      "learning_rate": 0.00019980162124865904,
      "loss": 0.0654,
      "step": 288
    },
    {
      "epoch": 0.4972043010752688,
      "grad_norm": 1.0489094682125353,
      "learning_rate": 0.00019979809577157332,
      "loss": 0.0938,
      "step": 289
    },
    {
      "epoch": 0.4989247311827957,
      "grad_norm": 1.8619835861226877,
      "learning_rate": 0.00019979453927503364,
      "loss": 0.1175,
      "step": 290
    },
    {
      "epoch": 0.5006451612903225,
      "grad_norm": 0.9119116189767066,
      "learning_rate": 0.0001997909517601455,
      "loss": 0.0536,
      "step": 291
    },
    {
      "epoch": 0.5023655913978494,
      "grad_norm": 0.815959150423769,
      "learning_rate": 0.00019978733322802397,
      "loss": 0.0708,
      "step": 292
    },
    {
      "epoch": 0.5040860215053763,
      "grad_norm": 1.07500375982166,
      "learning_rate": 0.00019978368367979372,
      "loss": 0.0972,
      "step": 293
    },
    {
      "epoch": 0.5058064516129033,
      "grad_norm": 1.09995369339445,
      "learning_rate": 0.00019978000311658917,
      "loss": 0.1051,
      "step": 294
    },
    {
      "epoch": 0.5075268817204301,
      "grad_norm": 0.5937582361013352,
      "learning_rate": 0.0001997762915395543,
      "loss": 0.0408,
      "step": 295
    },
    {
      "epoch": 0.509247311827957,
      "grad_norm": 1.176602154993053,
      "learning_rate": 0.00019977254894984275,
      "loss": 0.0647,
      "step": 296
    },
    {
      "epoch": 0.5109677419354839,
      "grad_norm": 0.58048971967265,
      "learning_rate": 0.00019976877534861776,
      "loss": 0.0709,
      "step": 297
    },
    {
      "epoch": 0.5126881720430108,
      "grad_norm": 0.6987494164724726,
      "learning_rate": 0.00019976497073705233,
      "loss": 0.0694,
      "step": 298
    },
    {
      "epoch": 0.5144086021505376,
      "grad_norm": 0.9410641948960919,
      "learning_rate": 0.00019976113511632895,
      "loss": 0.1017,
      "step": 299
    },
    {
      "epoch": 0.5161290322580645,
      "grad_norm": 0.9712582521769624,
      "learning_rate": 0.00019975726848763981,
      "loss": 0.0979,
      "step": 300
    },
    {
      "epoch": 0.5178494623655914,
      "grad_norm": 0.6308444180907915,
      "learning_rate": 0.00019975337085218682,
      "loss": 0.0565,
      "step": 301
    },
    {
      "epoch": 0.5195698924731182,
      "grad_norm": 1.1261552231519492,
      "learning_rate": 0.0001997494422111814,
      "loss": 0.1189,
      "step": 302
    },
    {
      "epoch": 0.5212903225806451,
      "grad_norm": 0.8408389179663259,
      "learning_rate": 0.00019974548256584463,
      "loss": 0.073,
      "step": 303
    },
    {
      "epoch": 0.5230107526881721,
      "grad_norm": 0.801912346341387,
      "learning_rate": 0.0001997414919174073,
      "loss": 0.1058,
      "step": 304
    },
    {
      "epoch": 0.524731182795699,
      "grad_norm": 0.8236889085558275,
      "learning_rate": 0.00019973747026710977,
      "loss": 0.0708,
      "step": 305
    },
    {
      "epoch": 0.5264516129032258,
      "grad_norm": 0.5687400286022897,
      "learning_rate": 0.00019973341761620207,
      "loss": 0.0515,
      "step": 306
    },
    {
      "epoch": 0.5281720430107527,
      "grad_norm": 0.8102486526047089,
      "learning_rate": 0.00019972933396594387,
      "loss": 0.0695,
      "step": 307
    },
    {
      "epoch": 0.5298924731182796,
      "grad_norm": 0.6596893307509898,
      "learning_rate": 0.0001997252193176044,
      "loss": 0.0704,
      "step": 308
    },
    {
      "epoch": 0.5316129032258065,
      "grad_norm": 1.116344374580892,
      "learning_rate": 0.00019972107367246267,
      "loss": 0.0808,
      "step": 309
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.8726545107508472,
      "learning_rate": 0.00019971689703180713,
      "loss": 0.1311,
      "step": 310
    },
    {
      "epoch": 0.5350537634408602,
      "grad_norm": 0.5715796701263455,
      "learning_rate": 0.00019971268939693605,
      "loss": 0.0472,
      "step": 311
    },
    {
      "epoch": 0.5367741935483871,
      "grad_norm": 0.8591149242472684,
      "learning_rate": 0.00019970845076915726,
      "loss": 0.07,
      "step": 312
    },
    {
      "epoch": 0.5384946236559139,
      "grad_norm": 0.9292500551405424,
      "learning_rate": 0.0001997041811497882,
      "loss": 0.0843,
      "step": 313
    },
    {
      "epoch": 0.5402150537634408,
      "grad_norm": 0.7939217016027789,
      "learning_rate": 0.00019969988054015594,
      "loss": 0.075,
      "step": 314
    },
    {
      "epoch": 0.5419354838709678,
      "grad_norm": 0.7119656703479199,
      "learning_rate": 0.00019969554894159723,
      "loss": 0.061,
      "step": 315
    },
    {
      "epoch": 0.5436559139784947,
      "grad_norm": 1.2169560971340365,
      "learning_rate": 0.00019969118635545843,
      "loss": 0.0911,
      "step": 316
    },
    {
      "epoch": 0.5453763440860215,
      "grad_norm": 0.8179305513894268,
      "learning_rate": 0.0001996867927830955,
      "loss": 0.0822,
      "step": 317
    },
    {
      "epoch": 0.5470967741935484,
      "grad_norm": 0.8919694916399825,
      "learning_rate": 0.00019968236822587407,
      "loss": 0.1011,
      "step": 318
    },
    {
      "epoch": 0.5488172043010753,
      "grad_norm": 0.7753990221788032,
      "learning_rate": 0.00019967791268516943,
      "loss": 0.0559,
      "step": 319
    },
    {
      "epoch": 0.5505376344086022,
      "grad_norm": 0.688799605540184,
      "learning_rate": 0.00019967342616236642,
      "loss": 0.0586,
      "step": 320
    },
    {
      "epoch": 0.552258064516129,
      "grad_norm": 0.9958853755607313,
      "learning_rate": 0.00019966890865885954,
      "loss": 0.1197,
      "step": 321
    },
    {
      "epoch": 0.5539784946236559,
      "grad_norm": 0.5891028824032937,
      "learning_rate": 0.00019966436017605297,
      "loss": 0.0457,
      "step": 322
    },
    {
      "epoch": 0.5556989247311828,
      "grad_norm": 0.9620882169145615,
      "learning_rate": 0.00019965978071536045,
      "loss": 0.1034,
      "step": 323
    },
    {
      "epoch": 0.5574193548387096,
      "grad_norm": 0.6955796793789053,
      "learning_rate": 0.00019965517027820538,
      "loss": 0.057,
      "step": 324
    },
    {
      "epoch": 0.5591397849462365,
      "grad_norm": 0.997910318246748,
      "learning_rate": 0.00019965052886602078,
      "loss": 0.1328,
      "step": 325
    },
    {
      "epoch": 0.5608602150537635,
      "grad_norm": 1.5242083407539482,
      "learning_rate": 0.00019964585648024933,
      "loss": 0.0804,
      "step": 326
    },
    {
      "epoch": 0.5625806451612904,
      "grad_norm": 0.7702485423098153,
      "learning_rate": 0.0001996411531223433,
      "loss": 0.0834,
      "step": 327
    },
    {
      "epoch": 0.5643010752688172,
      "grad_norm": 0.8902554154574842,
      "learning_rate": 0.00019963641879376458,
      "loss": 0.0656,
      "step": 328
    },
    {
      "epoch": 0.5660215053763441,
      "grad_norm": 0.5696813755072021,
      "learning_rate": 0.00019963165349598473,
      "loss": 0.0521,
      "step": 329
    },
    {
      "epoch": 0.567741935483871,
      "grad_norm": 1.413944337935541,
      "learning_rate": 0.0001996268572304849,
      "loss": 0.0782,
      "step": 330
    },
    {
      "epoch": 0.5694623655913978,
      "grad_norm": 0.7704802852797706,
      "learning_rate": 0.00019962202999875586,
      "loss": 0.0504,
      "step": 331
    },
    {
      "epoch": 0.5711827956989247,
      "grad_norm": 0.8994633370262647,
      "learning_rate": 0.00019961717180229802,
      "loss": 0.0678,
      "step": 332
    },
    {
      "epoch": 0.5729032258064516,
      "grad_norm": 1.1205481391662984,
      "learning_rate": 0.00019961228264262144,
      "loss": 0.1163,
      "step": 333
    },
    {
      "epoch": 0.5746236559139785,
      "grad_norm": 0.5069629806708182,
      "learning_rate": 0.0001996073625212458,
      "loss": 0.0445,
      "step": 334
    },
    {
      "epoch": 0.5763440860215053,
      "grad_norm": 0.9459560156348258,
      "learning_rate": 0.0001996024114397003,
      "loss": 0.0777,
      "step": 335
    },
    {
      "epoch": 0.5780645161290323,
      "grad_norm": 0.5629721665917173,
      "learning_rate": 0.00019959742939952392,
      "loss": 0.0672,
      "step": 336
    },
    {
      "epoch": 0.5797849462365592,
      "grad_norm": 1.3017010855471804,
      "learning_rate": 0.00019959241640226516,
      "loss": 0.1357,
      "step": 337
    },
    {
      "epoch": 0.5815053763440861,
      "grad_norm": 0.8526099949778622,
      "learning_rate": 0.00019958737244948216,
      "loss": 0.0712,
      "step": 338
    },
    {
      "epoch": 0.5832258064516129,
      "grad_norm": 0.9274107049118572,
      "learning_rate": 0.00019958229754274268,
      "loss": 0.0639,
      "step": 339
    },
    {
      "epoch": 0.5849462365591398,
      "grad_norm": 1.0382093505621997,
      "learning_rate": 0.0001995771916836242,
      "loss": 0.0695,
      "step": 340
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 1.084228954719613,
      "learning_rate": 0.00019957205487371364,
      "loss": 0.0584,
      "step": 341
    },
    {
      "epoch": 0.5883870967741935,
      "grad_norm": 0.6289035929712921,
      "learning_rate": 0.00019956688711460766,
      "loss": 0.0532,
      "step": 342
    },
    {
      "epoch": 0.5901075268817204,
      "grad_norm": 0.7359936715159775,
      "learning_rate": 0.00019956168840791255,
      "loss": 0.0526,
      "step": 343
    },
    {
      "epoch": 0.5918279569892473,
      "grad_norm": 0.7247761616498474,
      "learning_rate": 0.00019955645875524412,
      "loss": 0.0719,
      "step": 344
    },
    {
      "epoch": 0.5935483870967742,
      "grad_norm": 0.9769032220773686,
      "learning_rate": 0.0001995511981582279,
      "loss": 0.0684,
      "step": 345
    },
    {
      "epoch": 0.595268817204301,
      "grad_norm": 0.7258755351289993,
      "learning_rate": 0.000199545906618499,
      "loss": 0.0665,
      "step": 346
    },
    {
      "epoch": 0.596989247311828,
      "grad_norm": 1.0918349899299995,
      "learning_rate": 0.00019954058413770213,
      "loss": 0.0795,
      "step": 347
    },
    {
      "epoch": 0.5987096774193549,
      "grad_norm": 1.0325032764459208,
      "learning_rate": 0.00019953523071749167,
      "loss": 0.0643,
      "step": 348
    },
    {
      "epoch": 0.6004301075268818,
      "grad_norm": 0.49550842631995534,
      "learning_rate": 0.00019952984635953152,
      "loss": 0.0247,
      "step": 349
    },
    {
      "epoch": 0.6021505376344086,
      "grad_norm": 0.7623658391451495,
      "learning_rate": 0.00019952443106549533,
      "loss": 0.0727,
      "step": 350
    },
    {
      "epoch": 0.6038709677419355,
      "grad_norm": 1.1423270102151846,
      "learning_rate": 0.00019951898483706626,
      "loss": 0.0909,
      "step": 351
    },
    {
      "epoch": 0.6055913978494624,
      "grad_norm": 0.9169715616467636,
      "learning_rate": 0.00019951350767593708,
      "loss": 0.106,
      "step": 352
    },
    {
      "epoch": 0.6073118279569892,
      "grad_norm": 0.9217991948985454,
      "learning_rate": 0.00019950799958381028,
      "loss": 0.0823,
      "step": 353
    },
    {
      "epoch": 0.6090322580645161,
      "grad_norm": 0.6882453803391527,
      "learning_rate": 0.00019950246056239785,
      "loss": 0.034,
      "step": 354
    },
    {
      "epoch": 0.610752688172043,
      "grad_norm": 1.0277099542242163,
      "learning_rate": 0.0001994968906134215,
      "loss": 0.0758,
      "step": 355
    },
    {
      "epoch": 0.6124731182795699,
      "grad_norm": 1.1237564589969702,
      "learning_rate": 0.0001994912897386124,
      "loss": 0.1479,
      "step": 356
    },
    {
      "epoch": 0.6141935483870967,
      "grad_norm": 1.0588519715058846,
      "learning_rate": 0.00019948565793971148,
      "loss": 0.099,
      "step": 357
    },
    {
      "epoch": 0.6159139784946237,
      "grad_norm": 0.6432318529083518,
      "learning_rate": 0.00019947999521846923,
      "loss": 0.047,
      "step": 358
    },
    {
      "epoch": 0.6176344086021506,
      "grad_norm": 1.15472845157032,
      "learning_rate": 0.00019947430157664576,
      "loss": 0.0964,
      "step": 359
    },
    {
      "epoch": 0.6193548387096774,
      "grad_norm": 0.9975465063398996,
      "learning_rate": 0.00019946857701601075,
      "loss": 0.0544,
      "step": 360
    },
    {
      "epoch": 0.6210752688172043,
      "grad_norm": 0.9694401062258189,
      "learning_rate": 0.0001994628215383435,
      "loss": 0.0953,
      "step": 361
    },
    {
      "epoch": 0.6227956989247312,
      "grad_norm": 0.5504755760832135,
      "learning_rate": 0.000199457035145433,
      "loss": 0.0424,
      "step": 362
    },
    {
      "epoch": 0.6245161290322581,
      "grad_norm": 0.7612944061981088,
      "learning_rate": 0.00019945121783907776,
      "loss": 0.0836,
      "step": 363
    },
    {
      "epoch": 0.6262365591397849,
      "grad_norm": 0.5751383595595019,
      "learning_rate": 0.00019944536962108593,
      "loss": 0.0382,
      "step": 364
    },
    {
      "epoch": 0.6279569892473118,
      "grad_norm": 0.6613494749188271,
      "learning_rate": 0.00019943949049327524,
      "loss": 0.0537,
      "step": 365
    },
    {
      "epoch": 0.6296774193548387,
      "grad_norm": 1.0448163862872888,
      "learning_rate": 0.0001994335804574731,
      "loss": 0.0516,
      "step": 366
    },
    {
      "epoch": 0.6313978494623655,
      "grad_norm": 0.5824091846075118,
      "learning_rate": 0.00019942763951551643,
      "loss": 0.0581,
      "step": 367
    },
    {
      "epoch": 0.6331182795698925,
      "grad_norm": 1.4771157294088053,
      "learning_rate": 0.00019942166766925186,
      "loss": 0.0834,
      "step": 368
    },
    {
      "epoch": 0.6348387096774194,
      "grad_norm": 0.9492302796736384,
      "learning_rate": 0.00019941566492053553,
      "loss": 0.101,
      "step": 369
    },
    {
      "epoch": 0.6365591397849463,
      "grad_norm": 0.6002270756848275,
      "learning_rate": 0.00019940963127123323,
      "loss": 0.0482,
      "step": 370
    },
    {
      "epoch": 0.6382795698924731,
      "grad_norm": 0.8031875701113643,
      "learning_rate": 0.00019940356672322037,
      "loss": 0.0648,
      "step": 371
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7963858100872758,
      "learning_rate": 0.00019939747127838194,
      "loss": 0.0696,
      "step": 372
    },
    {
      "epoch": 0.6417204301075269,
      "grad_norm": 0.9119038126981521,
      "learning_rate": 0.00019939134493861255,
      "loss": 0.0859,
      "step": 373
    },
    {
      "epoch": 0.6434408602150538,
      "grad_norm": 0.8098578393983736,
      "learning_rate": 0.00019938518770581636,
      "loss": 0.0592,
      "step": 374
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.7642805219202837,
      "learning_rate": 0.0001993789995819072,
      "loss": 0.0598,
      "step": 375
    },
    {
      "epoch": 0.6468817204301075,
      "grad_norm": 0.8083101794899813,
      "learning_rate": 0.0001993727805688085,
      "loss": 0.0935,
      "step": 376
    },
    {
      "epoch": 0.6486021505376344,
      "grad_norm": 0.6640563973362891,
      "learning_rate": 0.00019936653066845322,
      "loss": 0.0611,
      "step": 377
    },
    {
      "epoch": 0.6503225806451612,
      "grad_norm": 1.0545449031728742,
      "learning_rate": 0.00019936024988278402,
      "loss": 0.0952,
      "step": 378
    },
    {
      "epoch": 0.6520430107526882,
      "grad_norm": 0.9536508256711423,
      "learning_rate": 0.00019935393821375307,
      "loss": 0.0547,
      "step": 379
    },
    {
      "epoch": 0.6537634408602151,
      "grad_norm": 1.8525790068727037,
      "learning_rate": 0.00019934759566332216,
      "loss": 0.1421,
      "step": 380
    },
    {
      "epoch": 0.655483870967742,
      "grad_norm": 0.6705094497540425,
      "learning_rate": 0.00019934122223346274,
      "loss": 0.0533,
      "step": 381
    },
    {
      "epoch": 0.6572043010752688,
      "grad_norm": 0.8667625165887085,
      "learning_rate": 0.00019933481792615583,
      "loss": 0.0508,
      "step": 382
    },
    {
      "epoch": 0.6589247311827957,
      "grad_norm": 1.0092663049179798,
      "learning_rate": 0.0001993283827433919,
      "loss": 0.1306,
      "step": 383
    },
    {
      "epoch": 0.6606451612903226,
      "grad_norm": 0.752227233680528,
      "learning_rate": 0.00019932191668717132,
      "loss": 0.0336,
      "step": 384
    },
    {
      "epoch": 0.6623655913978495,
      "grad_norm": 0.8940839866534952,
      "learning_rate": 0.00019931541975950378,
      "loss": 0.0564,
      "step": 385
    },
    {
      "epoch": 0.6640860215053763,
      "grad_norm": 0.907289729364217,
      "learning_rate": 0.0001993088919624087,
      "loss": 0.0576,
      "step": 386
    },
    {
      "epoch": 0.6658064516129032,
      "grad_norm": 1.03883000966182,
      "learning_rate": 0.00019930233329791503,
      "loss": 0.0588,
      "step": 387
    },
    {
      "epoch": 0.6675268817204301,
      "grad_norm": 0.7865082076966085,
      "learning_rate": 0.0001992957437680614,
      "loss": 0.0586,
      "step": 388
    },
    {
      "epoch": 0.6692473118279569,
      "grad_norm": 0.8307590555015167,
      "learning_rate": 0.00019928912337489595,
      "loss": 0.0652,
      "step": 389
    },
    {
      "epoch": 0.6709677419354839,
      "grad_norm": 1.1221618804522793,
      "learning_rate": 0.00019928247212047643,
      "loss": 0.0613,
      "step": 390
    },
    {
      "epoch": 0.6726881720430108,
      "grad_norm": 0.6986093508192801,
      "learning_rate": 0.00019927579000687023,
      "loss": 0.0565,
      "step": 391
    },
    {
      "epoch": 0.6744086021505377,
      "grad_norm": 1.6218902600988423,
      "learning_rate": 0.00019926907703615428,
      "loss": 0.133,
      "step": 392
    },
    {
      "epoch": 0.6761290322580645,
      "grad_norm": 0.828974668726866,
      "learning_rate": 0.00019926233321041512,
      "loss": 0.0672,
      "step": 393
    },
    {
      "epoch": 0.6778494623655914,
      "grad_norm": 0.9883459374862547,
      "learning_rate": 0.0001992555585317489,
      "loss": 0.0736,
      "step": 394
    },
    {
      "epoch": 0.6795698924731183,
      "grad_norm": 0.6539326495165407,
      "learning_rate": 0.0001992487530022613,
      "loss": 0.0629,
      "step": 395
    },
    {
      "epoch": 0.6812903225806451,
      "grad_norm": 0.7525561134712487,
      "learning_rate": 0.00019924191662406768,
      "loss": 0.0581,
      "step": 396
    },
    {
      "epoch": 0.683010752688172,
      "grad_norm": 0.7325145396379061,
      "learning_rate": 0.0001992350493992929,
      "loss": 0.0507,
      "step": 397
    },
    {
      "epoch": 0.6847311827956989,
      "grad_norm": 0.6941659668690865,
      "learning_rate": 0.00019922815133007144,
      "loss": 0.0773,
      "step": 398
    },
    {
      "epoch": 0.6864516129032258,
      "grad_norm": 1.2225866409294979,
      "learning_rate": 0.00019922122241854742,
      "loss": 0.1011,
      "step": 399
    },
    {
      "epoch": 0.6881720430107527,
      "grad_norm": 1.0794382788292063,
      "learning_rate": 0.00019921426266687444,
      "loss": 0.124,
      "step": 400
    },
    {
      "epoch": 0.6898924731182796,
      "grad_norm": 2.122844712917405,
      "learning_rate": 0.00019920727207721578,
      "loss": 0.112,
      "step": 401
    },
    {
      "epoch": 0.6916129032258065,
      "grad_norm": 0.8112643334269746,
      "learning_rate": 0.00019920025065174425,
      "loss": 0.0776,
      "step": 402
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.9860525266318952,
      "learning_rate": 0.0001991931983926423,
      "loss": 0.1242,
      "step": 403
    },
    {
      "epoch": 0.6950537634408602,
      "grad_norm": 0.9569148136171545,
      "learning_rate": 0.0001991861153021019,
      "loss": 0.057,
      "step": 404
    },
    {
      "epoch": 0.6967741935483871,
      "grad_norm": 0.7881911353663721,
      "learning_rate": 0.0001991790013823246,
      "loss": 0.0533,
      "step": 405
    },
    {
      "epoch": 0.698494623655914,
      "grad_norm": 1.066197453921431,
      "learning_rate": 0.00019917185663552165,
      "loss": 0.0608,
      "step": 406
    },
    {
      "epoch": 0.7002150537634408,
      "grad_norm": 0.6421187453895285,
      "learning_rate": 0.0001991646810639137,
      "loss": 0.0725,
      "step": 407
    },
    {
      "epoch": 0.7019354838709677,
      "grad_norm": 0.5935416330360006,
      "learning_rate": 0.00019915747466973116,
      "loss": 0.0457,
      "step": 408
    },
    {
      "epoch": 0.7036559139784946,
      "grad_norm": 0.6234251698327062,
      "learning_rate": 0.00019915023745521387,
      "loss": 0.0497,
      "step": 409
    },
    {
      "epoch": 0.7053763440860215,
      "grad_norm": 0.9859004439923542,
      "learning_rate": 0.00019914296942261136,
      "loss": 0.0924,
      "step": 410
    },
    {
      "epoch": 0.7070967741935484,
      "grad_norm": 0.7575321748684292,
      "learning_rate": 0.00019913567057418266,
      "loss": 0.0543,
      "step": 411
    },
    {
      "epoch": 0.7088172043010753,
      "grad_norm": 0.7798951047447261,
      "learning_rate": 0.00019912834091219644,
      "loss": 0.049,
      "step": 412
    },
    {
      "epoch": 0.7105376344086022,
      "grad_norm": 0.8959565676654839,
      "learning_rate": 0.0001991209804389309,
      "loss": 0.0634,
      "step": 413
    },
    {
      "epoch": 0.712258064516129,
      "grad_norm": 0.6878096247164991,
      "learning_rate": 0.00019911358915667386,
      "loss": 0.0708,
      "step": 414
    },
    {
      "epoch": 0.7139784946236559,
      "grad_norm": 0.8258503388576582,
      "learning_rate": 0.0001991061670677227,
      "loss": 0.1058,
      "step": 415
    },
    {
      "epoch": 0.7156989247311828,
      "grad_norm": 1.0715978381725404,
      "learning_rate": 0.00019909871417438433,
      "loss": 0.074,
      "step": 416
    },
    {
      "epoch": 0.7174193548387097,
      "grad_norm": 0.8159408419344297,
      "learning_rate": 0.0001990912304789753,
      "loss": 0.049,
      "step": 417
    },
    {
      "epoch": 0.7191397849462365,
      "grad_norm": 0.8653698974265057,
      "learning_rate": 0.0001990837159838217,
      "loss": 0.0848,
      "step": 418
    },
    {
      "epoch": 0.7208602150537634,
      "grad_norm": 0.5232195135729624,
      "learning_rate": 0.0001990761706912592,
      "loss": 0.0401,
      "step": 419
    },
    {
      "epoch": 0.7225806451612903,
      "grad_norm": 0.8205746565656332,
      "learning_rate": 0.00019906859460363307,
      "loss": 0.0782,
      "step": 420
    },
    {
      "epoch": 0.7243010752688172,
      "grad_norm": 1.1662248890063078,
      "learning_rate": 0.0001990609877232981,
      "loss": 0.0986,
      "step": 421
    },
    {
      "epoch": 0.7260215053763441,
      "grad_norm": 0.4662801330880106,
      "learning_rate": 0.00019905335005261868,
      "loss": 0.0473,
      "step": 422
    },
    {
      "epoch": 0.727741935483871,
      "grad_norm": 0.8549623964316353,
      "learning_rate": 0.00019904568159396878,
      "loss": 0.0698,
      "step": 423
    },
    {
      "epoch": 0.7294623655913979,
      "grad_norm": 1.0392356002523038,
      "learning_rate": 0.0001990379823497319,
      "loss": 0.0505,
      "step": 424
    },
    {
      "epoch": 0.7311827956989247,
      "grad_norm": 0.8857989794262573,
      "learning_rate": 0.00019903025232230118,
      "loss": 0.0595,
      "step": 425
    },
    {
      "epoch": 0.7329032258064516,
      "grad_norm": 0.6742771570481242,
      "learning_rate": 0.0001990224915140792,
      "loss": 0.0473,
      "step": 426
    },
    {
      "epoch": 0.7346236559139785,
      "grad_norm": 0.8536825442668636,
      "learning_rate": 0.0001990146999274783,
      "loss": 0.1356,
      "step": 427
    },
    {
      "epoch": 0.7363440860215054,
      "grad_norm": 0.9035483986978625,
      "learning_rate": 0.0001990068775649202,
      "loss": 0.0588,
      "step": 428
    },
    {
      "epoch": 0.7380645161290322,
      "grad_norm": 0.9721226438621773,
      "learning_rate": 0.00019899902442883626,
      "loss": 0.0726,
      "step": 429
    },
    {
      "epoch": 0.7397849462365591,
      "grad_norm": 1.0575398837017378,
      "learning_rate": 0.00019899114052166747,
      "loss": 0.0692,
      "step": 430
    },
    {
      "epoch": 0.741505376344086,
      "grad_norm": 0.7491087763384662,
      "learning_rate": 0.0001989832258458643,
      "loss": 0.0769,
      "step": 431
    },
    {
      "epoch": 0.743225806451613,
      "grad_norm": 0.953363228302131,
      "learning_rate": 0.00019897528040388674,
      "loss": 0.1023,
      "step": 432
    },
    {
      "epoch": 0.7449462365591398,
      "grad_norm": 1.2639371447521481,
      "learning_rate": 0.00019896730419820448,
      "loss": 0.1249,
      "step": 433
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 1.0678412171367377,
      "learning_rate": 0.0001989592972312967,
      "loss": 0.1268,
      "step": 434
    },
    {
      "epoch": 0.7483870967741936,
      "grad_norm": 0.9714864685379409,
      "learning_rate": 0.0001989512595056521,
      "loss": 0.0788,
      "step": 435
    },
    {
      "epoch": 0.7501075268817204,
      "grad_norm": 1.0084941527177185,
      "learning_rate": 0.00019894319102376905,
      "loss": 0.1129,
      "step": 436
    },
    {
      "epoch": 0.7518279569892473,
      "grad_norm": 1.0389418231016683,
      "learning_rate": 0.0001989350917881553,
      "loss": 0.0704,
      "step": 437
    },
    {
      "epoch": 0.7535483870967742,
      "grad_norm": 0.669568837669407,
      "learning_rate": 0.0001989269618013284,
      "loss": 0.0661,
      "step": 438
    },
    {
      "epoch": 0.7552688172043011,
      "grad_norm": 1.273421522565184,
      "learning_rate": 0.00019891880106581524,
      "loss": 0.0569,
      "step": 439
    },
    {
      "epoch": 0.7569892473118279,
      "grad_norm": 0.9246046812252152,
      "learning_rate": 0.00019891060958415242,
      "loss": 0.0714,
      "step": 440
    },
    {
      "epoch": 0.7587096774193548,
      "grad_norm": 1.0848017919429003,
      "learning_rate": 0.00019890238735888595,
      "loss": 0.0936,
      "step": 441
    },
    {
      "epoch": 0.7604301075268817,
      "grad_norm": 0.981332189651217,
      "learning_rate": 0.00019889413439257156,
      "loss": 0.0825,
      "step": 442
    },
    {
      "epoch": 0.7621505376344087,
      "grad_norm": 0.7032877135286395,
      "learning_rate": 0.00019888585068777445,
      "loss": 0.0797,
      "step": 443
    },
    {
      "epoch": 0.7638709677419355,
      "grad_norm": 0.9133936632998347,
      "learning_rate": 0.00019887753624706932,
      "loss": 0.1194,
      "step": 444
    },
    {
      "epoch": 0.7655913978494624,
      "grad_norm": 0.6993587658201781,
      "learning_rate": 0.0001988691910730405,
      "loss": 0.0559,
      "step": 445
    },
    {
      "epoch": 0.7673118279569893,
      "grad_norm": 0.4120031964167701,
      "learning_rate": 0.00019886081516828192,
      "loss": 0.0309,
      "step": 446
    },
    {
      "epoch": 0.7690322580645161,
      "grad_norm": 1.2105020746748845,
      "learning_rate": 0.00019885240853539693,
      "loss": 0.1106,
      "step": 447
    },
    {
      "epoch": 0.770752688172043,
      "grad_norm": 0.7543326242061196,
      "learning_rate": 0.0001988439711769985,
      "loss": 0.0709,
      "step": 448
    },
    {
      "epoch": 0.7724731182795699,
      "grad_norm": 0.6251388066718918,
      "learning_rate": 0.00019883550309570915,
      "loss": 0.0337,
      "step": 449
    },
    {
      "epoch": 0.7741935483870968,
      "grad_norm": 0.8032428866838602,
      "learning_rate": 0.000198827004294161,
      "loss": 0.0614,
      "step": 450
    },
    {
      "epoch": 0.7759139784946236,
      "grad_norm": 0.858989051888819,
      "learning_rate": 0.00019881847477499557,
      "loss": 0.0761,
      "step": 451
    },
    {
      "epoch": 0.7776344086021505,
      "grad_norm": 0.865773577501566,
      "learning_rate": 0.00019880991454086414,
      "loss": 0.0832,
      "step": 452
    },
    {
      "epoch": 0.7793548387096774,
      "grad_norm": 0.5344656609042824,
      "learning_rate": 0.0001988013235944273,
      "loss": 0.0554,
      "step": 453
    },
    {
      "epoch": 0.7810752688172043,
      "grad_norm": 1.1054655186725952,
      "learning_rate": 0.00019879270193835539,
      "loss": 0.0896,
      "step": 454
    },
    {
      "epoch": 0.7827956989247312,
      "grad_norm": 0.9915882960121263,
      "learning_rate": 0.00019878404957532814,
      "loss": 0.0903,
      "step": 455
    },
    {
      "epoch": 0.7845161290322581,
      "grad_norm": 0.678703177111698,
      "learning_rate": 0.00019877536650803501,
      "loss": 0.0969,
      "step": 456
    },
    {
      "epoch": 0.786236559139785,
      "grad_norm": 0.7597695620090639,
      "learning_rate": 0.00019876665273917476,
      "loss": 0.0872,
      "step": 457
    },
    {
      "epoch": 0.7879569892473118,
      "grad_norm": 0.720102944783097,
      "learning_rate": 0.0001987579082714559,
      "loss": 0.0498,
      "step": 458
    },
    {
      "epoch": 0.7896774193548387,
      "grad_norm": 0.6440371663592607,
      "learning_rate": 0.0001987491331075964,
      "loss": 0.0409,
      "step": 459
    },
    {
      "epoch": 0.7913978494623656,
      "grad_norm": 1.1925575721747494,
      "learning_rate": 0.00019874032725032375,
      "loss": 0.0528,
      "step": 460
    },
    {
      "epoch": 0.7931182795698924,
      "grad_norm": 0.2861400604382319,
      "learning_rate": 0.000198731490702375,
      "loss": 0.019,
      "step": 461
    },
    {
      "epoch": 0.7948387096774193,
      "grad_norm": 0.8459136446557914,
      "learning_rate": 0.00019872262346649677,
      "loss": 0.0826,
      "step": 462
    },
    {
      "epoch": 0.7965591397849462,
      "grad_norm": 0.9884393343495435,
      "learning_rate": 0.0001987137255454452,
      "loss": 0.0567,
      "step": 463
    },
    {
      "epoch": 0.7982795698924732,
      "grad_norm": 1.268585515151434,
      "learning_rate": 0.00019870479694198591,
      "loss": 0.0483,
      "step": 464
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.055770867561436,
      "learning_rate": 0.00019869583765889413,
      "loss": 0.0529,
      "step": 465
    },
    {
      "epoch": 0.8017204301075269,
      "grad_norm": 0.863855903612896,
      "learning_rate": 0.00019868684769895465,
      "loss": 0.0833,
      "step": 466
    },
    {
      "epoch": 0.8034408602150538,
      "grad_norm": 0.8825708451294668,
      "learning_rate": 0.00019867782706496173,
      "loss": 0.0783,
      "step": 467
    },
    {
      "epoch": 0.8051612903225807,
      "grad_norm": 2.0223207424221843,
      "learning_rate": 0.00019866877575971912,
      "loss": 0.0756,
      "step": 468
    },
    {
      "epoch": 0.8068817204301075,
      "grad_norm": 0.8124518246976075,
      "learning_rate": 0.0001986596937860402,
      "loss": 0.0548,
      "step": 469
    },
    {
      "epoch": 0.8086021505376344,
      "grad_norm": 0.9619604594774791,
      "learning_rate": 0.0001986505811467479,
      "loss": 0.1102,
      "step": 470
    },
    {
      "epoch": 0.8103225806451613,
      "grad_norm": 0.9936899404938914,
      "learning_rate": 0.00019864143784467455,
      "loss": 0.093,
      "step": 471
    },
    {
      "epoch": 0.8120430107526881,
      "grad_norm": 1.1566431394218788,
      "learning_rate": 0.00019863226388266213,
      "loss": 0.0996,
      "step": 472
    },
    {
      "epoch": 0.813763440860215,
      "grad_norm": 1.0541022666737403,
      "learning_rate": 0.00019862305926356211,
      "loss": 0.099,
      "step": 473
    },
    {
      "epoch": 0.8154838709677419,
      "grad_norm": 1.3819942894877206,
      "learning_rate": 0.0001986138239902355,
      "loss": 0.1012,
      "step": 474
    },
    {
      "epoch": 0.8172043010752689,
      "grad_norm": 0.6443356350914754,
      "learning_rate": 0.0001986045580655528,
      "loss": 0.0412,
      "step": 475
    },
    {
      "epoch": 0.8189247311827957,
      "grad_norm": 0.5243197915288043,
      "learning_rate": 0.0001985952614923941,
      "loss": 0.0395,
      "step": 476
    },
    {
      "epoch": 0.8206451612903226,
      "grad_norm": 0.7951595319639378,
      "learning_rate": 0.00019858593427364896,
      "loss": 0.04,
      "step": 477
    },
    {
      "epoch": 0.8223655913978495,
      "grad_norm": 0.9643551680692324,
      "learning_rate": 0.00019857657641221646,
      "loss": 0.0858,
      "step": 478
    },
    {
      "epoch": 0.8240860215053764,
      "grad_norm": 0.6848273537829241,
      "learning_rate": 0.00019856718791100525,
      "loss": 0.0758,
      "step": 479
    },
    {
      "epoch": 0.8258064516129032,
      "grad_norm": 0.8859124952062202,
      "learning_rate": 0.0001985577687729335,
      "loss": 0.0853,
      "step": 480
    },
    {
      "epoch": 0.8275268817204301,
      "grad_norm": 0.5902305700715721,
      "learning_rate": 0.00019854831900092886,
      "loss": 0.0537,
      "step": 481
    },
    {
      "epoch": 0.829247311827957,
      "grad_norm": 0.5461434303752687,
      "learning_rate": 0.00019853883859792857,
      "loss": 0.0484,
      "step": 482
    },
    {
      "epoch": 0.8309677419354838,
      "grad_norm": 1.0901502026506036,
      "learning_rate": 0.0001985293275668793,
      "loss": 0.0596,
      "step": 483
    },
    {
      "epoch": 0.8326881720430107,
      "grad_norm": 1.3850558769123318,
      "learning_rate": 0.00019851978591073731,
      "loss": 0.125,
      "step": 484
    },
    {
      "epoch": 0.8344086021505376,
      "grad_norm": 0.5733189814761516,
      "learning_rate": 0.00019851021363246835,
      "loss": 0.0332,
      "step": 485
    },
    {
      "epoch": 0.8361290322580646,
      "grad_norm": 1.2767493766740332,
      "learning_rate": 0.00019850061073504774,
      "loss": 0.0939,
      "step": 486
    },
    {
      "epoch": 0.8378494623655914,
      "grad_norm": 1.1326154166123672,
      "learning_rate": 0.00019849097722146022,
      "loss": 0.0684,
      "step": 487
    },
    {
      "epoch": 0.8395698924731183,
      "grad_norm": 0.7545862546554042,
      "learning_rate": 0.0001984813130947001,
      "loss": 0.0565,
      "step": 488
    },
    {
      "epoch": 0.8412903225806452,
      "grad_norm": 1.1308109555876005,
      "learning_rate": 0.0001984716183577712,
      "loss": 0.107,
      "step": 489
    },
    {
      "epoch": 0.843010752688172,
      "grad_norm": 1.181933390001188,
      "learning_rate": 0.0001984618930136869,
      "loss": 0.0428,
      "step": 490
    },
    {
      "epoch": 0.8447311827956989,
      "grad_norm": 0.7082651883599499,
      "learning_rate": 0.00019845213706547003,
      "loss": 0.0303,
      "step": 491
    },
    {
      "epoch": 0.8464516129032258,
      "grad_norm": 0.9972972443930034,
      "learning_rate": 0.00019844235051615298,
      "loss": 0.0816,
      "step": 492
    },
    {
      "epoch": 0.8481720430107527,
      "grad_norm": 1.1636607972815496,
      "learning_rate": 0.00019843253336877754,
      "loss": 0.0908,
      "step": 493
    },
    {
      "epoch": 0.8498924731182795,
      "grad_norm": 0.7968252475915217,
      "learning_rate": 0.0001984226856263952,
      "loss": 0.0758,
      "step": 494
    },
    {
      "epoch": 0.8516129032258064,
      "grad_norm": 1.0303603887519461,
      "learning_rate": 0.0001984128072920668,
      "loss": 0.0419,
      "step": 495
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.66908282075004,
      "learning_rate": 0.00019840289836886276,
      "loss": 0.0502,
      "step": 496
    },
    {
      "epoch": 0.8550537634408603,
      "grad_norm": 1.513042624563522,
      "learning_rate": 0.00019839295885986296,
      "loss": 0.1194,
      "step": 497
    },
    {
      "epoch": 0.8567741935483871,
      "grad_norm": 0.9037258780722089,
      "learning_rate": 0.00019838298876815688,
      "loss": 0.0538,
      "step": 498
    },
    {
      "epoch": 0.858494623655914,
      "grad_norm": 1.2894918283396757,
      "learning_rate": 0.0001983729880968434,
      "loss": 0.1003,
      "step": 499
    },
    {
      "epoch": 0.8602150537634409,
      "grad_norm": 0.7557753078842219,
      "learning_rate": 0.00019836295684903097,
      "loss": 0.0675,
      "step": 500
    },
    {
      "epoch": 0.8619354838709677,
      "grad_norm": 1.1298008681017375,
      "learning_rate": 0.00019835289502783752,
      "loss": 0.0849,
      "step": 501
    },
    {
      "epoch": 0.8636559139784946,
      "grad_norm": 1.7346031993070252,
      "learning_rate": 0.00019834280263639046,
      "loss": 0.1285,
      "step": 502
    },
    {
      "epoch": 0.8653763440860215,
      "grad_norm": 0.7267974914204707,
      "learning_rate": 0.00019833267967782678,
      "loss": 0.085,
      "step": 503
    },
    {
      "epoch": 0.8670967741935484,
      "grad_norm": 0.7474682763505824,
      "learning_rate": 0.00019832252615529288,
      "loss": 0.0966,
      "step": 504
    },
    {
      "epoch": 0.8688172043010752,
      "grad_norm": 0.7812233110122099,
      "learning_rate": 0.00019831234207194468,
      "loss": 0.061,
      "step": 505
    },
    {
      "epoch": 0.8705376344086021,
      "grad_norm": 1.062206352078586,
      "learning_rate": 0.00019830212743094768,
      "loss": 0.0655,
      "step": 506
    },
    {
      "epoch": 0.8722580645161291,
      "grad_norm": 0.7902319044228996,
      "learning_rate": 0.00019829188223547677,
      "loss": 0.0667,
      "step": 507
    },
    {
      "epoch": 0.873978494623656,
      "grad_norm": 0.660278921712064,
      "learning_rate": 0.0001982816064887164,
      "loss": 0.066,
      "step": 508
    },
    {
      "epoch": 0.8756989247311828,
      "grad_norm": 0.8211725692801014,
      "learning_rate": 0.0001982713001938605,
      "loss": 0.0942,
      "step": 509
    },
    {
      "epoch": 0.8774193548387097,
      "grad_norm": 0.5901539295156875,
      "learning_rate": 0.00019826096335411248,
      "loss": 0.0425,
      "step": 510
    },
    {
      "epoch": 0.8791397849462366,
      "grad_norm": 0.704178443908551,
      "learning_rate": 0.00019825059597268526,
      "loss": 0.045,
      "step": 511
    },
    {
      "epoch": 0.8808602150537634,
      "grad_norm": 0.7590099201229119,
      "learning_rate": 0.0001982401980528013,
      "loss": 0.079,
      "step": 512
    },
    {
      "epoch": 0.8825806451612903,
      "grad_norm": 0.6594487733436663,
      "learning_rate": 0.00019822976959769242,
      "loss": 0.0626,
      "step": 513
    },
    {
      "epoch": 0.8843010752688172,
      "grad_norm": 1.426010742264256,
      "learning_rate": 0.00019821931061060006,
      "loss": 0.1098,
      "step": 514
    },
    {
      "epoch": 0.886021505376344,
      "grad_norm": 0.9147811396371919,
      "learning_rate": 0.00019820882109477514,
      "loss": 0.084,
      "step": 515
    },
    {
      "epoch": 0.8877419354838709,
      "grad_norm": 1.0690994013951576,
      "learning_rate": 0.00019819830105347795,
      "loss": 0.0706,
      "step": 516
    },
    {
      "epoch": 0.8894623655913978,
      "grad_norm": 0.9465735339532005,
      "learning_rate": 0.0001981877504899784,
      "loss": 0.0979,
      "step": 517
    },
    {
      "epoch": 0.8911827956989248,
      "grad_norm": 1.1245779977484365,
      "learning_rate": 0.00019817716940755586,
      "loss": 0.0981,
      "step": 518
    },
    {
      "epoch": 0.8929032258064517,
      "grad_norm": 0.7512521207279118,
      "learning_rate": 0.00019816655780949917,
      "loss": 0.0769,
      "step": 519
    },
    {
      "epoch": 0.8946236559139785,
      "grad_norm": 0.6904781368460836,
      "learning_rate": 0.00019815591569910654,
      "loss": 0.051,
      "step": 520
    },
    {
      "epoch": 0.8963440860215054,
      "grad_norm": 1.1310113097987873,
      "learning_rate": 0.0001981452430796859,
      "loss": 0.084,
      "step": 521
    },
    {
      "epoch": 0.8980645161290323,
      "grad_norm": 0.7449716897991203,
      "learning_rate": 0.00019813453995455447,
      "loss": 0.0645,
      "step": 522
    },
    {
      "epoch": 0.8997849462365591,
      "grad_norm": 1.174149996157258,
      "learning_rate": 0.00019812380632703905,
      "loss": 0.0859,
      "step": 523
    },
    {
      "epoch": 0.901505376344086,
      "grad_norm": 0.6977007850366621,
      "learning_rate": 0.00019811304220047587,
      "loss": 0.0565,
      "step": 524
    },
    {
      "epoch": 0.9032258064516129,
      "grad_norm": 0.7620312263922757,
      "learning_rate": 0.00019810224757821064,
      "loss": 0.0884,
      "step": 525
    },
    {
      "epoch": 0.9049462365591397,
      "grad_norm": 1.144413782373763,
      "learning_rate": 0.0001980914224635986,
      "loss": 0.1166,
      "step": 526
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.8326252914145714,
      "learning_rate": 0.0001980805668600044,
      "loss": 0.0863,
      "step": 527
    },
    {
      "epoch": 0.9083870967741936,
      "grad_norm": 0.7688479117280752,
      "learning_rate": 0.00019806968077080227,
      "loss": 0.0674,
      "step": 528
    },
    {
      "epoch": 0.9101075268817205,
      "grad_norm": 0.4862497872067838,
      "learning_rate": 0.00019805876419937582,
      "loss": 0.0302,
      "step": 529
    },
    {
      "epoch": 0.9118279569892473,
      "grad_norm": 0.8686968930083552,
      "learning_rate": 0.00019804781714911812,
      "loss": 0.0401,
      "step": 530
    },
    {
      "epoch": 0.9135483870967742,
      "grad_norm": 0.8661225975251265,
      "learning_rate": 0.00019803683962343175,
      "loss": 0.0688,
      "step": 531
    },
    {
      "epoch": 0.9152688172043011,
      "grad_norm": 0.9746041411077405,
      "learning_rate": 0.00019802583162572881,
      "loss": 0.0923,
      "step": 532
    },
    {
      "epoch": 0.916989247311828,
      "grad_norm": 0.5425693132434127,
      "learning_rate": 0.0001980147931594308,
      "loss": 0.0322,
      "step": 533
    },
    {
      "epoch": 0.9187096774193548,
      "grad_norm": 0.711945740679935,
      "learning_rate": 0.00019800372422796878,
      "loss": 0.0607,
      "step": 534
    },
    {
      "epoch": 0.9204301075268817,
      "grad_norm": 0.495865596962372,
      "learning_rate": 0.00019799262483478317,
      "loss": 0.0366,
      "step": 535
    },
    {
      "epoch": 0.9221505376344086,
      "grad_norm": 0.6198960027139324,
      "learning_rate": 0.0001979814949833239,
      "loss": 0.0636,
      "step": 536
    },
    {
      "epoch": 0.9238709677419354,
      "grad_norm": 1.383709132240055,
      "learning_rate": 0.00019797033467705037,
      "loss": 0.1012,
      "step": 537
    },
    {
      "epoch": 0.9255913978494623,
      "grad_norm": 0.9928909636651605,
      "learning_rate": 0.0001979591439194315,
      "loss": 0.0638,
      "step": 538
    },
    {
      "epoch": 0.9273118279569893,
      "grad_norm": 0.98834347564179,
      "learning_rate": 0.00019794792271394553,
      "loss": 0.0421,
      "step": 539
    },
    {
      "epoch": 0.9290322580645162,
      "grad_norm": 1.0010415556871086,
      "learning_rate": 0.00019793667106408037,
      "loss": 0.055,
      "step": 540
    },
    {
      "epoch": 0.930752688172043,
      "grad_norm": 1.2655297720665648,
      "learning_rate": 0.0001979253889733332,
      "loss": 0.1149,
      "step": 541
    },
    {
      "epoch": 0.9324731182795699,
      "grad_norm": 1.3617738616667907,
      "learning_rate": 0.00019791407644521077,
      "loss": 0.0574,
      "step": 542
    },
    {
      "epoch": 0.9341935483870968,
      "grad_norm": 1.4826657342357843,
      "learning_rate": 0.0001979027334832293,
      "loss": 0.17,
      "step": 543
    },
    {
      "epoch": 0.9359139784946237,
      "grad_norm": 0.9516657808150005,
      "learning_rate": 0.00019789136009091437,
      "loss": 0.0846,
      "step": 544
    },
    {
      "epoch": 0.9376344086021505,
      "grad_norm": 0.9121233748784756,
      "learning_rate": 0.00019787995627180115,
      "loss": 0.0626,
      "step": 545
    },
    {
      "epoch": 0.9393548387096774,
      "grad_norm": 0.7070376070684072,
      "learning_rate": 0.0001978685220294341,
      "loss": 0.0503,
      "step": 546
    },
    {
      "epoch": 0.9410752688172043,
      "grad_norm": 0.6466240366334463,
      "learning_rate": 0.00019785705736736735,
      "loss": 0.0396,
      "step": 547
    },
    {
      "epoch": 0.9427956989247311,
      "grad_norm": 0.9782039750958375,
      "learning_rate": 0.0001978455622891643,
      "loss": 0.0727,
      "step": 548
    },
    {
      "epoch": 0.944516129032258,
      "grad_norm": 1.0652156129670878,
      "learning_rate": 0.00019783403679839788,
      "loss": 0.0741,
      "step": 549
    },
    {
      "epoch": 0.946236559139785,
      "grad_norm": 0.7919184853203176,
      "learning_rate": 0.00019782248089865047,
      "loss": 0.0877,
      "step": 550
    },
    {
      "epoch": 0.9479569892473119,
      "grad_norm": 0.6272295148926216,
      "learning_rate": 0.00019781089459351394,
      "loss": 0.0566,
      "step": 551
    },
    {
      "epoch": 0.9496774193548387,
      "grad_norm": 0.5937934741564056,
      "learning_rate": 0.0001977992778865895,
      "loss": 0.0626,
      "step": 552
    },
    {
      "epoch": 0.9513978494623656,
      "grad_norm": 0.8494287314440524,
      "learning_rate": 0.0001977876307814879,
      "loss": 0.0675,
      "step": 553
    },
    {
      "epoch": 0.9531182795698925,
      "grad_norm": 0.9538700509256823,
      "learning_rate": 0.0001977759532818294,
      "loss": 0.0737,
      "step": 554
    },
    {
      "epoch": 0.9548387096774194,
      "grad_norm": 1.036125602497031,
      "learning_rate": 0.00019776424539124352,
      "loss": 0.0801,
      "step": 555
    },
    {
      "epoch": 0.9565591397849462,
      "grad_norm": 0.36711491396209467,
      "learning_rate": 0.00019775250711336938,
      "loss": 0.0259,
      "step": 556
    },
    {
      "epoch": 0.9582795698924731,
      "grad_norm": 1.2692200946541754,
      "learning_rate": 0.00019774073845185548,
      "loss": 0.1096,
      "step": 557
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5729919159015241,
      "learning_rate": 0.00019772893941035977,
      "loss": 0.0431,
      "step": 558
    },
    {
      "epoch": 0.9617204301075268,
      "grad_norm": 1.2992541177204264,
      "learning_rate": 0.0001977171099925497,
      "loss": 0.084,
      "step": 559
    },
    {
      "epoch": 0.9634408602150538,
      "grad_norm": 0.623422013742347,
      "learning_rate": 0.00019770525020210204,
      "loss": 0.0292,
      "step": 560
    },
    {
      "epoch": 0.9651612903225807,
      "grad_norm": 1.2975714087932877,
      "learning_rate": 0.00019769336004270315,
      "loss": 0.0597,
      "step": 561
    },
    {
      "epoch": 0.9668817204301076,
      "grad_norm": 0.8168469375703694,
      "learning_rate": 0.00019768143951804873,
      "loss": 0.0831,
      "step": 562
    },
    {
      "epoch": 0.9686021505376344,
      "grad_norm": 1.7571880911900486,
      "learning_rate": 0.00019766948863184392,
      "loss": 0.0802,
      "step": 563
    },
    {
      "epoch": 0.9703225806451613,
      "grad_norm": 1.4326592474750617,
      "learning_rate": 0.00019765750738780336,
      "loss": 0.1217,
      "step": 564
    },
    {
      "epoch": 0.9720430107526882,
      "grad_norm": 0.7876243899597921,
      "learning_rate": 0.00019764549578965102,
      "loss": 0.0714,
      "step": 565
    },
    {
      "epoch": 0.973763440860215,
      "grad_norm": 0.6369825855530581,
      "learning_rate": 0.00019763345384112043,
      "loss": 0.034,
      "step": 566
    },
    {
      "epoch": 0.9754838709677419,
      "grad_norm": 0.9624940639315619,
      "learning_rate": 0.00019762138154595446,
      "loss": 0.0718,
      "step": 567
    },
    {
      "epoch": 0.9772043010752688,
      "grad_norm": 0.9060287045721599,
      "learning_rate": 0.0001976092789079055,
      "loss": 0.0817,
      "step": 568
    },
    {
      "epoch": 0.9789247311827957,
      "grad_norm": 0.8711750090243939,
      "learning_rate": 0.00019759714593073523,
      "loss": 0.1066,
      "step": 569
    },
    {
      "epoch": 0.9806451612903225,
      "grad_norm": 1.0520596254048662,
      "learning_rate": 0.00019758498261821493,
      "loss": 0.0542,
      "step": 570
    },
    {
      "epoch": 0.9823655913978495,
      "grad_norm": 0.3819159414570884,
      "learning_rate": 0.00019757278897412518,
      "loss": 0.0222,
      "step": 571
    },
    {
      "epoch": 0.9840860215053764,
      "grad_norm": 0.9929477074827199,
      "learning_rate": 0.00019756056500225603,
      "loss": 0.0785,
      "step": 572
    },
    {
      "epoch": 0.9858064516129033,
      "grad_norm": 0.9090649126264353,
      "learning_rate": 0.00019754831070640697,
      "loss": 0.0753,
      "step": 573
    },
    {
      "epoch": 0.9875268817204301,
      "grad_norm": 0.5793659153193724,
      "learning_rate": 0.00019753602609038696,
      "loss": 0.036,
      "step": 574
    },
    {
      "epoch": 0.989247311827957,
      "grad_norm": 0.5313860074011703,
      "learning_rate": 0.00019752371115801424,
      "loss": 0.0499,
      "step": 575
    },
    {
      "epoch": 0.9909677419354839,
      "grad_norm": 1.4056825092971976,
      "learning_rate": 0.0001975113659131166,
      "loss": 0.0988,
      "step": 576
    },
    {
      "epoch": 0.9926881720430107,
      "grad_norm": 1.4403711748306531,
      "learning_rate": 0.00019749899035953125,
      "loss": 0.1262,
      "step": 577
    },
    {
      "epoch": 0.9944086021505376,
      "grad_norm": 0.9449323658239552,
      "learning_rate": 0.00019748658450110474,
      "loss": 0.0815,
      "step": 578
    },
    {
      "epoch": 0.9961290322580645,
      "grad_norm": 1.1496424365206765,
      "learning_rate": 0.00019747414834169312,
      "loss": 0.098,
      "step": 579
    },
    {
      "epoch": 0.9978494623655914,
      "grad_norm": 0.8823093211209071,
      "learning_rate": 0.0001974616818851618,
      "loss": 0.0747,
      "step": 580
    },
    {
      "epoch": 0.9995698924731182,
      "grad_norm": 1.2626368189338784,
      "learning_rate": 0.0001974491851353856,
      "loss": 0.098,
      "step": 581
    },
    {
      "epoch": 1.001290322580645,
      "grad_norm": 0.951747707677421,
      "learning_rate": 0.00019743665809624888,
      "loss": 0.0721,
      "step": 582
    },
    {
      "epoch": 1.003010752688172,
      "grad_norm": 0.5893439552676706,
      "learning_rate": 0.0001974241007716452,
      "loss": 0.0403,
      "step": 583
    },
    {
      "epoch": 1.0047311827956988,
      "grad_norm": 0.6819482198179777,
      "learning_rate": 0.00019741151316547776,
      "loss": 0.0527,
      "step": 584
    },
    {
      "epoch": 1.0064516129032257,
      "grad_norm": 0.7903587910594339,
      "learning_rate": 0.000197398895281659,
      "loss": 0.0525,
      "step": 585
    },
    {
      "epoch": 1.0081720430107526,
      "grad_norm": 0.7972928582533696,
      "learning_rate": 0.00019738624712411086,
      "loss": 0.0755,
      "step": 586
    },
    {
      "epoch": 1.0098924731182797,
      "grad_norm": 0.6582418598903791,
      "learning_rate": 0.00019737356869676468,
      "loss": 0.0441,
      "step": 587
    },
    {
      "epoch": 1.0116129032258065,
      "grad_norm": 0.4828943409430865,
      "learning_rate": 0.00019736086000356114,
      "loss": 0.0242,
      "step": 588
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 1.1270039561264176,
      "learning_rate": 0.00019734812104845047,
      "loss": 0.0643,
      "step": 589
    },
    {
      "epoch": 1.0150537634408603,
      "grad_norm": 0.5078085605730523,
      "learning_rate": 0.00019733535183539215,
      "loss": 0.0317,
      "step": 590
    },
    {
      "epoch": 1.0167741935483872,
      "grad_norm": 0.892825257181879,
      "learning_rate": 0.0001973225523683552,
      "loss": 0.0671,
      "step": 591
    },
    {
      "epoch": 1.018494623655914,
      "grad_norm": 0.694838576530966,
      "learning_rate": 0.00019730972265131786,
      "loss": 0.0505,
      "step": 592
    },
    {
      "epoch": 1.020215053763441,
      "grad_norm": 0.5500733851678155,
      "learning_rate": 0.000197296862688268,
      "loss": 0.0354,
      "step": 593
    },
    {
      "epoch": 1.0219354838709678,
      "grad_norm": 0.5887785780808693,
      "learning_rate": 0.00019728397248320277,
      "loss": 0.0365,
      "step": 594
    },
    {
      "epoch": 1.0236559139784946,
      "grad_norm": 0.61493633619254,
      "learning_rate": 0.0001972710520401287,
      "loss": 0.0423,
      "step": 595
    },
    {
      "epoch": 1.0253763440860215,
      "grad_norm": 0.5871867725537042,
      "learning_rate": 0.0001972581013630617,
      "loss": 0.0332,
      "step": 596
    },
    {
      "epoch": 1.0270967741935484,
      "grad_norm": 0.7449297210218749,
      "learning_rate": 0.0001972451204560272,
      "loss": 0.0567,
      "step": 597
    },
    {
      "epoch": 1.0288172043010753,
      "grad_norm": 0.707812918123136,
      "learning_rate": 0.00019723210932305995,
      "loss": 0.0335,
      "step": 598
    },
    {
      "epoch": 1.0305376344086021,
      "grad_norm": 0.6620018078937144,
      "learning_rate": 0.0001972190679682041,
      "loss": 0.0259,
      "step": 599
    },
    {
      "epoch": 1.032258064516129,
      "grad_norm": 0.7789778563433706,
      "learning_rate": 0.00019720599639551313,
      "loss": 0.0357,
      "step": 600
    },
    {
      "epoch": 1.0339784946236559,
      "grad_norm": 1.0919382029670173,
      "learning_rate": 0.00019719289460905004,
      "loss": 0.0802,
      "step": 601
    },
    {
      "epoch": 1.0356989247311827,
      "grad_norm": 1.4922442014057735,
      "learning_rate": 0.0001971797626128871,
      "loss": 0.0696,
      "step": 602
    },
    {
      "epoch": 1.0374193548387096,
      "grad_norm": 1.5506042615996036,
      "learning_rate": 0.00019716660041110612,
      "loss": 0.0768,
      "step": 603
    },
    {
      "epoch": 1.0391397849462365,
      "grad_norm": 1.2353986030369954,
      "learning_rate": 0.00019715340800779808,
      "loss": 0.0688,
      "step": 604
    },
    {
      "epoch": 1.0408602150537634,
      "grad_norm": 0.6961910586371809,
      "learning_rate": 0.00019714018540706354,
      "loss": 0.0421,
      "step": 605
    },
    {
      "epoch": 1.0425806451612902,
      "grad_norm": 1.321416050594357,
      "learning_rate": 0.0001971269326130124,
      "loss": 0.0918,
      "step": 606
    },
    {
      "epoch": 1.044301075268817,
      "grad_norm": 1.0063874761877527,
      "learning_rate": 0.00019711364962976384,
      "loss": 0.0572,
      "step": 607
    },
    {
      "epoch": 1.046021505376344,
      "grad_norm": 0.6800669925874616,
      "learning_rate": 0.0001971003364614466,
      "loss": 0.0258,
      "step": 608
    },
    {
      "epoch": 1.047741935483871,
      "grad_norm": 0.5924070093422918,
      "learning_rate": 0.00019708699311219861,
      "loss": 0.0253,
      "step": 609
    },
    {
      "epoch": 1.049462365591398,
      "grad_norm": 0.6009458274453373,
      "learning_rate": 0.00019707361958616734,
      "loss": 0.0314,
      "step": 610
    },
    {
      "epoch": 1.0511827956989248,
      "grad_norm": 0.8777375484710908,
      "learning_rate": 0.00019706021588750957,
      "loss": 0.0459,
      "step": 611
    },
    {
      "epoch": 1.0529032258064517,
      "grad_norm": 0.7561141972471048,
      "learning_rate": 0.0001970467820203915,
      "loss": 0.0553,
      "step": 612
    },
    {
      "epoch": 1.0546236559139786,
      "grad_norm": 0.6878299959549854,
      "learning_rate": 0.0001970333179889886,
      "loss": 0.0409,
      "step": 613
    },
    {
      "epoch": 1.0563440860215054,
      "grad_norm": 0.9975306694210434,
      "learning_rate": 0.0001970198237974858,
      "loss": 0.0592,
      "step": 614
    },
    {
      "epoch": 1.0580645161290323,
      "grad_norm": 0.9664300053640462,
      "learning_rate": 0.00019700629945007742,
      "loss": 0.0523,
      "step": 615
    },
    {
      "epoch": 1.0597849462365592,
      "grad_norm": 2.877847661531081,
      "learning_rate": 0.00019699274495096712,
      "loss": 0.0393,
      "step": 616
    },
    {
      "epoch": 1.061505376344086,
      "grad_norm": 1.0508994850584505,
      "learning_rate": 0.00019697916030436796,
      "loss": 0.066,
      "step": 617
    },
    {
      "epoch": 1.063225806451613,
      "grad_norm": 0.6133026000931305,
      "learning_rate": 0.0001969655455145023,
      "loss": 0.0251,
      "step": 618
    },
    {
      "epoch": 1.0649462365591398,
      "grad_norm": 0.9877525549315996,
      "learning_rate": 0.00019695190058560197,
      "loss": 0.0459,
      "step": 619
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 1.0736043178672048,
      "learning_rate": 0.0001969382255219081,
      "loss": 0.0442,
      "step": 620
    },
    {
      "epoch": 1.0683870967741935,
      "grad_norm": 0.8658594759821924,
      "learning_rate": 0.00019692452032767115,
      "loss": 0.0469,
      "step": 621
    },
    {
      "epoch": 1.0701075268817204,
      "grad_norm": 1.5363912625550107,
      "learning_rate": 0.0001969107850071511,
      "loss": 0.1066,
      "step": 622
    },
    {
      "epoch": 1.0718279569892473,
      "grad_norm": 0.5233666583799976,
      "learning_rate": 0.00019689701956461707,
      "loss": 0.0189,
      "step": 623
    },
    {
      "epoch": 1.0735483870967741,
      "grad_norm": 1.0260415914807532,
      "learning_rate": 0.00019688322400434775,
      "loss": 0.0505,
      "step": 624
    },
    {
      "epoch": 1.075268817204301,
      "grad_norm": 0.5308424063679549,
      "learning_rate": 0.00019686939833063108,
      "loss": 0.019,
      "step": 625
    },
    {
      "epoch": 1.0769892473118279,
      "grad_norm": 0.42892845619869163,
      "learning_rate": 0.00019685554254776438,
      "loss": 0.0073,
      "step": 626
    },
    {
      "epoch": 1.0787096774193548,
      "grad_norm": 1.2435899103810775,
      "learning_rate": 0.00019684165666005433,
      "loss": 0.1106,
      "step": 627
    },
    {
      "epoch": 1.0804301075268816,
      "grad_norm": 1.3420371598478993,
      "learning_rate": 0.00019682774067181696,
      "loss": 0.0343,
      "step": 628
    },
    {
      "epoch": 1.0821505376344085,
      "grad_norm": 0.7585922897019299,
      "learning_rate": 0.00019681379458737772,
      "loss": 0.0374,
      "step": 629
    },
    {
      "epoch": 1.0838709677419356,
      "grad_norm": 1.284627703244203,
      "learning_rate": 0.0001967998184110713,
      "loss": 0.0624,
      "step": 630
    },
    {
      "epoch": 1.0855913978494625,
      "grad_norm": 1.3130069399761368,
      "learning_rate": 0.00019678581214724187,
      "loss": 0.0505,
      "step": 631
    },
    {
      "epoch": 1.0873118279569893,
      "grad_norm": 0.8690804262667176,
      "learning_rate": 0.00019677177580024283,
      "loss": 0.044,
      "step": 632
    },
    {
      "epoch": 1.0890322580645162,
      "grad_norm": 1.400400413763226,
      "learning_rate": 0.000196757709374437,
      "loss": 0.0567,
      "step": 633
    },
    {
      "epoch": 1.090752688172043,
      "grad_norm": 0.8877838958159684,
      "learning_rate": 0.00019674361287419653,
      "loss": 0.0313,
      "step": 634
    },
    {
      "epoch": 1.09247311827957,
      "grad_norm": 1.2284191655388073,
      "learning_rate": 0.00019672948630390294,
      "loss": 0.0579,
      "step": 635
    },
    {
      "epoch": 1.0941935483870968,
      "grad_norm": 0.9171323985535921,
      "learning_rate": 0.0001967153296679471,
      "loss": 0.0552,
      "step": 636
    },
    {
      "epoch": 1.0959139784946237,
      "grad_norm": 1.2092608447353592,
      "learning_rate": 0.00019670114297072914,
      "loss": 0.0481,
      "step": 637
    },
    {
      "epoch": 1.0976344086021506,
      "grad_norm": 1.069425239032517,
      "learning_rate": 0.00019668692621665866,
      "loss": 0.0687,
      "step": 638
    },
    {
      "epoch": 1.0993548387096774,
      "grad_norm": 1.1752069564693126,
      "learning_rate": 0.00019667267941015452,
      "loss": 0.0625,
      "step": 639
    },
    {
      "epoch": 1.1010752688172043,
      "grad_norm": 0.4925637652171197,
      "learning_rate": 0.00019665840255564493,
      "loss": 0.0184,
      "step": 640
    },
    {
      "epoch": 1.1027956989247312,
      "grad_norm": 1.4449902383611122,
      "learning_rate": 0.00019664409565756748,
      "loss": 0.0707,
      "step": 641
    },
    {
      "epoch": 1.104516129032258,
      "grad_norm": 1.0615197710383921,
      "learning_rate": 0.00019662975872036906,
      "loss": 0.0367,
      "step": 642
    },
    {
      "epoch": 1.106236559139785,
      "grad_norm": 1.2109672919429886,
      "learning_rate": 0.0001966153917485059,
      "loss": 0.0716,
      "step": 643
    },
    {
      "epoch": 1.1079569892473118,
      "grad_norm": 0.72889331211701,
      "learning_rate": 0.00019660099474644356,
      "loss": 0.0587,
      "step": 644
    },
    {
      "epoch": 1.1096774193548387,
      "grad_norm": 1.11489819437712,
      "learning_rate": 0.00019658656771865695,
      "loss": 0.0442,
      "step": 645
    },
    {
      "epoch": 1.1113978494623655,
      "grad_norm": 1.4546265754168748,
      "learning_rate": 0.00019657211066963033,
      "loss": 0.0537,
      "step": 646
    },
    {
      "epoch": 1.1131182795698924,
      "grad_norm": 1.4751707106843162,
      "learning_rate": 0.00019655762360385728,
      "loss": 0.0468,
      "step": 647
    },
    {
      "epoch": 1.1148387096774193,
      "grad_norm": 0.9884407005865838,
      "learning_rate": 0.00019654310652584064,
      "loss": 0.0617,
      "step": 648
    },
    {
      "epoch": 1.1165591397849461,
      "grad_norm": 1.636951670561553,
      "learning_rate": 0.0001965285594400927,
      "loss": 0.06,
      "step": 649
    },
    {
      "epoch": 1.118279569892473,
      "grad_norm": 1.1278304983357592,
      "learning_rate": 0.000196513982351135,
      "loss": 0.0447,
      "step": 650
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4512241281202705,
      "learning_rate": 0.0001964993752634984,
      "loss": 0.0622,
      "step": 651
    },
    {
      "epoch": 1.121720430107527,
      "grad_norm": 0.4190051429045835,
      "learning_rate": 0.00019648473818172316,
      "loss": 0.0149,
      "step": 652
    },
    {
      "epoch": 1.1234408602150538,
      "grad_norm": 1.1474926632107592,
      "learning_rate": 0.00019647007111035873,
      "loss": 0.0298,
      "step": 653
    },
    {
      "epoch": 1.1251612903225807,
      "grad_norm": 1.073525434803266,
      "learning_rate": 0.00019645537405396405,
      "loss": 0.0594,
      "step": 654
    },
    {
      "epoch": 1.1268817204301076,
      "grad_norm": 0.8936830015602922,
      "learning_rate": 0.0001964406470171072,
      "loss": 0.0312,
      "step": 655
    },
    {
      "epoch": 1.1286021505376345,
      "grad_norm": 1.1139057035980475,
      "learning_rate": 0.00019642589000436571,
      "loss": 0.0483,
      "step": 656
    },
    {
      "epoch": 1.1303225806451613,
      "grad_norm": 0.7928690089567072,
      "learning_rate": 0.00019641110302032636,
      "loss": 0.0426,
      "step": 657
    },
    {
      "epoch": 1.1320430107526882,
      "grad_norm": 1.136874861074452,
      "learning_rate": 0.00019639628606958533,
      "loss": 0.0472,
      "step": 658
    },
    {
      "epoch": 1.133763440860215,
      "grad_norm": 1.4291624453923324,
      "learning_rate": 0.00019638143915674802,
      "loss": 0.0725,
      "step": 659
    },
    {
      "epoch": 1.135483870967742,
      "grad_norm": 0.7350867049395542,
      "learning_rate": 0.00019636656228642918,
      "loss": 0.0553,
      "step": 660
    },
    {
      "epoch": 1.1372043010752688,
      "grad_norm": 0.5956176604637772,
      "learning_rate": 0.00019635165546325287,
      "loss": 0.0181,
      "step": 661
    },
    {
      "epoch": 1.1389247311827957,
      "grad_norm": 1.3609710195111986,
      "learning_rate": 0.00019633671869185245,
      "loss": 0.0259,
      "step": 662
    },
    {
      "epoch": 1.1406451612903226,
      "grad_norm": 0.5428546931373965,
      "learning_rate": 0.00019632175197687062,
      "loss": 0.0296,
      "step": 663
    },
    {
      "epoch": 1.1423655913978494,
      "grad_norm": 1.2575639514815373,
      "learning_rate": 0.00019630675532295936,
      "loss": 0.069,
      "step": 664
    },
    {
      "epoch": 1.1440860215053763,
      "grad_norm": 0.4604632432120962,
      "learning_rate": 0.00019629172873477995,
      "loss": 0.0255,
      "step": 665
    },
    {
      "epoch": 1.1458064516129032,
      "grad_norm": 0.5626589490263512,
      "learning_rate": 0.00019627667221700298,
      "loss": 0.0204,
      "step": 666
    },
    {
      "epoch": 1.14752688172043,
      "grad_norm": 0.9737132973253283,
      "learning_rate": 0.00019626158577430838,
      "loss": 0.0544,
      "step": 667
    },
    {
      "epoch": 1.149247311827957,
      "grad_norm": 1.3414857231583506,
      "learning_rate": 0.00019624646941138532,
      "loss": 0.0336,
      "step": 668
    },
    {
      "epoch": 1.1509677419354838,
      "grad_norm": 1.0061281473138062,
      "learning_rate": 0.00019623132313293228,
      "loss": 0.037,
      "step": 669
    },
    {
      "epoch": 1.1526881720430107,
      "grad_norm": 0.929660604391077,
      "learning_rate": 0.00019621614694365715,
      "loss": 0.0393,
      "step": 670
    },
    {
      "epoch": 1.1544086021505375,
      "grad_norm": 1.3375788275540637,
      "learning_rate": 0.00019620094084827692,
      "loss": 0.0641,
      "step": 671
    },
    {
      "epoch": 1.1561290322580646,
      "grad_norm": 1.342899111289923,
      "learning_rate": 0.00019618570485151806,
      "loss": 0.096,
      "step": 672
    },
    {
      "epoch": 1.1578494623655913,
      "grad_norm": 1.2881445284382085,
      "learning_rate": 0.00019617043895811618,
      "loss": 0.0712,
      "step": 673
    },
    {
      "epoch": 1.1595698924731184,
      "grad_norm": 0.8437559847499273,
      "learning_rate": 0.00019615514317281632,
      "loss": 0.0512,
      "step": 674
    },
    {
      "epoch": 1.1612903225806452,
      "grad_norm": 0.6645809519899015,
      "learning_rate": 0.00019613981750037272,
      "loss": 0.0288,
      "step": 675
    },
    {
      "epoch": 1.1630107526881721,
      "grad_norm": 1.1933437640374522,
      "learning_rate": 0.00019612446194554892,
      "loss": 0.0593,
      "step": 676
    },
    {
      "epoch": 1.164731182795699,
      "grad_norm": 1.1984981497219365,
      "learning_rate": 0.0001961090765131178,
      "loss": 0.0439,
      "step": 677
    },
    {
      "epoch": 1.1664516129032259,
      "grad_norm": 1.3823263087051978,
      "learning_rate": 0.0001960936612078615,
      "loss": 0.0563,
      "step": 678
    },
    {
      "epoch": 1.1681720430107527,
      "grad_norm": 0.7391912772538883,
      "learning_rate": 0.0001960782160345714,
      "loss": 0.0267,
      "step": 679
    },
    {
      "epoch": 1.1698924731182796,
      "grad_norm": 1.5934230215159648,
      "learning_rate": 0.00019606274099804823,
      "loss": 0.0657,
      "step": 680
    },
    {
      "epoch": 1.1716129032258065,
      "grad_norm": 1.2702693928133202,
      "learning_rate": 0.00019604723610310194,
      "loss": 0.0374,
      "step": 681
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 1.0963654215160559,
      "learning_rate": 0.00019603170135455182,
      "loss": 0.0783,
      "step": 682
    },
    {
      "epoch": 1.1750537634408602,
      "grad_norm": 0.7656916608333072,
      "learning_rate": 0.00019601613675722642,
      "loss": 0.0289,
      "step": 683
    },
    {
      "epoch": 1.176774193548387,
      "grad_norm": 0.9409314669361462,
      "learning_rate": 0.00019600054231596353,
      "loss": 0.038,
      "step": 684
    },
    {
      "epoch": 1.178494623655914,
      "grad_norm": 0.7568226970972591,
      "learning_rate": 0.0001959849180356103,
      "loss": 0.0281,
      "step": 685
    },
    {
      "epoch": 1.1802150537634408,
      "grad_norm": 0.7492304378535024,
      "learning_rate": 0.00019596926392102305,
      "loss": 0.0251,
      "step": 686
    },
    {
      "epoch": 1.1819354838709677,
      "grad_norm": 1.7037668644870074,
      "learning_rate": 0.00019595357997706744,
      "loss": 0.0648,
      "step": 687
    },
    {
      "epoch": 1.1836559139784946,
      "grad_norm": 2.0410256198984995,
      "learning_rate": 0.0001959378662086184,
      "loss": 0.0874,
      "step": 688
    },
    {
      "epoch": 1.1853763440860214,
      "grad_norm": 0.79768727203324,
      "learning_rate": 0.00019592212262056012,
      "loss": 0.0512,
      "step": 689
    },
    {
      "epoch": 1.1870967741935483,
      "grad_norm": 1.4144134032786184,
      "learning_rate": 0.00019590634921778601,
      "loss": 0.0782,
      "step": 690
    },
    {
      "epoch": 1.1888172043010752,
      "grad_norm": 0.954679474941393,
      "learning_rate": 0.00019589054600519881,
      "loss": 0.0874,
      "step": 691
    },
    {
      "epoch": 1.190537634408602,
      "grad_norm": 1.209628330970649,
      "learning_rate": 0.00019587471298771058,
      "loss": 0.0765,
      "step": 692
    },
    {
      "epoch": 1.1922580645161291,
      "grad_norm": 0.6672054136063826,
      "learning_rate": 0.00019585885017024248,
      "loss": 0.0226,
      "step": 693
    },
    {
      "epoch": 1.1939784946236558,
      "grad_norm": 0.7172744627847603,
      "learning_rate": 0.00019584295755772506,
      "loss": 0.014,
      "step": 694
    },
    {
      "epoch": 1.1956989247311829,
      "grad_norm": 0.9036582375948021,
      "learning_rate": 0.0001958270351550981,
      "loss": 0.063,
      "step": 695
    },
    {
      "epoch": 1.1974193548387098,
      "grad_norm": 0.7770175901492334,
      "learning_rate": 0.00019581108296731062,
      "loss": 0.0349,
      "step": 696
    },
    {
      "epoch": 1.1991397849462366,
      "grad_norm": 0.9078256336663685,
      "learning_rate": 0.00019579510099932093,
      "loss": 0.067,
      "step": 697
    },
    {
      "epoch": 1.2008602150537635,
      "grad_norm": 0.717552375032144,
      "learning_rate": 0.00019577908925609653,
      "loss": 0.0608,
      "step": 698
    },
    {
      "epoch": 1.2025806451612904,
      "grad_norm": 1.3172538348209046,
      "learning_rate": 0.0001957630477426143,
      "loss": 0.0513,
      "step": 699
    },
    {
      "epoch": 1.2043010752688172,
      "grad_norm": 0.5045472860305228,
      "learning_rate": 0.00019574697646386027,
      "loss": 0.0217,
      "step": 700
    },
    {
      "epoch": 1.2060215053763441,
      "grad_norm": 1.2990282239529194,
      "learning_rate": 0.0001957308754248297,
      "loss": 0.0352,
      "step": 701
    },
    {
      "epoch": 1.207741935483871,
      "grad_norm": 0.6473291128619557,
      "learning_rate": 0.00019571474463052723,
      "loss": 0.0189,
      "step": 702
    },
    {
      "epoch": 1.2094623655913979,
      "grad_norm": 1.2289778928010016,
      "learning_rate": 0.0001956985840859666,
      "loss": 0.0508,
      "step": 703
    },
    {
      "epoch": 1.2111827956989247,
      "grad_norm": 1.3309178662558132,
      "learning_rate": 0.00019568239379617088,
      "loss": 0.0887,
      "step": 704
    },
    {
      "epoch": 1.2129032258064516,
      "grad_norm": 1.0936407540425463,
      "learning_rate": 0.0001956661737661724,
      "loss": 0.031,
      "step": 705
    },
    {
      "epoch": 1.2146236559139785,
      "grad_norm": 1.704427321618059,
      "learning_rate": 0.00019564992400101266,
      "loss": 0.0821,
      "step": 706
    },
    {
      "epoch": 1.2163440860215053,
      "grad_norm": 0.9919936341714137,
      "learning_rate": 0.00019563364450574252,
      "loss": 0.029,
      "step": 707
    },
    {
      "epoch": 1.2180645161290322,
      "grad_norm": 1.682750699990995,
      "learning_rate": 0.0001956173352854219,
      "loss": 0.0909,
      "step": 708
    },
    {
      "epoch": 1.219784946236559,
      "grad_norm": 1.2575634804424705,
      "learning_rate": 0.00019560099634512013,
      "loss": 0.0528,
      "step": 709
    },
    {
      "epoch": 1.221505376344086,
      "grad_norm": 1.157777783457832,
      "learning_rate": 0.00019558462768991573,
      "loss": 0.0399,
      "step": 710
    },
    {
      "epoch": 1.2232258064516128,
      "grad_norm": 1.2881319051636404,
      "learning_rate": 0.0001955682293248964,
      "loss": 0.042,
      "step": 711
    },
    {
      "epoch": 1.2249462365591397,
      "grad_norm": 0.9139244836286727,
      "learning_rate": 0.00019555180125515912,
      "loss": 0.0334,
      "step": 712
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.7571159758092443,
      "learning_rate": 0.00019553534348581012,
      "loss": 0.0318,
      "step": 713
    },
    {
      "epoch": 1.2283870967741937,
      "grad_norm": 0.8170946360461981,
      "learning_rate": 0.0001955188560219648,
      "loss": 0.0389,
      "step": 714
    },
    {
      "epoch": 1.2301075268817203,
      "grad_norm": 0.6513209292728687,
      "learning_rate": 0.00019550233886874788,
      "loss": 0.0338,
      "step": 715
    },
    {
      "epoch": 1.2318279569892474,
      "grad_norm": 1.4458636165935865,
      "learning_rate": 0.00019548579203129321,
      "loss": 0.0699,
      "step": 716
    },
    {
      "epoch": 1.2335483870967743,
      "grad_norm": 1.7880255471061306,
      "learning_rate": 0.00019546921551474397,
      "loss": 0.0327,
      "step": 717
    },
    {
      "epoch": 1.2352688172043012,
      "grad_norm": 0.6948508847276728,
      "learning_rate": 0.00019545260932425244,
      "loss": 0.0258,
      "step": 718
    },
    {
      "epoch": 1.236989247311828,
      "grad_norm": 1.4865350776505717,
      "learning_rate": 0.00019543597346498027,
      "loss": 0.081,
      "step": 719
    },
    {
      "epoch": 1.238709677419355,
      "grad_norm": 0.8080610134528619,
      "learning_rate": 0.00019541930794209815,
      "loss": 0.0226,
      "step": 720
    },
    {
      "epoch": 1.2404301075268818,
      "grad_norm": 1.1306530279511844,
      "learning_rate": 0.00019540261276078616,
      "loss": 0.0638,
      "step": 721
    },
    {
      "epoch": 1.2421505376344086,
      "grad_norm": 1.050526926355455,
      "learning_rate": 0.0001953858879262335,
      "loss": 0.0573,
      "step": 722
    },
    {
      "epoch": 1.2438709677419355,
      "grad_norm": 1.0258516097258523,
      "learning_rate": 0.00019536913344363869,
      "loss": 0.0499,
      "step": 723
    },
    {
      "epoch": 1.2455913978494624,
      "grad_norm": 0.8934324826581505,
      "learning_rate": 0.00019535234931820927,
      "loss": 0.0487,
      "step": 724
    },
    {
      "epoch": 1.2473118279569892,
      "grad_norm": 0.7775411482469554,
      "learning_rate": 0.00019533553555516224,
      "loss": 0.0433,
      "step": 725
    },
    {
      "epoch": 1.2490322580645161,
      "grad_norm": 1.0645972030448818,
      "learning_rate": 0.00019531869215972362,
      "loss": 0.0499,
      "step": 726
    },
    {
      "epoch": 1.250752688172043,
      "grad_norm": 0.9288527480489425,
      "learning_rate": 0.00019530181913712872,
      "loss": 0.0384,
      "step": 727
    },
    {
      "epoch": 1.2524731182795699,
      "grad_norm": 0.5664923301480143,
      "learning_rate": 0.00019528491649262208,
      "loss": 0.0258,
      "step": 728
    },
    {
      "epoch": 1.2541935483870967,
      "grad_norm": 1.1044978655467812,
      "learning_rate": 0.00019526798423145735,
      "loss": 0.0715,
      "step": 729
    },
    {
      "epoch": 1.2559139784946236,
      "grad_norm": 1.2286583467941838,
      "learning_rate": 0.00019525102235889752,
      "loss": 0.0628,
      "step": 730
    },
    {
      "epoch": 1.2576344086021505,
      "grad_norm": 1.2206720562453794,
      "learning_rate": 0.00019523403088021467,
      "loss": 0.0934,
      "step": 731
    },
    {
      "epoch": 1.2593548387096773,
      "grad_norm": 0.8517476707581535,
      "learning_rate": 0.00019521700980069015,
      "loss": 0.0481,
      "step": 732
    },
    {
      "epoch": 1.2610752688172042,
      "grad_norm": 1.3358523404206397,
      "learning_rate": 0.00019519995912561447,
      "loss": 0.0668,
      "step": 733
    },
    {
      "epoch": 1.262795698924731,
      "grad_norm": 1.0267401098480726,
      "learning_rate": 0.00019518287886028738,
      "loss": 0.0705,
      "step": 734
    },
    {
      "epoch": 1.2645161290322582,
      "grad_norm": 0.7622698115135996,
      "learning_rate": 0.0001951657690100178,
      "loss": 0.0259,
      "step": 735
    },
    {
      "epoch": 1.2662365591397848,
      "grad_norm": 1.0992097039353643,
      "learning_rate": 0.00019514862958012384,
      "loss": 0.0477,
      "step": 736
    },
    {
      "epoch": 1.267956989247312,
      "grad_norm": 0.8513820685241161,
      "learning_rate": 0.0001951314605759328,
      "loss": 0.0389,
      "step": 737
    },
    {
      "epoch": 1.2696774193548386,
      "grad_norm": 0.9310138320070065,
      "learning_rate": 0.0001951142620027812,
      "loss": 0.043,
      "step": 738
    },
    {
      "epoch": 1.2713978494623657,
      "grad_norm": 1.3516713112808074,
      "learning_rate": 0.00019509703386601473,
      "loss": 0.083,
      "step": 739
    },
    {
      "epoch": 1.2731182795698925,
      "grad_norm": 1.187658490305302,
      "learning_rate": 0.0001950797761709883,
      "loss": 0.0395,
      "step": 740
    },
    {
      "epoch": 1.2748387096774194,
      "grad_norm": 1.1021407520644984,
      "learning_rate": 0.00019506248892306598,
      "loss": 0.0692,
      "step": 741
    },
    {
      "epoch": 1.2765591397849463,
      "grad_norm": 1.3772404765309345,
      "learning_rate": 0.000195045172127621,
      "loss": 0.0674,
      "step": 742
    },
    {
      "epoch": 1.2782795698924732,
      "grad_norm": 0.7641675471092451,
      "learning_rate": 0.00019502782579003581,
      "loss": 0.0728,
      "step": 743
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0435090375064924,
      "learning_rate": 0.00019501044991570204,
      "loss": 0.0394,
      "step": 744
    },
    {
      "epoch": 1.281720430107527,
      "grad_norm": 1.4302554486999954,
      "learning_rate": 0.0001949930445100205,
      "loss": 0.0962,
      "step": 745
    },
    {
      "epoch": 1.2834408602150538,
      "grad_norm": 1.57561455303438,
      "learning_rate": 0.00019497560957840117,
      "loss": 0.0798,
      "step": 746
    },
    {
      "epoch": 1.2851612903225806,
      "grad_norm": 1.3359550604133232,
      "learning_rate": 0.00019495814512626323,
      "loss": 0.0757,
      "step": 747
    },
    {
      "epoch": 1.2868817204301075,
      "grad_norm": 0.9907480198461064,
      "learning_rate": 0.000194940651159035,
      "loss": 0.056,
      "step": 748
    },
    {
      "epoch": 1.2886021505376344,
      "grad_norm": 0.5375893046245783,
      "learning_rate": 0.00019492312768215397,
      "loss": 0.0324,
      "step": 749
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 1.0910843232527692,
      "learning_rate": 0.00019490557470106686,
      "loss": 0.0571,
      "step": 750
    },
    {
      "epoch": 1.2920430107526881,
      "grad_norm": 0.37163476767066367,
      "learning_rate": 0.00019488799222122953,
      "loss": 0.0246,
      "step": 751
    },
    {
      "epoch": 1.293763440860215,
      "grad_norm": 1.2870336206032311,
      "learning_rate": 0.00019487038024810696,
      "loss": 0.068,
      "step": 752
    },
    {
      "epoch": 1.2954838709677419,
      "grad_norm": 0.8404859808692545,
      "learning_rate": 0.00019485273878717342,
      "loss": 0.0384,
      "step": 753
    },
    {
      "epoch": 1.2972043010752687,
      "grad_norm": 0.99331364477861,
      "learning_rate": 0.00019483506784391216,
      "loss": 0.0434,
      "step": 754
    },
    {
      "epoch": 1.2989247311827956,
      "grad_norm": 1.1927232371771226,
      "learning_rate": 0.00019481736742381578,
      "loss": 0.0354,
      "step": 755
    },
    {
      "epoch": 1.3006451612903227,
      "grad_norm": 1.200137707549465,
      "learning_rate": 0.0001947996375323859,
      "loss": 0.0816,
      "step": 756
    },
    {
      "epoch": 1.3023655913978494,
      "grad_norm": 0.5997548586332648,
      "learning_rate": 0.00019478187817513343,
      "loss": 0.0253,
      "step": 757
    },
    {
      "epoch": 1.3040860215053764,
      "grad_norm": 1.2580975899689208,
      "learning_rate": 0.00019476408935757832,
      "loss": 0.046,
      "step": 758
    },
    {
      "epoch": 1.305806451612903,
      "grad_norm": 1.1202373353393262,
      "learning_rate": 0.00019474627108524977,
      "loss": 0.0406,
      "step": 759
    },
    {
      "epoch": 1.3075268817204302,
      "grad_norm": 0.7358202950233773,
      "learning_rate": 0.00019472842336368604,
      "loss": 0.0339,
      "step": 760
    },
    {
      "epoch": 1.309247311827957,
      "grad_norm": 0.74266656801161,
      "learning_rate": 0.00019471054619843466,
      "loss": 0.0306,
      "step": 761
    },
    {
      "epoch": 1.310967741935484,
      "grad_norm": 1.5522305245698793,
      "learning_rate": 0.00019469263959505219,
      "loss": 0.0645,
      "step": 762
    },
    {
      "epoch": 1.3126881720430108,
      "grad_norm": 1.3181796609569236,
      "learning_rate": 0.00019467470355910438,
      "loss": 0.0464,
      "step": 763
    },
    {
      "epoch": 1.3144086021505377,
      "grad_norm": 1.0984088126856766,
      "learning_rate": 0.00019465673809616622,
      "loss": 0.0353,
      "step": 764
    },
    {
      "epoch": 1.3161290322580645,
      "grad_norm": 1.3271505641105517,
      "learning_rate": 0.00019463874321182175,
      "loss": 0.0559,
      "step": 765
    },
    {
      "epoch": 1.3178494623655914,
      "grad_norm": 0.9953862114467724,
      "learning_rate": 0.00019462071891166414,
      "loss": 0.0483,
      "step": 766
    },
    {
      "epoch": 1.3195698924731183,
      "grad_norm": 0.8802856503674323,
      "learning_rate": 0.0001946026652012958,
      "loss": 0.0283,
      "step": 767
    },
    {
      "epoch": 1.3212903225806452,
      "grad_norm": 1.1498738299154236,
      "learning_rate": 0.00019458458208632817,
      "loss": 0.0346,
      "step": 768
    },
    {
      "epoch": 1.323010752688172,
      "grad_norm": 1.2628511203605317,
      "learning_rate": 0.00019456646957238195,
      "loss": 0.0404,
      "step": 769
    },
    {
      "epoch": 1.324731182795699,
      "grad_norm": 1.3157329331879404,
      "learning_rate": 0.0001945483276650868,
      "loss": 0.0472,
      "step": 770
    },
    {
      "epoch": 1.3264516129032258,
      "grad_norm": 1.2742419924887456,
      "learning_rate": 0.0001945301563700817,
      "loss": 0.0692,
      "step": 771
    },
    {
      "epoch": 1.3281720430107526,
      "grad_norm": 1.5255046953826228,
      "learning_rate": 0.0001945119556930147,
      "loss": 0.0742,
      "step": 772
    },
    {
      "epoch": 1.3298924731182795,
      "grad_norm": 0.9336810982076541,
      "learning_rate": 0.00019449372563954293,
      "loss": 0.0422,
      "step": 773
    },
    {
      "epoch": 1.3316129032258064,
      "grad_norm": 1.3323648525450913,
      "learning_rate": 0.00019447546621533272,
      "loss": 0.0794,
      "step": 774
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.9682867412008823,
      "learning_rate": 0.0001944571774260595,
      "loss": 0.025,
      "step": 775
    },
    {
      "epoch": 1.3350537634408601,
      "grad_norm": 1.1364507775324644,
      "learning_rate": 0.00019443885927740784,
      "loss": 0.0729,
      "step": 776
    },
    {
      "epoch": 1.3367741935483872,
      "grad_norm": 1.6061605480704602,
      "learning_rate": 0.0001944205117750714,
      "loss": 0.0848,
      "step": 777
    },
    {
      "epoch": 1.3384946236559139,
      "grad_norm": 1.2425403345133283,
      "learning_rate": 0.000194402134924753,
      "loss": 0.05,
      "step": 778
    },
    {
      "epoch": 1.340215053763441,
      "grad_norm": 0.9094322083644406,
      "learning_rate": 0.00019438372873216455,
      "loss": 0.0347,
      "step": 779
    },
    {
      "epoch": 1.3419354838709676,
      "grad_norm": 1.1184390751185354,
      "learning_rate": 0.00019436529320302715,
      "loss": 0.0734,
      "step": 780
    },
    {
      "epoch": 1.3436559139784947,
      "grad_norm": 1.1798152466885425,
      "learning_rate": 0.00019434682834307095,
      "loss": 0.0422,
      "step": 781
    },
    {
      "epoch": 1.3453763440860216,
      "grad_norm": 1.755702241834077,
      "learning_rate": 0.0001943283341580352,
      "loss": 0.0609,
      "step": 782
    },
    {
      "epoch": 1.3470967741935485,
      "grad_norm": 1.295186425184064,
      "learning_rate": 0.00019430981065366836,
      "loss": 0.0855,
      "step": 783
    },
    {
      "epoch": 1.3488172043010753,
      "grad_norm": 1.2311770244137616,
      "learning_rate": 0.00019429125783572792,
      "loss": 0.043,
      "step": 784
    },
    {
      "epoch": 1.3505376344086022,
      "grad_norm": 0.8869952844304182,
      "learning_rate": 0.00019427267570998045,
      "loss": 0.0472,
      "step": 785
    },
    {
      "epoch": 1.352258064516129,
      "grad_norm": 0.6505874696514256,
      "learning_rate": 0.0001942540642822018,
      "loss": 0.0355,
      "step": 786
    },
    {
      "epoch": 1.353978494623656,
      "grad_norm": 0.45309005735822033,
      "learning_rate": 0.00019423542355817674,
      "loss": 0.0169,
      "step": 787
    },
    {
      "epoch": 1.3556989247311828,
      "grad_norm": 0.7463402183516831,
      "learning_rate": 0.0001942167535436992,
      "loss": 0.0225,
      "step": 788
    },
    {
      "epoch": 1.3574193548387097,
      "grad_norm": 0.9500917322221979,
      "learning_rate": 0.00019419805424457232,
      "loss": 0.0691,
      "step": 789
    },
    {
      "epoch": 1.3591397849462366,
      "grad_norm": 0.9240526347404531,
      "learning_rate": 0.00019417932566660815,
      "loss": 0.0321,
      "step": 790
    },
    {
      "epoch": 1.3608602150537634,
      "grad_norm": 0.9819663833292751,
      "learning_rate": 0.000194160567815628,
      "loss": 0.0388,
      "step": 791
    },
    {
      "epoch": 1.3625806451612903,
      "grad_norm": 1.6820120394447904,
      "learning_rate": 0.00019414178069746224,
      "loss": 0.0371,
      "step": 792
    },
    {
      "epoch": 1.3643010752688172,
      "grad_norm": 1.2282664166997281,
      "learning_rate": 0.00019412296431795028,
      "loss": 0.057,
      "step": 793
    },
    {
      "epoch": 1.366021505376344,
      "grad_norm": 1.5965605299729022,
      "learning_rate": 0.00019410411868294068,
      "loss": 0.0704,
      "step": 794
    },
    {
      "epoch": 1.367741935483871,
      "grad_norm": 1.3992432682737392,
      "learning_rate": 0.00019408524379829108,
      "loss": 0.076,
      "step": 795
    },
    {
      "epoch": 1.3694623655913978,
      "grad_norm": 2.0553109772572022,
      "learning_rate": 0.00019406633966986828,
      "loss": 0.0554,
      "step": 796
    },
    {
      "epoch": 1.3711827956989247,
      "grad_norm": 1.4881358017246828,
      "learning_rate": 0.000194047406303548,
      "loss": 0.0485,
      "step": 797
    },
    {
      "epoch": 1.3729032258064517,
      "grad_norm": 0.7945546224368712,
      "learning_rate": 0.00019402844370521515,
      "loss": 0.0686,
      "step": 798
    },
    {
      "epoch": 1.3746236559139784,
      "grad_norm": 0.8476590902879457,
      "learning_rate": 0.0001940094518807638,
      "loss": 0.0431,
      "step": 799
    },
    {
      "epoch": 1.3763440860215055,
      "grad_norm": 0.9690298381852147,
      "learning_rate": 0.000193990430836097,
      "loss": 0.0442,
      "step": 800
    },
    {
      "epoch": 1.3780645161290321,
      "grad_norm": 1.1821625883994098,
      "learning_rate": 0.00019397138057712692,
      "loss": 0.0486,
      "step": 801
    },
    {
      "epoch": 1.3797849462365592,
      "grad_norm": 0.8407541567482745,
      "learning_rate": 0.00019395230110977476,
      "loss": 0.0493,
      "step": 802
    },
    {
      "epoch": 1.381505376344086,
      "grad_norm": 0.8295399610918756,
      "learning_rate": 0.00019393319243997086,
      "loss": 0.0526,
      "step": 803
    },
    {
      "epoch": 1.383225806451613,
      "grad_norm": 0.4882713541975183,
      "learning_rate": 0.00019391405457365462,
      "loss": 0.0224,
      "step": 804
    },
    {
      "epoch": 1.3849462365591398,
      "grad_norm": 0.7615165357423768,
      "learning_rate": 0.0001938948875167745,
      "loss": 0.0323,
      "step": 805
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 1.422390925045247,
      "learning_rate": 0.00019387569127528808,
      "loss": 0.0764,
      "step": 806
    },
    {
      "epoch": 1.3883870967741936,
      "grad_norm": 1.9029464907634215,
      "learning_rate": 0.00019385646585516196,
      "loss": 0.0721,
      "step": 807
    },
    {
      "epoch": 1.3901075268817205,
      "grad_norm": 1.6646207115947376,
      "learning_rate": 0.0001938372112623718,
      "loss": 0.0568,
      "step": 808
    },
    {
      "epoch": 1.3918279569892473,
      "grad_norm": 1.3403321908118644,
      "learning_rate": 0.0001938179275029024,
      "loss": 0.0742,
      "step": 809
    },
    {
      "epoch": 1.3935483870967742,
      "grad_norm": 1.3919336575359982,
      "learning_rate": 0.00019379861458274753,
      "loss": 0.0725,
      "step": 810
    },
    {
      "epoch": 1.395268817204301,
      "grad_norm": 1.0767856641806774,
      "learning_rate": 0.00019377927250791008,
      "loss": 0.051,
      "step": 811
    },
    {
      "epoch": 1.396989247311828,
      "grad_norm": 1.2343896509299963,
      "learning_rate": 0.00019375990128440204,
      "loss": 0.1181,
      "step": 812
    },
    {
      "epoch": 1.3987096774193548,
      "grad_norm": 1.142920530328217,
      "learning_rate": 0.00019374050091824438,
      "loss": 0.0567,
      "step": 813
    },
    {
      "epoch": 1.4004301075268817,
      "grad_norm": 1.2788671024294156,
      "learning_rate": 0.00019372107141546712,
      "loss": 0.0538,
      "step": 814
    },
    {
      "epoch": 1.4021505376344086,
      "grad_norm": 0.5718198003885412,
      "learning_rate": 0.00019370161278210949,
      "loss": 0.0442,
      "step": 815
    },
    {
      "epoch": 1.4038709677419354,
      "grad_norm": 1.3191703084739195,
      "learning_rate": 0.00019368212502421955,
      "loss": 0.0569,
      "step": 816
    },
    {
      "epoch": 1.4055913978494623,
      "grad_norm": 1.0838443949690557,
      "learning_rate": 0.00019366260814785463,
      "loss": 0.0541,
      "step": 817
    },
    {
      "epoch": 1.4073118279569892,
      "grad_norm": 0.5735825083072943,
      "learning_rate": 0.00019364306215908088,
      "loss": 0.0376,
      "step": 818
    },
    {
      "epoch": 1.4090322580645163,
      "grad_norm": 0.48053749132393364,
      "learning_rate": 0.00019362348706397373,
      "loss": 0.0331,
      "step": 819
    },
    {
      "epoch": 1.410752688172043,
      "grad_norm": 0.8081765834212444,
      "learning_rate": 0.00019360388286861752,
      "loss": 0.0467,
      "step": 820
    },
    {
      "epoch": 1.41247311827957,
      "grad_norm": 1.4716983832875503,
      "learning_rate": 0.00019358424957910563,
      "loss": 0.0943,
      "step": 821
    },
    {
      "epoch": 1.4141935483870967,
      "grad_norm": 1.4055105873960356,
      "learning_rate": 0.0001935645872015406,
      "loss": 0.0698,
      "step": 822
    },
    {
      "epoch": 1.4159139784946237,
      "grad_norm": 0.8419501015592855,
      "learning_rate": 0.00019354489574203388,
      "loss": 0.0883,
      "step": 823
    },
    {
      "epoch": 1.4176344086021506,
      "grad_norm": 1.0751635313989722,
      "learning_rate": 0.000193525175206706,
      "loss": 0.0428,
      "step": 824
    },
    {
      "epoch": 1.4193548387096775,
      "grad_norm": 0.6734717461379724,
      "learning_rate": 0.00019350542560168655,
      "loss": 0.0354,
      "step": 825
    },
    {
      "epoch": 1.4210752688172044,
      "grad_norm": 0.768956426618122,
      "learning_rate": 0.00019348564693311417,
      "loss": 0.0612,
      "step": 826
    },
    {
      "epoch": 1.4227956989247312,
      "grad_norm": 0.5941388203926041,
      "learning_rate": 0.0001934658392071365,
      "loss": 0.0553,
      "step": 827
    },
    {
      "epoch": 1.424516129032258,
      "grad_norm": 1.0940138296469355,
      "learning_rate": 0.00019344600242991015,
      "loss": 0.0754,
      "step": 828
    },
    {
      "epoch": 1.426236559139785,
      "grad_norm": 0.9574620398068154,
      "learning_rate": 0.00019342613660760095,
      "loss": 0.0408,
      "step": 829
    },
    {
      "epoch": 1.4279569892473118,
      "grad_norm": 1.1617658798340842,
      "learning_rate": 0.00019340624174638354,
      "loss": 0.0829,
      "step": 830
    },
    {
      "epoch": 1.4296774193548387,
      "grad_norm": 1.047363992297295,
      "learning_rate": 0.0001933863178524417,
      "loss": 0.0656,
      "step": 831
    },
    {
      "epoch": 1.4313978494623656,
      "grad_norm": 0.9871725869152209,
      "learning_rate": 0.00019336636493196823,
      "loss": 0.0454,
      "step": 832
    },
    {
      "epoch": 1.4331182795698925,
      "grad_norm": 0.8534676105467801,
      "learning_rate": 0.00019334638299116496,
      "loss": 0.061,
      "step": 833
    },
    {
      "epoch": 1.4348387096774193,
      "grad_norm": 0.6093029305505905,
      "learning_rate": 0.0001933263720362427,
      "loss": 0.0274,
      "step": 834
    },
    {
      "epoch": 1.4365591397849462,
      "grad_norm": 0.8041010489975406,
      "learning_rate": 0.00019330633207342127,
      "loss": 0.0387,
      "step": 835
    },
    {
      "epoch": 1.438279569892473,
      "grad_norm": 0.7804618010727876,
      "learning_rate": 0.0001932862631089296,
      "loss": 0.0422,
      "step": 836
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6768926133644382,
      "learning_rate": 0.0001932661651490055,
      "loss": 0.0591,
      "step": 837
    },
    {
      "epoch": 1.4417204301075268,
      "grad_norm": 1.451907056460547,
      "learning_rate": 0.00019324603819989588,
      "loss": 0.0604,
      "step": 838
    },
    {
      "epoch": 1.4434408602150537,
      "grad_norm": 1.4161917714819936,
      "learning_rate": 0.00019322588226785664,
      "loss": 0.0829,
      "step": 839
    },
    {
      "epoch": 1.4451612903225808,
      "grad_norm": 0.8365284690995487,
      "learning_rate": 0.00019320569735915271,
      "loss": 0.0341,
      "step": 840
    },
    {
      "epoch": 1.4468817204301074,
      "grad_norm": 1.042692279647342,
      "learning_rate": 0.000193185483480058,
      "loss": 0.0497,
      "step": 841
    },
    {
      "epoch": 1.4486021505376345,
      "grad_norm": 1.0636122605698546,
      "learning_rate": 0.0001931652406368554,
      "loss": 0.1106,
      "step": 842
    },
    {
      "epoch": 1.4503225806451612,
      "grad_norm": 0.8817846271935654,
      "learning_rate": 0.00019314496883583688,
      "loss": 0.0312,
      "step": 843
    },
    {
      "epoch": 1.4520430107526883,
      "grad_norm": 1.0478239654293418,
      "learning_rate": 0.00019312466808330334,
      "loss": 0.0487,
      "step": 844
    },
    {
      "epoch": 1.453763440860215,
      "grad_norm": 0.7063783162052055,
      "learning_rate": 0.00019310433838556467,
      "loss": 0.0234,
      "step": 845
    },
    {
      "epoch": 1.455483870967742,
      "grad_norm": 0.86625023052122,
      "learning_rate": 0.00019308397974893986,
      "loss": 0.0641,
      "step": 846
    },
    {
      "epoch": 1.4572043010752689,
      "grad_norm": 0.7930173380321054,
      "learning_rate": 0.00019306359217975677,
      "loss": 0.0244,
      "step": 847
    },
    {
      "epoch": 1.4589247311827958,
      "grad_norm": 1.8955388998199345,
      "learning_rate": 0.0001930431756843523,
      "loss": 0.0339,
      "step": 848
    },
    {
      "epoch": 1.4606451612903226,
      "grad_norm": 0.9272716144432486,
      "learning_rate": 0.0001930227302690724,
      "loss": 0.0322,
      "step": 849
    },
    {
      "epoch": 1.4623655913978495,
      "grad_norm": 2.9050454392420644,
      "learning_rate": 0.0001930022559402719,
      "loss": 0.0932,
      "step": 850
    },
    {
      "epoch": 1.4640860215053764,
      "grad_norm": 1.4041116671308382,
      "learning_rate": 0.00019298175270431473,
      "loss": 0.0827,
      "step": 851
    },
    {
      "epoch": 1.4658064516129032,
      "grad_norm": 0.7704972580283119,
      "learning_rate": 0.0001929612205675737,
      "loss": 0.0328,
      "step": 852
    },
    {
      "epoch": 1.46752688172043,
      "grad_norm": 1.680355260863325,
      "learning_rate": 0.0001929406595364307,
      "loss": 0.0815,
      "step": 853
    },
    {
      "epoch": 1.469247311827957,
      "grad_norm": 1.4396551098476738,
      "learning_rate": 0.0001929200696172765,
      "loss": 0.0495,
      "step": 854
    },
    {
      "epoch": 1.4709677419354839,
      "grad_norm": 1.0212301429046078,
      "learning_rate": 0.00019289945081651092,
      "loss": 0.0389,
      "step": 855
    },
    {
      "epoch": 1.4726881720430107,
      "grad_norm": 0.8859440260341104,
      "learning_rate": 0.00019287880314054276,
      "loss": 0.056,
      "step": 856
    },
    {
      "epoch": 1.4744086021505376,
      "grad_norm": 0.938469016602388,
      "learning_rate": 0.00019285812659578978,
      "loss": 0.0324,
      "step": 857
    },
    {
      "epoch": 1.4761290322580645,
      "grad_norm": 1.4953375527614676,
      "learning_rate": 0.00019283742118867867,
      "loss": 0.072,
      "step": 858
    },
    {
      "epoch": 1.4778494623655913,
      "grad_norm": 1.6730774307220353,
      "learning_rate": 0.00019281668692564514,
      "loss": 0.085,
      "step": 859
    },
    {
      "epoch": 1.4795698924731182,
      "grad_norm": 1.1304762114751268,
      "learning_rate": 0.00019279592381313385,
      "loss": 0.0577,
      "step": 860
    },
    {
      "epoch": 1.481290322580645,
      "grad_norm": 0.515084364923538,
      "learning_rate": 0.00019277513185759844,
      "loss": 0.0329,
      "step": 861
    },
    {
      "epoch": 1.483010752688172,
      "grad_norm": 1.03418687877867,
      "learning_rate": 0.00019275431106550154,
      "loss": 0.0598,
      "step": 862
    },
    {
      "epoch": 1.484731182795699,
      "grad_norm": 0.9251331826853821,
      "learning_rate": 0.0001927334614433147,
      "loss": 0.0531,
      "step": 863
    },
    {
      "epoch": 1.4864516129032257,
      "grad_norm": 1.5693546466767356,
      "learning_rate": 0.00019271258299751842,
      "loss": 0.0785,
      "step": 864
    },
    {
      "epoch": 1.4881720430107528,
      "grad_norm": 0.654863838317591,
      "learning_rate": 0.0001926916757346022,
      "loss": 0.0478,
      "step": 865
    },
    {
      "epoch": 1.4898924731182794,
      "grad_norm": 3.464561234379544,
      "learning_rate": 0.00019267073966106445,
      "loss": 0.0821,
      "step": 866
    },
    {
      "epoch": 1.4916129032258065,
      "grad_norm": 0.8775394238729924,
      "learning_rate": 0.00019264977478341262,
      "loss": 0.0484,
      "step": 867
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 1.0596145804979358,
      "learning_rate": 0.00019262878110816299,
      "loss": 0.0686,
      "step": 868
    },
    {
      "epoch": 1.4950537634408603,
      "grad_norm": 1.0282859140733527,
      "learning_rate": 0.0001926077586418409,
      "loss": 0.055,
      "step": 869
    },
    {
      "epoch": 1.4967741935483871,
      "grad_norm": 0.6546492408510972,
      "learning_rate": 0.0001925867073909806,
      "loss": 0.0281,
      "step": 870
    },
    {
      "epoch": 1.498494623655914,
      "grad_norm": 0.9680768442849221,
      "learning_rate": 0.00019256562736212529,
      "loss": 0.0921,
      "step": 871
    },
    {
      "epoch": 1.5002150537634409,
      "grad_norm": 0.6713003811696581,
      "learning_rate": 0.00019254451856182708,
      "loss": 0.0405,
      "step": 872
    },
    {
      "epoch": 1.5019354838709678,
      "grad_norm": 0.8994229961396017,
      "learning_rate": 0.00019252338099664707,
      "loss": 0.0539,
      "step": 873
    },
    {
      "epoch": 1.5036559139784946,
      "grad_norm": 0.6457721376539085,
      "learning_rate": 0.00019250221467315528,
      "loss": 0.0591,
      "step": 874
    },
    {
      "epoch": 1.5053763440860215,
      "grad_norm": 0.6686808549654398,
      "learning_rate": 0.00019248101959793066,
      "loss": 0.0524,
      "step": 875
    },
    {
      "epoch": 1.5070967741935484,
      "grad_norm": 1.057350134454603,
      "learning_rate": 0.00019245979577756114,
      "loss": 0.0393,
      "step": 876
    },
    {
      "epoch": 1.5088172043010752,
      "grad_norm": 1.2729821836387207,
      "learning_rate": 0.0001924385432186435,
      "loss": 0.0905,
      "step": 877
    },
    {
      "epoch": 1.5105376344086021,
      "grad_norm": 1.1559758267100795,
      "learning_rate": 0.00019241726192778354,
      "loss": 0.0577,
      "step": 878
    },
    {
      "epoch": 1.512258064516129,
      "grad_norm": 1.0567555180476071,
      "learning_rate": 0.00019239595191159595,
      "loss": 0.0288,
      "step": 879
    },
    {
      "epoch": 1.513978494623656,
      "grad_norm": 0.7534368134546804,
      "learning_rate": 0.00019237461317670436,
      "loss": 0.0349,
      "step": 880
    },
    {
      "epoch": 1.5156989247311827,
      "grad_norm": 1.545859922095418,
      "learning_rate": 0.0001923532457297413,
      "loss": 0.0728,
      "step": 881
    },
    {
      "epoch": 1.5174193548387098,
      "grad_norm": 1.3109087844728227,
      "learning_rate": 0.0001923318495773483,
      "loss": 0.0371,
      "step": 882
    },
    {
      "epoch": 1.5191397849462365,
      "grad_norm": 1.267062873529522,
      "learning_rate": 0.00019231042472617568,
      "loss": 0.0843,
      "step": 883
    },
    {
      "epoch": 1.5208602150537636,
      "grad_norm": 0.7827517809048161,
      "learning_rate": 0.0001922889711828828,
      "loss": 0.0427,
      "step": 884
    },
    {
      "epoch": 1.5225806451612902,
      "grad_norm": 1.2304825020017502,
      "learning_rate": 0.00019226748895413787,
      "loss": 0.0352,
      "step": 885
    },
    {
      "epoch": 1.5243010752688173,
      "grad_norm": 1.4246485196415182,
      "learning_rate": 0.0001922459780466181,
      "loss": 0.0395,
      "step": 886
    },
    {
      "epoch": 1.526021505376344,
      "grad_norm": 0.8297816919460781,
      "learning_rate": 0.0001922244384670095,
      "loss": 0.0268,
      "step": 887
    },
    {
      "epoch": 1.527741935483871,
      "grad_norm": 1.016499741910001,
      "learning_rate": 0.00019220287022200707,
      "loss": 0.0261,
      "step": 888
    },
    {
      "epoch": 1.5294623655913977,
      "grad_norm": 0.9396997450469613,
      "learning_rate": 0.00019218127331831469,
      "loss": 0.0209,
      "step": 889
    },
    {
      "epoch": 1.5311827956989248,
      "grad_norm": 0.898634252954112,
      "learning_rate": 0.00019215964776264513,
      "loss": 0.0632,
      "step": 890
    },
    {
      "epoch": 1.5329032258064517,
      "grad_norm": 1.1814320236418505,
      "learning_rate": 0.00019213799356172014,
      "loss": 0.0995,
      "step": 891
    },
    {
      "epoch": 1.5346236559139785,
      "grad_norm": 0.9853740154522221,
      "learning_rate": 0.0001921163107222703,
      "loss": 0.0345,
      "step": 892
    },
    {
      "epoch": 1.5363440860215054,
      "grad_norm": 0.34690813662657044,
      "learning_rate": 0.0001920945992510351,
      "loss": 0.0096,
      "step": 893
    },
    {
      "epoch": 1.5380645161290323,
      "grad_norm": 0.8929820514179581,
      "learning_rate": 0.00019207285915476296,
      "loss": 0.0343,
      "step": 894
    },
    {
      "epoch": 1.5397849462365591,
      "grad_norm": 1.135511098672224,
      "learning_rate": 0.00019205109044021122,
      "loss": 0.0537,
      "step": 895
    },
    {
      "epoch": 1.541505376344086,
      "grad_norm": 1.3468014368191852,
      "learning_rate": 0.00019202929311414602,
      "loss": 0.0577,
      "step": 896
    },
    {
      "epoch": 1.543225806451613,
      "grad_norm": 1.1095999241047159,
      "learning_rate": 0.00019200746718334245,
      "loss": 0.0574,
      "step": 897
    },
    {
      "epoch": 1.5449462365591398,
      "grad_norm": 1.3427633751983723,
      "learning_rate": 0.00019198561265458455,
      "loss": 0.0784,
      "step": 898
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 1.3295836644672787,
      "learning_rate": 0.00019196372953466515,
      "loss": 0.088,
      "step": 899
    },
    {
      "epoch": 1.5483870967741935,
      "grad_norm": 1.4900337626074849,
      "learning_rate": 0.00019194181783038598,
      "loss": 0.0655,
      "step": 900
    },
    {
      "epoch": 1.5501075268817204,
      "grad_norm": 1.6231695951583731,
      "learning_rate": 0.00019191987754855772,
      "loss": 0.0658,
      "step": 901
    },
    {
      "epoch": 1.5518279569892472,
      "grad_norm": 1.1171590126777131,
      "learning_rate": 0.00019189790869599994,
      "loss": 0.0665,
      "step": 902
    },
    {
      "epoch": 1.5535483870967743,
      "grad_norm": 0.9114710510190378,
      "learning_rate": 0.00019187591127954094,
      "loss": 0.0474,
      "step": 903
    },
    {
      "epoch": 1.555268817204301,
      "grad_norm": 1.6235235555107526,
      "learning_rate": 0.00019185388530601808,
      "loss": 0.0601,
      "step": 904
    },
    {
      "epoch": 1.556989247311828,
      "grad_norm": 1.154837451782333,
      "learning_rate": 0.0001918318307822775,
      "loss": 0.0409,
      "step": 905
    },
    {
      "epoch": 1.5587096774193547,
      "grad_norm": 1.548040074659027,
      "learning_rate": 0.0001918097477151742,
      "loss": 0.095,
      "step": 906
    },
    {
      "epoch": 1.5604301075268818,
      "grad_norm": 1.4796586569357395,
      "learning_rate": 0.00019178763611157212,
      "loss": 0.0933,
      "step": 907
    },
    {
      "epoch": 1.5621505376344085,
      "grad_norm": 0.9043110632011356,
      "learning_rate": 0.00019176549597834405,
      "loss": 0.0429,
      "step": 908
    },
    {
      "epoch": 1.5638709677419356,
      "grad_norm": 1.2894392346839791,
      "learning_rate": 0.00019174332732237162,
      "loss": 0.0879,
      "step": 909
    },
    {
      "epoch": 1.5655913978494622,
      "grad_norm": 0.5708517059083114,
      "learning_rate": 0.00019172113015054532,
      "loss": 0.0649,
      "step": 910
    },
    {
      "epoch": 1.5673118279569893,
      "grad_norm": 1.262154549015779,
      "learning_rate": 0.00019169890446976454,
      "loss": 0.0403,
      "step": 911
    },
    {
      "epoch": 1.5690322580645162,
      "grad_norm": 0.4960663618479838,
      "learning_rate": 0.00019167665028693747,
      "loss": 0.0288,
      "step": 912
    },
    {
      "epoch": 1.570752688172043,
      "grad_norm": 0.4971614079436814,
      "learning_rate": 0.00019165436760898127,
      "loss": 0.0282,
      "step": 913
    },
    {
      "epoch": 1.57247311827957,
      "grad_norm": 1.0091712736890186,
      "learning_rate": 0.00019163205644282184,
      "loss": 0.0615,
      "step": 914
    },
    {
      "epoch": 1.5741935483870968,
      "grad_norm": 1.0973539583674257,
      "learning_rate": 0.000191609716795394,
      "loss": 0.0538,
      "step": 915
    },
    {
      "epoch": 1.5759139784946237,
      "grad_norm": 0.9924812345338819,
      "learning_rate": 0.00019158734867364143,
      "loss": 0.065,
      "step": 916
    },
    {
      "epoch": 1.5776344086021505,
      "grad_norm": 1.1692863915115888,
      "learning_rate": 0.00019156495208451658,
      "loss": 0.039,
      "step": 917
    },
    {
      "epoch": 1.5793548387096774,
      "grad_norm": 0.9196827317990747,
      "learning_rate": 0.00019154252703498085,
      "loss": 0.0642,
      "step": 918
    },
    {
      "epoch": 1.5810752688172043,
      "grad_norm": 1.0230834727545715,
      "learning_rate": 0.00019152007353200444,
      "loss": 0.0599,
      "step": 919
    },
    {
      "epoch": 1.5827956989247312,
      "grad_norm": 1.0091114586543033,
      "learning_rate": 0.00019149759158256638,
      "loss": 0.0803,
      "step": 920
    },
    {
      "epoch": 1.584516129032258,
      "grad_norm": 0.636878782920532,
      "learning_rate": 0.00019147508119365453,
      "loss": 0.0238,
      "step": 921
    },
    {
      "epoch": 1.586236559139785,
      "grad_norm": 0.5330132597914258,
      "learning_rate": 0.0001914525423722657,
      "loss": 0.0287,
      "step": 922
    },
    {
      "epoch": 1.5879569892473118,
      "grad_norm": 0.579613355476087,
      "learning_rate": 0.00019142997512540535,
      "loss": 0.0226,
      "step": 923
    },
    {
      "epoch": 1.5896774193548389,
      "grad_norm": 0.954683789962834,
      "learning_rate": 0.00019140737946008796,
      "loss": 0.0664,
      "step": 924
    },
    {
      "epoch": 1.5913978494623655,
      "grad_norm": 0.9622633593320242,
      "learning_rate": 0.0001913847553833367,
      "loss": 0.0579,
      "step": 925
    },
    {
      "epoch": 1.5931182795698926,
      "grad_norm": 1.3338087661024436,
      "learning_rate": 0.0001913621029021837,
      "loss": 0.0899,
      "step": 926
    },
    {
      "epoch": 1.5948387096774193,
      "grad_norm": 0.8211094885240617,
      "learning_rate": 0.00019133942202366981,
      "loss": 0.0438,
      "step": 927
    },
    {
      "epoch": 1.5965591397849463,
      "grad_norm": 0.8182708623098198,
      "learning_rate": 0.00019131671275484475,
      "loss": 0.0351,
      "step": 928
    },
    {
      "epoch": 1.598279569892473,
      "grad_norm": 0.9268705694418737,
      "learning_rate": 0.00019129397510276704,
      "loss": 0.04,
      "step": 929
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3390413030714985,
      "learning_rate": 0.00019127120907450412,
      "loss": 0.0657,
      "step": 930
    },
    {
      "epoch": 1.6017204301075267,
      "grad_norm": 2.180789912059822,
      "learning_rate": 0.0001912484146771321,
      "loss": 0.0883,
      "step": 931
    },
    {
      "epoch": 1.6034408602150538,
      "grad_norm": 1.2585465421802786,
      "learning_rate": 0.00019122559191773602,
      "loss": 0.0617,
      "step": 932
    },
    {
      "epoch": 1.6051612903225805,
      "grad_norm": 0.7351014532986536,
      "learning_rate": 0.00019120274080340965,
      "loss": 0.0334,
      "step": 933
    },
    {
      "epoch": 1.6068817204301076,
      "grad_norm": 1.3122031876635813,
      "learning_rate": 0.0001911798613412557,
      "loss": 0.0336,
      "step": 934
    },
    {
      "epoch": 1.6086021505376344,
      "grad_norm": 1.484090235429351,
      "learning_rate": 0.00019115695353838556,
      "loss": 0.0721,
      "step": 935
    },
    {
      "epoch": 1.6103225806451613,
      "grad_norm": 1.4251581744805646,
      "learning_rate": 0.0001911340174019195,
      "loss": 0.0866,
      "step": 936
    },
    {
      "epoch": 1.6120430107526882,
      "grad_norm": 1.6082491807343908,
      "learning_rate": 0.00019111105293898658,
      "loss": 0.055,
      "step": 937
    },
    {
      "epoch": 1.613763440860215,
      "grad_norm": 1.5023059966402166,
      "learning_rate": 0.00019108806015672464,
      "loss": 0.0806,
      "step": 938
    },
    {
      "epoch": 1.615483870967742,
      "grad_norm": 1.6756209217124787,
      "learning_rate": 0.00019106503906228035,
      "loss": 0.0767,
      "step": 939
    },
    {
      "epoch": 1.6172043010752688,
      "grad_norm": 0.9727903697260653,
      "learning_rate": 0.0001910419896628092,
      "loss": 0.056,
      "step": 940
    },
    {
      "epoch": 1.6189247311827957,
      "grad_norm": 1.3653916751051394,
      "learning_rate": 0.0001910189119654754,
      "loss": 0.0529,
      "step": 941
    },
    {
      "epoch": 1.6206451612903225,
      "grad_norm": 0.898731174907969,
      "learning_rate": 0.0001909958059774521,
      "loss": 0.0502,
      "step": 942
    },
    {
      "epoch": 1.6223655913978494,
      "grad_norm": 1.3007531953983202,
      "learning_rate": 0.00019097267170592106,
      "loss": 0.049,
      "step": 943
    },
    {
      "epoch": 1.6240860215053763,
      "grad_norm": 0.9545655890468048,
      "learning_rate": 0.00019094950915807298,
      "loss": 0.0523,
      "step": 944
    },
    {
      "epoch": 1.6258064516129034,
      "grad_norm": 1.030533105040643,
      "learning_rate": 0.00019092631834110723,
      "loss": 0.073,
      "step": 945
    },
    {
      "epoch": 1.62752688172043,
      "grad_norm": 0.7625491708937961,
      "learning_rate": 0.00019090309926223214,
      "loss": 0.047,
      "step": 946
    },
    {
      "epoch": 1.6292473118279571,
      "grad_norm": 1.1041501421907811,
      "learning_rate": 0.00019087985192866458,
      "loss": 0.0443,
      "step": 947
    },
    {
      "epoch": 1.6309677419354838,
      "grad_norm": 1.619412084024378,
      "learning_rate": 0.00019085657634763045,
      "loss": 0.079,
      "step": 948
    },
    {
      "epoch": 1.6326881720430109,
      "grad_norm": 0.9220646668692876,
      "learning_rate": 0.00019083327252636422,
      "loss": 0.0633,
      "step": 949
    },
    {
      "epoch": 1.6344086021505375,
      "grad_norm": 0.7564223861034153,
      "learning_rate": 0.00019080994047210927,
      "loss": 0.0456,
      "step": 950
    },
    {
      "epoch": 1.6361290322580646,
      "grad_norm": 1.0196960537182422,
      "learning_rate": 0.00019078658019211776,
      "loss": 0.0275,
      "step": 951
    },
    {
      "epoch": 1.6378494623655913,
      "grad_norm": 1.070216209356103,
      "learning_rate": 0.00019076319169365053,
      "loss": 0.0518,
      "step": 952
    },
    {
      "epoch": 1.6395698924731184,
      "grad_norm": 0.6633846792218794,
      "learning_rate": 0.00019073977498397727,
      "loss": 0.028,
      "step": 953
    },
    {
      "epoch": 1.641290322580645,
      "grad_norm": 1.38899026456782,
      "learning_rate": 0.00019071633007037634,
      "loss": 0.0843,
      "step": 954
    },
    {
      "epoch": 1.643010752688172,
      "grad_norm": 1.0883700415822373,
      "learning_rate": 0.00019069285696013505,
      "loss": 0.0431,
      "step": 955
    },
    {
      "epoch": 1.644731182795699,
      "grad_norm": 0.7763205486862254,
      "learning_rate": 0.0001906693556605493,
      "loss": 0.0397,
      "step": 956
    },
    {
      "epoch": 1.6464516129032258,
      "grad_norm": 1.1255707492270886,
      "learning_rate": 0.0001906458261789238,
      "loss": 0.0465,
      "step": 957
    },
    {
      "epoch": 1.6481720430107527,
      "grad_norm": 0.9384169780770407,
      "learning_rate": 0.0001906222685225721,
      "loss": 0.0421,
      "step": 958
    },
    {
      "epoch": 1.6498924731182796,
      "grad_norm": 0.7144125794278796,
      "learning_rate": 0.0001905986826988164,
      "loss": 0.0542,
      "step": 959
    },
    {
      "epoch": 1.6516129032258065,
      "grad_norm": 2.62591692867619,
      "learning_rate": 0.0001905750687149876,
      "loss": 0.0455,
      "step": 960
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 1.2923238223324143,
      "learning_rate": 0.00019055142657842562,
      "loss": 0.0419,
      "step": 961
    },
    {
      "epoch": 1.6550537634408602,
      "grad_norm": 0.6746246685843142,
      "learning_rate": 0.00019052775629647883,
      "loss": 0.0213,
      "step": 962
    },
    {
      "epoch": 1.656774193548387,
      "grad_norm": 1.8185409817741591,
      "learning_rate": 0.00019050405787650454,
      "loss": 0.0785,
      "step": 963
    },
    {
      "epoch": 1.658494623655914,
      "grad_norm": 0.5150701872813057,
      "learning_rate": 0.00019048033132586874,
      "loss": 0.0133,
      "step": 964
    },
    {
      "epoch": 1.6602150537634408,
      "grad_norm": 2.210197625653502,
      "learning_rate": 0.00019045657665194612,
      "loss": 0.0904,
      "step": 965
    },
    {
      "epoch": 1.661935483870968,
      "grad_norm": 1.6864452239698347,
      "learning_rate": 0.0001904327938621202,
      "loss": 0.115,
      "step": 966
    },
    {
      "epoch": 1.6636559139784945,
      "grad_norm": 0.8931426431062742,
      "learning_rate": 0.0001904089829637832,
      "loss": 0.0413,
      "step": 967
    },
    {
      "epoch": 1.6653763440860216,
      "grad_norm": 0.8349409409693225,
      "learning_rate": 0.00019038514396433603,
      "loss": 0.0405,
      "step": 968
    },
    {
      "epoch": 1.6670967741935483,
      "grad_norm": 1.084126012224163,
      "learning_rate": 0.00019036127687118844,
      "loss": 0.0248,
      "step": 969
    },
    {
      "epoch": 1.6688172043010754,
      "grad_norm": 0.81122259864228,
      "learning_rate": 0.0001903373816917588,
      "loss": 0.0436,
      "step": 970
    },
    {
      "epoch": 1.670537634408602,
      "grad_norm": 0.7813879823732698,
      "learning_rate": 0.0001903134584334743,
      "loss": 0.0339,
      "step": 971
    },
    {
      "epoch": 1.6722580645161291,
      "grad_norm": 0.7694427007825565,
      "learning_rate": 0.00019028950710377077,
      "loss": 0.0407,
      "step": 972
    },
    {
      "epoch": 1.6739784946236558,
      "grad_norm": 0.6619926011446207,
      "learning_rate": 0.00019026552771009284,
      "loss": 0.0278,
      "step": 973
    },
    {
      "epoch": 1.6756989247311829,
      "grad_norm": 1.202406978680847,
      "learning_rate": 0.00019024152025989382,
      "loss": 0.0675,
      "step": 974
    },
    {
      "epoch": 1.6774193548387095,
      "grad_norm": 0.4652832765034192,
      "learning_rate": 0.0001902174847606358,
      "loss": 0.0226,
      "step": 975
    },
    {
      "epoch": 1.6791397849462366,
      "grad_norm": 0.7053259836582544,
      "learning_rate": 0.0001901934212197895,
      "loss": 0.0257,
      "step": 976
    },
    {
      "epoch": 1.6808602150537635,
      "grad_norm": 1.365566739075853,
      "learning_rate": 0.0001901693296448344,
      "loss": 0.056,
      "step": 977
    },
    {
      "epoch": 1.6825806451612904,
      "grad_norm": 1.3707877897572576,
      "learning_rate": 0.0001901452100432587,
      "loss": 0.0536,
      "step": 978
    },
    {
      "epoch": 1.6843010752688172,
      "grad_norm": 0.9630480895608099,
      "learning_rate": 0.00019012106242255935,
      "loss": 0.0615,
      "step": 979
    },
    {
      "epoch": 1.686021505376344,
      "grad_norm": 0.8229640430480876,
      "learning_rate": 0.0001900968867902419,
      "loss": 0.0322,
      "step": 980
    },
    {
      "epoch": 1.687741935483871,
      "grad_norm": 1.7878300939421181,
      "learning_rate": 0.00019007268315382074,
      "loss": 0.1075,
      "step": 981
    },
    {
      "epoch": 1.6894623655913978,
      "grad_norm": 0.6622921429942885,
      "learning_rate": 0.00019004845152081882,
      "loss": 0.0296,
      "step": 982
    },
    {
      "epoch": 1.6911827956989247,
      "grad_norm": 1.816273990946769,
      "learning_rate": 0.00019002419189876788,
      "loss": 0.0739,
      "step": 983
    },
    {
      "epoch": 1.6929032258064516,
      "grad_norm": 1.1502128180604685,
      "learning_rate": 0.0001899999042952084,
      "loss": 0.0688,
      "step": 984
    },
    {
      "epoch": 1.6946236559139785,
      "grad_norm": 0.9113035298980917,
      "learning_rate": 0.00018997558871768945,
      "loss": 0.0583,
      "step": 985
    },
    {
      "epoch": 1.6963440860215053,
      "grad_norm": 0.6214939941816008,
      "learning_rate": 0.0001899512451737689,
      "loss": 0.0278,
      "step": 986
    },
    {
      "epoch": 1.6980645161290324,
      "grad_norm": 0.9418118125471779,
      "learning_rate": 0.00018992687367101323,
      "loss": 0.0458,
      "step": 987
    },
    {
      "epoch": 1.699784946236559,
      "grad_norm": 0.7333827192435506,
      "learning_rate": 0.0001899024742169976,
      "loss": 0.0244,
      "step": 988
    },
    {
      "epoch": 1.7015053763440862,
      "grad_norm": 1.38715792350802,
      "learning_rate": 0.000189878046819306,
      "loss": 0.0536,
      "step": 989
    },
    {
      "epoch": 1.7032258064516128,
      "grad_norm": 1.6773908558651585,
      "learning_rate": 0.00018985359148553088,
      "loss": 0.0821,
      "step": 990
    },
    {
      "epoch": 1.70494623655914,
      "grad_norm": 1.2216663306461946,
      "learning_rate": 0.00018982910822327363,
      "loss": 0.0546,
      "step": 991
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 2.591823944558764,
      "learning_rate": 0.0001898045970401441,
      "loss": 0.0728,
      "step": 992
    },
    {
      "epoch": 1.7083870967741936,
      "grad_norm": 1.1282494066116877,
      "learning_rate": 0.00018978005794376092,
      "loss": 0.0331,
      "step": 993
    },
    {
      "epoch": 1.7101075268817203,
      "grad_norm": 0.9951413822720234,
      "learning_rate": 0.0001897554909417514,
      "loss": 0.0712,
      "step": 994
    },
    {
      "epoch": 1.7118279569892474,
      "grad_norm": 0.9934067737315354,
      "learning_rate": 0.00018973089604175153,
      "loss": 0.0317,
      "step": 995
    },
    {
      "epoch": 1.713548387096774,
      "grad_norm": 0.9072964072656682,
      "learning_rate": 0.0001897062732514059,
      "loss": 0.0394,
      "step": 996
    },
    {
      "epoch": 1.7152688172043011,
      "grad_norm": 0.891105807207768,
      "learning_rate": 0.00018968162257836782,
      "loss": 0.0337,
      "step": 997
    },
    {
      "epoch": 1.716989247311828,
      "grad_norm": 1.1351422886126854,
      "learning_rate": 0.0001896569440302993,
      "loss": 0.0587,
      "step": 998
    },
    {
      "epoch": 1.7187096774193549,
      "grad_norm": 0.6823304278772271,
      "learning_rate": 0.00018963223761487097,
      "loss": 0.0193,
      "step": 999
    },
    {
      "epoch": 1.7204301075268817,
      "grad_norm": 1.0735999629080115,
      "learning_rate": 0.00018960750333976213,
      "loss": 0.0699,
      "step": 1000
    },
    {
      "epoch": 1.7221505376344086,
      "grad_norm": 2.761760143664141,
      "learning_rate": 0.0001895827412126607,
      "loss": 0.0842,
      "step": 1001
    },
    {
      "epoch": 1.7238709677419355,
      "grad_norm": 1.297884532821568,
      "learning_rate": 0.00018955795124126333,
      "loss": 0.0551,
      "step": 1002
    },
    {
      "epoch": 1.7255913978494624,
      "grad_norm": 1.8329440882527952,
      "learning_rate": 0.0001895331334332753,
      "loss": 0.076,
      "step": 1003
    },
    {
      "epoch": 1.7273118279569892,
      "grad_norm": 1.5574152582289105,
      "learning_rate": 0.00018950828779641055,
      "loss": 0.1176,
      "step": 1004
    },
    {
      "epoch": 1.729032258064516,
      "grad_norm": 0.7698698910607656,
      "learning_rate": 0.00018948341433839161,
      "loss": 0.0375,
      "step": 1005
    },
    {
      "epoch": 1.730752688172043,
      "grad_norm": 0.55537206026372,
      "learning_rate": 0.00018945851306694967,
      "loss": 0.0185,
      "step": 1006
    },
    {
      "epoch": 1.7324731182795698,
      "grad_norm": 0.8338937183258236,
      "learning_rate": 0.00018943358398982468,
      "loss": 0.0593,
      "step": 1007
    },
    {
      "epoch": 1.734193548387097,
      "grad_norm": 0.9144290389314946,
      "learning_rate": 0.00018940862711476513,
      "loss": 0.0386,
      "step": 1008
    },
    {
      "epoch": 1.7359139784946236,
      "grad_norm": 1.011399429104105,
      "learning_rate": 0.00018938364244952812,
      "loss": 0.0596,
      "step": 1009
    },
    {
      "epoch": 1.7376344086021507,
      "grad_norm": 0.754657831048994,
      "learning_rate": 0.00018935863000187948,
      "loss": 0.0343,
      "step": 1010
    },
    {
      "epoch": 1.7393548387096773,
      "grad_norm": 0.8345190524875554,
      "learning_rate": 0.0001893335897795936,
      "loss": 0.0469,
      "step": 1011
    },
    {
      "epoch": 1.7410752688172044,
      "grad_norm": 1.2231496386692209,
      "learning_rate": 0.00018930852179045355,
      "loss": 0.0471,
      "step": 1012
    },
    {
      "epoch": 1.742795698924731,
      "grad_norm": 1.017388858299792,
      "learning_rate": 0.000189283426042251,
      "loss": 0.0472,
      "step": 1013
    },
    {
      "epoch": 1.7445161290322582,
      "grad_norm": 0.8498374761600644,
      "learning_rate": 0.00018925830254278632,
      "loss": 0.0432,
      "step": 1014
    },
    {
      "epoch": 1.7462365591397848,
      "grad_norm": 1.0195773929442773,
      "learning_rate": 0.00018923315129986835,
      "loss": 0.0497,
      "step": 1015
    },
    {
      "epoch": 1.747956989247312,
      "grad_norm": 1.0759214591979602,
      "learning_rate": 0.00018920797232131476,
      "loss": 0.0259,
      "step": 1016
    },
    {
      "epoch": 1.7496774193548386,
      "grad_norm": 1.4907027422329064,
      "learning_rate": 0.00018918276561495165,
      "loss": 0.0864,
      "step": 1017
    },
    {
      "epoch": 1.7513978494623657,
      "grad_norm": 1.3096804425076254,
      "learning_rate": 0.00018915753118861387,
      "loss": 0.0604,
      "step": 1018
    },
    {
      "epoch": 1.7531182795698925,
      "grad_norm": 1.1146324229881104,
      "learning_rate": 0.0001891322690501448,
      "loss": 0.0521,
      "step": 1019
    },
    {
      "epoch": 1.7548387096774194,
      "grad_norm": 1.5680491280091573,
      "learning_rate": 0.0001891069792073965,
      "loss": 0.041,
      "step": 1020
    },
    {
      "epoch": 1.7565591397849463,
      "grad_norm": 1.2310666002206752,
      "learning_rate": 0.00018908166166822963,
      "loss": 0.0548,
      "step": 1021
    },
    {
      "epoch": 1.7582795698924731,
      "grad_norm": 0.9029912254420722,
      "learning_rate": 0.0001890563164405134,
      "loss": 0.0239,
      "step": 1022
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4093013623900505,
      "learning_rate": 0.00018903094353212566,
      "loss": 0.0342,
      "step": 1023
    },
    {
      "epoch": 1.7617204301075269,
      "grad_norm": 1.9747750270695124,
      "learning_rate": 0.00018900554295095293,
      "loss": 0.0952,
      "step": 1024
    },
    {
      "epoch": 1.7634408602150538,
      "grad_norm": 1.1372151070884005,
      "learning_rate": 0.00018898011470489022,
      "loss": 0.0506,
      "step": 1025
    },
    {
      "epoch": 1.7651612903225806,
      "grad_norm": 1.1958404782075158,
      "learning_rate": 0.0001889546588018412,
      "loss": 0.1138,
      "step": 1026
    },
    {
      "epoch": 1.7668817204301075,
      "grad_norm": 1.1842067696116987,
      "learning_rate": 0.00018892917524971812,
      "loss": 0.0572,
      "step": 1027
    },
    {
      "epoch": 1.7686021505376344,
      "grad_norm": 1.0271099368908057,
      "learning_rate": 0.00018890366405644186,
      "loss": 0.0385,
      "step": 1028
    },
    {
      "epoch": 1.7703225806451612,
      "grad_norm": 1.3240088054272907,
      "learning_rate": 0.00018887812522994186,
      "loss": 0.0525,
      "step": 1029
    },
    {
      "epoch": 1.772043010752688,
      "grad_norm": 1.3784433877567388,
      "learning_rate": 0.0001888525587781561,
      "loss": 0.0798,
      "step": 1030
    },
    {
      "epoch": 1.7737634408602152,
      "grad_norm": 1.293731694325089,
      "learning_rate": 0.00018882696470903128,
      "loss": 0.0507,
      "step": 1031
    },
    {
      "epoch": 1.7754838709677419,
      "grad_norm": 0.7330301473831248,
      "learning_rate": 0.00018880134303052252,
      "loss": 0.0269,
      "step": 1032
    },
    {
      "epoch": 1.777204301075269,
      "grad_norm": 1.2239055360198001,
      "learning_rate": 0.00018877569375059364,
      "loss": 0.034,
      "step": 1033
    },
    {
      "epoch": 1.7789247311827956,
      "grad_norm": 1.4146644896296683,
      "learning_rate": 0.00018875001687721705,
      "loss": 0.0305,
      "step": 1034
    },
    {
      "epoch": 1.7806451612903227,
      "grad_norm": 1.1144308104355434,
      "learning_rate": 0.0001887243124183736,
      "loss": 0.0667,
      "step": 1035
    },
    {
      "epoch": 1.7823655913978493,
      "grad_norm": 0.8034498061634002,
      "learning_rate": 0.0001886985803820529,
      "loss": 0.0406,
      "step": 1036
    },
    {
      "epoch": 1.7840860215053764,
      "grad_norm": 0.6110492488055949,
      "learning_rate": 0.00018867282077625295,
      "loss": 0.0286,
      "step": 1037
    },
    {
      "epoch": 1.785806451612903,
      "grad_norm": 1.062047230657274,
      "learning_rate": 0.00018864703360898047,
      "loss": 0.0621,
      "step": 1038
    },
    {
      "epoch": 1.7875268817204302,
      "grad_norm": 1.0426914457516903,
      "learning_rate": 0.0001886212188882506,
      "loss": 0.0611,
      "step": 1039
    },
    {
      "epoch": 1.789247311827957,
      "grad_norm": 0.8773872219246222,
      "learning_rate": 0.0001885953766220872,
      "loss": 0.0367,
      "step": 1040
    },
    {
      "epoch": 1.790967741935484,
      "grad_norm": 1.459509231026125,
      "learning_rate": 0.00018856950681852262,
      "loss": 0.0418,
      "step": 1041
    },
    {
      "epoch": 1.7926881720430108,
      "grad_norm": 0.9245744699996237,
      "learning_rate": 0.00018854360948559773,
      "loss": 0.058,
      "step": 1042
    },
    {
      "epoch": 1.7944086021505377,
      "grad_norm": 1.2786822194011072,
      "learning_rate": 0.000188517684631362,
      "loss": 0.0667,
      "step": 1043
    },
    {
      "epoch": 1.7961290322580645,
      "grad_norm": 1.0236029470826613,
      "learning_rate": 0.00018849173226387342,
      "loss": 0.0479,
      "step": 1044
    },
    {
      "epoch": 1.7978494623655914,
      "grad_norm": 1.1750797905392176,
      "learning_rate": 0.00018846575239119865,
      "loss": 0.1067,
      "step": 1045
    },
    {
      "epoch": 1.7995698924731183,
      "grad_norm": 1.7625966225216931,
      "learning_rate": 0.00018843974502141272,
      "loss": 0.0781,
      "step": 1046
    },
    {
      "epoch": 1.8012903225806451,
      "grad_norm": 1.5861386883621944,
      "learning_rate": 0.0001884137101625993,
      "loss": 0.0894,
      "step": 1047
    },
    {
      "epoch": 1.803010752688172,
      "grad_norm": 1.170880807104716,
      "learning_rate": 0.00018838764782285069,
      "loss": 0.0439,
      "step": 1048
    },
    {
      "epoch": 1.8047311827956989,
      "grad_norm": 1.3071719712982626,
      "learning_rate": 0.00018836155801026753,
      "loss": 0.0485,
      "step": 1049
    },
    {
      "epoch": 1.8064516129032258,
      "grad_norm": 1.03309919894774,
      "learning_rate": 0.00018833544073295917,
      "loss": 0.0253,
      "step": 1050
    },
    {
      "epoch": 1.8081720430107526,
      "grad_norm": 0.740628125570029,
      "learning_rate": 0.00018830929599904342,
      "loss": 0.0224,
      "step": 1051
    },
    {
      "epoch": 1.8098924731182797,
      "grad_norm": 0.4242004833278315,
      "learning_rate": 0.00018828312381664666,
      "loss": 0.0117,
      "step": 1052
    },
    {
      "epoch": 1.8116129032258064,
      "grad_norm": 1.2076392251283599,
      "learning_rate": 0.00018825692419390376,
      "loss": 0.038,
      "step": 1053
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 1.0394897189489705,
      "learning_rate": 0.00018823069713895817,
      "loss": 0.0561,
      "step": 1054
    },
    {
      "epoch": 1.8150537634408601,
      "grad_norm": 1.0767088490423642,
      "learning_rate": 0.0001882044426599618,
      "loss": 0.073,
      "step": 1055
    },
    {
      "epoch": 1.8167741935483872,
      "grad_norm": 1.3452425397433334,
      "learning_rate": 0.00018817816076507513,
      "loss": 0.0595,
      "step": 1056
    },
    {
      "epoch": 1.8184946236559139,
      "grad_norm": 1.2080374127994826,
      "learning_rate": 0.00018815185146246716,
      "loss": 0.0516,
      "step": 1057
    },
    {
      "epoch": 1.820215053763441,
      "grad_norm": 0.5102882061498036,
      "learning_rate": 0.00018812551476031543,
      "loss": 0.0378,
      "step": 1058
    },
    {
      "epoch": 1.8219354838709676,
      "grad_norm": 1.2427355983784685,
      "learning_rate": 0.00018809915066680594,
      "loss": 0.0562,
      "step": 1059
    },
    {
      "epoch": 1.8236559139784947,
      "grad_norm": 1.4678108170079436,
      "learning_rate": 0.00018807275919013324,
      "loss": 0.094,
      "step": 1060
    },
    {
      "epoch": 1.8253763440860213,
      "grad_norm": 0.7580169403393163,
      "learning_rate": 0.0001880463403385004,
      "loss": 0.0331,
      "step": 1061
    },
    {
      "epoch": 1.8270967741935484,
      "grad_norm": 0.9592072010411204,
      "learning_rate": 0.00018801989412011894,
      "loss": 0.0352,
      "step": 1062
    },
    {
      "epoch": 1.8288172043010753,
      "grad_norm": 1.3088362996383234,
      "learning_rate": 0.00018799342054320897,
      "loss": 0.0524,
      "step": 1063
    },
    {
      "epoch": 1.8305376344086022,
      "grad_norm": 1.4324805031175896,
      "learning_rate": 0.00018796691961599904,
      "loss": 0.0619,
      "step": 1064
    },
    {
      "epoch": 1.832258064516129,
      "grad_norm": 1.1504153119687897,
      "learning_rate": 0.00018794039134672623,
      "loss": 0.0645,
      "step": 1065
    },
    {
      "epoch": 1.833978494623656,
      "grad_norm": 0.7154836166067997,
      "learning_rate": 0.00018791383574363614,
      "loss": 0.0268,
      "step": 1066
    },
    {
      "epoch": 1.8356989247311828,
      "grad_norm": 0.5146052668214554,
      "learning_rate": 0.0001878872528149828,
      "loss": 0.0248,
      "step": 1067
    },
    {
      "epoch": 1.8374193548387097,
      "grad_norm": 1.2594133603827937,
      "learning_rate": 0.00018786064256902875,
      "loss": 0.0765,
      "step": 1068
    },
    {
      "epoch": 1.8391397849462365,
      "grad_norm": 1.314794960703601,
      "learning_rate": 0.00018783400501404512,
      "loss": 0.0809,
      "step": 1069
    },
    {
      "epoch": 1.8408602150537634,
      "grad_norm": 1.2497831305750247,
      "learning_rate": 0.00018780734015831142,
      "loss": 0.1218,
      "step": 1070
    },
    {
      "epoch": 1.8425806451612903,
      "grad_norm": 1.1008755324805017,
      "learning_rate": 0.00018778064801011564,
      "loss": 0.0729,
      "step": 1071
    },
    {
      "epoch": 1.8443010752688171,
      "grad_norm": 1.0120899105952772,
      "learning_rate": 0.00018775392857775432,
      "loss": 0.0606,
      "step": 1072
    },
    {
      "epoch": 1.8460215053763442,
      "grad_norm": 0.4869706324179358,
      "learning_rate": 0.00018772718186953243,
      "loss": 0.0499,
      "step": 1073
    },
    {
      "epoch": 1.847741935483871,
      "grad_norm": 0.8689300890962496,
      "learning_rate": 0.00018770040789376345,
      "loss": 0.074,
      "step": 1074
    },
    {
      "epoch": 1.849462365591398,
      "grad_norm": 0.8951400313681763,
      "learning_rate": 0.00018767360665876935,
      "loss": 0.0489,
      "step": 1075
    },
    {
      "epoch": 1.8511827956989246,
      "grad_norm": 0.7399547966969395,
      "learning_rate": 0.00018764677817288052,
      "loss": 0.0425,
      "step": 1076
    },
    {
      "epoch": 1.8529032258064517,
      "grad_norm": 0.9513646940194117,
      "learning_rate": 0.00018761992244443584,
      "loss": 0.0452,
      "step": 1077
    },
    {
      "epoch": 1.8546236559139784,
      "grad_norm": 0.617428952074675,
      "learning_rate": 0.00018759303948178268,
      "loss": 0.0409,
      "step": 1078
    },
    {
      "epoch": 1.8563440860215055,
      "grad_norm": 1.2082696348847117,
      "learning_rate": 0.00018756612929327684,
      "loss": 0.0817,
      "step": 1079
    },
    {
      "epoch": 1.8580645161290321,
      "grad_norm": 1.3403045094880943,
      "learning_rate": 0.00018753919188728264,
      "loss": 0.077,
      "step": 1080
    },
    {
      "epoch": 1.8597849462365592,
      "grad_norm": 0.7695843336810038,
      "learning_rate": 0.00018751222727217276,
      "loss": 0.0781,
      "step": 1081
    },
    {
      "epoch": 1.8615053763440859,
      "grad_norm": 0.9273000223915944,
      "learning_rate": 0.00018748523545632846,
      "loss": 0.0597,
      "step": 1082
    },
    {
      "epoch": 1.863225806451613,
      "grad_norm": 0.5867171939133005,
      "learning_rate": 0.00018745821644813938,
      "loss": 0.027,
      "step": 1083
    },
    {
      "epoch": 1.8649462365591398,
      "grad_norm": 0.6451991751892442,
      "learning_rate": 0.00018743117025600355,
      "loss": 0.0304,
      "step": 1084
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.8399604304150577,
      "learning_rate": 0.00018740409688832764,
      "loss": 0.0513,
      "step": 1085
    },
    {
      "epoch": 1.8683870967741936,
      "grad_norm": 0.6000831637470346,
      "learning_rate": 0.00018737699635352657,
      "loss": 0.0462,
      "step": 1086
    },
    {
      "epoch": 1.8701075268817204,
      "grad_norm": 1.0560854331463296,
      "learning_rate": 0.0001873498686600238,
      "loss": 0.0569,
      "step": 1087
    },
    {
      "epoch": 1.8718279569892473,
      "grad_norm": 0.6292448205850514,
      "learning_rate": 0.00018732271381625127,
      "loss": 0.0263,
      "step": 1088
    },
    {
      "epoch": 1.8735483870967742,
      "grad_norm": 1.5491757376984825,
      "learning_rate": 0.00018729553183064926,
      "loss": 0.0584,
      "step": 1089
    },
    {
      "epoch": 1.875268817204301,
      "grad_norm": 0.5484596703721597,
      "learning_rate": 0.0001872683227116665,
      "loss": 0.0317,
      "step": 1090
    },
    {
      "epoch": 1.876989247311828,
      "grad_norm": 0.924068852096397,
      "learning_rate": 0.00018724108646776024,
      "loss": 0.0569,
      "step": 1091
    },
    {
      "epoch": 1.8787096774193548,
      "grad_norm": 1.8345652171082176,
      "learning_rate": 0.00018721382310739608,
      "loss": 0.0719,
      "step": 1092
    },
    {
      "epoch": 1.8804301075268817,
      "grad_norm": 1.1315083709627278,
      "learning_rate": 0.0001871865326390481,
      "loss": 0.0764,
      "step": 1093
    },
    {
      "epoch": 1.8821505376344088,
      "grad_norm": 1.2070200055549603,
      "learning_rate": 0.00018715921507119875,
      "loss": 0.066,
      "step": 1094
    },
    {
      "epoch": 1.8838709677419354,
      "grad_norm": 1.499244721219832,
      "learning_rate": 0.00018713187041233896,
      "loss": 0.0735,
      "step": 1095
    },
    {
      "epoch": 1.8855913978494625,
      "grad_norm": 2.1103854064692404,
      "learning_rate": 0.00018710449867096802,
      "loss": 0.141,
      "step": 1096
    },
    {
      "epoch": 1.8873118279569892,
      "grad_norm": 1.034563426743212,
      "learning_rate": 0.0001870770998555937,
      "loss": 0.0559,
      "step": 1097
    },
    {
      "epoch": 1.8890322580645162,
      "grad_norm": 0.9525479645160718,
      "learning_rate": 0.00018704967397473215,
      "loss": 0.0578,
      "step": 1098
    },
    {
      "epoch": 1.890752688172043,
      "grad_norm": 0.7564222335285837,
      "learning_rate": 0.00018702222103690797,
      "loss": 0.0504,
      "step": 1099
    },
    {
      "epoch": 1.89247311827957,
      "grad_norm": 0.6391290222871072,
      "learning_rate": 0.00018699474105065406,
      "loss": 0.0366,
      "step": 1100
    },
    {
      "epoch": 1.8941935483870966,
      "grad_norm": 0.7614306179951906,
      "learning_rate": 0.00018696723402451191,
      "loss": 0.0395,
      "step": 1101
    },
    {
      "epoch": 1.8959139784946237,
      "grad_norm": 0.5868222397419919,
      "learning_rate": 0.00018693969996703123,
      "loss": 0.0266,
      "step": 1102
    },
    {
      "epoch": 1.8976344086021504,
      "grad_norm": 0.9468367115667625,
      "learning_rate": 0.00018691213888677024,
      "loss": 0.0545,
      "step": 1103
    },
    {
      "epoch": 1.8993548387096775,
      "grad_norm": 1.1654019264034248,
      "learning_rate": 0.00018688455079229557,
      "loss": 0.0392,
      "step": 1104
    },
    {
      "epoch": 1.9010752688172043,
      "grad_norm": 0.7718366852606243,
      "learning_rate": 0.00018685693569218216,
      "loss": 0.0506,
      "step": 1105
    },
    {
      "epoch": 1.9027956989247312,
      "grad_norm": 0.7112437245248969,
      "learning_rate": 0.00018682929359501338,
      "loss": 0.0498,
      "step": 1106
    },
    {
      "epoch": 1.904516129032258,
      "grad_norm": 0.5328595263104011,
      "learning_rate": 0.00018680162450938106,
      "loss": 0.0204,
      "step": 1107
    },
    {
      "epoch": 1.906236559139785,
      "grad_norm": 0.8161733262723883,
      "learning_rate": 0.00018677392844388533,
      "loss": 0.0394,
      "step": 1108
    },
    {
      "epoch": 1.9079569892473118,
      "grad_norm": 0.8203358646951836,
      "learning_rate": 0.00018674620540713475,
      "loss": 0.0666,
      "step": 1109
    },
    {
      "epoch": 1.9096774193548387,
      "grad_norm": 1.35635745078069,
      "learning_rate": 0.00018671845540774626,
      "loss": 0.0677,
      "step": 1110
    },
    {
      "epoch": 1.9113978494623656,
      "grad_norm": 0.7016332356760987,
      "learning_rate": 0.00018669067845434513,
      "loss": 0.0285,
      "step": 1111
    },
    {
      "epoch": 1.9131182795698924,
      "grad_norm": 0.8441268795761591,
      "learning_rate": 0.0001866628745555651,
      "loss": 0.0339,
      "step": 1112
    },
    {
      "epoch": 1.9148387096774193,
      "grad_norm": 0.993132298236028,
      "learning_rate": 0.00018663504372004824,
      "loss": 0.0494,
      "step": 1113
    },
    {
      "epoch": 1.9165591397849462,
      "grad_norm": 1.8664367529876695,
      "learning_rate": 0.00018660718595644494,
      "loss": 0.0707,
      "step": 1114
    },
    {
      "epoch": 1.9182795698924733,
      "grad_norm": 1.197249166659433,
      "learning_rate": 0.00018657930127341407,
      "loss": 0.0354,
      "step": 1115
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.6318020085771758,
      "learning_rate": 0.00018655138967962277,
      "loss": 0.0466,
      "step": 1116
    },
    {
      "epoch": 1.921720430107527,
      "grad_norm": 0.864117754043066,
      "learning_rate": 0.00018652345118374655,
      "loss": 0.0321,
      "step": 1117
    },
    {
      "epoch": 1.9234408602150537,
      "grad_norm": 1.274608157458689,
      "learning_rate": 0.00018649548579446936,
      "loss": 0.0528,
      "step": 1118
    },
    {
      "epoch": 1.9251612903225808,
      "grad_norm": 0.9604227176230848,
      "learning_rate": 0.00018646749352048346,
      "loss": 0.0249,
      "step": 1119
    },
    {
      "epoch": 1.9268817204301074,
      "grad_norm": 0.7523327073190794,
      "learning_rate": 0.00018643947437048944,
      "loss": 0.0303,
      "step": 1120
    },
    {
      "epoch": 1.9286021505376345,
      "grad_norm": 1.169941402154699,
      "learning_rate": 0.00018641142835319627,
      "loss": 0.0471,
      "step": 1121
    },
    {
      "epoch": 1.9303225806451612,
      "grad_norm": 0.926396783743241,
      "learning_rate": 0.00018638335547732133,
      "loss": 0.0381,
      "step": 1122
    },
    {
      "epoch": 1.9320430107526883,
      "grad_norm": 1.3593799873596708,
      "learning_rate": 0.0001863552557515902,
      "loss": 0.0566,
      "step": 1123
    },
    {
      "epoch": 1.933763440860215,
      "grad_norm": 1.4823524778450337,
      "learning_rate": 0.00018632712918473698,
      "loss": 0.057,
      "step": 1124
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.8311768201163631,
      "learning_rate": 0.000186298975785504,
      "loss": 0.0364,
      "step": 1125
    },
    {
      "epoch": 1.9372043010752689,
      "grad_norm": 0.7160810673468609,
      "learning_rate": 0.0001862707955626419,
      "loss": 0.0322,
      "step": 1126
    },
    {
      "epoch": 1.9389247311827957,
      "grad_norm": 1.3172137604399055,
      "learning_rate": 0.0001862425885249098,
      "loss": 0.067,
      "step": 1127
    },
    {
      "epoch": 1.9406451612903226,
      "grad_norm": 0.9688332512019652,
      "learning_rate": 0.000186214354681075,
      "loss": 0.0249,
      "step": 1128
    },
    {
      "epoch": 1.9423655913978495,
      "grad_norm": 0.8128651525991772,
      "learning_rate": 0.0001861860940399133,
      "loss": 0.0237,
      "step": 1129
    },
    {
      "epoch": 1.9440860215053763,
      "grad_norm": 0.2988471422602086,
      "learning_rate": 0.00018615780661020864,
      "loss": 0.0074,
      "step": 1130
    },
    {
      "epoch": 1.9458064516129032,
      "grad_norm": 1.0861848073236293,
      "learning_rate": 0.0001861294924007534,
      "loss": 0.0475,
      "step": 1131
    },
    {
      "epoch": 1.94752688172043,
      "grad_norm": 1.2274144214695681,
      "learning_rate": 0.0001861011514203483,
      "loss": 0.0551,
      "step": 1132
    },
    {
      "epoch": 1.949247311827957,
      "grad_norm": 0.6642962622542657,
      "learning_rate": 0.00018607278367780233,
      "loss": 0.0436,
      "step": 1133
    },
    {
      "epoch": 1.9509677419354838,
      "grad_norm": 1.3634804877598203,
      "learning_rate": 0.00018604438918193273,
      "loss": 0.0622,
      "step": 1134
    },
    {
      "epoch": 1.9526881720430107,
      "grad_norm": 0.8276312785309424,
      "learning_rate": 0.00018601596794156527,
      "loss": 0.0329,
      "step": 1135
    },
    {
      "epoch": 1.9544086021505378,
      "grad_norm": 1.4020275147797916,
      "learning_rate": 0.0001859875199655338,
      "loss": 0.0676,
      "step": 1136
    },
    {
      "epoch": 1.9561290322580644,
      "grad_norm": 1.0394044647784262,
      "learning_rate": 0.00018595904526268062,
      "loss": 0.0488,
      "step": 1137
    },
    {
      "epoch": 1.9578494623655915,
      "grad_norm": 1.2601170460340712,
      "learning_rate": 0.0001859305438418563,
      "loss": 0.0742,
      "step": 1138
    },
    {
      "epoch": 1.9595698924731182,
      "grad_norm": 1.7518321729587716,
      "learning_rate": 0.0001859020157119197,
      "loss": 0.0731,
      "step": 1139
    },
    {
      "epoch": 1.9612903225806453,
      "grad_norm": 0.7175153091340164,
      "learning_rate": 0.000185873460881738,
      "loss": 0.0272,
      "step": 1140
    },
    {
      "epoch": 1.963010752688172,
      "grad_norm": 1.1736708272184622,
      "learning_rate": 0.00018584487936018661,
      "loss": 0.0833,
      "step": 1141
    },
    {
      "epoch": 1.964731182795699,
      "grad_norm": 1.642994959048472,
      "learning_rate": 0.00018581627115614943,
      "loss": 0.0353,
      "step": 1142
    },
    {
      "epoch": 1.9664516129032257,
      "grad_norm": 0.6616939401381763,
      "learning_rate": 0.00018578763627851837,
      "loss": 0.0435,
      "step": 1143
    },
    {
      "epoch": 1.9681720430107528,
      "grad_norm": 0.779105210295479,
      "learning_rate": 0.00018575897473619395,
      "loss": 0.0234,
      "step": 1144
    },
    {
      "epoch": 1.9698924731182794,
      "grad_norm": 1.139271490981447,
      "learning_rate": 0.00018573028653808465,
      "loss": 0.0915,
      "step": 1145
    },
    {
      "epoch": 1.9716129032258065,
      "grad_norm": 0.5376182155886144,
      "learning_rate": 0.00018570157169310752,
      "loss": 0.0172,
      "step": 1146
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 1.7527463075704677,
      "learning_rate": 0.00018567283021018769,
      "loss": 0.0606,
      "step": 1147
    },
    {
      "epoch": 1.9750537634408603,
      "grad_norm": 1.1869989134412404,
      "learning_rate": 0.0001856440620982587,
      "loss": 0.039,
      "step": 1148
    },
    {
      "epoch": 1.9767741935483871,
      "grad_norm": 1.2782994570208641,
      "learning_rate": 0.00018561526736626224,
      "loss": 0.0554,
      "step": 1149
    },
    {
      "epoch": 1.978494623655914,
      "grad_norm": 1.3091194153836467,
      "learning_rate": 0.00018558644602314846,
      "loss": 0.0512,
      "step": 1150
    },
    {
      "epoch": 1.9802150537634409,
      "grad_norm": 1.2444469046633502,
      "learning_rate": 0.00018555759807787557,
      "loss": 0.0722,
      "step": 1151
    },
    {
      "epoch": 1.9819354838709677,
      "grad_norm": 1.857531156664683,
      "learning_rate": 0.00018552872353941018,
      "loss": 0.0822,
      "step": 1152
    },
    {
      "epoch": 1.9836559139784946,
      "grad_norm": 1.9098900154505944,
      "learning_rate": 0.00018549982241672716,
      "loss": 0.0805,
      "step": 1153
    },
    {
      "epoch": 1.9853763440860215,
      "grad_norm": 1.095114736675963,
      "learning_rate": 0.00018547089471880962,
      "loss": 0.0483,
      "step": 1154
    },
    {
      "epoch": 1.9870967741935484,
      "grad_norm": 0.8179793150872322,
      "learning_rate": 0.00018544194045464886,
      "loss": 0.0664,
      "step": 1155
    },
    {
      "epoch": 1.9888172043010752,
      "grad_norm": 0.43567498723803894,
      "learning_rate": 0.0001854129596332446,
      "loss": 0.0388,
      "step": 1156
    },
    {
      "epoch": 1.990537634408602,
      "grad_norm": 1.1017805326836578,
      "learning_rate": 0.00018538395226360462,
      "loss": 0.0506,
      "step": 1157
    },
    {
      "epoch": 1.992258064516129,
      "grad_norm": 1.038353963820053,
      "learning_rate": 0.00018535491835474516,
      "loss": 0.0563,
      "step": 1158
    },
    {
      "epoch": 1.993978494623656,
      "grad_norm": 0.9944540445169332,
      "learning_rate": 0.00018532585791569052,
      "loss": 0.0644,
      "step": 1159
    },
    {
      "epoch": 1.9956989247311827,
      "grad_norm": 0.6982714987619175,
      "learning_rate": 0.00018529677095547337,
      "loss": 0.0505,
      "step": 1160
    },
    {
      "epoch": 1.9974193548387098,
      "grad_norm": 0.9777052436735996,
      "learning_rate": 0.00018526765748313456,
      "loss": 0.0577,
      "step": 1161
    },
    {
      "epoch": 1.9991397849462365,
      "grad_norm": 0.9731266563887911,
      "learning_rate": 0.00018523851750772318,
      "loss": 0.0641,
      "step": 1162
    },
    {
      "epoch": 2.0008602150537635,
      "grad_norm": 1.108577622334509,
      "learning_rate": 0.0001852093510382966,
      "loss": 0.0666,
      "step": 1163
    },
    {
      "epoch": 2.00258064516129,
      "grad_norm": 0.6484635246689353,
      "learning_rate": 0.00018518015808392045,
      "loss": 0.0382,
      "step": 1164
    },
    {
      "epoch": 2.0043010752688173,
      "grad_norm": 0.7720271913134092,
      "learning_rate": 0.00018515093865366846,
      "loss": 0.0333,
      "step": 1165
    },
    {
      "epoch": 2.006021505376344,
      "grad_norm": 0.5615632148169785,
      "learning_rate": 0.0001851216927566227,
      "loss": 0.0339,
      "step": 1166
    },
    {
      "epoch": 2.007741935483871,
      "grad_norm": 0.7861314928147745,
      "learning_rate": 0.00018509242040187348,
      "loss": 0.0429,
      "step": 1167
    },
    {
      "epoch": 2.0094623655913977,
      "grad_norm": 1.0091080508575145,
      "learning_rate": 0.00018506312159851927,
      "loss": 0.0594,
      "step": 1168
    },
    {
      "epoch": 2.0111827956989248,
      "grad_norm": 0.709047501187193,
      "learning_rate": 0.0001850337963556668,
      "loss": 0.0411,
      "step": 1169
    },
    {
      "epoch": 2.0129032258064514,
      "grad_norm": 0.4820394195008297,
      "learning_rate": 0.000185004444682431,
      "loss": 0.0283,
      "step": 1170
    },
    {
      "epoch": 2.0146236559139785,
      "grad_norm": 0.5638975897970744,
      "learning_rate": 0.00018497506658793496,
      "loss": 0.0353,
      "step": 1171
    },
    {
      "epoch": 2.016344086021505,
      "grad_norm": 0.635582869578704,
      "learning_rate": 0.00018494566208131016,
      "loss": 0.0198,
      "step": 1172
    },
    {
      "epoch": 2.0180645161290323,
      "grad_norm": 0.6650407523401637,
      "learning_rate": 0.00018491623117169605,
      "loss": 0.0253,
      "step": 1173
    },
    {
      "epoch": 2.0197849462365594,
      "grad_norm": 0.5676084357769616,
      "learning_rate": 0.00018488677386824045,
      "loss": 0.0411,
      "step": 1174
    },
    {
      "epoch": 2.021505376344086,
      "grad_norm": 0.46743876026656017,
      "learning_rate": 0.00018485729018009937,
      "loss": 0.019,
      "step": 1175
    },
    {
      "epoch": 2.023225806451613,
      "grad_norm": 1.0108217650704991,
      "learning_rate": 0.00018482778011643696,
      "loss": 0.0386,
      "step": 1176
    },
    {
      "epoch": 2.0249462365591397,
      "grad_norm": 1.4630291864796907,
      "learning_rate": 0.00018479824368642565,
      "loss": 0.0475,
      "step": 1177
    },
    {
      "epoch": 2.026666666666667,
      "grad_norm": 0.6485820303537846,
      "learning_rate": 0.00018476868089924593,
      "loss": 0.0159,
      "step": 1178
    },
    {
      "epoch": 2.0283870967741935,
      "grad_norm": 1.5111616075621894,
      "learning_rate": 0.00018473909176408663,
      "loss": 0.0496,
      "step": 1179
    },
    {
      "epoch": 2.0301075268817206,
      "grad_norm": 0.30944511934994445,
      "learning_rate": 0.0001847094762901447,
      "loss": 0.0084,
      "step": 1180
    },
    {
      "epoch": 2.0318279569892472,
      "grad_norm": 1.3092421187180663,
      "learning_rate": 0.00018467983448662527,
      "loss": 0.0415,
      "step": 1181
    },
    {
      "epoch": 2.0335483870967743,
      "grad_norm": 0.6116521150081902,
      "learning_rate": 0.00018465016636274166,
      "loss": 0.0152,
      "step": 1182
    },
    {
      "epoch": 2.035268817204301,
      "grad_norm": 1.0090220721584833,
      "learning_rate": 0.00018462047192771542,
      "loss": 0.0324,
      "step": 1183
    },
    {
      "epoch": 2.036989247311828,
      "grad_norm": 1.1042114501834388,
      "learning_rate": 0.00018459075119077616,
      "loss": 0.0198,
      "step": 1184
    },
    {
      "epoch": 2.0387096774193547,
      "grad_norm": 0.9250210720106758,
      "learning_rate": 0.00018456100416116184,
      "loss": 0.0119,
      "step": 1185
    },
    {
      "epoch": 2.040430107526882,
      "grad_norm": 1.524856696149976,
      "learning_rate": 0.0001845312308481184,
      "loss": 0.0322,
      "step": 1186
    },
    {
      "epoch": 2.0421505376344085,
      "grad_norm": 1.0765915853077574,
      "learning_rate": 0.00018450143126090015,
      "loss": 0.0266,
      "step": 1187
    },
    {
      "epoch": 2.0438709677419356,
      "grad_norm": 0.9931146625869293,
      "learning_rate": 0.00018447160540876933,
      "loss": 0.0112,
      "step": 1188
    },
    {
      "epoch": 2.045591397849462,
      "grad_norm": 0.9511553660043661,
      "learning_rate": 0.0001844417533009966,
      "loss": 0.0715,
      "step": 1189
    },
    {
      "epoch": 2.0473118279569893,
      "grad_norm": 0.6146013870947227,
      "learning_rate": 0.00018441187494686053,
      "loss": 0.0226,
      "step": 1190
    },
    {
      "epoch": 2.049032258064516,
      "grad_norm": 1.1585744891454395,
      "learning_rate": 0.0001843819703556481,
      "loss": 0.0521,
      "step": 1191
    },
    {
      "epoch": 2.050752688172043,
      "grad_norm": 0.7446260347000311,
      "learning_rate": 0.00018435203953665424,
      "loss": 0.0685,
      "step": 1192
    },
    {
      "epoch": 2.0524731182795697,
      "grad_norm": 0.562130138383207,
      "learning_rate": 0.00018432208249918213,
      "loss": 0.0104,
      "step": 1193
    },
    {
      "epoch": 2.054193548387097,
      "grad_norm": 1.3204462289298884,
      "learning_rate": 0.00018429209925254308,
      "loss": 0.0293,
      "step": 1194
    },
    {
      "epoch": 2.055913978494624,
      "grad_norm": 0.47295538077533633,
      "learning_rate": 0.00018426208980605653,
      "loss": 0.0237,
      "step": 1195
    },
    {
      "epoch": 2.0576344086021505,
      "grad_norm": 0.7902715245669388,
      "learning_rate": 0.0001842320541690501,
      "loss": 0.0108,
      "step": 1196
    },
    {
      "epoch": 2.0593548387096776,
      "grad_norm": 0.9694487142431981,
      "learning_rate": 0.00018420199235085952,
      "loss": 0.0382,
      "step": 1197
    },
    {
      "epoch": 2.0610752688172043,
      "grad_norm": 0.708202219552234,
      "learning_rate": 0.00018417190436082866,
      "loss": 0.0503,
      "step": 1198
    },
    {
      "epoch": 2.0627956989247314,
      "grad_norm": 0.6651059612249248,
      "learning_rate": 0.00018414179020830956,
      "loss": 0.0324,
      "step": 1199
    },
    {
      "epoch": 2.064516129032258,
      "grad_norm": 1.5339309878371254,
      "learning_rate": 0.00018411164990266235,
      "loss": 0.0228,
      "step": 1200
    },
    {
      "epoch": 2.066236559139785,
      "grad_norm": 0.8788373013379032,
      "learning_rate": 0.0001840814834532553,
      "loss": 0.0335,
      "step": 1201
    },
    {
      "epoch": 2.0679569892473117,
      "grad_norm": 0.7064829059797642,
      "learning_rate": 0.0001840512908694648,
      "loss": 0.0189,
      "step": 1202
    },
    {
      "epoch": 2.069677419354839,
      "grad_norm": 0.46363477826938654,
      "learning_rate": 0.00018402107216067534,
      "loss": 0.0126,
      "step": 1203
    },
    {
      "epoch": 2.0713978494623655,
      "grad_norm": 0.2975878605591272,
      "learning_rate": 0.00018399082733627965,
      "loss": 0.008,
      "step": 1204
    },
    {
      "epoch": 2.0731182795698926,
      "grad_norm": 0.5100559768676892,
      "learning_rate": 0.00018396055640567847,
      "loss": 0.0105,
      "step": 1205
    },
    {
      "epoch": 2.0748387096774192,
      "grad_norm": 0.6060094417214883,
      "learning_rate": 0.00018393025937828058,
      "loss": 0.0206,
      "step": 1206
    },
    {
      "epoch": 2.0765591397849463,
      "grad_norm": 0.8776868982378054,
      "learning_rate": 0.00018389993626350307,
      "loss": 0.0499,
      "step": 1207
    },
    {
      "epoch": 2.078279569892473,
      "grad_norm": 0.7027154954824054,
      "learning_rate": 0.000183869587070771,
      "loss": 0.0133,
      "step": 1208
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.32016036556018257,
      "learning_rate": 0.00018383921180951758,
      "loss": 0.0071,
      "step": 1209
    },
    {
      "epoch": 2.0817204301075267,
      "grad_norm": 1.1455129773835582,
      "learning_rate": 0.00018380881048918405,
      "loss": 0.0237,
      "step": 1210
    },
    {
      "epoch": 2.083440860215054,
      "grad_norm": 1.1342480123229932,
      "learning_rate": 0.00018377838311921992,
      "loss": 0.0439,
      "step": 1211
    },
    {
      "epoch": 2.0851612903225805,
      "grad_norm": 0.7016611438223858,
      "learning_rate": 0.00018374792970908262,
      "loss": 0.0142,
      "step": 1212
    },
    {
      "epoch": 2.0868817204301076,
      "grad_norm": 0.8292434588486011,
      "learning_rate": 0.00018371745026823772,
      "loss": 0.0134,
      "step": 1213
    },
    {
      "epoch": 2.088602150537634,
      "grad_norm": 0.5908632090216162,
      "learning_rate": 0.00018368694480615897,
      "loss": 0.0126,
      "step": 1214
    },
    {
      "epoch": 2.0903225806451613,
      "grad_norm": 1.983425855286128,
      "learning_rate": 0.0001836564133323281,
      "loss": 0.0502,
      "step": 1215
    },
    {
      "epoch": 2.092043010752688,
      "grad_norm": 0.7450673045631425,
      "learning_rate": 0.000183625855856235,
      "loss": 0.0139,
      "step": 1216
    },
    {
      "epoch": 2.093763440860215,
      "grad_norm": 1.6867769358027151,
      "learning_rate": 0.00018359527238737754,
      "loss": 0.0456,
      "step": 1217
    },
    {
      "epoch": 2.095483870967742,
      "grad_norm": 1.4601949623026984,
      "learning_rate": 0.00018356466293526183,
      "loss": 0.0436,
      "step": 1218
    },
    {
      "epoch": 2.097204301075269,
      "grad_norm": 0.3187290794654162,
      "learning_rate": 0.00018353402750940188,
      "loss": 0.0053,
      "step": 1219
    },
    {
      "epoch": 2.098924731182796,
      "grad_norm": 1.414455285297145,
      "learning_rate": 0.00018350336611931993,
      "loss": 0.0461,
      "step": 1220
    },
    {
      "epoch": 2.1006451612903225,
      "grad_norm": 0.357219947790833,
      "learning_rate": 0.00018347267877454618,
      "loss": 0.0071,
      "step": 1221
    },
    {
      "epoch": 2.1023655913978496,
      "grad_norm": 1.2257961587863644,
      "learning_rate": 0.0001834419654846189,
      "loss": 0.0232,
      "step": 1222
    },
    {
      "epoch": 2.1040860215053763,
      "grad_norm": 1.4717709849226401,
      "learning_rate": 0.00018341122625908454,
      "loss": 0.0441,
      "step": 1223
    },
    {
      "epoch": 2.1058064516129034,
      "grad_norm": 1.3877821697671318,
      "learning_rate": 0.0001833804611074975,
      "loss": 0.03,
      "step": 1224
    },
    {
      "epoch": 2.10752688172043,
      "grad_norm": 1.2143859481710824,
      "learning_rate": 0.0001833496700394202,
      "loss": 0.026,
      "step": 1225
    },
    {
      "epoch": 2.109247311827957,
      "grad_norm": 0.922666473001719,
      "learning_rate": 0.0001833188530644233,
      "loss": 0.0275,
      "step": 1226
    },
    {
      "epoch": 2.1109677419354838,
      "grad_norm": 0.5489621509935501,
      "learning_rate": 0.0001832880101920853,
      "loss": 0.0159,
      "step": 1227
    },
    {
      "epoch": 2.112688172043011,
      "grad_norm": 1.5199928859935554,
      "learning_rate": 0.00018325714143199292,
      "loss": 0.0263,
      "step": 1228
    },
    {
      "epoch": 2.1144086021505375,
      "grad_norm": 1.189723313965922,
      "learning_rate": 0.00018322624679374078,
      "loss": 0.0575,
      "step": 1229
    },
    {
      "epoch": 2.1161290322580646,
      "grad_norm": 1.4500622062606408,
      "learning_rate": 0.00018319532628693167,
      "loss": 0.0328,
      "step": 1230
    },
    {
      "epoch": 2.1178494623655912,
      "grad_norm": 1.1087604531705824,
      "learning_rate": 0.00018316437992117637,
      "loss": 0.0223,
      "step": 1231
    },
    {
      "epoch": 2.1195698924731183,
      "grad_norm": 0.5030695359737077,
      "learning_rate": 0.00018313340770609367,
      "loss": 0.0084,
      "step": 1232
    },
    {
      "epoch": 2.121290322580645,
      "grad_norm": 0.30692321905206543,
      "learning_rate": 0.00018310240965131041,
      "loss": 0.0065,
      "step": 1233
    },
    {
      "epoch": 2.123010752688172,
      "grad_norm": 0.23239455251915192,
      "learning_rate": 0.0001830713857664615,
      "loss": 0.0036,
      "step": 1234
    },
    {
      "epoch": 2.1247311827956987,
      "grad_norm": 0.48009140151884505,
      "learning_rate": 0.00018304033606118982,
      "loss": 0.013,
      "step": 1235
    },
    {
      "epoch": 2.126451612903226,
      "grad_norm": 1.5432487561652553,
      "learning_rate": 0.00018300926054514634,
      "loss": 0.0427,
      "step": 1236
    },
    {
      "epoch": 2.1281720430107525,
      "grad_norm": 1.4808976005089973,
      "learning_rate": 0.00018297815922799,
      "loss": 0.0171,
      "step": 1237
    },
    {
      "epoch": 2.1298924731182796,
      "grad_norm": 1.1922875950391956,
      "learning_rate": 0.00018294703211938775,
      "loss": 0.0323,
      "step": 1238
    },
    {
      "epoch": 2.1316129032258067,
      "grad_norm": 0.6663523690986505,
      "learning_rate": 0.00018291587922901462,
      "loss": 0.0115,
      "step": 1239
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 2.204120008404529,
      "learning_rate": 0.0001828847005665536,
      "loss": 0.0344,
      "step": 1240
    },
    {
      "epoch": 2.1350537634408604,
      "grad_norm": 1.8089816386979054,
      "learning_rate": 0.0001828534961416957,
      "loss": 0.0264,
      "step": 1241
    },
    {
      "epoch": 2.136774193548387,
      "grad_norm": 0.7503054061328226,
      "learning_rate": 0.00018282226596413997,
      "loss": 0.0211,
      "step": 1242
    },
    {
      "epoch": 2.138494623655914,
      "grad_norm": 1.1853715360933987,
      "learning_rate": 0.00018279101004359344,
      "loss": 0.0298,
      "step": 1243
    },
    {
      "epoch": 2.140215053763441,
      "grad_norm": 1.2983192793406237,
      "learning_rate": 0.0001827597283897711,
      "loss": 0.0512,
      "step": 1244
    },
    {
      "epoch": 2.141935483870968,
      "grad_norm": 0.7937099954838333,
      "learning_rate": 0.000182728421012396,
      "loss": 0.0094,
      "step": 1245
    },
    {
      "epoch": 2.1436559139784945,
      "grad_norm": 0.6135274597734098,
      "learning_rate": 0.00018269708792119921,
      "loss": 0.0315,
      "step": 1246
    },
    {
      "epoch": 2.1453763440860216,
      "grad_norm": 0.5496450055308473,
      "learning_rate": 0.00018266572912591968,
      "loss": 0.0103,
      "step": 1247
    },
    {
      "epoch": 2.1470967741935483,
      "grad_norm": 1.6207760588956075,
      "learning_rate": 0.00018263434463630445,
      "loss": 0.0344,
      "step": 1248
    },
    {
      "epoch": 2.1488172043010754,
      "grad_norm": 1.3510949222988695,
      "learning_rate": 0.00018260293446210852,
      "loss": 0.025,
      "step": 1249
    },
    {
      "epoch": 2.150537634408602,
      "grad_norm": 1.097941116759815,
      "learning_rate": 0.00018257149861309485,
      "loss": 0.046,
      "step": 1250
    },
    {
      "epoch": 2.152258064516129,
      "grad_norm": 0.3451650957481371,
      "learning_rate": 0.0001825400370990344,
      "loss": 0.006,
      "step": 1251
    },
    {
      "epoch": 2.1539784946236558,
      "grad_norm": 1.2780652272978525,
      "learning_rate": 0.00018250854992970608,
      "loss": 0.0282,
      "step": 1252
    },
    {
      "epoch": 2.155698924731183,
      "grad_norm": 0.704843842274336,
      "learning_rate": 0.00018247703711489686,
      "loss": 0.0099,
      "step": 1253
    },
    {
      "epoch": 2.1574193548387095,
      "grad_norm": 0.6970657595835243,
      "learning_rate": 0.00018244549866440157,
      "loss": 0.0162,
      "step": 1254
    },
    {
      "epoch": 2.1591397849462366,
      "grad_norm": 0.5865171844978369,
      "learning_rate": 0.00018241393458802305,
      "loss": 0.0092,
      "step": 1255
    },
    {
      "epoch": 2.1608602150537632,
      "grad_norm": 0.7528562123376513,
      "learning_rate": 0.00018238234489557215,
      "loss": 0.0083,
      "step": 1256
    },
    {
      "epoch": 2.1625806451612903,
      "grad_norm": 1.5219173863631816,
      "learning_rate": 0.00018235072959686766,
      "loss": 0.036,
      "step": 1257
    },
    {
      "epoch": 2.164301075268817,
      "grad_norm": 0.6078254984466803,
      "learning_rate": 0.0001823190887017362,
      "loss": 0.0099,
      "step": 1258
    },
    {
      "epoch": 2.166021505376344,
      "grad_norm": 1.1155891472788644,
      "learning_rate": 0.0001822874222200126,
      "loss": 0.0378,
      "step": 1259
    },
    {
      "epoch": 2.167741935483871,
      "grad_norm": 1.4110481529982903,
      "learning_rate": 0.00018225573016153945,
      "loss": 0.0291,
      "step": 1260
    },
    {
      "epoch": 2.169462365591398,
      "grad_norm": 2.8127869448609153,
      "learning_rate": 0.00018222401253616732,
      "loss": 0.0784,
      "step": 1261
    },
    {
      "epoch": 2.171182795698925,
      "grad_norm": 1.558624915877623,
      "learning_rate": 0.00018219226935375476,
      "loss": 0.0614,
      "step": 1262
    },
    {
      "epoch": 2.1729032258064516,
      "grad_norm": 1.485454468941367,
      "learning_rate": 0.00018216050062416826,
      "loss": 0.0388,
      "step": 1263
    },
    {
      "epoch": 2.1746236559139787,
      "grad_norm": 1.2993697053618205,
      "learning_rate": 0.00018212870635728222,
      "loss": 0.0195,
      "step": 1264
    },
    {
      "epoch": 2.1763440860215053,
      "grad_norm": 0.8494635949326077,
      "learning_rate": 0.00018209688656297904,
      "loss": 0.0106,
      "step": 1265
    },
    {
      "epoch": 2.1780645161290324,
      "grad_norm": 0.19417482477088233,
      "learning_rate": 0.000182065041251149,
      "loss": 0.0046,
      "step": 1266
    },
    {
      "epoch": 2.179784946236559,
      "grad_norm": 1.3284174334688812,
      "learning_rate": 0.0001820331704316903,
      "loss": 0.0455,
      "step": 1267
    },
    {
      "epoch": 2.181505376344086,
      "grad_norm": 0.8141270064578598,
      "learning_rate": 0.00018200127411450916,
      "loss": 0.0201,
      "step": 1268
    },
    {
      "epoch": 2.183225806451613,
      "grad_norm": 1.5730658432295281,
      "learning_rate": 0.00018196935230951956,
      "loss": 0.0259,
      "step": 1269
    },
    {
      "epoch": 2.18494623655914,
      "grad_norm": 1.5070793259147848,
      "learning_rate": 0.00018193740502664362,
      "loss": 0.0261,
      "step": 1270
    },
    {
      "epoch": 2.1866666666666665,
      "grad_norm": 1.1715394727598427,
      "learning_rate": 0.00018190543227581118,
      "loss": 0.0252,
      "step": 1271
    },
    {
      "epoch": 2.1883870967741936,
      "grad_norm": 0.665032484522972,
      "learning_rate": 0.0001818734340669601,
      "loss": 0.0181,
      "step": 1272
    },
    {
      "epoch": 2.1901075268817203,
      "grad_norm": 1.1384707658170101,
      "learning_rate": 0.0001818414104100361,
      "loss": 0.0479,
      "step": 1273
    },
    {
      "epoch": 2.1918279569892474,
      "grad_norm": 0.6643739341390651,
      "learning_rate": 0.0001818093613149929,
      "loss": 0.0155,
      "step": 1274
    },
    {
      "epoch": 2.193548387096774,
      "grad_norm": 1.549371506150755,
      "learning_rate": 0.00018177728679179205,
      "loss": 0.0283,
      "step": 1275
    },
    {
      "epoch": 2.195268817204301,
      "grad_norm": 0.9541353111570985,
      "learning_rate": 0.000181745186850403,
      "loss": 0.0118,
      "step": 1276
    },
    {
      "epoch": 2.1969892473118278,
      "grad_norm": 0.5767725509399356,
      "learning_rate": 0.0001817130615008031,
      "loss": 0.0225,
      "step": 1277
    },
    {
      "epoch": 2.198709677419355,
      "grad_norm": 0.6687639123533278,
      "learning_rate": 0.00018168091075297768,
      "loss": 0.0121,
      "step": 1278
    },
    {
      "epoch": 2.2004301075268815,
      "grad_norm": 0.9621043172917948,
      "learning_rate": 0.00018164873461691986,
      "loss": 0.0309,
      "step": 1279
    },
    {
      "epoch": 2.2021505376344086,
      "grad_norm": 0.9550951756200777,
      "learning_rate": 0.0001816165331026307,
      "loss": 0.0395,
      "step": 1280
    },
    {
      "epoch": 2.2038709677419357,
      "grad_norm": 0.8466619426951139,
      "learning_rate": 0.00018158430622011918,
      "loss": 0.0309,
      "step": 1281
    },
    {
      "epoch": 2.2055913978494623,
      "grad_norm": 0.8486993518966122,
      "learning_rate": 0.00018155205397940208,
      "loss": 0.0269,
      "step": 1282
    },
    {
      "epoch": 2.2073118279569894,
      "grad_norm": 0.7756480039409985,
      "learning_rate": 0.00018151977639050415,
      "loss": 0.0159,
      "step": 1283
    },
    {
      "epoch": 2.209032258064516,
      "grad_norm": 0.9090979011700154,
      "learning_rate": 0.00018148747346345793,
      "loss": 0.0268,
      "step": 1284
    },
    {
      "epoch": 2.210752688172043,
      "grad_norm": 0.2715577724438341,
      "learning_rate": 0.0001814551452083039,
      "loss": 0.0076,
      "step": 1285
    },
    {
      "epoch": 2.21247311827957,
      "grad_norm": 2.0424082601431333,
      "learning_rate": 0.0001814227916350904,
      "loss": 0.0411,
      "step": 1286
    },
    {
      "epoch": 2.214193548387097,
      "grad_norm": 0.9555811976788414,
      "learning_rate": 0.00018139041275387364,
      "loss": 0.029,
      "step": 1287
    },
    {
      "epoch": 2.2159139784946236,
      "grad_norm": 0.9857133195215917,
      "learning_rate": 0.00018135800857471768,
      "loss": 0.0488,
      "step": 1288
    },
    {
      "epoch": 2.2176344086021507,
      "grad_norm": 1.5628444375782333,
      "learning_rate": 0.00018132557910769447,
      "loss": 0.0414,
      "step": 1289
    },
    {
      "epoch": 2.2193548387096773,
      "grad_norm": 1.746108053232715,
      "learning_rate": 0.00018129312436288383,
      "loss": 0.0421,
      "step": 1290
    },
    {
      "epoch": 2.2210752688172044,
      "grad_norm": 0.7834096049067454,
      "learning_rate": 0.00018126064435037336,
      "loss": 0.0251,
      "step": 1291
    },
    {
      "epoch": 2.222795698924731,
      "grad_norm": 0.8289884290872837,
      "learning_rate": 0.0001812281390802586,
      "loss": 0.0312,
      "step": 1292
    },
    {
      "epoch": 2.224516129032258,
      "grad_norm": 1.0805772081999347,
      "learning_rate": 0.00018119560856264287,
      "loss": 0.0226,
      "step": 1293
    },
    {
      "epoch": 2.226236559139785,
      "grad_norm": 0.9480923627785567,
      "learning_rate": 0.00018116305280763744,
      "loss": 0.0169,
      "step": 1294
    },
    {
      "epoch": 2.227956989247312,
      "grad_norm": 0.7579928222277176,
      "learning_rate": 0.00018113047182536127,
      "loss": 0.0077,
      "step": 1295
    },
    {
      "epoch": 2.2296774193548385,
      "grad_norm": 1.6063554325960492,
      "learning_rate": 0.0001810978656259413,
      "loss": 0.0247,
      "step": 1296
    },
    {
      "epoch": 2.2313978494623656,
      "grad_norm": 1.5479274382875259,
      "learning_rate": 0.0001810652342195123,
      "loss": 0.0567,
      "step": 1297
    },
    {
      "epoch": 2.2331182795698923,
      "grad_norm": 1.301830928656859,
      "learning_rate": 0.00018103257761621676,
      "loss": 0.0298,
      "step": 1298
    },
    {
      "epoch": 2.2348387096774194,
      "grad_norm": 1.785232807596439,
      "learning_rate": 0.0001809998958262051,
      "loss": 0.0316,
      "step": 1299
    },
    {
      "epoch": 2.236559139784946,
      "grad_norm": 1.4064416699168012,
      "learning_rate": 0.00018096718885963556,
      "loss": 0.0617,
      "step": 1300
    },
    {
      "epoch": 2.238279569892473,
      "grad_norm": 0.8476230461739392,
      "learning_rate": 0.00018093445672667414,
      "loss": 0.0194,
      "step": 1301
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.8351230306564612,
      "learning_rate": 0.00018090169943749476,
      "loss": 0.0175,
      "step": 1302
    },
    {
      "epoch": 2.241720430107527,
      "grad_norm": 0.5387754011669027,
      "learning_rate": 0.0001808689170022791,
      "loss": 0.0095,
      "step": 1303
    },
    {
      "epoch": 2.243440860215054,
      "grad_norm": 1.2356899607879026,
      "learning_rate": 0.00018083610943121664,
      "loss": 0.0559,
      "step": 1304
    },
    {
      "epoch": 2.2451612903225806,
      "grad_norm": 0.8177391353967282,
      "learning_rate": 0.0001808032767345047,
      "loss": 0.0255,
      "step": 1305
    },
    {
      "epoch": 2.2468817204301077,
      "grad_norm": 0.7062057602511185,
      "learning_rate": 0.00018077041892234846,
      "loss": 0.0294,
      "step": 1306
    },
    {
      "epoch": 2.2486021505376343,
      "grad_norm": 1.3067924276465308,
      "learning_rate": 0.00018073753600496078,
      "loss": 0.0327,
      "step": 1307
    },
    {
      "epoch": 2.2503225806451614,
      "grad_norm": 0.9585215402398793,
      "learning_rate": 0.00018070462799256248,
      "loss": 0.0157,
      "step": 1308
    },
    {
      "epoch": 2.252043010752688,
      "grad_norm": 1.1840036169920347,
      "learning_rate": 0.000180671694895382,
      "loss": 0.0192,
      "step": 1309
    },
    {
      "epoch": 2.253763440860215,
      "grad_norm": 1.647164194235874,
      "learning_rate": 0.00018063873672365574,
      "loss": 0.0225,
      "step": 1310
    },
    {
      "epoch": 2.255483870967742,
      "grad_norm": 0.8247420829016952,
      "learning_rate": 0.00018060575348762784,
      "loss": 0.0314,
      "step": 1311
    },
    {
      "epoch": 2.257204301075269,
      "grad_norm": 1.3476620668823451,
      "learning_rate": 0.00018057274519755017,
      "loss": 0.0407,
      "step": 1312
    },
    {
      "epoch": 2.2589247311827956,
      "grad_norm": 0.7245547870024259,
      "learning_rate": 0.00018053971186368246,
      "loss": 0.0375,
      "step": 1313
    },
    {
      "epoch": 2.2606451612903227,
      "grad_norm": 0.86906736616875,
      "learning_rate": 0.00018050665349629222,
      "loss": 0.0209,
      "step": 1314
    },
    {
      "epoch": 2.2623655913978493,
      "grad_norm": 2.029978491412456,
      "learning_rate": 0.00018047357010565467,
      "loss": 0.0553,
      "step": 1315
    },
    {
      "epoch": 2.2640860215053764,
      "grad_norm": 0.9398309840508594,
      "learning_rate": 0.00018044046170205292,
      "loss": 0.0281,
      "step": 1316
    },
    {
      "epoch": 2.265806451612903,
      "grad_norm": 0.5720842888358236,
      "learning_rate": 0.00018040732829577777,
      "loss": 0.011,
      "step": 1317
    },
    {
      "epoch": 2.26752688172043,
      "grad_norm": 2.1126513359207886,
      "learning_rate": 0.00018037416989712777,
      "loss": 0.1096,
      "step": 1318
    },
    {
      "epoch": 2.269247311827957,
      "grad_norm": 0.705061294175131,
      "learning_rate": 0.00018034098651640933,
      "loss": 0.0253,
      "step": 1319
    },
    {
      "epoch": 2.270967741935484,
      "grad_norm": 0.6784020145694123,
      "learning_rate": 0.00018030777816393657,
      "loss": 0.022,
      "step": 1320
    },
    {
      "epoch": 2.2726881720430105,
      "grad_norm": 0.5826177807020714,
      "learning_rate": 0.0001802745448500314,
      "loss": 0.011,
      "step": 1321
    },
    {
      "epoch": 2.2744086021505376,
      "grad_norm": 0.8491623281652004,
      "learning_rate": 0.00018024128658502346,
      "loss": 0.0148,
      "step": 1322
    },
    {
      "epoch": 2.2761290322580647,
      "grad_norm": 1.1008892495030342,
      "learning_rate": 0.0001802080033792501,
      "loss": 0.0186,
      "step": 1323
    },
    {
      "epoch": 2.2778494623655914,
      "grad_norm": 1.2647695297898909,
      "learning_rate": 0.00018017469524305658,
      "loss": 0.0616,
      "step": 1324
    },
    {
      "epoch": 2.279569892473118,
      "grad_norm": 0.36962186762619503,
      "learning_rate": 0.00018014136218679567,
      "loss": 0.0111,
      "step": 1325
    },
    {
      "epoch": 2.281290322580645,
      "grad_norm": 1.1069614808775095,
      "learning_rate": 0.00018010800422082815,
      "loss": 0.029,
      "step": 1326
    },
    {
      "epoch": 2.283010752688172,
      "grad_norm": 0.592590069520205,
      "learning_rate": 0.0001800746213555223,
      "loss": 0.0109,
      "step": 1327
    },
    {
      "epoch": 2.284731182795699,
      "grad_norm": 1.4151802570643484,
      "learning_rate": 0.00018004121360125437,
      "loss": 0.0255,
      "step": 1328
    },
    {
      "epoch": 2.286451612903226,
      "grad_norm": 0.7022859998660307,
      "learning_rate": 0.00018000778096840812,
      "loss": 0.0113,
      "step": 1329
    },
    {
      "epoch": 2.2881720430107526,
      "grad_norm": 0.9781781044664468,
      "learning_rate": 0.00017997432346737524,
      "loss": 0.0235,
      "step": 1330
    },
    {
      "epoch": 2.2898924731182797,
      "grad_norm": 0.6973667192738848,
      "learning_rate": 0.00017994084110855497,
      "loss": 0.0117,
      "step": 1331
    },
    {
      "epoch": 2.2916129032258064,
      "grad_norm": 0.8056464129729806,
      "learning_rate": 0.00017990733390235445,
      "loss": 0.0122,
      "step": 1332
    },
    {
      "epoch": 2.2933333333333334,
      "grad_norm": 0.6532417655267546,
      "learning_rate": 0.00017987380185918844,
      "loss": 0.04,
      "step": 1333
    },
    {
      "epoch": 2.29505376344086,
      "grad_norm": 0.6402222604710069,
      "learning_rate": 0.0001798402449894794,
      "loss": 0.0319,
      "step": 1334
    },
    {
      "epoch": 2.296774193548387,
      "grad_norm": 1.9294504956695513,
      "learning_rate": 0.0001798066633036576,
      "loss": 0.0481,
      "step": 1335
    },
    {
      "epoch": 2.298494623655914,
      "grad_norm": 1.3835470701050976,
      "learning_rate": 0.0001797730568121609,
      "loss": 0.0388,
      "step": 1336
    },
    {
      "epoch": 2.300215053763441,
      "grad_norm": 1.566400822053123,
      "learning_rate": 0.00017973942552543503,
      "loss": 0.0549,
      "step": 1337
    },
    {
      "epoch": 2.3019354838709676,
      "grad_norm": 0.8476759294250181,
      "learning_rate": 0.00017970576945393327,
      "loss": 0.0159,
      "step": 1338
    },
    {
      "epoch": 2.3036559139784947,
      "grad_norm": 1.455011920399862,
      "learning_rate": 0.0001796720886081167,
      "loss": 0.0619,
      "step": 1339
    },
    {
      "epoch": 2.3053763440860213,
      "grad_norm": 0.6279098833826069,
      "learning_rate": 0.00017963838299845403,
      "loss": 0.0104,
      "step": 1340
    },
    {
      "epoch": 2.3070967741935484,
      "grad_norm": 0.9372216757946186,
      "learning_rate": 0.0001796046526354218,
      "loss": 0.0349,
      "step": 1341
    },
    {
      "epoch": 2.308817204301075,
      "grad_norm": 0.9008600935272206,
      "learning_rate": 0.00017957089752950408,
      "loss": 0.0387,
      "step": 1342
    },
    {
      "epoch": 2.310537634408602,
      "grad_norm": 1.5124688747706723,
      "learning_rate": 0.0001795371176911927,
      "loss": 0.037,
      "step": 1343
    },
    {
      "epoch": 2.3122580645161293,
      "grad_norm": 1.2031717969593638,
      "learning_rate": 0.0001795033131309872,
      "loss": 0.0423,
      "step": 1344
    },
    {
      "epoch": 2.313978494623656,
      "grad_norm": 1.9639209556079502,
      "learning_rate": 0.00017946948385939477,
      "loss": 0.0923,
      "step": 1345
    },
    {
      "epoch": 2.3156989247311826,
      "grad_norm": 0.8415293006252044,
      "learning_rate": 0.00017943562988693033,
      "loss": 0.0194,
      "step": 1346
    },
    {
      "epoch": 2.3174193548387096,
      "grad_norm": 1.307883327749892,
      "learning_rate": 0.0001794017512241164,
      "loss": 0.0512,
      "step": 1347
    },
    {
      "epoch": 2.3191397849462367,
      "grad_norm": 1.2293642279819108,
      "learning_rate": 0.00017936784788148328,
      "loss": 0.0387,
      "step": 1348
    },
    {
      "epoch": 2.3208602150537634,
      "grad_norm": 1.505019617923066,
      "learning_rate": 0.00017933391986956878,
      "loss": 0.0458,
      "step": 1349
    },
    {
      "epoch": 2.3225806451612905,
      "grad_norm": 1.0212925446891656,
      "learning_rate": 0.00017929996719891856,
      "loss": 0.0299,
      "step": 1350
    },
    {
      "epoch": 2.324301075268817,
      "grad_norm": 0.6427916784986022,
      "learning_rate": 0.00017926598988008582,
      "loss": 0.037,
      "step": 1351
    },
    {
      "epoch": 2.3260215053763442,
      "grad_norm": 0.5458733201416723,
      "learning_rate": 0.00017923198792363148,
      "loss": 0.0136,
      "step": 1352
    },
    {
      "epoch": 2.327741935483871,
      "grad_norm": 1.2936673174781423,
      "learning_rate": 0.00017919796134012412,
      "loss": 0.0357,
      "step": 1353
    },
    {
      "epoch": 2.329462365591398,
      "grad_norm": 1.929961075995898,
      "learning_rate": 0.00017916391014013988,
      "loss": 0.0328,
      "step": 1354
    },
    {
      "epoch": 2.3311827956989246,
      "grad_norm": 0.6816655255821353,
      "learning_rate": 0.00017912983433426271,
      "loss": 0.0342,
      "step": 1355
    },
    {
      "epoch": 2.3329032258064517,
      "grad_norm": 1.9554170538885705,
      "learning_rate": 0.00017909573393308409,
      "loss": 0.0249,
      "step": 1356
    },
    {
      "epoch": 2.3346236559139784,
      "grad_norm": 0.6133731110216163,
      "learning_rate": 0.00017906160894720315,
      "loss": 0.0162,
      "step": 1357
    },
    {
      "epoch": 2.3363440860215055,
      "grad_norm": 0.33390623498735666,
      "learning_rate": 0.00017902745938722675,
      "loss": 0.0119,
      "step": 1358
    },
    {
      "epoch": 2.338064516129032,
      "grad_norm": 0.738867309126026,
      "learning_rate": 0.00017899328526376927,
      "loss": 0.0355,
      "step": 1359
    },
    {
      "epoch": 2.339784946236559,
      "grad_norm": 0.7976556353084874,
      "learning_rate": 0.00017895908658745283,
      "loss": 0.0309,
      "step": 1360
    },
    {
      "epoch": 2.341505376344086,
      "grad_norm": 1.1203124685441328,
      "learning_rate": 0.00017892486336890708,
      "loss": 0.0564,
      "step": 1361
    },
    {
      "epoch": 2.343225806451613,
      "grad_norm": 0.6822102367291363,
      "learning_rate": 0.00017889061561876938,
      "loss": 0.0254,
      "step": 1362
    },
    {
      "epoch": 2.3449462365591396,
      "grad_norm": 0.5020085065413306,
      "learning_rate": 0.0001788563433476847,
      "loss": 0.0146,
      "step": 1363
    },
    {
      "epoch": 2.3466666666666667,
      "grad_norm": 0.30548592040233197,
      "learning_rate": 0.0001788220465663056,
      "loss": 0.008,
      "step": 1364
    },
    {
      "epoch": 2.3483870967741938,
      "grad_norm": 0.899427379258233,
      "learning_rate": 0.00017878772528529232,
      "loss": 0.0199,
      "step": 1365
    },
    {
      "epoch": 2.3501075268817204,
      "grad_norm": 0.9660605883283407,
      "learning_rate": 0.00017875337951531262,
      "loss": 0.0317,
      "step": 1366
    },
    {
      "epoch": 2.351827956989247,
      "grad_norm": 1.3289533729951537,
      "learning_rate": 0.00017871900926704198,
      "loss": 0.0394,
      "step": 1367
    },
    {
      "epoch": 2.353548387096774,
      "grad_norm": 0.5258973418339917,
      "learning_rate": 0.00017868461455116337,
      "loss": 0.0217,
      "step": 1368
    },
    {
      "epoch": 2.3552688172043013,
      "grad_norm": 0.7820634464352963,
      "learning_rate": 0.00017865019537836743,
      "loss": 0.0449,
      "step": 1369
    },
    {
      "epoch": 2.356989247311828,
      "grad_norm": 0.8795320654974194,
      "learning_rate": 0.00017861575175935246,
      "loss": 0.0201,
      "step": 1370
    },
    {
      "epoch": 2.358709677419355,
      "grad_norm": 0.8391128850838303,
      "learning_rate": 0.00017858128370482426,
      "loss": 0.0356,
      "step": 1371
    },
    {
      "epoch": 2.3604301075268816,
      "grad_norm": 0.6122913473006308,
      "learning_rate": 0.00017854679122549625,
      "loss": 0.0205,
      "step": 1372
    },
    {
      "epoch": 2.3621505376344087,
      "grad_norm": 0.585641811962755,
      "learning_rate": 0.0001785122743320895,
      "loss": 0.0127,
      "step": 1373
    },
    {
      "epoch": 2.3638709677419354,
      "grad_norm": 0.9078321379975491,
      "learning_rate": 0.00017847773303533257,
      "loss": 0.0289,
      "step": 1374
    },
    {
      "epoch": 2.3655913978494625,
      "grad_norm": 1.7415425293998699,
      "learning_rate": 0.00017844316734596166,
      "loss": 0.0328,
      "step": 1375
    },
    {
      "epoch": 2.367311827956989,
      "grad_norm": 0.9641709152846226,
      "learning_rate": 0.0001784085772747206,
      "loss": 0.0197,
      "step": 1376
    },
    {
      "epoch": 2.3690322580645162,
      "grad_norm": 0.6398509010790543,
      "learning_rate": 0.00017837396283236075,
      "loss": 0.0868,
      "step": 1377
    },
    {
      "epoch": 2.370752688172043,
      "grad_norm": 0.7545520744273172,
      "learning_rate": 0.00017833932402964102,
      "loss": 0.0195,
      "step": 1378
    },
    {
      "epoch": 2.37247311827957,
      "grad_norm": 1.186459850716911,
      "learning_rate": 0.00017830466087732786,
      "loss": 0.0447,
      "step": 1379
    },
    {
      "epoch": 2.3741935483870966,
      "grad_norm": 0.27625110765819016,
      "learning_rate": 0.00017826997338619546,
      "loss": 0.0048,
      "step": 1380
    },
    {
      "epoch": 2.3759139784946237,
      "grad_norm": 3.262340434802601,
      "learning_rate": 0.0001782352615670253,
      "loss": 0.0546,
      "step": 1381
    },
    {
      "epoch": 2.3776344086021504,
      "grad_norm": 1.3975021605921911,
      "learning_rate": 0.00017820052543060676,
      "loss": 0.0391,
      "step": 1382
    },
    {
      "epoch": 2.3793548387096775,
      "grad_norm": 1.1396017023031453,
      "learning_rate": 0.0001781657649877365,
      "loss": 0.0437,
      "step": 1383
    },
    {
      "epoch": 2.381075268817204,
      "grad_norm": 1.0853310847452877,
      "learning_rate": 0.00017813098024921882,
      "loss": 0.0172,
      "step": 1384
    },
    {
      "epoch": 2.382795698924731,
      "grad_norm": 0.6749103294260206,
      "learning_rate": 0.0001780961712258656,
      "loss": 0.019,
      "step": 1385
    },
    {
      "epoch": 2.3845161290322583,
      "grad_norm": 1.0778680631263118,
      "learning_rate": 0.00017806133792849633,
      "loss": 0.0269,
      "step": 1386
    },
    {
      "epoch": 2.386236559139785,
      "grad_norm": 1.431314310650008,
      "learning_rate": 0.00017802648036793786,
      "loss": 0.0351,
      "step": 1387
    },
    {
      "epoch": 2.3879569892473116,
      "grad_norm": 0.8116325027074559,
      "learning_rate": 0.00017799159855502476,
      "loss": 0.0241,
      "step": 1388
    },
    {
      "epoch": 2.3896774193548387,
      "grad_norm": 1.291227541741605,
      "learning_rate": 0.00017795669250059902,
      "loss": 0.0375,
      "step": 1389
    },
    {
      "epoch": 2.3913978494623658,
      "grad_norm": 0.7634146138302372,
      "learning_rate": 0.00017792176221551026,
      "loss": 0.0167,
      "step": 1390
    },
    {
      "epoch": 2.3931182795698924,
      "grad_norm": 0.851887623101648,
      "learning_rate": 0.00017788680771061555,
      "loss": 0.0303,
      "step": 1391
    },
    {
      "epoch": 2.3948387096774195,
      "grad_norm": 0.873053527028827,
      "learning_rate": 0.00017785182899677954,
      "loss": 0.0124,
      "step": 1392
    },
    {
      "epoch": 2.396559139784946,
      "grad_norm": 0.8515703571088353,
      "learning_rate": 0.0001778168260848744,
      "loss": 0.0267,
      "step": 1393
    },
    {
      "epoch": 2.3982795698924733,
      "grad_norm": 1.5775474710735005,
      "learning_rate": 0.00017778179898577973,
      "loss": 0.0265,
      "step": 1394
    },
    {
      "epoch": 2.4,
      "grad_norm": 5.548487853292212,
      "learning_rate": 0.00017774674771038287,
      "loss": 0.0127,
      "step": 1395
    },
    {
      "epoch": 2.401720430107527,
      "grad_norm": 1.281862836510704,
      "learning_rate": 0.0001777116722695784,
      "loss": 0.0287,
      "step": 1396
    },
    {
      "epoch": 2.4034408602150537,
      "grad_norm": 1.0552355465041168,
      "learning_rate": 0.00017767657267426859,
      "loss": 0.0476,
      "step": 1397
    },
    {
      "epoch": 2.4051612903225807,
      "grad_norm": 0.28062580701729056,
      "learning_rate": 0.0001776414489353632,
      "loss": 0.0059,
      "step": 1398
    },
    {
      "epoch": 2.4068817204301074,
      "grad_norm": 1.042251520225194,
      "learning_rate": 0.0001776063010637794,
      "loss": 0.0152,
      "step": 1399
    },
    {
      "epoch": 2.4086021505376345,
      "grad_norm": 1.0781042948526924,
      "learning_rate": 0.000177571129070442,
      "loss": 0.0282,
      "step": 1400
    },
    {
      "epoch": 2.410322580645161,
      "grad_norm": 2.322814713357724,
      "learning_rate": 0.00017753593296628318,
      "loss": 0.0699,
      "step": 1401
    },
    {
      "epoch": 2.4120430107526882,
      "grad_norm": 1.6065417605032029,
      "learning_rate": 0.00017750071276224265,
      "loss": 0.0338,
      "step": 1402
    },
    {
      "epoch": 2.413763440860215,
      "grad_norm": 1.1394403602591092,
      "learning_rate": 0.0001774654684692677,
      "loss": 0.0395,
      "step": 1403
    },
    {
      "epoch": 2.415483870967742,
      "grad_norm": 0.8438028551462322,
      "learning_rate": 0.00017743020009831296,
      "loss": 0.014,
      "step": 1404
    },
    {
      "epoch": 2.4172043010752686,
      "grad_norm": 0.8133856458624862,
      "learning_rate": 0.00017739490766034068,
      "loss": 0.0253,
      "step": 1405
    },
    {
      "epoch": 2.4189247311827957,
      "grad_norm": 1.0797286239146335,
      "learning_rate": 0.0001773595911663205,
      "loss": 0.0168,
      "step": 1406
    },
    {
      "epoch": 2.420645161290323,
      "grad_norm": 1.4044871795074096,
      "learning_rate": 0.00017732425062722958,
      "loss": 0.0326,
      "step": 1407
    },
    {
      "epoch": 2.4223655913978495,
      "grad_norm": 0.8428620380228404,
      "learning_rate": 0.0001772888860540525,
      "loss": 0.034,
      "step": 1408
    },
    {
      "epoch": 2.424086021505376,
      "grad_norm": 1.6167421388462697,
      "learning_rate": 0.0001772534974577814,
      "loss": 0.053,
      "step": 1409
    },
    {
      "epoch": 2.425806451612903,
      "grad_norm": 1.3283815575893472,
      "learning_rate": 0.00017721808484941583,
      "loss": 0.0649,
      "step": 1410
    },
    {
      "epoch": 2.4275268817204303,
      "grad_norm": 0.7364671533773435,
      "learning_rate": 0.00017718264823996278,
      "loss": 0.0354,
      "step": 1411
    },
    {
      "epoch": 2.429247311827957,
      "grad_norm": 0.6791359509627571,
      "learning_rate": 0.00017714718764043675,
      "loss": 0.011,
      "step": 1412
    },
    {
      "epoch": 2.430967741935484,
      "grad_norm": 0.734207269430516,
      "learning_rate": 0.00017711170306185969,
      "loss": 0.0152,
      "step": 1413
    },
    {
      "epoch": 2.4326881720430107,
      "grad_norm": 1.3450774670681998,
      "learning_rate": 0.000177076194515261,
      "loss": 0.0403,
      "step": 1414
    },
    {
      "epoch": 2.434408602150538,
      "grad_norm": 1.7007607191885397,
      "learning_rate": 0.00017704066201167746,
      "loss": 0.0327,
      "step": 1415
    },
    {
      "epoch": 2.4361290322580644,
      "grad_norm": 1.1492635378911327,
      "learning_rate": 0.0001770051055621534,
      "loss": 0.0297,
      "step": 1416
    },
    {
      "epoch": 2.4378494623655915,
      "grad_norm": 0.8997387146810246,
      "learning_rate": 0.00017696952517774062,
      "loss": 0.0227,
      "step": 1417
    },
    {
      "epoch": 2.439569892473118,
      "grad_norm": 1.285320134576116,
      "learning_rate": 0.00017693392086949816,
      "loss": 0.0225,
      "step": 1418
    },
    {
      "epoch": 2.4412903225806453,
      "grad_norm": 0.9827297010872862,
      "learning_rate": 0.0001768982926484927,
      "loss": 0.0276,
      "step": 1419
    },
    {
      "epoch": 2.443010752688172,
      "grad_norm": 1.7222792790407664,
      "learning_rate": 0.00017686264052579827,
      "loss": 0.0483,
      "step": 1420
    },
    {
      "epoch": 2.444731182795699,
      "grad_norm": 1.4245422834815424,
      "learning_rate": 0.00017682696451249634,
      "loss": 0.0187,
      "step": 1421
    },
    {
      "epoch": 2.4464516129032257,
      "grad_norm": 1.2191309921409137,
      "learning_rate": 0.0001767912646196758,
      "loss": 0.0351,
      "step": 1422
    },
    {
      "epoch": 2.4481720430107528,
      "grad_norm": 1.290262316423724,
      "learning_rate": 0.00017675554085843292,
      "loss": 0.0632,
      "step": 1423
    },
    {
      "epoch": 2.4498924731182794,
      "grad_norm": 0.8690006050589882,
      "learning_rate": 0.0001767197932398715,
      "loss": 0.0214,
      "step": 1424
    },
    {
      "epoch": 2.4516129032258065,
      "grad_norm": 0.7080356720476185,
      "learning_rate": 0.0001766840217751027,
      "loss": 0.0213,
      "step": 1425
    },
    {
      "epoch": 2.453333333333333,
      "grad_norm": 0.6086253019813551,
      "learning_rate": 0.000176648226475245,
      "loss": 0.014,
      "step": 1426
    },
    {
      "epoch": 2.4550537634408602,
      "grad_norm": 0.9943923180744173,
      "learning_rate": 0.00017661240735142447,
      "loss": 0.03,
      "step": 1427
    },
    {
      "epoch": 2.4567741935483873,
      "grad_norm": 0.5346700329167998,
      "learning_rate": 0.00017657656441477437,
      "loss": 0.0094,
      "step": 1428
    },
    {
      "epoch": 2.458494623655914,
      "grad_norm": 1.486510221396706,
      "learning_rate": 0.00017654069767643557,
      "loss": 0.0623,
      "step": 1429
    },
    {
      "epoch": 2.4602150537634406,
      "grad_norm": 0.9388667049247191,
      "learning_rate": 0.00017650480714755622,
      "loss": 0.0166,
      "step": 1430
    },
    {
      "epoch": 2.4619354838709677,
      "grad_norm": 0.3270580916290882,
      "learning_rate": 0.0001764688928392919,
      "loss": 0.0064,
      "step": 1431
    },
    {
      "epoch": 2.463655913978495,
      "grad_norm": 0.5200306201575077,
      "learning_rate": 0.00017643295476280554,
      "loss": 0.0163,
      "step": 1432
    },
    {
      "epoch": 2.4653763440860215,
      "grad_norm": 1.924521573157994,
      "learning_rate": 0.0001763969929292675,
      "loss": 0.0552,
      "step": 1433
    },
    {
      "epoch": 2.4670967741935486,
      "grad_norm": 4.950130265077672,
      "learning_rate": 0.00017636100734985552,
      "loss": 0.0102,
      "step": 1434
    },
    {
      "epoch": 2.468817204301075,
      "grad_norm": 0.7655143283538032,
      "learning_rate": 0.00017632499803575474,
      "loss": 0.0197,
      "step": 1435
    },
    {
      "epoch": 2.4705376344086023,
      "grad_norm": 0.2731835847151557,
      "learning_rate": 0.00017628896499815756,
      "loss": 0.0049,
      "step": 1436
    },
    {
      "epoch": 2.472258064516129,
      "grad_norm": 0.8327413471415959,
      "learning_rate": 0.00017625290824826396,
      "loss": 0.0705,
      "step": 1437
    },
    {
      "epoch": 2.473978494623656,
      "grad_norm": 0.6485501134279142,
      "learning_rate": 0.00017621682779728112,
      "loss": 0.0227,
      "step": 1438
    },
    {
      "epoch": 2.4756989247311827,
      "grad_norm": 1.2263939025666493,
      "learning_rate": 0.00017618072365642361,
      "loss": 0.0284,
      "step": 1439
    },
    {
      "epoch": 2.47741935483871,
      "grad_norm": 1.0434992969776595,
      "learning_rate": 0.00017614459583691346,
      "loss": 0.0357,
      "step": 1440
    },
    {
      "epoch": 2.4791397849462364,
      "grad_norm": 0.48224990253903255,
      "learning_rate": 0.00017610844434997995,
      "loss": 0.0058,
      "step": 1441
    },
    {
      "epoch": 2.4808602150537635,
      "grad_norm": 1.3828232879903772,
      "learning_rate": 0.00017607226920685976,
      "loss": 0.0169,
      "step": 1442
    },
    {
      "epoch": 2.48258064516129,
      "grad_norm": 1.628878020106753,
      "learning_rate": 0.00017603607041879698,
      "loss": 0.0359,
      "step": 1443
    },
    {
      "epoch": 2.4843010752688173,
      "grad_norm": 1.693660595598209,
      "learning_rate": 0.00017599984799704287,
      "loss": 0.0614,
      "step": 1444
    },
    {
      "epoch": 2.486021505376344,
      "grad_norm": 1.8580114400914605,
      "learning_rate": 0.00017596360195285633,
      "loss": 0.0741,
      "step": 1445
    },
    {
      "epoch": 2.487741935483871,
      "grad_norm": 1.0602059990927553,
      "learning_rate": 0.0001759273322975033,
      "loss": 0.0209,
      "step": 1446
    },
    {
      "epoch": 2.4894623655913977,
      "grad_norm": 1.4882322573545188,
      "learning_rate": 0.00017589103904225723,
      "loss": 0.0269,
      "step": 1447
    },
    {
      "epoch": 2.4911827956989248,
      "grad_norm": 1.8571406113930868,
      "learning_rate": 0.00017585472219839888,
      "loss": 0.046,
      "step": 1448
    },
    {
      "epoch": 2.492903225806452,
      "grad_norm": 1.034596003575847,
      "learning_rate": 0.0001758183817772163,
      "loss": 0.0187,
      "step": 1449
    },
    {
      "epoch": 2.4946236559139785,
      "grad_norm": 1.391121615606328,
      "learning_rate": 0.0001757820177900049,
      "loss": 0.064,
      "step": 1450
    },
    {
      "epoch": 2.496344086021505,
      "grad_norm": 1.2566089617627951,
      "learning_rate": 0.00017574563024806746,
      "loss": 0.0437,
      "step": 1451
    },
    {
      "epoch": 2.4980645161290322,
      "grad_norm": 0.7199780555357149,
      "learning_rate": 0.00017570921916271396,
      "loss": 0.0143,
      "step": 1452
    },
    {
      "epoch": 2.4997849462365593,
      "grad_norm": 0.959288845992778,
      "learning_rate": 0.00017567278454526183,
      "loss": 0.0177,
      "step": 1453
    },
    {
      "epoch": 2.501505376344086,
      "grad_norm": 3.5853810751630926,
      "learning_rate": 0.00017563632640703574,
      "loss": 0.0431,
      "step": 1454
    },
    {
      "epoch": 2.5032258064516126,
      "grad_norm": 1.2493510023899013,
      "learning_rate": 0.00017559984475936762,
      "loss": 0.0255,
      "step": 1455
    },
    {
      "epoch": 2.5049462365591397,
      "grad_norm": 1.223269308589348,
      "learning_rate": 0.0001755633396135969,
      "loss": 0.0258,
      "step": 1456
    },
    {
      "epoch": 2.506666666666667,
      "grad_norm": 1.1902263086554707,
      "learning_rate": 0.00017552681098107007,
      "loss": 0.0538,
      "step": 1457
    },
    {
      "epoch": 2.5083870967741935,
      "grad_norm": 0.7536423723313933,
      "learning_rate": 0.0001754902588731411,
      "loss": 0.0302,
      "step": 1458
    },
    {
      "epoch": 2.5101075268817206,
      "grad_norm": 0.9057227013362494,
      "learning_rate": 0.00017545368330117115,
      "loss": 0.0112,
      "step": 1459
    },
    {
      "epoch": 2.511827956989247,
      "grad_norm": 0.7656267295357362,
      "learning_rate": 0.00017541708427652877,
      "loss": 0.0409,
      "step": 1460
    },
    {
      "epoch": 2.5135483870967743,
      "grad_norm": 0.24972371015926326,
      "learning_rate": 0.00017538046181058968,
      "loss": 0.0066,
      "step": 1461
    },
    {
      "epoch": 2.515268817204301,
      "grad_norm": 0.8519996260583258,
      "learning_rate": 0.00017534381591473704,
      "loss": 0.0548,
      "step": 1462
    },
    {
      "epoch": 2.516989247311828,
      "grad_norm": 0.9892526994452414,
      "learning_rate": 0.00017530714660036112,
      "loss": 0.0292,
      "step": 1463
    },
    {
      "epoch": 2.5187096774193547,
      "grad_norm": 0.85581675177527,
      "learning_rate": 0.00017527045387885957,
      "loss": 0.0226,
      "step": 1464
    },
    {
      "epoch": 2.520430107526882,
      "grad_norm": 0.9864419137434873,
      "learning_rate": 0.00017523373776163733,
      "loss": 0.0194,
      "step": 1465
    },
    {
      "epoch": 2.5221505376344084,
      "grad_norm": 1.3739000930226337,
      "learning_rate": 0.00017519699826010654,
      "loss": 0.012,
      "step": 1466
    },
    {
      "epoch": 2.5238709677419355,
      "grad_norm": 1.0945250782052334,
      "learning_rate": 0.00017516023538568671,
      "loss": 0.0453,
      "step": 1467
    },
    {
      "epoch": 2.525591397849462,
      "grad_norm": 1.4552966704432992,
      "learning_rate": 0.0001751234491498045,
      "loss": 0.0469,
      "step": 1468
    },
    {
      "epoch": 2.5273118279569893,
      "grad_norm": 0.882548519898629,
      "learning_rate": 0.0001750866395638939,
      "loss": 0.0334,
      "step": 1469
    },
    {
      "epoch": 2.5290322580645164,
      "grad_norm": 2.4660816382303277,
      "learning_rate": 0.00017504980663939613,
      "loss": 0.0652,
      "step": 1470
    },
    {
      "epoch": 2.530752688172043,
      "grad_norm": 0.5737900490566961,
      "learning_rate": 0.00017501295038775973,
      "loss": 0.0167,
      "step": 1471
    },
    {
      "epoch": 2.5324731182795697,
      "grad_norm": 1.0580241615232933,
      "learning_rate": 0.00017497607082044036,
      "loss": 0.0301,
      "step": 1472
    },
    {
      "epoch": 2.5341935483870968,
      "grad_norm": 0.7342637483437867,
      "learning_rate": 0.00017493916794890106,
      "loss": 0.0191,
      "step": 1473
    },
    {
      "epoch": 2.535913978494624,
      "grad_norm": 0.9870403513425156,
      "learning_rate": 0.00017490224178461205,
      "loss": 0.0143,
      "step": 1474
    },
    {
      "epoch": 2.5376344086021505,
      "grad_norm": 1.342002079580849,
      "learning_rate": 0.0001748652923390508,
      "loss": 0.0341,
      "step": 1475
    },
    {
      "epoch": 2.539354838709677,
      "grad_norm": 0.7859835366220839,
      "learning_rate": 0.000174828319623702,
      "loss": 0.0131,
      "step": 1476
    },
    {
      "epoch": 2.5410752688172042,
      "grad_norm": 0.829976436780797,
      "learning_rate": 0.00017479132365005756,
      "loss": 0.0155,
      "step": 1477
    },
    {
      "epoch": 2.5427956989247313,
      "grad_norm": 0.8932909961222514,
      "learning_rate": 0.00017475430442961672,
      "loss": 0.0172,
      "step": 1478
    },
    {
      "epoch": 2.544516129032258,
      "grad_norm": 1.219820553692629,
      "learning_rate": 0.0001747172619738858,
      "loss": 0.0393,
      "step": 1479
    },
    {
      "epoch": 2.546236559139785,
      "grad_norm": 1.1340892136611658,
      "learning_rate": 0.00017468019629437846,
      "loss": 0.0263,
      "step": 1480
    },
    {
      "epoch": 2.5479569892473117,
      "grad_norm": 0.6223447418421415,
      "learning_rate": 0.00017464310740261554,
      "loss": 0.0149,
      "step": 1481
    },
    {
      "epoch": 2.549677419354839,
      "grad_norm": 1.3959449727417264,
      "learning_rate": 0.00017460599531012502,
      "loss": 0.0341,
      "step": 1482
    },
    {
      "epoch": 2.5513978494623655,
      "grad_norm": 0.3504020823450833,
      "learning_rate": 0.0001745688600284422,
      "loss": 0.0051,
      "step": 1483
    },
    {
      "epoch": 2.5531182795698926,
      "grad_norm": 0.7771746552096677,
      "learning_rate": 0.0001745317015691096,
      "loss": 0.0097,
      "step": 1484
    },
    {
      "epoch": 2.554838709677419,
      "grad_norm": 0.41516049562483986,
      "learning_rate": 0.0001744945199436768,
      "loss": 0.007,
      "step": 1485
    },
    {
      "epoch": 2.5565591397849463,
      "grad_norm": 0.5347380685245151,
      "learning_rate": 0.0001744573151637007,
      "loss": 0.0126,
      "step": 1486
    },
    {
      "epoch": 2.558279569892473,
      "grad_norm": 1.236547505001168,
      "learning_rate": 0.00017442008724074542,
      "loss": 0.0197,
      "step": 1487
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.942459038986673,
      "learning_rate": 0.00017438283618638212,
      "loss": 0.0199,
      "step": 1488
    },
    {
      "epoch": 2.5617204301075267,
      "grad_norm": 1.7885479195665486,
      "learning_rate": 0.00017434556201218938,
      "loss": 0.0438,
      "step": 1489
    },
    {
      "epoch": 2.563440860215054,
      "grad_norm": 1.7363083488627653,
      "learning_rate": 0.0001743082647297527,
      "loss": 0.0679,
      "step": 1490
    },
    {
      "epoch": 2.565161290322581,
      "grad_norm": 1.4729036857248579,
      "learning_rate": 0.00017427094435066502,
      "loss": 0.0353,
      "step": 1491
    },
    {
      "epoch": 2.5668817204301075,
      "grad_norm": 1.0985150189664503,
      "learning_rate": 0.00017423360088652628,
      "loss": 0.0389,
      "step": 1492
    },
    {
      "epoch": 2.568602150537634,
      "grad_norm": 1.3104562653099263,
      "learning_rate": 0.00017419623434894365,
      "loss": 0.0329,
      "step": 1493
    },
    {
      "epoch": 2.5703225806451613,
      "grad_norm": 1.278463075959315,
      "learning_rate": 0.00017415884474953147,
      "loss": 0.0438,
      "step": 1494
    },
    {
      "epoch": 2.5720430107526884,
      "grad_norm": 1.3129144066249905,
      "learning_rate": 0.0001741214320999113,
      "loss": 0.0459,
      "step": 1495
    },
    {
      "epoch": 2.573763440860215,
      "grad_norm": 0.7410377951427247,
      "learning_rate": 0.00017408399641171175,
      "loss": 0.0233,
      "step": 1496
    },
    {
      "epoch": 2.5754838709677417,
      "grad_norm": 0.945528490722425,
      "learning_rate": 0.00017404653769656874,
      "loss": 0.0381,
      "step": 1497
    },
    {
      "epoch": 2.5772043010752688,
      "grad_norm": 1.02464102932087,
      "learning_rate": 0.0001740090559661252,
      "loss": 0.0167,
      "step": 1498
    },
    {
      "epoch": 2.578924731182796,
      "grad_norm": 0.986412090099861,
      "learning_rate": 0.0001739715512320313,
      "loss": 0.0145,
      "step": 1499
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 1.2191632229690053,
      "learning_rate": 0.00017393402350594436,
      "loss": 0.0495,
      "step": 1500
    },
    {
      "epoch": 2.5823655913978496,
      "grad_norm": 0.9034524992346216,
      "learning_rate": 0.00017389647279952882,
      "loss": 0.0359,
      "step": 1501
    },
    {
      "epoch": 2.5840860215053763,
      "grad_norm": 1.451281699576941,
      "learning_rate": 0.00017385889912445622,
      "loss": 0.039,
      "step": 1502
    },
    {
      "epoch": 2.5858064516129033,
      "grad_norm": 0.9955023992898092,
      "learning_rate": 0.00017382130249240537,
      "loss": 0.0281,
      "step": 1503
    },
    {
      "epoch": 2.58752688172043,
      "grad_norm": 0.9270797208900448,
      "learning_rate": 0.0001737836829150621,
      "loss": 0.0207,
      "step": 1504
    },
    {
      "epoch": 2.589247311827957,
      "grad_norm": 2.984229511344719,
      "learning_rate": 0.00017374604040411935,
      "loss": 0.0393,
      "step": 1505
    },
    {
      "epoch": 2.5909677419354837,
      "grad_norm": 1.4593910753926094,
      "learning_rate": 0.00017370837497127735,
      "loss": 0.0305,
      "step": 1506
    },
    {
      "epoch": 2.592688172043011,
      "grad_norm": 1.0661814121087456,
      "learning_rate": 0.00017367068662824323,
      "loss": 0.033,
      "step": 1507
    },
    {
      "epoch": 2.5944086021505375,
      "grad_norm": 0.7806933612606404,
      "learning_rate": 0.00017363297538673146,
      "loss": 0.0227,
      "step": 1508
    },
    {
      "epoch": 2.5961290322580646,
      "grad_norm": 0.7506229186461877,
      "learning_rate": 0.0001735952412584635,
      "loss": 0.0137,
      "step": 1509
    },
    {
      "epoch": 2.5978494623655912,
      "grad_norm": 1.0941585205419613,
      "learning_rate": 0.00017355748425516794,
      "loss": 0.0359,
      "step": 1510
    },
    {
      "epoch": 2.5995698924731183,
      "grad_norm": 0.8290806400946774,
      "learning_rate": 0.00017351970438858047,
      "loss": 0.0295,
      "step": 1511
    },
    {
      "epoch": 2.6012903225806454,
      "grad_norm": 0.5660973250949498,
      "learning_rate": 0.00017348190167044394,
      "loss": 0.0156,
      "step": 1512
    },
    {
      "epoch": 2.603010752688172,
      "grad_norm": 1.400881062541992,
      "learning_rate": 0.00017344407611250828,
      "loss": 0.0279,
      "step": 1513
    },
    {
      "epoch": 2.6047311827956987,
      "grad_norm": 1.223263135954661,
      "learning_rate": 0.00017340622772653048,
      "loss": 0.0246,
      "step": 1514
    },
    {
      "epoch": 2.606451612903226,
      "grad_norm": 0.49902037442246483,
      "learning_rate": 0.00017336835652427465,
      "loss": 0.0085,
      "step": 1515
    },
    {
      "epoch": 2.608172043010753,
      "grad_norm": 1.2806166038451139,
      "learning_rate": 0.00017333046251751202,
      "loss": 0.0394,
      "step": 1516
    },
    {
      "epoch": 2.6098924731182795,
      "grad_norm": 1.2329637540288256,
      "learning_rate": 0.0001732925457180209,
      "loss": 0.0398,
      "step": 1517
    },
    {
      "epoch": 2.611612903225806,
      "grad_norm": 0.43975046864582157,
      "learning_rate": 0.0001732546061375866,
      "loss": 0.0119,
      "step": 1518
    },
    {
      "epoch": 2.6133333333333333,
      "grad_norm": 0.5608178883073593,
      "learning_rate": 0.00017321664378800166,
      "loss": 0.0154,
      "step": 1519
    },
    {
      "epoch": 2.6150537634408604,
      "grad_norm": 1.1506698375036528,
      "learning_rate": 0.00017317865868106557,
      "loss": 0.025,
      "step": 1520
    },
    {
      "epoch": 2.616774193548387,
      "grad_norm": 0.7390365449999613,
      "learning_rate": 0.00017314065082858497,
      "loss": 0.0103,
      "step": 1521
    },
    {
      "epoch": 2.618494623655914,
      "grad_norm": 0.7355072597414414,
      "learning_rate": 0.0001731026202423735,
      "loss": 0.0093,
      "step": 1522
    },
    {
      "epoch": 2.6202150537634408,
      "grad_norm": 0.7975612625067919,
      "learning_rate": 0.00017306456693425194,
      "loss": 0.0257,
      "step": 1523
    },
    {
      "epoch": 2.621935483870968,
      "grad_norm": 0.5879096224109358,
      "learning_rate": 0.00017302649091604813,
      "loss": 0.009,
      "step": 1524
    },
    {
      "epoch": 2.6236559139784945,
      "grad_norm": 1.6428789257108862,
      "learning_rate": 0.00017298839219959683,
      "loss": 0.052,
      "step": 1525
    },
    {
      "epoch": 2.6253763440860216,
      "grad_norm": 0.8115076219259979,
      "learning_rate": 0.0001729502707967401,
      "loss": 0.0246,
      "step": 1526
    },
    {
      "epoch": 2.6270967741935483,
      "grad_norm": 2.3868230538039996,
      "learning_rate": 0.0001729121267193268,
      "loss": 0.0674,
      "step": 1527
    },
    {
      "epoch": 2.6288172043010753,
      "grad_norm": 1.6217654239903792,
      "learning_rate": 0.000172873959979213,
      "loss": 0.0507,
      "step": 1528
    },
    {
      "epoch": 2.630537634408602,
      "grad_norm": 2.4463139986321543,
      "learning_rate": 0.00017283577058826177,
      "loss": 0.046,
      "step": 1529
    },
    {
      "epoch": 2.632258064516129,
      "grad_norm": 1.9162684158025505,
      "learning_rate": 0.00017279755855834322,
      "loss": 0.0409,
      "step": 1530
    },
    {
      "epoch": 2.6339784946236557,
      "grad_norm": 1.5271680691681133,
      "learning_rate": 0.0001727593239013345,
      "loss": 0.0139,
      "step": 1531
    },
    {
      "epoch": 2.635698924731183,
      "grad_norm": 1.5837958491711537,
      "learning_rate": 0.00017272106662911973,
      "loss": 0.067,
      "step": 1532
    },
    {
      "epoch": 2.63741935483871,
      "grad_norm": 2.2888616177162637,
      "learning_rate": 0.00017268278675359018,
      "loss": 0.0621,
      "step": 1533
    },
    {
      "epoch": 2.6391397849462366,
      "grad_norm": 0.6564607808647123,
      "learning_rate": 0.00017264448428664408,
      "loss": 0.0186,
      "step": 1534
    },
    {
      "epoch": 2.6408602150537632,
      "grad_norm": 1.086860555083909,
      "learning_rate": 0.00017260615924018664,
      "loss": 0.0303,
      "step": 1535
    },
    {
      "epoch": 2.6425806451612903,
      "grad_norm": 1.3860483623365776,
      "learning_rate": 0.00017256781162613017,
      "loss": 0.0309,
      "step": 1536
    },
    {
      "epoch": 2.6443010752688174,
      "grad_norm": 1.1576942138349666,
      "learning_rate": 0.00017252944145639392,
      "loss": 0.0368,
      "step": 1537
    },
    {
      "epoch": 2.646021505376344,
      "grad_norm": 1.2589604052557373,
      "learning_rate": 0.0001724910487429042,
      "loss": 0.0259,
      "step": 1538
    },
    {
      "epoch": 2.6477419354838707,
      "grad_norm": 1.0707385401276395,
      "learning_rate": 0.00017245263349759436,
      "loss": 0.0452,
      "step": 1539
    },
    {
      "epoch": 2.649462365591398,
      "grad_norm": 1.542465792744992,
      "learning_rate": 0.00017241419573240462,
      "loss": 0.0789,
      "step": 1540
    },
    {
      "epoch": 2.651182795698925,
      "grad_norm": 1.1903379423204206,
      "learning_rate": 0.00017237573545928237,
      "loss": 0.0336,
      "step": 1541
    },
    {
      "epoch": 2.6529032258064515,
      "grad_norm": 0.3373416083052798,
      "learning_rate": 0.00017233725269018188,
      "loss": 0.0085,
      "step": 1542
    },
    {
      "epoch": 2.6546236559139786,
      "grad_norm": 0.9285679002227898,
      "learning_rate": 0.00017229874743706443,
      "loss": 0.019,
      "step": 1543
    },
    {
      "epoch": 2.6563440860215053,
      "grad_norm": 1.5536257721220976,
      "learning_rate": 0.0001722602197118983,
      "loss": 0.039,
      "step": 1544
    },
    {
      "epoch": 2.6580645161290324,
      "grad_norm": 0.5109296376547717,
      "learning_rate": 0.0001722216695266588,
      "loss": 0.0116,
      "step": 1545
    },
    {
      "epoch": 2.659784946236559,
      "grad_norm": 2.115801495803392,
      "learning_rate": 0.00017218309689332815,
      "loss": 0.053,
      "step": 1546
    },
    {
      "epoch": 2.661505376344086,
      "grad_norm": 1.1508073315584222,
      "learning_rate": 0.00017214450182389559,
      "loss": 0.0263,
      "step": 1547
    },
    {
      "epoch": 2.6632258064516128,
      "grad_norm": 0.8281348483098934,
      "learning_rate": 0.0001721058843303573,
      "loss": 0.0123,
      "step": 1548
    },
    {
      "epoch": 2.66494623655914,
      "grad_norm": 1.3831794564786197,
      "learning_rate": 0.00017206724442471645,
      "loss": 0.0502,
      "step": 1549
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.7638371183589676,
      "learning_rate": 0.0001720285821189832,
      "loss": 0.0233,
      "step": 1550
    },
    {
      "epoch": 2.6683870967741936,
      "grad_norm": 0.7057931678435532,
      "learning_rate": 0.00017198989742517467,
      "loss": 0.033,
      "step": 1551
    },
    {
      "epoch": 2.6701075268817203,
      "grad_norm": 1.0462487860957614,
      "learning_rate": 0.00017195119035531484,
      "loss": 0.0245,
      "step": 1552
    },
    {
      "epoch": 2.6718279569892474,
      "grad_norm": 0.9843488890912246,
      "learning_rate": 0.00017191246092143478,
      "loss": 0.0374,
      "step": 1553
    },
    {
      "epoch": 2.6735483870967744,
      "grad_norm": 1.4762276368839307,
      "learning_rate": 0.00017187370913557246,
      "loss": 0.0461,
      "step": 1554
    },
    {
      "epoch": 2.675268817204301,
      "grad_norm": 0.7214611193047582,
      "learning_rate": 0.00017183493500977278,
      "loss": 0.0197,
      "step": 1555
    },
    {
      "epoch": 2.6769892473118277,
      "grad_norm": 0.8030851864032849,
      "learning_rate": 0.00017179613855608755,
      "loss": 0.0118,
      "step": 1556
    },
    {
      "epoch": 2.678709677419355,
      "grad_norm": 0.6676801959229796,
      "learning_rate": 0.00017175731978657567,
      "loss": 0.0137,
      "step": 1557
    },
    {
      "epoch": 2.680430107526882,
      "grad_norm": 1.070772342276629,
      "learning_rate": 0.00017171847871330276,
      "loss": 0.0423,
      "step": 1558
    },
    {
      "epoch": 2.6821505376344086,
      "grad_norm": 1.3368063916783461,
      "learning_rate": 0.00017167961534834153,
      "loss": 0.0755,
      "step": 1559
    },
    {
      "epoch": 2.6838709677419352,
      "grad_norm": 1.3580720921459015,
      "learning_rate": 0.0001716407297037716,
      "loss": 0.0483,
      "step": 1560
    },
    {
      "epoch": 2.6855913978494623,
      "grad_norm": 0.21890248076280253,
      "learning_rate": 0.00017160182179167942,
      "loss": 0.0052,
      "step": 1561
    },
    {
      "epoch": 2.6873118279569894,
      "grad_norm": 0.928073467826229,
      "learning_rate": 0.0001715628916241585,
      "loss": 0.0339,
      "step": 1562
    },
    {
      "epoch": 2.689032258064516,
      "grad_norm": 0.34341614431318557,
      "learning_rate": 0.00017152393921330918,
      "loss": 0.007,
      "step": 1563
    },
    {
      "epoch": 2.690752688172043,
      "grad_norm": 0.5905304108032945,
      "learning_rate": 0.0001714849645712387,
      "loss": 0.0145,
      "step": 1564
    },
    {
      "epoch": 2.69247311827957,
      "grad_norm": 2.2890958605242284,
      "learning_rate": 0.00017144596771006128,
      "loss": 0.0229,
      "step": 1565
    },
    {
      "epoch": 2.694193548387097,
      "grad_norm": 0.9630703500170407,
      "learning_rate": 0.00017140694864189795,
      "loss": 0.0631,
      "step": 1566
    },
    {
      "epoch": 2.6959139784946236,
      "grad_norm": 1.1332340408033865,
      "learning_rate": 0.00017136790737887675,
      "loss": 0.0209,
      "step": 1567
    },
    {
      "epoch": 2.6976344086021506,
      "grad_norm": 0.9380465072144241,
      "learning_rate": 0.00017132884393313255,
      "loss": 0.0225,
      "step": 1568
    },
    {
      "epoch": 2.6993548387096773,
      "grad_norm": 0.8211607556599466,
      "learning_rate": 0.00017128975831680714,
      "loss": 0.0144,
      "step": 1569
    },
    {
      "epoch": 2.7010752688172044,
      "grad_norm": 2.4029871141221153,
      "learning_rate": 0.00017125065054204917,
      "loss": 0.0895,
      "step": 1570
    },
    {
      "epoch": 2.702795698924731,
      "grad_norm": 1.3258115667330543,
      "learning_rate": 0.00017121152062101423,
      "loss": 0.0348,
      "step": 1571
    },
    {
      "epoch": 2.704516129032258,
      "grad_norm": 1.4922750771362927,
      "learning_rate": 0.00017117236856586474,
      "loss": 0.0457,
      "step": 1572
    },
    {
      "epoch": 2.706236559139785,
      "grad_norm": 0.21415505619055625,
      "learning_rate": 0.00017113319438877004,
      "loss": 0.0051,
      "step": 1573
    },
    {
      "epoch": 2.707956989247312,
      "grad_norm": 0.7009684458909562,
      "learning_rate": 0.0001710939981019063,
      "loss": 0.0113,
      "step": 1574
    },
    {
      "epoch": 2.709677419354839,
      "grad_norm": 0.2878994484963052,
      "learning_rate": 0.00017105477971745666,
      "loss": 0.0064,
      "step": 1575
    },
    {
      "epoch": 2.7113978494623656,
      "grad_norm": 0.8712542732868382,
      "learning_rate": 0.00017101553924761103,
      "loss": 0.0427,
      "step": 1576
    },
    {
      "epoch": 2.7131182795698923,
      "grad_norm": 1.4309932177749973,
      "learning_rate": 0.00017097627670456617,
      "loss": 0.0233,
      "step": 1577
    },
    {
      "epoch": 2.7148387096774194,
      "grad_norm": 1.7108014465924921,
      "learning_rate": 0.0001709369921005258,
      "loss": 0.0416,
      "step": 1578
    },
    {
      "epoch": 2.7165591397849465,
      "grad_norm": 1.5193915136515654,
      "learning_rate": 0.0001708976854477004,
      "loss": 0.0324,
      "step": 1579
    },
    {
      "epoch": 2.718279569892473,
      "grad_norm": 0.7510481161325008,
      "learning_rate": 0.00017085835675830738,
      "loss": 0.0168,
      "step": 1580
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.694621053358993,
      "learning_rate": 0.00017081900604457096,
      "loss": 0.0156,
      "step": 1581
    },
    {
      "epoch": 2.721720430107527,
      "grad_norm": 1.8608936326935464,
      "learning_rate": 0.0001707796333187222,
      "loss": 0.027,
      "step": 1582
    },
    {
      "epoch": 2.723440860215054,
      "grad_norm": 1.384924276183808,
      "learning_rate": 0.000170740238592999,
      "loss": 0.0383,
      "step": 1583
    },
    {
      "epoch": 2.7251612903225806,
      "grad_norm": 1.2962849245966435,
      "learning_rate": 0.00017070082187964616,
      "loss": 0.0412,
      "step": 1584
    },
    {
      "epoch": 2.7268817204301077,
      "grad_norm": 1.024417989740198,
      "learning_rate": 0.00017066138319091524,
      "loss": 0.0275,
      "step": 1585
    },
    {
      "epoch": 2.7286021505376343,
      "grad_norm": 0.9462800908509642,
      "learning_rate": 0.00017062192253906465,
      "loss": 0.0181,
      "step": 1586
    },
    {
      "epoch": 2.7303225806451614,
      "grad_norm": 1.9447014443468507,
      "learning_rate": 0.00017058243993635963,
      "loss": 0.0344,
      "step": 1587
    },
    {
      "epoch": 2.732043010752688,
      "grad_norm": 1.3161416703983408,
      "learning_rate": 0.00017054293539507228,
      "loss": 0.0464,
      "step": 1588
    },
    {
      "epoch": 2.733763440860215,
      "grad_norm": 0.7597224621787877,
      "learning_rate": 0.00017050340892748139,
      "loss": 0.0463,
      "step": 1589
    },
    {
      "epoch": 2.735483870967742,
      "grad_norm": 1.4460399438819866,
      "learning_rate": 0.00017046386054587277,
      "loss": 0.0751,
      "step": 1590
    },
    {
      "epoch": 2.737204301075269,
      "grad_norm": 1.465511496447601,
      "learning_rate": 0.0001704242902625389,
      "loss": 0.0344,
      "step": 1591
    },
    {
      "epoch": 2.7389247311827956,
      "grad_norm": 1.6654163368974937,
      "learning_rate": 0.00017038469808977906,
      "loss": 0.056,
      "step": 1592
    },
    {
      "epoch": 2.7406451612903227,
      "grad_norm": 0.4050769231414057,
      "learning_rate": 0.0001703450840398994,
      "loss": 0.01,
      "step": 1593
    },
    {
      "epoch": 2.7423655913978493,
      "grad_norm": 0.8641118108856896,
      "learning_rate": 0.00017030544812521287,
      "loss": 0.0312,
      "step": 1594
    },
    {
      "epoch": 2.7440860215053764,
      "grad_norm": 1.3325839187013884,
      "learning_rate": 0.00017026579035803914,
      "loss": 0.0416,
      "step": 1595
    },
    {
      "epoch": 2.7458064516129035,
      "grad_norm": 1.2081249102924305,
      "learning_rate": 0.00017022611075070474,
      "loss": 0.0302,
      "step": 1596
    },
    {
      "epoch": 2.74752688172043,
      "grad_norm": 1.3913106561716573,
      "learning_rate": 0.00017018640931554298,
      "loss": 0.0707,
      "step": 1597
    },
    {
      "epoch": 2.749247311827957,
      "grad_norm": 0.9766178618561566,
      "learning_rate": 0.00017014668606489387,
      "loss": 0.0321,
      "step": 1598
    },
    {
      "epoch": 2.750967741935484,
      "grad_norm": 0.8206331278086811,
      "learning_rate": 0.0001701069410111044,
      "loss": 0.0129,
      "step": 1599
    },
    {
      "epoch": 2.752688172043011,
      "grad_norm": 1.2621930441745866,
      "learning_rate": 0.00017006717416652816,
      "loss": 0.0336,
      "step": 1600
    },
    {
      "epoch": 2.7544086021505376,
      "grad_norm": 1.1364504418870662,
      "learning_rate": 0.00017002738554352552,
      "loss": 0.0321,
      "step": 1601
    },
    {
      "epoch": 2.7561290322580643,
      "grad_norm": 1.304533883590031,
      "learning_rate": 0.00016998757515446369,
      "loss": 0.0442,
      "step": 1602
    },
    {
      "epoch": 2.7578494623655914,
      "grad_norm": 1.395221141896137,
      "learning_rate": 0.00016994774301171662,
      "loss": 0.0399,
      "step": 1603
    },
    {
      "epoch": 2.7595698924731185,
      "grad_norm": 0.6386002222225039,
      "learning_rate": 0.00016990788912766503,
      "loss": 0.0318,
      "step": 1604
    },
    {
      "epoch": 2.761290322580645,
      "grad_norm": 0.8511376253482542,
      "learning_rate": 0.00016986801351469644,
      "loss": 0.023,
      "step": 1605
    },
    {
      "epoch": 2.763010752688172,
      "grad_norm": 0.7093788119128659,
      "learning_rate": 0.00016982811618520494,
      "loss": 0.0135,
      "step": 1606
    },
    {
      "epoch": 2.764731182795699,
      "grad_norm": 0.5998729965928328,
      "learning_rate": 0.0001697881971515916,
      "loss": 0.0148,
      "step": 1607
    },
    {
      "epoch": 2.766451612903226,
      "grad_norm": 1.7422296879892865,
      "learning_rate": 0.00016974825642626412,
      "loss": 0.0474,
      "step": 1608
    },
    {
      "epoch": 2.7681720430107526,
      "grad_norm": 0.8069058450316388,
      "learning_rate": 0.00016970829402163695,
      "loss": 0.0094,
      "step": 1609
    },
    {
      "epoch": 2.7698924731182797,
      "grad_norm": 0.8803884384749389,
      "learning_rate": 0.00016966830995013133,
      "loss": 0.0286,
      "step": 1610
    },
    {
      "epoch": 2.7716129032258063,
      "grad_norm": 0.24358822124350787,
      "learning_rate": 0.00016962830422417508,
      "loss": 0.0047,
      "step": 1611
    },
    {
      "epoch": 2.7733333333333334,
      "grad_norm": 1.0126611978663898,
      "learning_rate": 0.00016958827685620298,
      "loss": 0.0279,
      "step": 1612
    },
    {
      "epoch": 2.77505376344086,
      "grad_norm": 1.8764435831510307,
      "learning_rate": 0.0001695482278586564,
      "loss": 0.0666,
      "step": 1613
    },
    {
      "epoch": 2.776774193548387,
      "grad_norm": 0.696318859304969,
      "learning_rate": 0.0001695081572439834,
      "loss": 0.0193,
      "step": 1614
    },
    {
      "epoch": 2.778494623655914,
      "grad_norm": 0.9977484176473275,
      "learning_rate": 0.00016946806502463887,
      "loss": 0.0373,
      "step": 1615
    },
    {
      "epoch": 2.780215053763441,
      "grad_norm": 0.7838746771908646,
      "learning_rate": 0.0001694279512130843,
      "loss": 0.0208,
      "step": 1616
    },
    {
      "epoch": 2.781935483870968,
      "grad_norm": 1.248688844434818,
      "learning_rate": 0.00016938781582178804,
      "loss": 0.0229,
      "step": 1617
    },
    {
      "epoch": 2.7836559139784947,
      "grad_norm": 1.1910826679305735,
      "learning_rate": 0.00016934765886322497,
      "loss": 0.0336,
      "step": 1618
    },
    {
      "epoch": 2.7853763440860213,
      "grad_norm": 1.539181909623283,
      "learning_rate": 0.0001693074803498768,
      "loss": 0.0336,
      "step": 1619
    },
    {
      "epoch": 2.7870967741935484,
      "grad_norm": 0.966370572231515,
      "learning_rate": 0.00016926728029423188,
      "loss": 0.0205,
      "step": 1620
    },
    {
      "epoch": 2.7888172043010755,
      "grad_norm": 0.8219922316876743,
      "learning_rate": 0.00016922705870878527,
      "loss": 0.0393,
      "step": 1621
    },
    {
      "epoch": 2.790537634408602,
      "grad_norm": 0.9569340803830583,
      "learning_rate": 0.00016918681560603878,
      "loss": 0.0402,
      "step": 1622
    },
    {
      "epoch": 2.792258064516129,
      "grad_norm": 1.0473147997009564,
      "learning_rate": 0.0001691465509985008,
      "loss": 0.0284,
      "step": 1623
    },
    {
      "epoch": 2.793978494623656,
      "grad_norm": 0.5232200411415446,
      "learning_rate": 0.00016910626489868649,
      "loss": 0.0155,
      "step": 1624
    },
    {
      "epoch": 2.795698924731183,
      "grad_norm": 1.4904794707856976,
      "learning_rate": 0.00016906595731911762,
      "loss": 0.0263,
      "step": 1625
    },
    {
      "epoch": 2.7974193548387096,
      "grad_norm": 0.7576325600641957,
      "learning_rate": 0.00016902562827232273,
      "loss": 0.0193,
      "step": 1626
    },
    {
      "epoch": 2.7991397849462367,
      "grad_norm": 0.8900795905830048,
      "learning_rate": 0.00016898527777083698,
      "loss": 0.0214,
      "step": 1627
    },
    {
      "epoch": 2.8008602150537634,
      "grad_norm": 0.4002317952225277,
      "learning_rate": 0.00016894490582720215,
      "loss": 0.0091,
      "step": 1628
    },
    {
      "epoch": 2.8025806451612905,
      "grad_norm": 2.084354402065069,
      "learning_rate": 0.00016890451245396673,
      "loss": 0.0971,
      "step": 1629
    },
    {
      "epoch": 2.804301075268817,
      "grad_norm": 0.7403968802819698,
      "learning_rate": 0.00016886409766368594,
      "loss": 0.0238,
      "step": 1630
    },
    {
      "epoch": 2.806021505376344,
      "grad_norm": 1.6721566945959612,
      "learning_rate": 0.00016882366146892154,
      "loss": 0.033,
      "step": 1631
    },
    {
      "epoch": 2.807741935483871,
      "grad_norm": 1.2128410223043318,
      "learning_rate": 0.00016878320388224202,
      "loss": 0.0514,
      "step": 1632
    },
    {
      "epoch": 2.809462365591398,
      "grad_norm": 0.7466404132399281,
      "learning_rate": 0.00016874272491622245,
      "loss": 0.0136,
      "step": 1633
    },
    {
      "epoch": 2.8111827956989246,
      "grad_norm": 1.4005748712932562,
      "learning_rate": 0.0001687022245834446,
      "loss": 0.0346,
      "step": 1634
    },
    {
      "epoch": 2.8129032258064517,
      "grad_norm": 1.1431831763060019,
      "learning_rate": 0.0001686617028964969,
      "loss": 0.0413,
      "step": 1635
    },
    {
      "epoch": 2.8146236559139783,
      "grad_norm": 0.5748839560378374,
      "learning_rate": 0.00016862115986797437,
      "loss": 0.0141,
      "step": 1636
    },
    {
      "epoch": 2.8163440860215054,
      "grad_norm": 0.5838107602137296,
      "learning_rate": 0.00016858059551047867,
      "loss": 0.0188,
      "step": 1637
    },
    {
      "epoch": 2.8180645161290325,
      "grad_norm": 1.0630541086005054,
      "learning_rate": 0.0001685400098366181,
      "loss": 0.0361,
      "step": 1638
    },
    {
      "epoch": 2.819784946236559,
      "grad_norm": 0.4233223346147942,
      "learning_rate": 0.00016849940285900761,
      "loss": 0.0066,
      "step": 1639
    },
    {
      "epoch": 2.821505376344086,
      "grad_norm": 1.4102084962545394,
      "learning_rate": 0.00016845877459026868,
      "loss": 0.0177,
      "step": 1640
    },
    {
      "epoch": 2.823225806451613,
      "grad_norm": 1.6783199158099742,
      "learning_rate": 0.00016841812504302957,
      "loss": 0.0347,
      "step": 1641
    },
    {
      "epoch": 2.82494623655914,
      "grad_norm": 2.673097652269119,
      "learning_rate": 0.00016837745422992499,
      "loss": 0.0587,
      "step": 1642
    },
    {
      "epoch": 2.8266666666666667,
      "grad_norm": 0.7770923066683433,
      "learning_rate": 0.00016833676216359634,
      "loss": 0.0191,
      "step": 1643
    },
    {
      "epoch": 2.8283870967741933,
      "grad_norm": 1.3195478502553153,
      "learning_rate": 0.00016829604885669163,
      "loss": 0.0554,
      "step": 1644
    },
    {
      "epoch": 2.8301075268817204,
      "grad_norm": 0.9060343573903772,
      "learning_rate": 0.00016825531432186543,
      "loss": 0.0175,
      "step": 1645
    },
    {
      "epoch": 2.8318279569892475,
      "grad_norm": 0.6774938372665826,
      "learning_rate": 0.00016821455857177894,
      "loss": 0.0156,
      "step": 1646
    },
    {
      "epoch": 2.833548387096774,
      "grad_norm": 1.0752397615795433,
      "learning_rate": 0.00016817378161909996,
      "loss": 0.022,
      "step": 1647
    },
    {
      "epoch": 2.8352688172043012,
      "grad_norm": 2.3782339500041796,
      "learning_rate": 0.00016813298347650285,
      "loss": 0.0197,
      "step": 1648
    },
    {
      "epoch": 2.836989247311828,
      "grad_norm": 0.7146340746618882,
      "learning_rate": 0.00016809216415666862,
      "loss": 0.0213,
      "step": 1649
    },
    {
      "epoch": 2.838709677419355,
      "grad_norm": 1.1004303642430613,
      "learning_rate": 0.0001680513236722848,
      "loss": 0.0198,
      "step": 1650
    },
    {
      "epoch": 2.8404301075268816,
      "grad_norm": 1.6596371245570556,
      "learning_rate": 0.00016801046203604548,
      "loss": 0.0491,
      "step": 1651
    },
    {
      "epoch": 2.8421505376344087,
      "grad_norm": 1.7648893377860748,
      "learning_rate": 0.00016796957926065134,
      "loss": 0.0608,
      "step": 1652
    },
    {
      "epoch": 2.8438709677419354,
      "grad_norm": 0.767681736360778,
      "learning_rate": 0.00016792867535880972,
      "loss": 0.0127,
      "step": 1653
    },
    {
      "epoch": 2.8455913978494625,
      "grad_norm": 1.8025499886395553,
      "learning_rate": 0.00016788775034323443,
      "loss": 0.0207,
      "step": 1654
    },
    {
      "epoch": 2.847311827956989,
      "grad_norm": 1.0666567885287812,
      "learning_rate": 0.0001678468042266459,
      "loss": 0.0136,
      "step": 1655
    },
    {
      "epoch": 2.849032258064516,
      "grad_norm": 0.5963986313296243,
      "learning_rate": 0.000167805837021771,
      "loss": 0.0129,
      "step": 1656
    },
    {
      "epoch": 2.850752688172043,
      "grad_norm": 0.8106382900896868,
      "learning_rate": 0.0001677648487413433,
      "loss": 0.0215,
      "step": 1657
    },
    {
      "epoch": 2.85247311827957,
      "grad_norm": 1.882619515554844,
      "learning_rate": 0.00016772383939810288,
      "loss": 0.0467,
      "step": 1658
    },
    {
      "epoch": 2.854193548387097,
      "grad_norm": 3.3443034953188255,
      "learning_rate": 0.00016768280900479634,
      "loss": 0.026,
      "step": 1659
    },
    {
      "epoch": 2.8559139784946237,
      "grad_norm": 2.7010947540833445,
      "learning_rate": 0.00016764175757417682,
      "loss": 0.0418,
      "step": 1660
    },
    {
      "epoch": 2.8576344086021503,
      "grad_norm": 0.38698937726302246,
      "learning_rate": 0.000167600685119004,
      "loss": 0.0102,
      "step": 1661
    },
    {
      "epoch": 2.8593548387096774,
      "grad_norm": 1.0020637395401273,
      "learning_rate": 0.00016755959165204413,
      "loss": 0.0128,
      "step": 1662
    },
    {
      "epoch": 2.8610752688172045,
      "grad_norm": 0.6371993985262818,
      "learning_rate": 0.00016751847718606997,
      "loss": 0.0144,
      "step": 1663
    },
    {
      "epoch": 2.862795698924731,
      "grad_norm": 0.8493911385750684,
      "learning_rate": 0.00016747734173386077,
      "loss": 0.0127,
      "step": 1664
    },
    {
      "epoch": 2.864516129032258,
      "grad_norm": 0.8914178103368003,
      "learning_rate": 0.00016743618530820238,
      "loss": 0.0329,
      "step": 1665
    },
    {
      "epoch": 2.866236559139785,
      "grad_norm": 1.6941088100806212,
      "learning_rate": 0.0001673950079218871,
      "loss": 0.038,
      "step": 1666
    },
    {
      "epoch": 2.867956989247312,
      "grad_norm": 2.3870422047036697,
      "learning_rate": 0.0001673538095877138,
      "loss": 0.0475,
      "step": 1667
    },
    {
      "epoch": 2.8696774193548387,
      "grad_norm": 1.2285637995190073,
      "learning_rate": 0.00016731259031848778,
      "loss": 0.0195,
      "step": 1668
    },
    {
      "epoch": 2.8713978494623653,
      "grad_norm": 0.9635824527182446,
      "learning_rate": 0.00016727135012702097,
      "loss": 0.0175,
      "step": 1669
    },
    {
      "epoch": 2.8731182795698924,
      "grad_norm": 0.8014760569430125,
      "learning_rate": 0.0001672300890261317,
      "loss": 0.0088,
      "step": 1670
    },
    {
      "epoch": 2.8748387096774195,
      "grad_norm": 2.258326837727027,
      "learning_rate": 0.00016718880702864478,
      "loss": 0.0379,
      "step": 1671
    },
    {
      "epoch": 2.876559139784946,
      "grad_norm": 0.8758571443193175,
      "learning_rate": 0.0001671475041473917,
      "loss": 0.0146,
      "step": 1672
    },
    {
      "epoch": 2.8782795698924732,
      "grad_norm": 1.3495180859093654,
      "learning_rate": 0.00016710618039521014,
      "loss": 0.036,
      "step": 1673
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.3551652696185799,
      "learning_rate": 0.00016706483578494456,
      "loss": 0.0238,
      "step": 1674
    },
    {
      "epoch": 2.881720430107527,
      "grad_norm": 0.23789789089579602,
      "learning_rate": 0.00016702347032944575,
      "loss": 0.0041,
      "step": 1675
    },
    {
      "epoch": 2.8834408602150536,
      "grad_norm": 1.5805562759816412,
      "learning_rate": 0.00016698208404157097,
      "loss": 0.0469,
      "step": 1676
    },
    {
      "epoch": 2.8851612903225807,
      "grad_norm": 0.6548682775923781,
      "learning_rate": 0.00016694067693418405,
      "loss": 0.0118,
      "step": 1677
    },
    {
      "epoch": 2.8868817204301074,
      "grad_norm": 1.8287812304249031,
      "learning_rate": 0.00016689924902015517,
      "loss": 0.0884,
      "step": 1678
    },
    {
      "epoch": 2.8886021505376345,
      "grad_norm": 1.9462854288865996,
      "learning_rate": 0.00016685780031236108,
      "loss": 0.0237,
      "step": 1679
    },
    {
      "epoch": 2.8903225806451616,
      "grad_norm": 1.8827388354294363,
      "learning_rate": 0.00016681633082368498,
      "loss": 0.0505,
      "step": 1680
    },
    {
      "epoch": 2.892043010752688,
      "grad_norm": 1.014954680061839,
      "learning_rate": 0.00016677484056701645,
      "loss": 0.0256,
      "step": 1681
    },
    {
      "epoch": 2.893763440860215,
      "grad_norm": 1.4040177194002978,
      "learning_rate": 0.0001667333295552516,
      "loss": 0.0236,
      "step": 1682
    },
    {
      "epoch": 2.895483870967742,
      "grad_norm": 1.8666084942891117,
      "learning_rate": 0.00016669179780129297,
      "loss": 0.0272,
      "step": 1683
    },
    {
      "epoch": 2.897204301075269,
      "grad_norm": 0.7713519930154236,
      "learning_rate": 0.00016665024531804958,
      "loss": 0.0347,
      "step": 1684
    },
    {
      "epoch": 2.8989247311827957,
      "grad_norm": 0.7677407168668062,
      "learning_rate": 0.00016660867211843678,
      "loss": 0.0108,
      "step": 1685
    },
    {
      "epoch": 2.9006451612903223,
      "grad_norm": 1.2482921794742432,
      "learning_rate": 0.00016656707821537654,
      "loss": 0.0243,
      "step": 1686
    },
    {
      "epoch": 2.9023655913978494,
      "grad_norm": 1.495758390204963,
      "learning_rate": 0.0001665254636217971,
      "loss": 0.0403,
      "step": 1687
    },
    {
      "epoch": 2.9040860215053765,
      "grad_norm": 1.3127100553486772,
      "learning_rate": 0.0001664838283506332,
      "loss": 0.0332,
      "step": 1688
    },
    {
      "epoch": 2.905806451612903,
      "grad_norm": 1.115519289289623,
      "learning_rate": 0.000166442172414826,
      "loss": 0.0307,
      "step": 1689
    },
    {
      "epoch": 2.90752688172043,
      "grad_norm": 2.068243779127971,
      "learning_rate": 0.00016640049582732308,
      "loss": 0.0628,
      "step": 1690
    },
    {
      "epoch": 2.909247311827957,
      "grad_norm": 1.2089552233843073,
      "learning_rate": 0.0001663587986010785,
      "loss": 0.0441,
      "step": 1691
    },
    {
      "epoch": 2.910967741935484,
      "grad_norm": 1.58903865445962,
      "learning_rate": 0.0001663170807490526,
      "loss": 0.0555,
      "step": 1692
    },
    {
      "epoch": 2.9126881720430107,
      "grad_norm": 0.6921768029693254,
      "learning_rate": 0.0001662753422842123,
      "loss": 0.0199,
      "step": 1693
    },
    {
      "epoch": 2.9144086021505378,
      "grad_norm": 0.6341757293381289,
      "learning_rate": 0.00016623358321953078,
      "loss": 0.0174,
      "step": 1694
    },
    {
      "epoch": 2.9161290322580644,
      "grad_norm": 0.2951595958024446,
      "learning_rate": 0.0001661918035679877,
      "loss": 0.0107,
      "step": 1695
    },
    {
      "epoch": 2.9178494623655915,
      "grad_norm": 0.48872139398678893,
      "learning_rate": 0.00016615000334256906,
      "loss": 0.0205,
      "step": 1696
    },
    {
      "epoch": 2.919569892473118,
      "grad_norm": 0.5638799671817692,
      "learning_rate": 0.00016610818255626732,
      "loss": 0.0114,
      "step": 1697
    },
    {
      "epoch": 2.9212903225806452,
      "grad_norm": 0.5386373929965171,
      "learning_rate": 0.0001660663412220813,
      "loss": 0.0101,
      "step": 1698
    },
    {
      "epoch": 2.923010752688172,
      "grad_norm": 1.147488258133314,
      "learning_rate": 0.0001660244793530162,
      "loss": 0.0405,
      "step": 1699
    },
    {
      "epoch": 2.924731182795699,
      "grad_norm": 1.0844773155119047,
      "learning_rate": 0.00016598259696208373,
      "loss": 0.0382,
      "step": 1700
    },
    {
      "epoch": 2.9264516129032256,
      "grad_norm": 1.3856650740370864,
      "learning_rate": 0.00016594069406230166,
      "loss": 0.0401,
      "step": 1701
    },
    {
      "epoch": 2.9281720430107527,
      "grad_norm": 0.8662876613094945,
      "learning_rate": 0.00016589877066669449,
      "loss": 0.0282,
      "step": 1702
    },
    {
      "epoch": 2.9298924731182794,
      "grad_norm": 1.1731657032609746,
      "learning_rate": 0.00016585682678829286,
      "loss": 0.0454,
      "step": 1703
    },
    {
      "epoch": 2.9316129032258065,
      "grad_norm": 0.860528207358414,
      "learning_rate": 0.00016581486244013392,
      "loss": 0.0255,
      "step": 1704
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.6501646770410524,
      "learning_rate": 0.00016577287763526108,
      "loss": 0.0386,
      "step": 1705
    },
    {
      "epoch": 2.93505376344086,
      "grad_norm": 1.310225975770352,
      "learning_rate": 0.00016573087238672414,
      "loss": 0.0445,
      "step": 1706
    },
    {
      "epoch": 2.936774193548387,
      "grad_norm": 0.2579395042332346,
      "learning_rate": 0.00016568884670757926,
      "loss": 0.008,
      "step": 1707
    },
    {
      "epoch": 2.938494623655914,
      "grad_norm": 1.5033832214205258,
      "learning_rate": 0.00016564680061088895,
      "loss": 0.0211,
      "step": 1708
    },
    {
      "epoch": 2.940215053763441,
      "grad_norm": 0.9677224963187484,
      "learning_rate": 0.0001656047341097221,
      "loss": 0.053,
      "step": 1709
    },
    {
      "epoch": 2.9419354838709677,
      "grad_norm": 1.2390563495599938,
      "learning_rate": 0.00016556264721715382,
      "loss": 0.0182,
      "step": 1710
    },
    {
      "epoch": 2.9436559139784944,
      "grad_norm": 0.7882868999762561,
      "learning_rate": 0.00016552053994626579,
      "loss": 0.0352,
      "step": 1711
    },
    {
      "epoch": 2.9453763440860214,
      "grad_norm": 0.9931562989442705,
      "learning_rate": 0.00016547841231014573,
      "loss": 0.0291,
      "step": 1712
    },
    {
      "epoch": 2.9470967741935485,
      "grad_norm": 0.9331851579094324,
      "learning_rate": 0.00016543626432188795,
      "loss": 0.0158,
      "step": 1713
    },
    {
      "epoch": 2.948817204301075,
      "grad_norm": 0.9386824637776446,
      "learning_rate": 0.0001653940959945929,
      "loss": 0.0173,
      "step": 1714
    },
    {
      "epoch": 2.9505376344086023,
      "grad_norm": 0.9036887277972133,
      "learning_rate": 0.0001653519073413675,
      "loss": 0.0477,
      "step": 1715
    },
    {
      "epoch": 2.952258064516129,
      "grad_norm": 1.1664257832444402,
      "learning_rate": 0.00016530969837532487,
      "loss": 0.0628,
      "step": 1716
    },
    {
      "epoch": 2.953978494623656,
      "grad_norm": 0.8892292971348063,
      "learning_rate": 0.00016526746910958449,
      "loss": 0.0354,
      "step": 1717
    },
    {
      "epoch": 2.9556989247311827,
      "grad_norm": 1.0203383773104164,
      "learning_rate": 0.00016522521955727215,
      "loss": 0.0344,
      "step": 1718
    },
    {
      "epoch": 2.9574193548387098,
      "grad_norm": 0.9762343201236791,
      "learning_rate": 0.00016518294973151995,
      "loss": 0.0226,
      "step": 1719
    },
    {
      "epoch": 2.9591397849462364,
      "grad_norm": 1.5419691538952787,
      "learning_rate": 0.00016514065964546632,
      "loss": 0.1066,
      "step": 1720
    },
    {
      "epoch": 2.9608602150537635,
      "grad_norm": 1.4003634131800153,
      "learning_rate": 0.0001650983493122559,
      "loss": 0.0387,
      "step": 1721
    },
    {
      "epoch": 2.96258064516129,
      "grad_norm": 1.4037099253470802,
      "learning_rate": 0.00016505601874503971,
      "loss": 0.0266,
      "step": 1722
    },
    {
      "epoch": 2.9643010752688173,
      "grad_norm": 0.5487999351066111,
      "learning_rate": 0.000165013667956975,
      "loss": 0.0091,
      "step": 1723
    },
    {
      "epoch": 2.966021505376344,
      "grad_norm": 0.826437128590987,
      "learning_rate": 0.00016497129696122533,
      "loss": 0.0296,
      "step": 1724
    },
    {
      "epoch": 2.967741935483871,
      "grad_norm": 1.1072064708105371,
      "learning_rate": 0.0001649289057709606,
      "loss": 0.0241,
      "step": 1725
    },
    {
      "epoch": 2.969462365591398,
      "grad_norm": 1.1006040913624788,
      "learning_rate": 0.00016488649439935687,
      "loss": 0.0502,
      "step": 1726
    },
    {
      "epoch": 2.9711827956989247,
      "grad_norm": 1.339601052507035,
      "learning_rate": 0.00016484406285959655,
      "loss": 0.0452,
      "step": 1727
    },
    {
      "epoch": 2.9729032258064514,
      "grad_norm": 1.0837765117756282,
      "learning_rate": 0.00016480161116486826,
      "loss": 0.0319,
      "step": 1728
    },
    {
      "epoch": 2.9746236559139785,
      "grad_norm": 0.9328055934302909,
      "learning_rate": 0.00016475913932836699,
      "loss": 0.0327,
      "step": 1729
    },
    {
      "epoch": 2.9763440860215056,
      "grad_norm": 1.4036674417043002,
      "learning_rate": 0.0001647166473632939,
      "loss": 0.0548,
      "step": 1730
    },
    {
      "epoch": 2.9780645161290322,
      "grad_norm": 0.42268058262446984,
      "learning_rate": 0.00016467413528285644,
      "loss": 0.0068,
      "step": 1731
    },
    {
      "epoch": 2.979784946236559,
      "grad_norm": 1.3534717714071738,
      "learning_rate": 0.00016463160310026828,
      "loss": 0.0504,
      "step": 1732
    },
    {
      "epoch": 2.981505376344086,
      "grad_norm": 1.3900815288692998,
      "learning_rate": 0.0001645890508287494,
      "loss": 0.0471,
      "step": 1733
    },
    {
      "epoch": 2.983225806451613,
      "grad_norm": 1.2222276227137319,
      "learning_rate": 0.00016454647848152595,
      "loss": 0.0382,
      "step": 1734
    },
    {
      "epoch": 2.9849462365591397,
      "grad_norm": 1.1904065169678026,
      "learning_rate": 0.00016450388607183034,
      "loss": 0.0212,
      "step": 1735
    },
    {
      "epoch": 2.986666666666667,
      "grad_norm": 1.0495432670603575,
      "learning_rate": 0.0001644612736129013,
      "loss": 0.0445,
      "step": 1736
    },
    {
      "epoch": 2.9883870967741935,
      "grad_norm": 0.7680610416210165,
      "learning_rate": 0.00016441864111798368,
      "loss": 0.0288,
      "step": 1737
    },
    {
      "epoch": 2.9901075268817205,
      "grad_norm": 1.373993889977564,
      "learning_rate": 0.0001643759886003286,
      "loss": 0.0338,
      "step": 1738
    },
    {
      "epoch": 2.991827956989247,
      "grad_norm": 1.0665592638452295,
      "learning_rate": 0.00016433331607319343,
      "loss": 0.0126,
      "step": 1739
    },
    {
      "epoch": 2.9935483870967743,
      "grad_norm": 1.0117426996713181,
      "learning_rate": 0.00016429062354984168,
      "loss": 0.0309,
      "step": 1740
    },
    {
      "epoch": 2.995268817204301,
      "grad_norm": 0.7298009073210517,
      "learning_rate": 0.00016424791104354322,
      "loss": 0.0352,
      "step": 1741
    },
    {
      "epoch": 2.996989247311828,
      "grad_norm": 1.6745558381643222,
      "learning_rate": 0.00016420517856757395,
      "loss": 0.0576,
      "step": 1742
    },
    {
      "epoch": 2.9987096774193547,
      "grad_norm": 1.348749211987417,
      "learning_rate": 0.0001641624261352161,
      "loss": 0.0268,
      "step": 1743
    },
    {
      "epoch": 3.0004301075268818,
      "grad_norm": 1.0161158558960457,
      "learning_rate": 0.0001641196537597581,
      "loss": 0.0441,
      "step": 1744
    },
    {
      "epoch": 3.0021505376344084,
      "grad_norm": 0.7424898997708345,
      "learning_rate": 0.00016407686145449455,
      "loss": 0.0157,
      "step": 1745
    },
    {
      "epoch": 3.0038709677419355,
      "grad_norm": 0.6645632695223487,
      "learning_rate": 0.00016403404923272618,
      "loss": 0.0174,
      "step": 1746
    },
    {
      "epoch": 3.005591397849462,
      "grad_norm": 0.6596820725938237,
      "learning_rate": 0.00016399121710776004,
      "loss": 0.0139,
      "step": 1747
    },
    {
      "epoch": 3.0073118279569893,
      "grad_norm": 0.4104614350329472,
      "learning_rate": 0.00016394836509290927,
      "loss": 0.0103,
      "step": 1748
    },
    {
      "epoch": 3.009032258064516,
      "grad_norm": 0.6363474878582883,
      "learning_rate": 0.00016390549320149323,
      "loss": 0.0105,
      "step": 1749
    },
    {
      "epoch": 3.010752688172043,
      "grad_norm": 1.159167324339107,
      "learning_rate": 0.00016386260144683745,
      "loss": 0.0436,
      "step": 1750
    },
    {
      "epoch": 3.01247311827957,
      "grad_norm": 0.30448296366286676,
      "learning_rate": 0.00016381968984227366,
      "loss": 0.0056,
      "step": 1751
    },
    {
      "epoch": 3.0141935483870967,
      "grad_norm": 0.8234259064441621,
      "learning_rate": 0.00016377675840113968,
      "loss": 0.0162,
      "step": 1752
    },
    {
      "epoch": 3.015913978494624,
      "grad_norm": 0.4837472699920337,
      "learning_rate": 0.00016373380713677959,
      "loss": 0.011,
      "step": 1753
    },
    {
      "epoch": 3.0176344086021505,
      "grad_norm": 0.943374585883077,
      "learning_rate": 0.0001636908360625436,
      "loss": 0.0322,
      "step": 1754
    },
    {
      "epoch": 3.0193548387096776,
      "grad_norm": 0.6565145759353548,
      "learning_rate": 0.00016364784519178803,
      "loss": 0.0179,
      "step": 1755
    },
    {
      "epoch": 3.0210752688172042,
      "grad_norm": 0.37172032619703554,
      "learning_rate": 0.00016360483453787546,
      "loss": 0.0174,
      "step": 1756
    },
    {
      "epoch": 3.0227956989247313,
      "grad_norm": 1.5488264182987794,
      "learning_rate": 0.00016356180411417447,
      "loss": 0.0203,
      "step": 1757
    },
    {
      "epoch": 3.024516129032258,
      "grad_norm": 0.22558416655051336,
      "learning_rate": 0.00016351875393405996,
      "loss": 0.0076,
      "step": 1758
    },
    {
      "epoch": 3.026236559139785,
      "grad_norm": 0.5242414987694746,
      "learning_rate": 0.00016347568401091277,
      "loss": 0.0164,
      "step": 1759
    },
    {
      "epoch": 3.0279569892473117,
      "grad_norm": 0.643730261539365,
      "learning_rate": 0.00016343259435812004,
      "loss": 0.0143,
      "step": 1760
    },
    {
      "epoch": 3.029677419354839,
      "grad_norm": 0.22912356690196245,
      "learning_rate": 0.00016338948498907503,
      "loss": 0.0035,
      "step": 1761
    },
    {
      "epoch": 3.0313978494623655,
      "grad_norm": 0.5084497073090466,
      "learning_rate": 0.00016334635591717703,
      "loss": 0.0055,
      "step": 1762
    },
    {
      "epoch": 3.0331182795698926,
      "grad_norm": 1.0126475722701311,
      "learning_rate": 0.0001633032071558315,
      "loss": 0.0353,
      "step": 1763
    },
    {
      "epoch": 3.034838709677419,
      "grad_norm": 0.1410110465895585,
      "learning_rate": 0.00016326003871845,
      "loss": 0.0015,
      "step": 1764
    },
    {
      "epoch": 3.0365591397849463,
      "grad_norm": 0.23454787494920834,
      "learning_rate": 0.00016321685061845034,
      "loss": 0.0033,
      "step": 1765
    },
    {
      "epoch": 3.038279569892473,
      "grad_norm": 0.33201721053016164,
      "learning_rate": 0.00016317364286925627,
      "loss": 0.0049,
      "step": 1766
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.6610813485920249,
      "learning_rate": 0.00016313041548429773,
      "loss": 0.022,
      "step": 1767
    },
    {
      "epoch": 3.0417204301075267,
      "grad_norm": 0.33105556213581394,
      "learning_rate": 0.0001630871684770107,
      "loss": 0.0053,
      "step": 1768
    },
    {
      "epoch": 3.043440860215054,
      "grad_norm": 0.6668055228713339,
      "learning_rate": 0.00016304390186083737,
      "loss": 0.0178,
      "step": 1769
    },
    {
      "epoch": 3.0451612903225804,
      "grad_norm": 1.3760679308345518,
      "learning_rate": 0.00016300061564922594,
      "loss": 0.0175,
      "step": 1770
    },
    {
      "epoch": 3.0468817204301075,
      "grad_norm": 0.18056260504563668,
      "learning_rate": 0.00016295730985563074,
      "loss": 0.0018,
      "step": 1771
    },
    {
      "epoch": 3.0486021505376346,
      "grad_norm": 0.15478489093457193,
      "learning_rate": 0.0001629139844935121,
      "loss": 0.0023,
      "step": 1772
    },
    {
      "epoch": 3.0503225806451613,
      "grad_norm": 1.2458622493928928,
      "learning_rate": 0.00016287063957633654,
      "loss": 0.0188,
      "step": 1773
    },
    {
      "epoch": 3.0520430107526884,
      "grad_norm": 0.4989320317928498,
      "learning_rate": 0.00016282727511757666,
      "loss": 0.0082,
      "step": 1774
    },
    {
      "epoch": 3.053763440860215,
      "grad_norm": 2.230298394286332,
      "learning_rate": 0.00016278389113071103,
      "loss": 0.0266,
      "step": 1775
    },
    {
      "epoch": 3.055483870967742,
      "grad_norm": 0.275317913631783,
      "learning_rate": 0.00016274048762922436,
      "loss": 0.0047,
      "step": 1776
    },
    {
      "epoch": 3.0572043010752687,
      "grad_norm": 0.22711536121503226,
      "learning_rate": 0.00016269706462660746,
      "loss": 0.0025,
      "step": 1777
    },
    {
      "epoch": 3.058924731182796,
      "grad_norm": 0.047948718341259,
      "learning_rate": 0.00016265362213635712,
      "loss": 0.0005,
      "step": 1778
    },
    {
      "epoch": 3.0606451612903225,
      "grad_norm": 1.4847471213970291,
      "learning_rate": 0.00016261016017197623,
      "loss": 0.0217,
      "step": 1779
    },
    {
      "epoch": 3.0623655913978496,
      "grad_norm": 1.0742549690067948,
      "learning_rate": 0.00016256667874697377,
      "loss": 0.0186,
      "step": 1780
    },
    {
      "epoch": 3.0640860215053762,
      "grad_norm": 1.0327541334418229,
      "learning_rate": 0.00016252317787486466,
      "loss": 0.0159,
      "step": 1781
    },
    {
      "epoch": 3.0658064516129033,
      "grad_norm": 0.4213087479658346,
      "learning_rate": 0.00016247965756916997,
      "loss": 0.0066,
      "step": 1782
    },
    {
      "epoch": 3.06752688172043,
      "grad_norm": 0.16610743290933327,
      "learning_rate": 0.0001624361178434168,
      "loss": 0.002,
      "step": 1783
    },
    {
      "epoch": 3.069247311827957,
      "grad_norm": 0.04051984471008372,
      "learning_rate": 0.0001623925587111382,
      "loss": 0.0005,
      "step": 1784
    },
    {
      "epoch": 3.0709677419354837,
      "grad_norm": 0.6189828373550926,
      "learning_rate": 0.00016234898018587337,
      "loss": 0.0141,
      "step": 1785
    },
    {
      "epoch": 3.072688172043011,
      "grad_norm": 0.5485233389813204,
      "learning_rate": 0.0001623053822811674,
      "loss": 0.0052,
      "step": 1786
    },
    {
      "epoch": 3.0744086021505375,
      "grad_norm": 0.39621442109534316,
      "learning_rate": 0.0001622617650105716,
      "loss": 0.0047,
      "step": 1787
    },
    {
      "epoch": 3.0761290322580646,
      "grad_norm": 0.47561525962995604,
      "learning_rate": 0.00016221812838764307,
      "loss": 0.0058,
      "step": 1788
    },
    {
      "epoch": 3.077849462365591,
      "grad_norm": 1.2369718200071231,
      "learning_rate": 0.0001621744724259451,
      "loss": 0.019,
      "step": 1789
    },
    {
      "epoch": 3.0795698924731183,
      "grad_norm": 1.4379206055160145,
      "learning_rate": 0.00016213079713904688,
      "loss": 0.0213,
      "step": 1790
    },
    {
      "epoch": 3.081290322580645,
      "grad_norm": 1.4066015584684999,
      "learning_rate": 0.00016208710254052373,
      "loss": 0.0172,
      "step": 1791
    },
    {
      "epoch": 3.083010752688172,
      "grad_norm": 1.0232815850023564,
      "learning_rate": 0.00016204338864395684,
      "loss": 0.0063,
      "step": 1792
    },
    {
      "epoch": 3.084731182795699,
      "grad_norm": 1.3734579964751201,
      "learning_rate": 0.0001619996554629334,
      "loss": 0.0172,
      "step": 1793
    },
    {
      "epoch": 3.086451612903226,
      "grad_norm": 2.783983933879573,
      "learning_rate": 0.0001619559030110468,
      "loss": 0.0461,
      "step": 1794
    },
    {
      "epoch": 3.088172043010753,
      "grad_norm": 0.41987566312307195,
      "learning_rate": 0.00016191213130189612,
      "loss": 0.0044,
      "step": 1795
    },
    {
      "epoch": 3.0898924731182795,
      "grad_norm": 0.5506769958854029,
      "learning_rate": 0.00016186834034908669,
      "loss": 0.0134,
      "step": 1796
    },
    {
      "epoch": 3.0916129032258066,
      "grad_norm": 2.6937357886373086,
      "learning_rate": 0.00016182453016622963,
      "loss": 0.0931,
      "step": 1797
    },
    {
      "epoch": 3.0933333333333333,
      "grad_norm": 1.9702878348571384,
      "learning_rate": 0.00016178070076694213,
      "loss": 0.0363,
      "step": 1798
    },
    {
      "epoch": 3.0950537634408604,
      "grad_norm": 0.9777698458817613,
      "learning_rate": 0.00016173685216484737,
      "loss": 0.0077,
      "step": 1799
    },
    {
      "epoch": 3.096774193548387,
      "grad_norm": 0.21703527660746347,
      "learning_rate": 0.0001616929843735744,
      "loss": 0.0039,
      "step": 1800
    },
    {
      "epoch": 3.098494623655914,
      "grad_norm": 0.4305090343523205,
      "learning_rate": 0.00016164909740675834,
      "loss": 0.0069,
      "step": 1801
    },
    {
      "epoch": 3.1002150537634408,
      "grad_norm": 0.6391139671765691,
      "learning_rate": 0.00016160519127804025,
      "loss": 0.0091,
      "step": 1802
    },
    {
      "epoch": 3.101935483870968,
      "grad_norm": 1.1920876772510731,
      "learning_rate": 0.0001615612660010671,
      "loss": 0.0264,
      "step": 1803
    },
    {
      "epoch": 3.1036559139784945,
      "grad_norm": 0.8977499352018138,
      "learning_rate": 0.00016151732158949184,
      "loss": 0.0173,
      "step": 1804
    },
    {
      "epoch": 3.1053763440860216,
      "grad_norm": 0.49809258401249196,
      "learning_rate": 0.00016147335805697334,
      "loss": 0.0103,
      "step": 1805
    },
    {
      "epoch": 3.1070967741935482,
      "grad_norm": 1.4510898417907812,
      "learning_rate": 0.0001614293754171765,
      "loss": 0.0083,
      "step": 1806
    },
    {
      "epoch": 3.1088172043010753,
      "grad_norm": 0.22548793199663794,
      "learning_rate": 0.00016138537368377202,
      "loss": 0.0046,
      "step": 1807
    },
    {
      "epoch": 3.110537634408602,
      "grad_norm": 1.0709771539520008,
      "learning_rate": 0.00016134135287043669,
      "loss": 0.0266,
      "step": 1808
    },
    {
      "epoch": 3.112258064516129,
      "grad_norm": 0.46059520683046073,
      "learning_rate": 0.00016129731299085307,
      "loss": 0.0042,
      "step": 1809
    },
    {
      "epoch": 3.1139784946236557,
      "grad_norm": 2.47820630429705,
      "learning_rate": 0.00016125325405870976,
      "loss": 0.0607,
      "step": 1810
    },
    {
      "epoch": 3.115698924731183,
      "grad_norm": 1.1507954223296977,
      "learning_rate": 0.0001612091760877013,
      "loss": 0.0115,
      "step": 1811
    },
    {
      "epoch": 3.1174193548387095,
      "grad_norm": 0.12309335030838063,
      "learning_rate": 0.00016116507909152804,
      "loss": 0.0029,
      "step": 1812
    },
    {
      "epoch": 3.1191397849462366,
      "grad_norm": 1.1294150358582604,
      "learning_rate": 0.0001611209630838963,
      "loss": 0.0157,
      "step": 1813
    },
    {
      "epoch": 3.1208602150537637,
      "grad_norm": 1.686853248494712,
      "learning_rate": 0.00016107682807851834,
      "loss": 0.0598,
      "step": 1814
    },
    {
      "epoch": 3.1225806451612903,
      "grad_norm": 1.1152703757093294,
      "learning_rate": 0.0001610326740891123,
      "loss": 0.026,
      "step": 1815
    },
    {
      "epoch": 3.1243010752688174,
      "grad_norm": 0.8900420148714895,
      "learning_rate": 0.00016098850112940217,
      "loss": 0.0321,
      "step": 1816
    },
    {
      "epoch": 3.126021505376344,
      "grad_norm": 0.904234495547423,
      "learning_rate": 0.00016094430921311794,
      "loss": 0.0251,
      "step": 1817
    },
    {
      "epoch": 3.127741935483871,
      "grad_norm": 1.1518985623417657,
      "learning_rate": 0.00016090009835399537,
      "loss": 0.0627,
      "step": 1818
    },
    {
      "epoch": 3.129462365591398,
      "grad_norm": 0.529317298260833,
      "learning_rate": 0.00016085586856577622,
      "loss": 0.0151,
      "step": 1819
    },
    {
      "epoch": 3.131182795698925,
      "grad_norm": 0.3122164742751545,
      "learning_rate": 0.00016081161986220807,
      "loss": 0.0092,
      "step": 1820
    },
    {
      "epoch": 3.1329032258064515,
      "grad_norm": 0.6977075673822842,
      "learning_rate": 0.0001607673522570444,
      "loss": 0.0093,
      "step": 1821
    },
    {
      "epoch": 3.1346236559139786,
      "grad_norm": 0.834449945156459,
      "learning_rate": 0.00016072306576404456,
      "loss": 0.0144,
      "step": 1822
    },
    {
      "epoch": 3.1363440860215053,
      "grad_norm": 0.9434376165513598,
      "learning_rate": 0.00016067876039697375,
      "loss": 0.0141,
      "step": 1823
    },
    {
      "epoch": 3.1380645161290324,
      "grad_norm": 1.1651852110106817,
      "learning_rate": 0.00016063443616960311,
      "loss": 0.0193,
      "step": 1824
    },
    {
      "epoch": 3.139784946236559,
      "grad_norm": 0.4333446166894205,
      "learning_rate": 0.00016059009309570956,
      "loss": 0.007,
      "step": 1825
    },
    {
      "epoch": 3.141505376344086,
      "grad_norm": 0.7194562352668513,
      "learning_rate": 0.00016054573118907587,
      "loss": 0.0101,
      "step": 1826
    },
    {
      "epoch": 3.1432258064516128,
      "grad_norm": 0.605627393528715,
      "learning_rate": 0.00016050135046349073,
      "loss": 0.0093,
      "step": 1827
    },
    {
      "epoch": 3.14494623655914,
      "grad_norm": 1.8727157117463256,
      "learning_rate": 0.0001604569509327487,
      "loss": 0.0292,
      "step": 1828
    },
    {
      "epoch": 3.1466666666666665,
      "grad_norm": 1.041290386547169,
      "learning_rate": 0.00016041253261065002,
      "loss": 0.03,
      "step": 1829
    },
    {
      "epoch": 3.1483870967741936,
      "grad_norm": 1.7899623839807859,
      "learning_rate": 0.00016036809551100105,
      "loss": 0.032,
      "step": 1830
    },
    {
      "epoch": 3.1501075268817202,
      "grad_norm": 1.6967718394648073,
      "learning_rate": 0.00016032363964761363,
      "loss": 0.0187,
      "step": 1831
    },
    {
      "epoch": 3.1518279569892473,
      "grad_norm": 1.4903127131271348,
      "learning_rate": 0.0001602791650343058,
      "loss": 0.0386,
      "step": 1832
    },
    {
      "epoch": 3.153548387096774,
      "grad_norm": 0.5034886116239631,
      "learning_rate": 0.00016023467168490115,
      "loss": 0.0096,
      "step": 1833
    },
    {
      "epoch": 3.155268817204301,
      "grad_norm": 0.7845361238690798,
      "learning_rate": 0.0001601901596132292,
      "loss": 0.0107,
      "step": 1834
    },
    {
      "epoch": 3.156989247311828,
      "grad_norm": 0.619864289699254,
      "learning_rate": 0.00016014562883312535,
      "loss": 0.0262,
      "step": 1835
    },
    {
      "epoch": 3.158709677419355,
      "grad_norm": 1.7323624635465855,
      "learning_rate": 0.00016010107935843067,
      "loss": 0.0363,
      "step": 1836
    },
    {
      "epoch": 3.160430107526882,
      "grad_norm": 0.7865481047907732,
      "learning_rate": 0.00016005651120299218,
      "loss": 0.0065,
      "step": 1837
    },
    {
      "epoch": 3.1621505376344086,
      "grad_norm": 1.3096189487693581,
      "learning_rate": 0.00016001192438066261,
      "loss": 0.0196,
      "step": 1838
    },
    {
      "epoch": 3.1638709677419357,
      "grad_norm": 2.8725994904586365,
      "learning_rate": 0.00015996731890530059,
      "loss": 0.0287,
      "step": 1839
    },
    {
      "epoch": 3.1655913978494623,
      "grad_norm": 4.295235801263017,
      "learning_rate": 0.0001599226947907704,
      "loss": 0.022,
      "step": 1840
    },
    {
      "epoch": 3.1673118279569894,
      "grad_norm": 1.7762363454062107,
      "learning_rate": 0.00015987805205094227,
      "loss": 0.0201,
      "step": 1841
    },
    {
      "epoch": 3.169032258064516,
      "grad_norm": 0.6825421390943857,
      "learning_rate": 0.00015983339069969212,
      "loss": 0.013,
      "step": 1842
    },
    {
      "epoch": 3.170752688172043,
      "grad_norm": 0.5568031879745012,
      "learning_rate": 0.0001597887107509017,
      "loss": 0.009,
      "step": 1843
    },
    {
      "epoch": 3.17247311827957,
      "grad_norm": 0.2309319662074782,
      "learning_rate": 0.00015974401221845853,
      "loss": 0.0032,
      "step": 1844
    },
    {
      "epoch": 3.174193548387097,
      "grad_norm": 1.1277291684525002,
      "learning_rate": 0.00015969929511625586,
      "loss": 0.0217,
      "step": 1845
    },
    {
      "epoch": 3.1759139784946235,
      "grad_norm": 1.3014905472313791,
      "learning_rate": 0.00015965455945819279,
      "loss": 0.0205,
      "step": 1846
    },
    {
      "epoch": 3.1776344086021506,
      "grad_norm": 1.4203760478547043,
      "learning_rate": 0.00015960980525817414,
      "loss": 0.0461,
      "step": 1847
    },
    {
      "epoch": 3.1793548387096773,
      "grad_norm": 1.0432230764828663,
      "learning_rate": 0.00015956503253011052,
      "loss": 0.0347,
      "step": 1848
    },
    {
      "epoch": 3.1810752688172044,
      "grad_norm": 0.9572307452460542,
      "learning_rate": 0.00015952024128791827,
      "loss": 0.018,
      "step": 1849
    },
    {
      "epoch": 3.182795698924731,
      "grad_norm": 1.2897074077091237,
      "learning_rate": 0.0001594754315455195,
      "loss": 0.0227,
      "step": 1850
    },
    {
      "epoch": 3.184516129032258,
      "grad_norm": 1.4828826384807277,
      "learning_rate": 0.0001594306033168421,
      "loss": 0.0164,
      "step": 1851
    },
    {
      "epoch": 3.1862365591397848,
      "grad_norm": 0.4363605028508113,
      "learning_rate": 0.0001593857566158196,
      "loss": 0.01,
      "step": 1852
    },
    {
      "epoch": 3.187956989247312,
      "grad_norm": 1.2262833346629507,
      "learning_rate": 0.00015934089145639143,
      "loss": 0.0138,
      "step": 1853
    },
    {
      "epoch": 3.1896774193548385,
      "grad_norm": 1.1105352816916447,
      "learning_rate": 0.00015929600785250257,
      "loss": 0.0238,
      "step": 1854
    },
    {
      "epoch": 3.1913978494623656,
      "grad_norm": 0.23989716344613524,
      "learning_rate": 0.00015925110581810394,
      "loss": 0.0059,
      "step": 1855
    },
    {
      "epoch": 3.1931182795698927,
      "grad_norm": 1.6680106741135146,
      "learning_rate": 0.00015920618536715203,
      "loss": 0.0287,
      "step": 1856
    },
    {
      "epoch": 3.1948387096774193,
      "grad_norm": 0.6063903365553397,
      "learning_rate": 0.00015916124651360914,
      "loss": 0.0097,
      "step": 1857
    },
    {
      "epoch": 3.1965591397849464,
      "grad_norm": 0.31871358889089957,
      "learning_rate": 0.00015911628927144325,
      "loss": 0.0068,
      "step": 1858
    },
    {
      "epoch": 3.198279569892473,
      "grad_norm": 1.2468249626867314,
      "learning_rate": 0.000159071313654628,
      "loss": 0.0105,
      "step": 1859
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.8269989830443053,
      "learning_rate": 0.00015902631967714293,
      "loss": 0.0258,
      "step": 1860
    },
    {
      "epoch": 3.201720430107527,
      "grad_norm": 0.6548607681776881,
      "learning_rate": 0.00015898130735297308,
      "loss": 0.0099,
      "step": 1861
    },
    {
      "epoch": 3.203440860215054,
      "grad_norm": 1.7602935298665878,
      "learning_rate": 0.00015893627669610926,
      "loss": 0.0334,
      "step": 1862
    },
    {
      "epoch": 3.2051612903225806,
      "grad_norm": 0.5853229036506217,
      "learning_rate": 0.00015889122772054802,
      "loss": 0.0058,
      "step": 1863
    },
    {
      "epoch": 3.2068817204301077,
      "grad_norm": 0.3036806864665268,
      "learning_rate": 0.00015884616044029162,
      "loss": 0.0052,
      "step": 1864
    },
    {
      "epoch": 3.2086021505376343,
      "grad_norm": 0.6402224685380522,
      "learning_rate": 0.0001588010748693479,
      "loss": 0.0079,
      "step": 1865
    },
    {
      "epoch": 3.2103225806451614,
      "grad_norm": 1.2416142261817238,
      "learning_rate": 0.00015875597102173048,
      "loss": 0.0072,
      "step": 1866
    },
    {
      "epoch": 3.212043010752688,
      "grad_norm": 0.7810938733156947,
      "learning_rate": 0.0001587108489114586,
      "loss": 0.0143,
      "step": 1867
    },
    {
      "epoch": 3.213763440860215,
      "grad_norm": 1.5354972313597965,
      "learning_rate": 0.00015866570855255728,
      "loss": 0.0163,
      "step": 1868
    },
    {
      "epoch": 3.215483870967742,
      "grad_norm": 1.2850571430946687,
      "learning_rate": 0.0001586205499590571,
      "loss": 0.0224,
      "step": 1869
    },
    {
      "epoch": 3.217204301075269,
      "grad_norm": 0.2174039434335095,
      "learning_rate": 0.0001585753731449944,
      "loss": 0.0033,
      "step": 1870
    },
    {
      "epoch": 3.2189247311827955,
      "grad_norm": 1.4035082753704977,
      "learning_rate": 0.000158530178124411,
      "loss": 0.0269,
      "step": 1871
    },
    {
      "epoch": 3.2206451612903226,
      "grad_norm": 1.2581294711551014,
      "learning_rate": 0.00015848496491135462,
      "loss": 0.0113,
      "step": 1872
    },
    {
      "epoch": 3.2223655913978493,
      "grad_norm": 1.1873643291836045,
      "learning_rate": 0.00015843973351987848,
      "loss": 0.0167,
      "step": 1873
    },
    {
      "epoch": 3.2240860215053764,
      "grad_norm": 1.365770049237868,
      "learning_rate": 0.00015839448396404157,
      "loss": 0.0171,
      "step": 1874
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.9416574969341716,
      "learning_rate": 0.00015834921625790838,
      "loss": 0.0054,
      "step": 1875
    },
    {
      "epoch": 3.22752688172043,
      "grad_norm": 0.1986870790603898,
      "learning_rate": 0.0001583039304155491,
      "loss": 0.0014,
      "step": 1876
    },
    {
      "epoch": 3.229247311827957,
      "grad_norm": 0.32619777617226386,
      "learning_rate": 0.0001582586264510396,
      "loss": 0.0034,
      "step": 1877
    },
    {
      "epoch": 3.230967741935484,
      "grad_norm": 1.0829160076768405,
      "learning_rate": 0.0001582133043784614,
      "loss": 0.0156,
      "step": 1878
    },
    {
      "epoch": 3.232688172043011,
      "grad_norm": 0.8844684298527835,
      "learning_rate": 0.00015816796421190153,
      "loss": 0.0235,
      "step": 1879
    },
    {
      "epoch": 3.2344086021505376,
      "grad_norm": 0.6994002546825103,
      "learning_rate": 0.00015812260596545277,
      "loss": 0.0138,
      "step": 1880
    },
    {
      "epoch": 3.2361290322580647,
      "grad_norm": 3.1100716639582546,
      "learning_rate": 0.00015807722965321342,
      "loss": 0.0332,
      "step": 1881
    },
    {
      "epoch": 3.2378494623655913,
      "grad_norm": 0.7015008174769326,
      "learning_rate": 0.00015803183528928746,
      "loss": 0.0077,
      "step": 1882
    },
    {
      "epoch": 3.2395698924731184,
      "grad_norm": 0.7066270526017968,
      "learning_rate": 0.00015798642288778448,
      "loss": 0.0149,
      "step": 1883
    },
    {
      "epoch": 3.241290322580645,
      "grad_norm": 0.20833949873354143,
      "learning_rate": 0.00015794099246281963,
      "loss": 0.0023,
      "step": 1884
    },
    {
      "epoch": 3.243010752688172,
      "grad_norm": 0.26041414938205976,
      "learning_rate": 0.00015789554402851366,
      "loss": 0.0032,
      "step": 1885
    },
    {
      "epoch": 3.244731182795699,
      "grad_norm": 0.48030170676867023,
      "learning_rate": 0.00015785007759899303,
      "loss": 0.0042,
      "step": 1886
    },
    {
      "epoch": 3.246451612903226,
      "grad_norm": 1.491376448007277,
      "learning_rate": 0.00015780459318838968,
      "loss": 0.0128,
      "step": 1887
    },
    {
      "epoch": 3.2481720430107526,
      "grad_norm": 0.36193949287109,
      "learning_rate": 0.00015775909081084115,
      "loss": 0.0033,
      "step": 1888
    },
    {
      "epoch": 3.2498924731182797,
      "grad_norm": 1.7891390126300937,
      "learning_rate": 0.0001577135704804906,
      "loss": 0.0276,
      "step": 1889
    },
    {
      "epoch": 3.2516129032258063,
      "grad_norm": 0.30129695658973243,
      "learning_rate": 0.00015766803221148673,
      "loss": 0.0022,
      "step": 1890
    },
    {
      "epoch": 3.2533333333333334,
      "grad_norm": 0.7827494697384695,
      "learning_rate": 0.00015762247601798385,
      "loss": 0.0054,
      "step": 1891
    },
    {
      "epoch": 3.25505376344086,
      "grad_norm": 1.121351242191702,
      "learning_rate": 0.00015757690191414188,
      "loss": 0.0359,
      "step": 1892
    },
    {
      "epoch": 3.256774193548387,
      "grad_norm": 2.362288298383231,
      "learning_rate": 0.0001575313099141262,
      "loss": 0.0802,
      "step": 1893
    },
    {
      "epoch": 3.258494623655914,
      "grad_norm": 0.2611035506568923,
      "learning_rate": 0.00015748570003210782,
      "loss": 0.0028,
      "step": 1894
    },
    {
      "epoch": 3.260215053763441,
      "grad_norm": 1.4059668066722513,
      "learning_rate": 0.00015744007228226333,
      "loss": 0.0509,
      "step": 1895
    },
    {
      "epoch": 3.2619354838709675,
      "grad_norm": 0.1573288688154355,
      "learning_rate": 0.0001573944266787748,
      "loss": 0.0012,
      "step": 1896
    },
    {
      "epoch": 3.2636559139784946,
      "grad_norm": 1.1421739989961495,
      "learning_rate": 0.00015734876323582995,
      "loss": 0.0391,
      "step": 1897
    },
    {
      "epoch": 3.2653763440860217,
      "grad_norm": 0.4847890000132312,
      "learning_rate": 0.00015730308196762192,
      "loss": 0.0057,
      "step": 1898
    },
    {
      "epoch": 3.2670967741935484,
      "grad_norm": 0.7508880935272993,
      "learning_rate": 0.0001572573828883495,
      "loss": 0.0074,
      "step": 1899
    },
    {
      "epoch": 3.268817204301075,
      "grad_norm": 0.2044103208013758,
      "learning_rate": 0.00015721166601221698,
      "loss": 0.0025,
      "step": 1900
    },
    {
      "epoch": 3.270537634408602,
      "grad_norm": 0.8899365900775367,
      "learning_rate": 0.00015716593135343417,
      "loss": 0.0076,
      "step": 1901
    },
    {
      "epoch": 3.272258064516129,
      "grad_norm": 0.8165811634835723,
      "learning_rate": 0.00015712017892621636,
      "loss": 0.0123,
      "step": 1902
    },
    {
      "epoch": 3.273978494623656,
      "grad_norm": 0.7418005836878276,
      "learning_rate": 0.0001570744087447845,
      "loss": 0.0075,
      "step": 1903
    },
    {
      "epoch": 3.275698924731183,
      "grad_norm": 0.8140847668420059,
      "learning_rate": 0.00015702862082336489,
      "loss": 0.0083,
      "step": 1904
    },
    {
      "epoch": 3.2774193548387096,
      "grad_norm": 0.7741181148639413,
      "learning_rate": 0.00015698281517618953,
      "loss": 0.0124,
      "step": 1905
    },
    {
      "epoch": 3.2791397849462367,
      "grad_norm": 1.7669791960709034,
      "learning_rate": 0.00015693699181749572,
      "loss": 0.028,
      "step": 1906
    },
    {
      "epoch": 3.2808602150537634,
      "grad_norm": 1.3418859992477647,
      "learning_rate": 0.00015689115076152646,
      "loss": 0.02,
      "step": 1907
    },
    {
      "epoch": 3.2825806451612904,
      "grad_norm": 0.7612676403024458,
      "learning_rate": 0.0001568452920225301,
      "loss": 0.0134,
      "step": 1908
    },
    {
      "epoch": 3.284301075268817,
      "grad_norm": 0.10439127524856939,
      "learning_rate": 0.00015679941561476057,
      "loss": 0.0011,
      "step": 1909
    },
    {
      "epoch": 3.286021505376344,
      "grad_norm": 2.671139839165867,
      "learning_rate": 0.0001567535215524773,
      "loss": 0.0815,
      "step": 1910
    },
    {
      "epoch": 3.287741935483871,
      "grad_norm": 0.5059849024895731,
      "learning_rate": 0.00015670760984994514,
      "loss": 0.0058,
      "step": 1911
    },
    {
      "epoch": 3.289462365591398,
      "grad_norm": 1.3885885569552645,
      "learning_rate": 0.00015666168052143448,
      "loss": 0.0445,
      "step": 1912
    },
    {
      "epoch": 3.2911827956989246,
      "grad_norm": 0.9323031603393186,
      "learning_rate": 0.00015661573358122114,
      "loss": 0.015,
      "step": 1913
    },
    {
      "epoch": 3.2929032258064517,
      "grad_norm": 0.8301955739402823,
      "learning_rate": 0.0001565697690435865,
      "loss": 0.008,
      "step": 1914
    },
    {
      "epoch": 3.2946236559139783,
      "grad_norm": 0.7970202606373459,
      "learning_rate": 0.00015652378692281732,
      "loss": 0.0133,
      "step": 1915
    },
    {
      "epoch": 3.2963440860215054,
      "grad_norm": 0.29050217908836684,
      "learning_rate": 0.0001564777872332059,
      "loss": 0.0039,
      "step": 1916
    },
    {
      "epoch": 3.298064516129032,
      "grad_norm": 0.9765723136101125,
      "learning_rate": 0.0001564317699890499,
      "loss": 0.0075,
      "step": 1917
    },
    {
      "epoch": 3.299784946236559,
      "grad_norm": 1.2754418290854184,
      "learning_rate": 0.0001563857352046525,
      "loss": 0.034,
      "step": 1918
    },
    {
      "epoch": 3.3015053763440863,
      "grad_norm": 0.1719613315171528,
      "learning_rate": 0.00015633968289432236,
      "loss": 0.0038,
      "step": 1919
    },
    {
      "epoch": 3.303225806451613,
      "grad_norm": 0.23669908650569793,
      "learning_rate": 0.00015629361307237355,
      "loss": 0.005,
      "step": 1920
    },
    {
      "epoch": 3.3049462365591395,
      "grad_norm": 0.4731025640363452,
      "learning_rate": 0.0001562475257531256,
      "loss": 0.0105,
      "step": 1921
    },
    {
      "epoch": 3.3066666666666666,
      "grad_norm": 1.6391463622684233,
      "learning_rate": 0.0001562014209509034,
      "loss": 0.0119,
      "step": 1922
    },
    {
      "epoch": 3.3083870967741937,
      "grad_norm": 0.6623661376632896,
      "learning_rate": 0.0001561552986800375,
      "loss": 0.0066,
      "step": 1923
    },
    {
      "epoch": 3.3101075268817204,
      "grad_norm": 2.01821399058185,
      "learning_rate": 0.00015610915895486352,
      "loss": 0.0248,
      "step": 1924
    },
    {
      "epoch": 3.3118279569892475,
      "grad_norm": 1.0631404574124521,
      "learning_rate": 0.00015606300178972287,
      "loss": 0.0082,
      "step": 1925
    },
    {
      "epoch": 3.313548387096774,
      "grad_norm": 1.93442249251628,
      "learning_rate": 0.00015601682719896208,
      "loss": 0.0221,
      "step": 1926
    },
    {
      "epoch": 3.315268817204301,
      "grad_norm": 7.508138574194392,
      "learning_rate": 0.00015597063519693337,
      "loss": 0.0374,
      "step": 1927
    },
    {
      "epoch": 3.316989247311828,
      "grad_norm": 0.5582931467256046,
      "learning_rate": 0.0001559244257979941,
      "loss": 0.0055,
      "step": 1928
    },
    {
      "epoch": 3.318709677419355,
      "grad_norm": 0.34047350157146616,
      "learning_rate": 0.0001558781990165073,
      "loss": 0.0037,
      "step": 1929
    },
    {
      "epoch": 3.3204301075268816,
      "grad_norm": 1.1639385801757098,
      "learning_rate": 0.00015583195486684116,
      "loss": 0.0179,
      "step": 1930
    },
    {
      "epoch": 3.3221505376344087,
      "grad_norm": 0.5132192067907847,
      "learning_rate": 0.00015578569336336951,
      "loss": 0.0071,
      "step": 1931
    },
    {
      "epoch": 3.3238709677419354,
      "grad_norm": 0.723951648026254,
      "learning_rate": 0.00015573941452047131,
      "loss": 0.005,
      "step": 1932
    },
    {
      "epoch": 3.3255913978494624,
      "grad_norm": 0.529517714809804,
      "learning_rate": 0.0001556931183525312,
      "loss": 0.0119,
      "step": 1933
    },
    {
      "epoch": 3.327311827956989,
      "grad_norm": 0.07070766113554589,
      "learning_rate": 0.00015564680487393888,
      "loss": 0.0011,
      "step": 1934
    },
    {
      "epoch": 3.329032258064516,
      "grad_norm": 3.5017840195420162,
      "learning_rate": 0.0001556004740990897,
      "loss": 0.0829,
      "step": 1935
    },
    {
      "epoch": 3.330752688172043,
      "grad_norm": 0.6369840526842848,
      "learning_rate": 0.00015555412604238432,
      "loss": 0.0077,
      "step": 1936
    },
    {
      "epoch": 3.33247311827957,
      "grad_norm": 0.9871445666175696,
      "learning_rate": 0.00015550776071822866,
      "loss": 0.0272,
      "step": 1937
    },
    {
      "epoch": 3.3341935483870966,
      "grad_norm": 0.15201342619102268,
      "learning_rate": 0.00015546137814103416,
      "loss": 0.0014,
      "step": 1938
    },
    {
      "epoch": 3.3359139784946237,
      "grad_norm": 1.193809113601661,
      "learning_rate": 0.0001554149783252175,
      "loss": 0.0127,
      "step": 1939
    },
    {
      "epoch": 3.3376344086021508,
      "grad_norm": 0.6211191065776165,
      "learning_rate": 0.00015536856128520077,
      "loss": 0.0095,
      "step": 1940
    },
    {
      "epoch": 3.3393548387096774,
      "grad_norm": 1.173159004534979,
      "learning_rate": 0.00015532212703541143,
      "loss": 0.0107,
      "step": 1941
    },
    {
      "epoch": 3.341075268817204,
      "grad_norm": 0.8501943172619877,
      "learning_rate": 0.0001552756755902823,
      "loss": 0.0123,
      "step": 1942
    },
    {
      "epoch": 3.342795698924731,
      "grad_norm": 0.7771717949675174,
      "learning_rate": 0.00015522920696425146,
      "loss": 0.0128,
      "step": 1943
    },
    {
      "epoch": 3.3445161290322583,
      "grad_norm": 0.9095871532175064,
      "learning_rate": 0.0001551827211717624,
      "loss": 0.0072,
      "step": 1944
    },
    {
      "epoch": 3.346236559139785,
      "grad_norm": 1.276021076014445,
      "learning_rate": 0.00015513621822726395,
      "loss": 0.0117,
      "step": 1945
    },
    {
      "epoch": 3.347956989247312,
      "grad_norm": 0.6652687445095701,
      "learning_rate": 0.00015508969814521025,
      "loss": 0.0047,
      "step": 1946
    },
    {
      "epoch": 3.3496774193548386,
      "grad_norm": 0.6526457038563234,
      "learning_rate": 0.00015504316094006078,
      "loss": 0.0168,
      "step": 1947
    },
    {
      "epoch": 3.3513978494623657,
      "grad_norm": 0.644159928609872,
      "learning_rate": 0.0001549966066262803,
      "loss": 0.0068,
      "step": 1948
    },
    {
      "epoch": 3.3531182795698924,
      "grad_norm": 0.6268753991122847,
      "learning_rate": 0.00015495003521833893,
      "loss": 0.0118,
      "step": 1949
    },
    {
      "epoch": 3.3548387096774195,
      "grad_norm": 3.2365099919829596,
      "learning_rate": 0.00015490344673071212,
      "loss": 0.0197,
      "step": 1950
    },
    {
      "epoch": 3.356559139784946,
      "grad_norm": 0.46402090691462583,
      "learning_rate": 0.00015485684117788056,
      "loss": 0.0047,
      "step": 1951
    },
    {
      "epoch": 3.3582795698924732,
      "grad_norm": 1.564094548227057,
      "learning_rate": 0.0001548102185743303,
      "loss": 0.024,
      "step": 1952
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.8780816199214181,
      "learning_rate": 0.00015476357893455268,
      "loss": 0.0117,
      "step": 1953
    },
    {
      "epoch": 3.361720430107527,
      "grad_norm": 3.301266601321382,
      "learning_rate": 0.00015471692227304434,
      "loss": 0.0365,
      "step": 1954
    },
    {
      "epoch": 3.3634408602150536,
      "grad_norm": 0.6318299953667083,
      "learning_rate": 0.0001546702486043072,
      "loss": 0.0076,
      "step": 1955
    },
    {
      "epoch": 3.3651612903225807,
      "grad_norm": 1.1248252390122597,
      "learning_rate": 0.00015462355794284847,
      "loss": 0.0248,
      "step": 1956
    },
    {
      "epoch": 3.3668817204301074,
      "grad_norm": 0.27483140698086844,
      "learning_rate": 0.00015457685030318064,
      "loss": 0.0031,
      "step": 1957
    },
    {
      "epoch": 3.3686021505376345,
      "grad_norm": 1.203796227386089,
      "learning_rate": 0.00015453012569982143,
      "loss": 0.017,
      "step": 1958
    },
    {
      "epoch": 3.370322580645161,
      "grad_norm": 0.6224900097617766,
      "learning_rate": 0.00015448338414729396,
      "loss": 0.0053,
      "step": 1959
    },
    {
      "epoch": 3.372043010752688,
      "grad_norm": 0.7177063544988191,
      "learning_rate": 0.00015443662566012645,
      "loss": 0.005,
      "step": 1960
    },
    {
      "epoch": 3.3737634408602153,
      "grad_norm": 0.7613508269708916,
      "learning_rate": 0.00015438985025285256,
      "loss": 0.0018,
      "step": 1961
    },
    {
      "epoch": 3.375483870967742,
      "grad_norm": 1.396105431376861,
      "learning_rate": 0.00015434305794001106,
      "loss": 0.0185,
      "step": 1962
    },
    {
      "epoch": 3.3772043010752686,
      "grad_norm": 1.6448124898312415,
      "learning_rate": 0.00015429624873614602,
      "loss": 0.0854,
      "step": 1963
    },
    {
      "epoch": 3.3789247311827957,
      "grad_norm": 0.2151225909115289,
      "learning_rate": 0.00015424942265580683,
      "loss": 0.0022,
      "step": 1964
    },
    {
      "epoch": 3.3806451612903228,
      "grad_norm": 0.2974200427898268,
      "learning_rate": 0.00015420257971354807,
      "loss": 0.0018,
      "step": 1965
    },
    {
      "epoch": 3.3823655913978494,
      "grad_norm": 0.3516280918220694,
      "learning_rate": 0.00015415571992392953,
      "loss": 0.0026,
      "step": 1966
    },
    {
      "epoch": 3.3840860215053765,
      "grad_norm": 0.47192401375007786,
      "learning_rate": 0.00015410884330151626,
      "loss": 0.0038,
      "step": 1967
    },
    {
      "epoch": 3.385806451612903,
      "grad_norm": 0.5891210266049003,
      "learning_rate": 0.0001540619498608786,
      "loss": 0.0091,
      "step": 1968
    },
    {
      "epoch": 3.3875268817204303,
      "grad_norm": 0.7793626610401115,
      "learning_rate": 0.00015401503961659204,
      "loss": 0.0093,
      "step": 1969
    },
    {
      "epoch": 3.389247311827957,
      "grad_norm": 2.3803488231487666,
      "learning_rate": 0.0001539681125832373,
      "loss": 0.0569,
      "step": 1970
    },
    {
      "epoch": 3.390967741935484,
      "grad_norm": 0.9579437872548495,
      "learning_rate": 0.0001539211687754003,
      "loss": 0.0258,
      "step": 1971
    },
    {
      "epoch": 3.3926881720430107,
      "grad_norm": 1.1950283108012876,
      "learning_rate": 0.00015387420820767235,
      "loss": 0.0255,
      "step": 1972
    },
    {
      "epoch": 3.3944086021505377,
      "grad_norm": 1.0161451110563835,
      "learning_rate": 0.00015382723089464974,
      "loss": 0.0136,
      "step": 1973
    },
    {
      "epoch": 3.3961290322580644,
      "grad_norm": 1.1466035752048536,
      "learning_rate": 0.00015378023685093406,
      "loss": 0.0128,
      "step": 1974
    },
    {
      "epoch": 3.3978494623655915,
      "grad_norm": 0.11291889777221936,
      "learning_rate": 0.00015373322609113206,
      "loss": 0.0018,
      "step": 1975
    },
    {
      "epoch": 3.399569892473118,
      "grad_norm": 0.730134009745689,
      "learning_rate": 0.00015368619862985583,
      "loss": 0.0053,
      "step": 1976
    },
    {
      "epoch": 3.4012903225806452,
      "grad_norm": 0.35083564011496227,
      "learning_rate": 0.00015363915448172246,
      "loss": 0.0039,
      "step": 1977
    },
    {
      "epoch": 3.403010752688172,
      "grad_norm": 1.8503028353191402,
      "learning_rate": 0.0001535920936613543,
      "loss": 0.0095,
      "step": 1978
    },
    {
      "epoch": 3.404731182795699,
      "grad_norm": 1.4246567961566265,
      "learning_rate": 0.00015354501618337899,
      "loss": 0.013,
      "step": 1979
    },
    {
      "epoch": 3.4064516129032256,
      "grad_norm": 1.373511372737171,
      "learning_rate": 0.00015349792206242917,
      "loss": 0.0144,
      "step": 1980
    },
    {
      "epoch": 3.4081720430107527,
      "grad_norm": 0.4336841163451538,
      "learning_rate": 0.00015345081131314274,
      "loss": 0.0053,
      "step": 1981
    },
    {
      "epoch": 3.40989247311828,
      "grad_norm": 1.3141911958632926,
      "learning_rate": 0.0001534036839501628,
      "loss": 0.0215,
      "step": 1982
    },
    {
      "epoch": 3.4116129032258065,
      "grad_norm": 0.6477628989682578,
      "learning_rate": 0.00015335653998813754,
      "loss": 0.012,
      "step": 1983
    },
    {
      "epoch": 3.413333333333333,
      "grad_norm": 1.1167528702754512,
      "learning_rate": 0.00015330937944172033,
      "loss": 0.0138,
      "step": 1984
    },
    {
      "epoch": 3.41505376344086,
      "grad_norm": 0.0314097085547416,
      "learning_rate": 0.00015326220232556975,
      "loss": 0.0004,
      "step": 1985
    },
    {
      "epoch": 3.4167741935483873,
      "grad_norm": 0.5506334207124203,
      "learning_rate": 0.00015321500865434948,
      "loss": 0.006,
      "step": 1986
    },
    {
      "epoch": 3.418494623655914,
      "grad_norm": 0.47531340693176194,
      "learning_rate": 0.00015316779844272836,
      "loss": 0.0033,
      "step": 1987
    },
    {
      "epoch": 3.420215053763441,
      "grad_norm": 0.40368879413422093,
      "learning_rate": 0.00015312057170538035,
      "loss": 0.0059,
      "step": 1988
    },
    {
      "epoch": 3.4219354838709677,
      "grad_norm": 1.8330870511364874,
      "learning_rate": 0.00015307332845698455,
      "loss": 0.1148,
      "step": 1989
    },
    {
      "epoch": 3.423655913978495,
      "grad_norm": 1.0081308788033003,
      "learning_rate": 0.00015302606871222526,
      "loss": 0.0099,
      "step": 1990
    },
    {
      "epoch": 3.4253763440860214,
      "grad_norm": 1.210540628515885,
      "learning_rate": 0.00015297879248579184,
      "loss": 0.011,
      "step": 1991
    },
    {
      "epoch": 3.4270967741935485,
      "grad_norm": 0.3577854026877226,
      "learning_rate": 0.00015293149979237876,
      "loss": 0.0036,
      "step": 1992
    },
    {
      "epoch": 3.428817204301075,
      "grad_norm": 0.48699452129678533,
      "learning_rate": 0.0001528841906466856,
      "loss": 0.0101,
      "step": 1993
    },
    {
      "epoch": 3.4305376344086023,
      "grad_norm": 0.701303630953236,
      "learning_rate": 0.00015283686506341716,
      "loss": 0.0068,
      "step": 1994
    },
    {
      "epoch": 3.432258064516129,
      "grad_norm": 1.4847997006869083,
      "learning_rate": 0.00015278952305728324,
      "loss": 0.0311,
      "step": 1995
    },
    {
      "epoch": 3.433978494623656,
      "grad_norm": 0.3469554352254612,
      "learning_rate": 0.00015274216464299881,
      "loss": 0.0045,
      "step": 1996
    },
    {
      "epoch": 3.4356989247311827,
      "grad_norm": 1.9005575346541477,
      "learning_rate": 0.0001526947898352839,
      "loss": 0.0502,
      "step": 1997
    },
    {
      "epoch": 3.4374193548387098,
      "grad_norm": 0.11834411165340636,
      "learning_rate": 0.0001526473986488636,
      "loss": 0.0012,
      "step": 1998
    },
    {
      "epoch": 3.4391397849462364,
      "grad_norm": 1.8776306076633853,
      "learning_rate": 0.00015259999109846822,
      "loss": 0.0467,
      "step": 1999
    },
    {
      "epoch": 3.4408602150537635,
      "grad_norm": 0.7933771924076926,
      "learning_rate": 0.00015255256719883299,
      "loss": 0.0144,
      "step": 2000
    },
    {
      "epoch": 3.44258064516129,
      "grad_norm": 0.8884674551725823,
      "learning_rate": 0.00015250512696469838,
      "loss": 0.021,
      "step": 2001
    },
    {
      "epoch": 3.4443010752688172,
      "grad_norm": 1.9681180991874005,
      "learning_rate": 0.00015245767041080981,
      "loss": 0.0123,
      "step": 2002
    },
    {
      "epoch": 3.4460215053763443,
      "grad_norm": 0.4541877587789377,
      "learning_rate": 0.00015241019755191787,
      "loss": 0.0061,
      "step": 2003
    },
    {
      "epoch": 3.447741935483871,
      "grad_norm": 0.12088141362492358,
      "learning_rate": 0.00015236270840277816,
      "loss": 0.0022,
      "step": 2004
    },
    {
      "epoch": 3.4494623655913976,
      "grad_norm": 0.744065943592123,
      "learning_rate": 0.0001523152029781513,
      "loss": 0.0184,
      "step": 2005
    },
    {
      "epoch": 3.4511827956989247,
      "grad_norm": 0.8484339336738803,
      "learning_rate": 0.0001522676812928031,
      "loss": 0.0075,
      "step": 2006
    },
    {
      "epoch": 3.452903225806452,
      "grad_norm": 0.7230146805607708,
      "learning_rate": 0.00015222014336150434,
      "loss": 0.0128,
      "step": 2007
    },
    {
      "epoch": 3.4546236559139785,
      "grad_norm": 1.2254090596737661,
      "learning_rate": 0.00015217258919903083,
      "loss": 0.0178,
      "step": 2008
    },
    {
      "epoch": 3.4563440860215056,
      "grad_norm": 1.1795144932613268,
      "learning_rate": 0.00015212501882016344,
      "loss": 0.0185,
      "step": 2009
    },
    {
      "epoch": 3.458064516129032,
      "grad_norm": 0.22150958414921743,
      "learning_rate": 0.0001520774322396882,
      "loss": 0.0028,
      "step": 2010
    },
    {
      "epoch": 3.4597849462365593,
      "grad_norm": 1.2885841182425732,
      "learning_rate": 0.00015202982947239594,
      "loss": 0.0373,
      "step": 2011
    },
    {
      "epoch": 3.461505376344086,
      "grad_norm": 1.4479592552152312,
      "learning_rate": 0.00015198221053308272,
      "loss": 0.0192,
      "step": 2012
    },
    {
      "epoch": 3.463225806451613,
      "grad_norm": 1.3381518360457147,
      "learning_rate": 0.00015193457543654954,
      "loss": 0.0377,
      "step": 2013
    },
    {
      "epoch": 3.4649462365591397,
      "grad_norm": 1.2277624758319379,
      "learning_rate": 0.00015188692419760246,
      "loss": 0.0309,
      "step": 2014
    },
    {
      "epoch": 3.466666666666667,
      "grad_norm": 0.045749062110706076,
      "learning_rate": 0.00015183925683105254,
      "loss": 0.0008,
      "step": 2015
    },
    {
      "epoch": 3.4683870967741934,
      "grad_norm": 0.21165473446120475,
      "learning_rate": 0.0001517915733517158,
      "loss": 0.0031,
      "step": 2016
    },
    {
      "epoch": 3.4701075268817205,
      "grad_norm": 1.5123811005736303,
      "learning_rate": 0.00015174387377441337,
      "loss": 0.026,
      "step": 2017
    },
    {
      "epoch": 3.471827956989247,
      "grad_norm": 0.8085096081212024,
      "learning_rate": 0.00015169615811397132,
      "loss": 0.0253,
      "step": 2018
    },
    {
      "epoch": 3.4735483870967743,
      "grad_norm": 0.6879164637850532,
      "learning_rate": 0.0001516484263852207,
      "loss": 0.0217,
      "step": 2019
    },
    {
      "epoch": 3.475268817204301,
      "grad_norm": 1.2058196313446088,
      "learning_rate": 0.00015160067860299766,
      "loss": 0.0524,
      "step": 2020
    },
    {
      "epoch": 3.476989247311828,
      "grad_norm": 2.3697152255903573,
      "learning_rate": 0.00015155291478214319,
      "loss": 0.0584,
      "step": 2021
    },
    {
      "epoch": 3.4787096774193547,
      "grad_norm": 0.5156423859570897,
      "learning_rate": 0.0001515051349375034,
      "loss": 0.0076,
      "step": 2022
    },
    {
      "epoch": 3.4804301075268818,
      "grad_norm": 1.7368693215382014,
      "learning_rate": 0.0001514573390839293,
      "loss": 0.0381,
      "step": 2023
    },
    {
      "epoch": 3.482150537634409,
      "grad_norm": 0.5565885217853375,
      "learning_rate": 0.00015140952723627688,
      "loss": 0.0123,
      "step": 2024
    },
    {
      "epoch": 3.4838709677419355,
      "grad_norm": 1.0289934989970229,
      "learning_rate": 0.0001513616994094071,
      "loss": 0.0226,
      "step": 2025
    },
    {
      "epoch": 3.485591397849462,
      "grad_norm": 1.2559411565595031,
      "learning_rate": 0.00015131385561818598,
      "loss": 0.0107,
      "step": 2026
    },
    {
      "epoch": 3.4873118279569892,
      "grad_norm": 0.6963949665879412,
      "learning_rate": 0.0001512659958774844,
      "loss": 0.0143,
      "step": 2027
    },
    {
      "epoch": 3.4890322580645163,
      "grad_norm": 0.3159410637189679,
      "learning_rate": 0.00015121812020217818,
      "loss": 0.0063,
      "step": 2028
    },
    {
      "epoch": 3.490752688172043,
      "grad_norm": 0.5530666491382178,
      "learning_rate": 0.00015117022860714816,
      "loss": 0.0175,
      "step": 2029
    },
    {
      "epoch": 3.49247311827957,
      "grad_norm": 0.5480016371072182,
      "learning_rate": 0.00015112232110728015,
      "loss": 0.0042,
      "step": 2030
    },
    {
      "epoch": 3.4941935483870967,
      "grad_norm": 1.0179891969451447,
      "learning_rate": 0.00015107439771746482,
      "loss": 0.028,
      "step": 2031
    },
    {
      "epoch": 3.495913978494624,
      "grad_norm": 1.757486755541504,
      "learning_rate": 0.00015102645845259778,
      "loss": 0.0313,
      "step": 2032
    },
    {
      "epoch": 3.4976344086021505,
      "grad_norm": 0.8197349956367391,
      "learning_rate": 0.0001509785033275797,
      "loss": 0.0092,
      "step": 2033
    },
    {
      "epoch": 3.4993548387096776,
      "grad_norm": 1.2998665500265918,
      "learning_rate": 0.00015093053235731605,
      "loss": 0.0183,
      "step": 2034
    },
    {
      "epoch": 3.501075268817204,
      "grad_norm": 1.3681873536701965,
      "learning_rate": 0.00015088254555671723,
      "loss": 0.0138,
      "step": 2035
    },
    {
      "epoch": 3.5027956989247313,
      "grad_norm": 1.2492575891222506,
      "learning_rate": 0.00015083454294069867,
      "loss": 0.0078,
      "step": 2036
    },
    {
      "epoch": 3.504516129032258,
      "grad_norm": 1.1663885468086879,
      "learning_rate": 0.00015078652452418063,
      "loss": 0.0212,
      "step": 2037
    },
    {
      "epoch": 3.506236559139785,
      "grad_norm": 0.686334020201801,
      "learning_rate": 0.00015073849032208822,
      "loss": 0.0099,
      "step": 2038
    },
    {
      "epoch": 3.5079569892473117,
      "grad_norm": 0.22089237068092704,
      "learning_rate": 0.0001506904403493516,
      "loss": 0.002,
      "step": 2039
    },
    {
      "epoch": 3.509677419354839,
      "grad_norm": 1.504759399578529,
      "learning_rate": 0.0001506423746209058,
      "loss": 0.0214,
      "step": 2040
    },
    {
      "epoch": 3.5113978494623654,
      "grad_norm": 1.1981801386389341,
      "learning_rate": 0.00015059429315169063,
      "loss": 0.0191,
      "step": 2041
    },
    {
      "epoch": 3.5131182795698925,
      "grad_norm": 0.41706107577196727,
      "learning_rate": 0.00015054619595665088,
      "loss": 0.0062,
      "step": 2042
    },
    {
      "epoch": 3.514838709677419,
      "grad_norm": 0.05722337967443268,
      "learning_rate": 0.00015049808305073626,
      "loss": 0.0008,
      "step": 2043
    },
    {
      "epoch": 3.5165591397849463,
      "grad_norm": 0.6741728499431747,
      "learning_rate": 0.0001504499544489013,
      "loss": 0.0103,
      "step": 2044
    },
    {
      "epoch": 3.5182795698924734,
      "grad_norm": 0.8071282025908961,
      "learning_rate": 0.0001504018101661055,
      "loss": 0.0128,
      "step": 2045
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.7204232557091651,
      "learning_rate": 0.00015035365021731306,
      "loss": 0.0224,
      "step": 2046
    },
    {
      "epoch": 3.5217204301075267,
      "grad_norm": 1.227772159201797,
      "learning_rate": 0.0001503054746174932,
      "loss": 0.0354,
      "step": 2047
    },
    {
      "epoch": 3.5234408602150538,
      "grad_norm": 1.287674523423957,
      "learning_rate": 0.00015025728338162,
      "loss": 0.0117,
      "step": 2048
    },
    {
      "epoch": 3.525161290322581,
      "grad_norm": 1.5522763315686943,
      "learning_rate": 0.00015020907652467228,
      "loss": 0.0226,
      "step": 2049
    },
    {
      "epoch": 3.5268817204301075,
      "grad_norm": 0.08213941037395307,
      "learning_rate": 0.0001501608540616339,
      "loss": 0.0015,
      "step": 2050
    },
    {
      "epoch": 3.528602150537634,
      "grad_norm": 1.0168184241751417,
      "learning_rate": 0.0001501126160074934,
      "loss": 0.0158,
      "step": 2051
    },
    {
      "epoch": 3.5303225806451612,
      "grad_norm": 1.3942042934978636,
      "learning_rate": 0.00015006436237724425,
      "loss": 0.0238,
      "step": 2052
    },
    {
      "epoch": 3.5320430107526883,
      "grad_norm": 0.09002105430937761,
      "learning_rate": 0.00015001609318588473,
      "loss": 0.001,
      "step": 2053
    },
    {
      "epoch": 3.533763440860215,
      "grad_norm": 0.5536247818035261,
      "learning_rate": 0.00014996780844841795,
      "loss": 0.0087,
      "step": 2054
    },
    {
      "epoch": 3.535483870967742,
      "grad_norm": 1.4190612298697305,
      "learning_rate": 0.00014991950817985197,
      "loss": 0.0171,
      "step": 2055
    },
    {
      "epoch": 3.5372043010752687,
      "grad_norm": 1.0384039859673393,
      "learning_rate": 0.00014987119239519948,
      "loss": 0.0526,
      "step": 2056
    },
    {
      "epoch": 3.538924731182796,
      "grad_norm": 2.4620112607298132,
      "learning_rate": 0.0001498228611094781,
      "loss": 0.0101,
      "step": 2057
    },
    {
      "epoch": 3.5406451612903225,
      "grad_norm": 0.6157982189009952,
      "learning_rate": 0.00014977451433771037,
      "loss": 0.0036,
      "step": 2058
    },
    {
      "epoch": 3.5423655913978496,
      "grad_norm": 0.6836053173283443,
      "learning_rate": 0.00014972615209492344,
      "loss": 0.0053,
      "step": 2059
    },
    {
      "epoch": 3.544086021505376,
      "grad_norm": 0.9998186057871732,
      "learning_rate": 0.00014967777439614936,
      "loss": 0.0148,
      "step": 2060
    },
    {
      "epoch": 3.5458064516129033,
      "grad_norm": 1.0620962242500378,
      "learning_rate": 0.00014962938125642503,
      "loss": 0.0227,
      "step": 2061
    },
    {
      "epoch": 3.54752688172043,
      "grad_norm": 1.5453729889454002,
      "learning_rate": 0.00014958097269079205,
      "loss": 0.0241,
      "step": 2062
    },
    {
      "epoch": 3.549247311827957,
      "grad_norm": 0.9001437729742743,
      "learning_rate": 0.00014953254871429694,
      "loss": 0.0059,
      "step": 2063
    },
    {
      "epoch": 3.5509677419354837,
      "grad_norm": 0.8121351787902316,
      "learning_rate": 0.0001494841093419909,
      "loss": 0.0196,
      "step": 2064
    },
    {
      "epoch": 3.552688172043011,
      "grad_norm": 2.010708304655618,
      "learning_rate": 0.00014943565458893,
      "loss": 0.0321,
      "step": 2065
    },
    {
      "epoch": 3.554408602150538,
      "grad_norm": 1.0264237207385527,
      "learning_rate": 0.000149387184470175,
      "loss": 0.0106,
      "step": 2066
    },
    {
      "epoch": 3.5561290322580645,
      "grad_norm": 1.3181678656398141,
      "learning_rate": 0.00014933869900079147,
      "loss": 0.0166,
      "step": 2067
    },
    {
      "epoch": 3.557849462365591,
      "grad_norm": 0.3528255026374396,
      "learning_rate": 0.00014929019819584984,
      "loss": 0.0019,
      "step": 2068
    },
    {
      "epoch": 3.5595698924731183,
      "grad_norm": 0.8024308348044883,
      "learning_rate": 0.00014924168207042517,
      "loss": 0.0235,
      "step": 2069
    },
    {
      "epoch": 3.5612903225806454,
      "grad_norm": 1.5728357165893103,
      "learning_rate": 0.00014919315063959736,
      "loss": 0.023,
      "step": 2070
    },
    {
      "epoch": 3.563010752688172,
      "grad_norm": 0.8570876348513493,
      "learning_rate": 0.00014914460391845106,
      "loss": 0.0108,
      "step": 2071
    },
    {
      "epoch": 3.5647311827956987,
      "grad_norm": 0.5118070109516337,
      "learning_rate": 0.00014909604192207568,
      "loss": 0.0094,
      "step": 2072
    },
    {
      "epoch": 3.5664516129032258,
      "grad_norm": 0.6802473692304163,
      "learning_rate": 0.00014904746466556533,
      "loss": 0.0311,
      "step": 2073
    },
    {
      "epoch": 3.568172043010753,
      "grad_norm": 0.5966058193347913,
      "learning_rate": 0.0001489988721640189,
      "loss": 0.0069,
      "step": 2074
    },
    {
      "epoch": 3.5698924731182795,
      "grad_norm": 0.6005254315048142,
      "learning_rate": 0.00014895026443254,
      "loss": 0.0063,
      "step": 2075
    },
    {
      "epoch": 3.5716129032258066,
      "grad_norm": 0.20782739289050628,
      "learning_rate": 0.00014890164148623704,
      "loss": 0.0012,
      "step": 2076
    },
    {
      "epoch": 3.5733333333333333,
      "grad_norm": 1.279413303316477,
      "learning_rate": 0.00014885300334022307,
      "loss": 0.0507,
      "step": 2077
    },
    {
      "epoch": 3.5750537634408603,
      "grad_norm": 1.4113522844215993,
      "learning_rate": 0.0001488043500096159,
      "loss": 0.0156,
      "step": 2078
    },
    {
      "epoch": 3.576774193548387,
      "grad_norm": 0.5754232667246774,
      "learning_rate": 0.00014875568150953805,
      "loss": 0.0085,
      "step": 2079
    },
    {
      "epoch": 3.578494623655914,
      "grad_norm": 0.7369528610621279,
      "learning_rate": 0.00014870699785511678,
      "loss": 0.0094,
      "step": 2080
    },
    {
      "epoch": 3.5802150537634407,
      "grad_norm": 3.052200943776864,
      "learning_rate": 0.00014865829906148404,
      "loss": 0.0194,
      "step": 2081
    },
    {
      "epoch": 3.581935483870968,
      "grad_norm": 1.2237659501580267,
      "learning_rate": 0.00014860958514377654,
      "loss": 0.0213,
      "step": 2082
    },
    {
      "epoch": 3.5836559139784945,
      "grad_norm": 1.394134121976689,
      "learning_rate": 0.00014856085611713557,
      "loss": 0.0199,
      "step": 2083
    },
    {
      "epoch": 3.5853763440860216,
      "grad_norm": 1.8535605992148074,
      "learning_rate": 0.00014851211199670721,
      "loss": 0.0425,
      "step": 2084
    },
    {
      "epoch": 3.587096774193548,
      "grad_norm": 0.34925553226906847,
      "learning_rate": 0.00014846335279764225,
      "loss": 0.0034,
      "step": 2085
    },
    {
      "epoch": 3.5888172043010753,
      "grad_norm": 1.3080498221204124,
      "learning_rate": 0.00014841457853509606,
      "loss": 0.0446,
      "step": 2086
    },
    {
      "epoch": 3.5905376344086024,
      "grad_norm": 1.301417072343651,
      "learning_rate": 0.00014836578922422882,
      "loss": 0.0202,
      "step": 2087
    },
    {
      "epoch": 3.592258064516129,
      "grad_norm": 1.0867702826080212,
      "learning_rate": 0.00014831698488020526,
      "loss": 0.0245,
      "step": 2088
    },
    {
      "epoch": 3.5939784946236557,
      "grad_norm": 0.6540212118622853,
      "learning_rate": 0.00014826816551819495,
      "loss": 0.0197,
      "step": 2089
    },
    {
      "epoch": 3.595698924731183,
      "grad_norm": 1.1476913461634188,
      "learning_rate": 0.00014821933115337192,
      "loss": 0.0231,
      "step": 2090
    },
    {
      "epoch": 3.59741935483871,
      "grad_norm": 1.18764830288734,
      "learning_rate": 0.00014817048180091501,
      "loss": 0.0164,
      "step": 2091
    },
    {
      "epoch": 3.5991397849462365,
      "grad_norm": 0.20135340850764255,
      "learning_rate": 0.0001481216174760077,
      "loss": 0.0032,
      "step": 2092
    },
    {
      "epoch": 3.600860215053763,
      "grad_norm": 1.017724487718781,
      "learning_rate": 0.0001480727381938381,
      "loss": 0.0185,
      "step": 2093
    },
    {
      "epoch": 3.6025806451612903,
      "grad_norm": 0.14145623597753576,
      "learning_rate": 0.00014802384396959893,
      "loss": 0.0025,
      "step": 2094
    },
    {
      "epoch": 3.6043010752688174,
      "grad_norm": 0.8103310627699288,
      "learning_rate": 0.00014797493481848764,
      "loss": 0.0211,
      "step": 2095
    },
    {
      "epoch": 3.606021505376344,
      "grad_norm": 1.711957221306614,
      "learning_rate": 0.00014792601075570627,
      "loss": 0.0345,
      "step": 2096
    },
    {
      "epoch": 3.607741935483871,
      "grad_norm": 0.357667173024868,
      "learning_rate": 0.00014787707179646144,
      "loss": 0.0042,
      "step": 2097
    },
    {
      "epoch": 3.6094623655913978,
      "grad_norm": 0.6969105521288389,
      "learning_rate": 0.00014782811795596454,
      "loss": 0.0097,
      "step": 2098
    },
    {
      "epoch": 3.611182795698925,
      "grad_norm": 2.2204671211022005,
      "learning_rate": 0.0001477791492494315,
      "loss": 0.0476,
      "step": 2099
    },
    {
      "epoch": 3.6129032258064515,
      "grad_norm": 0.800561465928617,
      "learning_rate": 0.00014773016569208283,
      "loss": 0.0142,
      "step": 2100
    },
    {
      "epoch": 3.6146236559139786,
      "grad_norm": 0.740707414282364,
      "learning_rate": 0.0001476811672991437,
      "loss": 0.0126,
      "step": 2101
    },
    {
      "epoch": 3.6163440860215053,
      "grad_norm": 0.837362289137291,
      "learning_rate": 0.00014763215408584394,
      "loss": 0.0354,
      "step": 2102
    },
    {
      "epoch": 3.6180645161290323,
      "grad_norm": 0.877984845257918,
      "learning_rate": 0.0001475831260674179,
      "loss": 0.0203,
      "step": 2103
    },
    {
      "epoch": 3.619784946236559,
      "grad_norm": 1.6906737986506877,
      "learning_rate": 0.00014753408325910458,
      "loss": 0.0385,
      "step": 2104
    },
    {
      "epoch": 3.621505376344086,
      "grad_norm": 1.0490146542066026,
      "learning_rate": 0.00014748502567614758,
      "loss": 0.0096,
      "step": 2105
    },
    {
      "epoch": 3.6232258064516127,
      "grad_norm": 0.9031535406611961,
      "learning_rate": 0.00014743595333379509,
      "loss": 0.0229,
      "step": 2106
    },
    {
      "epoch": 3.62494623655914,
      "grad_norm": 1.11818373985469,
      "learning_rate": 0.00014738686624729986,
      "loss": 0.0083,
      "step": 2107
    },
    {
      "epoch": 3.626666666666667,
      "grad_norm": 1.5297418068044168,
      "learning_rate": 0.00014733776443191926,
      "loss": 0.0252,
      "step": 2108
    },
    {
      "epoch": 3.6283870967741936,
      "grad_norm": 1.457595011406462,
      "learning_rate": 0.00014728864790291521,
      "loss": 0.031,
      "step": 2109
    },
    {
      "epoch": 3.6301075268817202,
      "grad_norm": 1.8264729821364782,
      "learning_rate": 0.0001472395166755542,
      "loss": 0.0446,
      "step": 2110
    },
    {
      "epoch": 3.6318279569892473,
      "grad_norm": 1.0121633101394287,
      "learning_rate": 0.00014719037076510731,
      "loss": 0.0177,
      "step": 2111
    },
    {
      "epoch": 3.6335483870967744,
      "grad_norm": 0.17897322182973294,
      "learning_rate": 0.00014714121018685018,
      "loss": 0.0037,
      "step": 2112
    },
    {
      "epoch": 3.635268817204301,
      "grad_norm": 1.0241337749125548,
      "learning_rate": 0.00014709203495606298,
      "loss": 0.0129,
      "step": 2113
    },
    {
      "epoch": 3.6369892473118277,
      "grad_norm": 1.30849802399175,
      "learning_rate": 0.00014704284508803048,
      "loss": 0.0107,
      "step": 2114
    },
    {
      "epoch": 3.638709677419355,
      "grad_norm": 0.12454585224151694,
      "learning_rate": 0.000146993640598042,
      "loss": 0.0022,
      "step": 2115
    },
    {
      "epoch": 3.640430107526882,
      "grad_norm": 0.3849450191083578,
      "learning_rate": 0.00014694442150139136,
      "loss": 0.0082,
      "step": 2116
    },
    {
      "epoch": 3.6421505376344085,
      "grad_norm": 0.3808572498249723,
      "learning_rate": 0.00014689518781337693,
      "loss": 0.0071,
      "step": 2117
    },
    {
      "epoch": 3.6438709677419356,
      "grad_norm": 0.8617128947997178,
      "learning_rate": 0.00014684593954930166,
      "loss": 0.0174,
      "step": 2118
    },
    {
      "epoch": 3.6455913978494623,
      "grad_norm": 0.5666934294469598,
      "learning_rate": 0.00014679667672447296,
      "loss": 0.0121,
      "step": 2119
    },
    {
      "epoch": 3.6473118279569894,
      "grad_norm": 1.2957312133835968,
      "learning_rate": 0.00014674739935420283,
      "loss": 0.0331,
      "step": 2120
    },
    {
      "epoch": 3.649032258064516,
      "grad_norm": 0.31265933004175084,
      "learning_rate": 0.00014669810745380777,
      "loss": 0.0031,
      "step": 2121
    },
    {
      "epoch": 3.650752688172043,
      "grad_norm": 2.005780604903097,
      "learning_rate": 0.00014664880103860877,
      "loss": 0.0369,
      "step": 2122
    },
    {
      "epoch": 3.6524731182795698,
      "grad_norm": 0.08728109244282256,
      "learning_rate": 0.00014659948012393139,
      "loss": 0.0016,
      "step": 2123
    },
    {
      "epoch": 3.654193548387097,
      "grad_norm": 0.33290004866290274,
      "learning_rate": 0.0001465501447251056,
      "loss": 0.0048,
      "step": 2124
    },
    {
      "epoch": 3.6559139784946235,
      "grad_norm": 0.2687736735101996,
      "learning_rate": 0.000146500794857466,
      "loss": 0.0023,
      "step": 2125
    },
    {
      "epoch": 3.6576344086021506,
      "grad_norm": 0.9821664252466727,
      "learning_rate": 0.00014645143053635158,
      "loss": 0.0175,
      "step": 2126
    },
    {
      "epoch": 3.6593548387096773,
      "grad_norm": 1.866028057614708,
      "learning_rate": 0.0001464020517771059,
      "loss": 0.0251,
      "step": 2127
    },
    {
      "epoch": 3.6610752688172044,
      "grad_norm": 0.6397450663780142,
      "learning_rate": 0.00014635265859507687,
      "loss": 0.0082,
      "step": 2128
    },
    {
      "epoch": 3.6627956989247314,
      "grad_norm": 0.9438820716793086,
      "learning_rate": 0.00014630325100561711,
      "loss": 0.015,
      "step": 2129
    },
    {
      "epoch": 3.664516129032258,
      "grad_norm": 1.0734032134317102,
      "learning_rate": 0.00014625382902408356,
      "loss": 0.0247,
      "step": 2130
    },
    {
      "epoch": 3.6662365591397847,
      "grad_norm": 2.4185434706364823,
      "learning_rate": 0.00014620439266583757,
      "loss": 0.0127,
      "step": 2131
    },
    {
      "epoch": 3.667956989247312,
      "grad_norm": 0.27296473723593595,
      "learning_rate": 0.00014615494194624516,
      "loss": 0.0045,
      "step": 2132
    },
    {
      "epoch": 3.669677419354839,
      "grad_norm": 1.0909186380749962,
      "learning_rate": 0.00014610547688067666,
      "loss": 0.0189,
      "step": 2133
    },
    {
      "epoch": 3.6713978494623656,
      "grad_norm": 0.08563193241133536,
      "learning_rate": 0.00014605599748450694,
      "loss": 0.0005,
      "step": 2134
    },
    {
      "epoch": 3.6731182795698922,
      "grad_norm": 0.32717056143826806,
      "learning_rate": 0.00014600650377311522,
      "loss": 0.0045,
      "step": 2135
    },
    {
      "epoch": 3.6748387096774193,
      "grad_norm": 0.19743305836103228,
      "learning_rate": 0.0001459569957618853,
      "loss": 0.0023,
      "step": 2136
    },
    {
      "epoch": 3.6765591397849464,
      "grad_norm": 1.413744596668621,
      "learning_rate": 0.00014590747346620537,
      "loss": 0.0453,
      "step": 2137
    },
    {
      "epoch": 3.678279569892473,
      "grad_norm": 1.0417758489361568,
      "learning_rate": 0.000145857936901468,
      "loss": 0.0171,
      "step": 2138
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.8322613833006645,
      "learning_rate": 0.0001458083860830703,
      "loss": 0.0081,
      "step": 2139
    },
    {
      "epoch": 3.681720430107527,
      "grad_norm": 0.4722381583222966,
      "learning_rate": 0.00014575882102641372,
      "loss": 0.0073,
      "step": 2140
    },
    {
      "epoch": 3.683440860215054,
      "grad_norm": 0.35574277721470227,
      "learning_rate": 0.0001457092417469042,
      "loss": 0.0028,
      "step": 2141
    },
    {
      "epoch": 3.6851612903225806,
      "grad_norm": 1.5377061036391932,
      "learning_rate": 0.0001456596482599521,
      "loss": 0.0206,
      "step": 2142
    },
    {
      "epoch": 3.6868817204301076,
      "grad_norm": 0.23225721175302153,
      "learning_rate": 0.0001456100405809721,
      "loss": 0.0016,
      "step": 2143
    },
    {
      "epoch": 3.6886021505376343,
      "grad_norm": 0.9121402345397858,
      "learning_rate": 0.00014556041872538345,
      "loss": 0.0297,
      "step": 2144
    },
    {
      "epoch": 3.6903225806451614,
      "grad_norm": 1.9253390274820528,
      "learning_rate": 0.00014551078270860966,
      "loss": 0.0256,
      "step": 2145
    },
    {
      "epoch": 3.692043010752688,
      "grad_norm": 0.14259465304688554,
      "learning_rate": 0.00014546113254607868,
      "loss": 0.0009,
      "step": 2146
    },
    {
      "epoch": 3.693763440860215,
      "grad_norm": 1.1747481187578412,
      "learning_rate": 0.00014541146825322297,
      "loss": 0.0373,
      "step": 2147
    },
    {
      "epoch": 3.695483870967742,
      "grad_norm": 1.7833635432723054,
      "learning_rate": 0.00014536178984547922,
      "loss": 0.0535,
      "step": 2148
    },
    {
      "epoch": 3.697204301075269,
      "grad_norm": 0.5768653294843809,
      "learning_rate": 0.00014531209733828856,
      "loss": 0.0056,
      "step": 2149
    },
    {
      "epoch": 3.698924731182796,
      "grad_norm": 3.0238114749981277,
      "learning_rate": 0.0001452623907470966,
      "loss": 0.0419,
      "step": 2150
    },
    {
      "epoch": 3.7006451612903226,
      "grad_norm": 0.9504252502442767,
      "learning_rate": 0.00014521267008735315,
      "loss": 0.0119,
      "step": 2151
    },
    {
      "epoch": 3.7023655913978493,
      "grad_norm": 3.570688907263864,
      "learning_rate": 0.00014516293537451258,
      "loss": 0.0198,
      "step": 2152
    },
    {
      "epoch": 3.7040860215053764,
      "grad_norm": 1.2654696418354245,
      "learning_rate": 0.00014511318662403347,
      "loss": 0.0354,
      "step": 2153
    },
    {
      "epoch": 3.7058064516129035,
      "grad_norm": 0.7079183231400458,
      "learning_rate": 0.00014506342385137887,
      "loss": 0.0159,
      "step": 2154
    },
    {
      "epoch": 3.70752688172043,
      "grad_norm": 0.2966210928060147,
      "learning_rate": 0.00014501364707201613,
      "loss": 0.0028,
      "step": 2155
    },
    {
      "epoch": 3.7092473118279568,
      "grad_norm": 0.18446115656582387,
      "learning_rate": 0.00014496385630141697,
      "loss": 0.0024,
      "step": 2156
    },
    {
      "epoch": 3.710967741935484,
      "grad_norm": 0.37451767104623007,
      "learning_rate": 0.00014491405155505748,
      "loss": 0.0104,
      "step": 2157
    },
    {
      "epoch": 3.712688172043011,
      "grad_norm": 1.0219490777424984,
      "learning_rate": 0.0001448642328484181,
      "loss": 0.0163,
      "step": 2158
    },
    {
      "epoch": 3.7144086021505376,
      "grad_norm": 0.7587255900000566,
      "learning_rate": 0.0001448144001969835,
      "loss": 0.0107,
      "step": 2159
    },
    {
      "epoch": 3.7161290322580647,
      "grad_norm": 0.5090257377888646,
      "learning_rate": 0.00014476455361624283,
      "loss": 0.0108,
      "step": 2160
    },
    {
      "epoch": 3.7178494623655913,
      "grad_norm": 1.3571138868745851,
      "learning_rate": 0.00014471469312168954,
      "loss": 0.0177,
      "step": 2161
    },
    {
      "epoch": 3.7195698924731184,
      "grad_norm": 0.12127669276009302,
      "learning_rate": 0.0001446648187288213,
      "loss": 0.0017,
      "step": 2162
    },
    {
      "epoch": 3.721290322580645,
      "grad_norm": 1.0230764470907285,
      "learning_rate": 0.00014461493045314026,
      "loss": 0.0105,
      "step": 2163
    },
    {
      "epoch": 3.723010752688172,
      "grad_norm": 1.306031339043011,
      "learning_rate": 0.0001445650283101527,
      "loss": 0.0217,
      "step": 2164
    },
    {
      "epoch": 3.724731182795699,
      "grad_norm": 0.16012527200970092,
      "learning_rate": 0.0001445151123153694,
      "loss": 0.0017,
      "step": 2165
    },
    {
      "epoch": 3.726451612903226,
      "grad_norm": 0.32458905849074016,
      "learning_rate": 0.00014446518248430526,
      "loss": 0.0034,
      "step": 2166
    },
    {
      "epoch": 3.7281720430107526,
      "grad_norm": 0.8102163745962103,
      "learning_rate": 0.00014441523883247965,
      "loss": 0.0181,
      "step": 2167
    },
    {
      "epoch": 3.7298924731182796,
      "grad_norm": 0.9326904272365482,
      "learning_rate": 0.0001443652813754161,
      "loss": 0.0168,
      "step": 2168
    },
    {
      "epoch": 3.7316129032258063,
      "grad_norm": 0.29930836726746013,
      "learning_rate": 0.00014431531012864258,
      "loss": 0.0036,
      "step": 2169
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 1.8598314314719724,
      "learning_rate": 0.0001442653251076912,
      "loss": 0.0398,
      "step": 2170
    },
    {
      "epoch": 3.7350537634408605,
      "grad_norm": 1.3334851608444986,
      "learning_rate": 0.00014421532632809841,
      "loss": 0.0139,
      "step": 2171
    },
    {
      "epoch": 3.736774193548387,
      "grad_norm": 1.954878038599201,
      "learning_rate": 0.00014416531380540497,
      "loss": 0.0346,
      "step": 2172
    },
    {
      "epoch": 3.738494623655914,
      "grad_norm": 0.2114925516367409,
      "learning_rate": 0.00014411528755515576,
      "loss": 0.0039,
      "step": 2173
    },
    {
      "epoch": 3.740215053763441,
      "grad_norm": 1.3233591894600691,
      "learning_rate": 0.0001440652475929002,
      "loss": 0.0119,
      "step": 2174
    },
    {
      "epoch": 3.741935483870968,
      "grad_norm": 0.9635811103060302,
      "learning_rate": 0.00014401519393419178,
      "loss": 0.0201,
      "step": 2175
    },
    {
      "epoch": 3.7436559139784946,
      "grad_norm": 0.8321240652902937,
      "learning_rate": 0.00014396512659458824,
      "loss": 0.0104,
      "step": 2176
    },
    {
      "epoch": 3.7453763440860213,
      "grad_norm": 0.6239199904237832,
      "learning_rate": 0.00014391504558965157,
      "loss": 0.01,
      "step": 2177
    },
    {
      "epoch": 3.7470967741935484,
      "grad_norm": 0.6824419477048042,
      "learning_rate": 0.00014386495093494817,
      "loss": 0.0169,
      "step": 2178
    },
    {
      "epoch": 3.7488172043010755,
      "grad_norm": 1.1978440669608827,
      "learning_rate": 0.00014381484264604848,
      "loss": 0.0251,
      "step": 2179
    },
    {
      "epoch": 3.750537634408602,
      "grad_norm": 0.8745719394988756,
      "learning_rate": 0.00014376472073852732,
      "loss": 0.0072,
      "step": 2180
    },
    {
      "epoch": 3.7522580645161288,
      "grad_norm": 1.1360607994123164,
      "learning_rate": 0.0001437145852279636,
      "loss": 0.0141,
      "step": 2181
    },
    {
      "epoch": 3.753978494623656,
      "grad_norm": 0.7366131376593721,
      "learning_rate": 0.00014366443612994067,
      "loss": 0.0296,
      "step": 2182
    },
    {
      "epoch": 3.755698924731183,
      "grad_norm": 0.96113721722807,
      "learning_rate": 0.00014361427346004586,
      "loss": 0.0077,
      "step": 2183
    },
    {
      "epoch": 3.7574193548387096,
      "grad_norm": 1.1944338418477016,
      "learning_rate": 0.0001435640972338709,
      "loss": 0.0182,
      "step": 2184
    },
    {
      "epoch": 3.7591397849462367,
      "grad_norm": 3.6649741006143346,
      "learning_rate": 0.00014351390746701172,
      "loss": 0.0171,
      "step": 2185
    },
    {
      "epoch": 3.7608602150537633,
      "grad_norm": 1.2913098405120789,
      "learning_rate": 0.00014346370417506828,
      "loss": 0.017,
      "step": 2186
    },
    {
      "epoch": 3.7625806451612904,
      "grad_norm": 1.2976778905199247,
      "learning_rate": 0.00014341348737364495,
      "loss": 0.015,
      "step": 2187
    },
    {
      "epoch": 3.764301075268817,
      "grad_norm": 0.5306830493778397,
      "learning_rate": 0.00014336325707835023,
      "loss": 0.0067,
      "step": 2188
    },
    {
      "epoch": 3.766021505376344,
      "grad_norm": 0.845303529433514,
      "learning_rate": 0.00014331301330479677,
      "loss": 0.017,
      "step": 2189
    },
    {
      "epoch": 3.767741935483871,
      "grad_norm": 0.8848841667055483,
      "learning_rate": 0.00014326275606860146,
      "loss": 0.008,
      "step": 2190
    },
    {
      "epoch": 3.769462365591398,
      "grad_norm": 0.8551838748020786,
      "learning_rate": 0.00014321248538538535,
      "loss": 0.0226,
      "step": 2191
    },
    {
      "epoch": 3.771182795698925,
      "grad_norm": 1.0034243590562932,
      "learning_rate": 0.00014316220127077377,
      "loss": 0.0169,
      "step": 2192
    },
    {
      "epoch": 3.7729032258064517,
      "grad_norm": 2.578999285545634,
      "learning_rate": 0.000143111903740396,
      "loss": 0.0616,
      "step": 2193
    },
    {
      "epoch": 3.7746236559139783,
      "grad_norm": 0.7524289758488868,
      "learning_rate": 0.00014306159280988567,
      "loss": 0.0058,
      "step": 2194
    },
    {
      "epoch": 3.7763440860215054,
      "grad_norm": 0.7477068628939423,
      "learning_rate": 0.00014301126849488056,
      "loss": 0.0107,
      "step": 2195
    },
    {
      "epoch": 3.7780645161290325,
      "grad_norm": 1.2244809575914704,
      "learning_rate": 0.00014296093081102252,
      "loss": 0.024,
      "step": 2196
    },
    {
      "epoch": 3.779784946236559,
      "grad_norm": 0.5034756713444304,
      "learning_rate": 0.0001429105797739577,
      "loss": 0.0042,
      "step": 2197
    },
    {
      "epoch": 3.781505376344086,
      "grad_norm": 1.6442014755260939,
      "learning_rate": 0.00014286021539933625,
      "loss": 0.009,
      "step": 2198
    },
    {
      "epoch": 3.783225806451613,
      "grad_norm": 1.2193854940180353,
      "learning_rate": 0.0001428098377028126,
      "loss": 0.0449,
      "step": 2199
    },
    {
      "epoch": 3.78494623655914,
      "grad_norm": 0.41872969653491865,
      "learning_rate": 0.0001427594467000451,
      "loss": 0.0038,
      "step": 2200
    },
    {
      "epoch": 3.7866666666666666,
      "grad_norm": 1.2357139067604985,
      "learning_rate": 0.00014270904240669654,
      "loss": 0.0116,
      "step": 2201
    },
    {
      "epoch": 3.7883870967741933,
      "grad_norm": 0.8906906040940942,
      "learning_rate": 0.00014265862483843367,
      "loss": 0.0074,
      "step": 2202
    },
    {
      "epoch": 3.7901075268817204,
      "grad_norm": 0.3758442625954273,
      "learning_rate": 0.00014260819401092732,
      "loss": 0.0049,
      "step": 2203
    },
    {
      "epoch": 3.7918279569892475,
      "grad_norm": 0.7117862767407717,
      "learning_rate": 0.0001425577499398525,
      "loss": 0.0278,
      "step": 2204
    },
    {
      "epoch": 3.793548387096774,
      "grad_norm": 1.3852058991515923,
      "learning_rate": 0.00014250729264088843,
      "loss": 0.0273,
      "step": 2205
    },
    {
      "epoch": 3.795268817204301,
      "grad_norm": 3.0771140336023914,
      "learning_rate": 0.0001424568221297183,
      "loss": 0.0192,
      "step": 2206
    },
    {
      "epoch": 3.796989247311828,
      "grad_norm": 0.11615165556180457,
      "learning_rate": 0.00014240633842202947,
      "loss": 0.0023,
      "step": 2207
    },
    {
      "epoch": 3.798709677419355,
      "grad_norm": 0.3326834934826449,
      "learning_rate": 0.00014235584153351338,
      "loss": 0.0048,
      "step": 2208
    },
    {
      "epoch": 3.8004301075268816,
      "grad_norm": 0.5803609319494856,
      "learning_rate": 0.00014230533147986554,
      "loss": 0.0065,
      "step": 2209
    },
    {
      "epoch": 3.8021505376344087,
      "grad_norm": 0.49608367873773584,
      "learning_rate": 0.0001422548082767857,
      "loss": 0.0068,
      "step": 2210
    },
    {
      "epoch": 3.8038709677419353,
      "grad_norm": 0.8759765408031646,
      "learning_rate": 0.0001422042719399775,
      "loss": 0.0112,
      "step": 2211
    },
    {
      "epoch": 3.8055913978494624,
      "grad_norm": 0.3021040735725694,
      "learning_rate": 0.00014215372248514875,
      "loss": 0.0027,
      "step": 2212
    },
    {
      "epoch": 3.807311827956989,
      "grad_norm": 2.0371555131683166,
      "learning_rate": 0.0001421031599280114,
      "loss": 0.0197,
      "step": 2213
    },
    {
      "epoch": 3.809032258064516,
      "grad_norm": 0.21886536646997487,
      "learning_rate": 0.00014205258428428135,
      "loss": 0.0035,
      "step": 2214
    },
    {
      "epoch": 3.810752688172043,
      "grad_norm": 1.6715356367434808,
      "learning_rate": 0.00014200199556967867,
      "loss": 0.0485,
      "step": 2215
    },
    {
      "epoch": 3.81247311827957,
      "grad_norm": 1.571424487662362,
      "learning_rate": 0.00014195139379992742,
      "loss": 0.0132,
      "step": 2216
    },
    {
      "epoch": 3.814193548387097,
      "grad_norm": 1.5632579548906262,
      "learning_rate": 0.00014190077899075575,
      "loss": 0.0437,
      "step": 2217
    },
    {
      "epoch": 3.8159139784946237,
      "grad_norm": 0.7236016377060764,
      "learning_rate": 0.00014185015115789588,
      "loss": 0.012,
      "step": 2218
    },
    {
      "epoch": 3.8176344086021503,
      "grad_norm": 1.6510393320981682,
      "learning_rate": 0.00014179951031708407,
      "loss": 0.0128,
      "step": 2219
    },
    {
      "epoch": 3.8193548387096774,
      "grad_norm": 4.06893783996791,
      "learning_rate": 0.00014174885648406057,
      "loss": 0.0371,
      "step": 2220
    },
    {
      "epoch": 3.8210752688172045,
      "grad_norm": 0.44140664166157034,
      "learning_rate": 0.00014169818967456975,
      "loss": 0.0045,
      "step": 2221
    },
    {
      "epoch": 3.822795698924731,
      "grad_norm": 3.561065058205113,
      "learning_rate": 0.0001416475099043599,
      "loss": 0.0309,
      "step": 2222
    },
    {
      "epoch": 3.824516129032258,
      "grad_norm": 1.3712512301987694,
      "learning_rate": 0.00014159681718918353,
      "loss": 0.0093,
      "step": 2223
    },
    {
      "epoch": 3.826236559139785,
      "grad_norm": 1.1835869126739225,
      "learning_rate": 0.000141546111544797,
      "loss": 0.0127,
      "step": 2224
    },
    {
      "epoch": 3.827956989247312,
      "grad_norm": 1.3642603472098094,
      "learning_rate": 0.00014149539298696074,
      "loss": 0.0382,
      "step": 2225
    },
    {
      "epoch": 3.8296774193548386,
      "grad_norm": 5.56141562885222,
      "learning_rate": 0.00014144466153143918,
      "loss": 0.0201,
      "step": 2226
    },
    {
      "epoch": 3.8313978494623657,
      "grad_norm": 1.228845309260678,
      "learning_rate": 0.00014139391719400078,
      "loss": 0.0352,
      "step": 2227
    },
    {
      "epoch": 3.8331182795698924,
      "grad_norm": 0.8811296098982082,
      "learning_rate": 0.00014134315999041807,
      "loss": 0.0138,
      "step": 2228
    },
    {
      "epoch": 3.8348387096774195,
      "grad_norm": 0.33332108604660904,
      "learning_rate": 0.00014129238993646742,
      "loss": 0.0063,
      "step": 2229
    },
    {
      "epoch": 3.836559139784946,
      "grad_norm": 0.9172900949760608,
      "learning_rate": 0.00014124160704792938,
      "loss": 0.0162,
      "step": 2230
    },
    {
      "epoch": 3.838279569892473,
      "grad_norm": 0.5645039537958917,
      "learning_rate": 0.00014119081134058827,
      "loss": 0.0068,
      "step": 2231
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.8378892750982516,
      "learning_rate": 0.00014114000283023262,
      "loss": 0.0394,
      "step": 2232
    },
    {
      "epoch": 3.841720430107527,
      "grad_norm": 0.52761499347681,
      "learning_rate": 0.00014108918153265485,
      "loss": 0.0107,
      "step": 2233
    },
    {
      "epoch": 3.8434408602150536,
      "grad_norm": 0.6153580597177258,
      "learning_rate": 0.00014103834746365124,
      "loss": 0.0074,
      "step": 2234
    },
    {
      "epoch": 3.8451612903225807,
      "grad_norm": 0.30265967552494216,
      "learning_rate": 0.0001409875006390222,
      "loss": 0.002,
      "step": 2235
    },
    {
      "epoch": 3.8468817204301073,
      "grad_norm": 1.4003460330655821,
      "learning_rate": 0.0001409366410745721,
      "loss": 0.0233,
      "step": 2236
    },
    {
      "epoch": 3.8486021505376344,
      "grad_norm": 0.6127570619537049,
      "learning_rate": 0.00014088576878610912,
      "loss": 0.0258,
      "step": 2237
    },
    {
      "epoch": 3.8503225806451615,
      "grad_norm": 0.8142055920896586,
      "learning_rate": 0.00014083488378944557,
      "loss": 0.0124,
      "step": 2238
    },
    {
      "epoch": 3.852043010752688,
      "grad_norm": 0.5962576287356358,
      "learning_rate": 0.00014078398610039756,
      "loss": 0.0103,
      "step": 2239
    },
    {
      "epoch": 3.853763440860215,
      "grad_norm": 1.9036028003982015,
      "learning_rate": 0.00014073307573478526,
      "loss": 0.0332,
      "step": 2240
    },
    {
      "epoch": 3.855483870967742,
      "grad_norm": 0.772015095050028,
      "learning_rate": 0.00014068215270843278,
      "loss": 0.0086,
      "step": 2241
    },
    {
      "epoch": 3.857204301075269,
      "grad_norm": 1.8247022415463525,
      "learning_rate": 0.00014063121703716803,
      "loss": 0.0276,
      "step": 2242
    },
    {
      "epoch": 3.8589247311827957,
      "grad_norm": 0.6910812829266034,
      "learning_rate": 0.00014058026873682298,
      "loss": 0.0147,
      "step": 2243
    },
    {
      "epoch": 3.8606451612903223,
      "grad_norm": 1.6733459406770945,
      "learning_rate": 0.00014052930782323353,
      "loss": 0.017,
      "step": 2244
    },
    {
      "epoch": 3.8623655913978494,
      "grad_norm": 0.5494866040452814,
      "learning_rate": 0.00014047833431223938,
      "loss": 0.0052,
      "step": 2245
    },
    {
      "epoch": 3.8640860215053765,
      "grad_norm": 0.5888500255578373,
      "learning_rate": 0.00014042734821968428,
      "loss": 0.0045,
      "step": 2246
    },
    {
      "epoch": 3.865806451612903,
      "grad_norm": 0.15398389276036203,
      "learning_rate": 0.00014037634956141586,
      "loss": 0.0018,
      "step": 2247
    },
    {
      "epoch": 3.8675268817204302,
      "grad_norm": 0.90617256727577,
      "learning_rate": 0.00014032533835328556,
      "loss": 0.0212,
      "step": 2248
    },
    {
      "epoch": 3.869247311827957,
      "grad_norm": 0.18687827647703242,
      "learning_rate": 0.00014027431461114878,
      "loss": 0.0014,
      "step": 2249
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.8702554500932079,
      "learning_rate": 0.00014022327835086496,
      "loss": 0.0178,
      "step": 2250
    },
    {
      "epoch": 3.8726881720430106,
      "grad_norm": 1.1050843392049796,
      "learning_rate": 0.00014017222958829714,
      "loss": 0.0146,
      "step": 2251
    },
    {
      "epoch": 3.8744086021505377,
      "grad_norm": 0.4572177758650927,
      "learning_rate": 0.0001401211683393125,
      "loss": 0.003,
      "step": 2252
    },
    {
      "epoch": 3.8761290322580644,
      "grad_norm": 0.2906886387650882,
      "learning_rate": 0.00014007009461978196,
      "loss": 0.0044,
      "step": 2253
    },
    {
      "epoch": 3.8778494623655915,
      "grad_norm": 1.0295971540062312,
      "learning_rate": 0.00014001900844558038,
      "loss": 0.0346,
      "step": 2254
    },
    {
      "epoch": 3.879569892473118,
      "grad_norm": 0.7000403352745409,
      "learning_rate": 0.00013996790983258648,
      "loss": 0.0218,
      "step": 2255
    },
    {
      "epoch": 3.881290322580645,
      "grad_norm": 1.5139972190828042,
      "learning_rate": 0.0001399167987966828,
      "loss": 0.042,
      "step": 2256
    },
    {
      "epoch": 3.883010752688172,
      "grad_norm": 0.5819626758061345,
      "learning_rate": 0.00013986567535375583,
      "loss": 0.0056,
      "step": 2257
    },
    {
      "epoch": 3.884731182795699,
      "grad_norm": 0.8480475571875267,
      "learning_rate": 0.00013981453951969583,
      "loss": 0.0238,
      "step": 2258
    },
    {
      "epoch": 3.886451612903226,
      "grad_norm": 1.216500259298125,
      "learning_rate": 0.00013976339131039695,
      "loss": 0.0174,
      "step": 2259
    },
    {
      "epoch": 3.8881720430107527,
      "grad_norm": 0.9392958228270335,
      "learning_rate": 0.0001397122307417572,
      "loss": 0.0193,
      "step": 2260
    },
    {
      "epoch": 3.8898924731182793,
      "grad_norm": 1.0291517270644546,
      "learning_rate": 0.00013966105782967843,
      "loss": 0.0184,
      "step": 2261
    },
    {
      "epoch": 3.8916129032258064,
      "grad_norm": 0.8624031688630038,
      "learning_rate": 0.00013960987259006627,
      "loss": 0.0059,
      "step": 2262
    },
    {
      "epoch": 3.8933333333333335,
      "grad_norm": 0.507861804520978,
      "learning_rate": 0.00013955867503883022,
      "loss": 0.0048,
      "step": 2263
    },
    {
      "epoch": 3.89505376344086,
      "grad_norm": 2.1505901302580663,
      "learning_rate": 0.0001395074651918837,
      "loss": 0.0116,
      "step": 2264
    },
    {
      "epoch": 3.896774193548387,
      "grad_norm": 0.5917424941246987,
      "learning_rate": 0.00013945624306514376,
      "loss": 0.0077,
      "step": 2265
    },
    {
      "epoch": 3.898494623655914,
      "grad_norm": 1.5440231404577311,
      "learning_rate": 0.0001394050086745314,
      "loss": 0.0286,
      "step": 2266
    },
    {
      "epoch": 3.900215053763441,
      "grad_norm": 0.6473835686665186,
      "learning_rate": 0.00013935376203597143,
      "loss": 0.003,
      "step": 2267
    },
    {
      "epoch": 3.9019354838709677,
      "grad_norm": 1.2521164418543616,
      "learning_rate": 0.00013930250316539238,
      "loss": 0.0159,
      "step": 2268
    },
    {
      "epoch": 3.9036559139784948,
      "grad_norm": 0.5239841482966113,
      "learning_rate": 0.0001392512320787267,
      "loss": 0.0062,
      "step": 2269
    },
    {
      "epoch": 3.9053763440860214,
      "grad_norm": 0.843756992941325,
      "learning_rate": 0.00013919994879191055,
      "loss": 0.0031,
      "step": 2270
    },
    {
      "epoch": 3.9070967741935485,
      "grad_norm": 1.0220332374294518,
      "learning_rate": 0.00013914865332088393,
      "loss": 0.021,
      "step": 2271
    },
    {
      "epoch": 3.908817204301075,
      "grad_norm": 0.8098925507427944,
      "learning_rate": 0.00013909734568159053,
      "loss": 0.0239,
      "step": 2272
    },
    {
      "epoch": 3.9105376344086022,
      "grad_norm": 0.8252693198883138,
      "learning_rate": 0.000139046025889978,
      "loss": 0.0108,
      "step": 2273
    },
    {
      "epoch": 3.912258064516129,
      "grad_norm": 3.295101216561191,
      "learning_rate": 0.00013899469396199757,
      "loss": 0.0168,
      "step": 2274
    },
    {
      "epoch": 3.913978494623656,
      "grad_norm": 0.45930968799700556,
      "learning_rate": 0.00013894334991360448,
      "loss": 0.0031,
      "step": 2275
    },
    {
      "epoch": 3.9156989247311826,
      "grad_norm": 0.7955201865968624,
      "learning_rate": 0.00013889199376075742,
      "loss": 0.0105,
      "step": 2276
    },
    {
      "epoch": 3.9174193548387097,
      "grad_norm": 1.420522919395795,
      "learning_rate": 0.00013884062551941913,
      "loss": 0.0394,
      "step": 2277
    },
    {
      "epoch": 3.9191397849462364,
      "grad_norm": 0.508584367334061,
      "learning_rate": 0.000138789245205556,
      "loss": 0.0092,
      "step": 2278
    },
    {
      "epoch": 3.9208602150537635,
      "grad_norm": 1.1139773839219183,
      "learning_rate": 0.0001387378528351381,
      "loss": 0.0219,
      "step": 2279
    },
    {
      "epoch": 3.9225806451612906,
      "grad_norm": 0.5105975545707544,
      "learning_rate": 0.00013868644842413935,
      "loss": 0.0033,
      "step": 2280
    },
    {
      "epoch": 3.924301075268817,
      "grad_norm": 1.8467667340686893,
      "learning_rate": 0.00013863503198853738,
      "loss": 0.036,
      "step": 2281
    },
    {
      "epoch": 3.926021505376344,
      "grad_norm": 1.637061684935908,
      "learning_rate": 0.00013858360354431355,
      "loss": 0.0172,
      "step": 2282
    },
    {
      "epoch": 3.927741935483871,
      "grad_norm": 1.2930178741096992,
      "learning_rate": 0.00013853216310745294,
      "loss": 0.0096,
      "step": 2283
    },
    {
      "epoch": 3.929462365591398,
      "grad_norm": 0.9320473587068004,
      "learning_rate": 0.0001384807106939444,
      "loss": 0.0138,
      "step": 2284
    },
    {
      "epoch": 3.9311827956989247,
      "grad_norm": 0.08070322468851127,
      "learning_rate": 0.0001384292463197805,
      "loss": 0.0009,
      "step": 2285
    },
    {
      "epoch": 3.9329032258064514,
      "grad_norm": 0.22231038523558166,
      "learning_rate": 0.00013837777000095744,
      "loss": 0.0026,
      "step": 2286
    },
    {
      "epoch": 3.9346236559139784,
      "grad_norm": 0.8140359408045679,
      "learning_rate": 0.00013832628175347524,
      "loss": 0.0076,
      "step": 2287
    },
    {
      "epoch": 3.9363440860215055,
      "grad_norm": 1.6270409934178631,
      "learning_rate": 0.0001382747815933376,
      "loss": 0.0527,
      "step": 2288
    },
    {
      "epoch": 3.938064516129032,
      "grad_norm": 0.51319534638824,
      "learning_rate": 0.00013822326953655186,
      "loss": 0.0053,
      "step": 2289
    },
    {
      "epoch": 3.9397849462365593,
      "grad_norm": 1.220332928791705,
      "learning_rate": 0.0001381717455991291,
      "loss": 0.0098,
      "step": 2290
    },
    {
      "epoch": 3.941505376344086,
      "grad_norm": 0.9782268762532007,
      "learning_rate": 0.00013812020979708418,
      "loss": 0.0093,
      "step": 2291
    },
    {
      "epoch": 3.943225806451613,
      "grad_norm": 0.32267584111063113,
      "learning_rate": 0.0001380686621464355,
      "loss": 0.004,
      "step": 2292
    },
    {
      "epoch": 3.9449462365591397,
      "grad_norm": 0.6846358354196413,
      "learning_rate": 0.0001380171026632052,
      "loss": 0.0149,
      "step": 2293
    },
    {
      "epoch": 3.9466666666666668,
      "grad_norm": 1.3120093786476552,
      "learning_rate": 0.00013796553136341915,
      "loss": 0.0129,
      "step": 2294
    },
    {
      "epoch": 3.9483870967741934,
      "grad_norm": 1.1834384884418057,
      "learning_rate": 0.00013791394826310685,
      "loss": 0.017,
      "step": 2295
    },
    {
      "epoch": 3.9501075268817205,
      "grad_norm": 1.150965483001101,
      "learning_rate": 0.00013786235337830144,
      "loss": 0.0105,
      "step": 2296
    },
    {
      "epoch": 3.951827956989247,
      "grad_norm": 0.9971602035925287,
      "learning_rate": 0.00013781074672503975,
      "loss": 0.007,
      "step": 2297
    },
    {
      "epoch": 3.9535483870967743,
      "grad_norm": 0.4572716102596252,
      "learning_rate": 0.00013775912831936226,
      "loss": 0.0045,
      "step": 2298
    },
    {
      "epoch": 3.955268817204301,
      "grad_norm": 1.577532428505047,
      "learning_rate": 0.00013770749817731316,
      "loss": 0.0231,
      "step": 2299
    },
    {
      "epoch": 3.956989247311828,
      "grad_norm": 1.5485227799651091,
      "learning_rate": 0.0001376558563149402,
      "loss": 0.049,
      "step": 2300
    },
    {
      "epoch": 3.958709677419355,
      "grad_norm": 0.9923999597062808,
      "learning_rate": 0.00013760420274829482,
      "loss": 0.0092,
      "step": 2301
    },
    {
      "epoch": 3.9604301075268817,
      "grad_norm": 1.401085959570589,
      "learning_rate": 0.0001375525374934321,
      "loss": 0.0269,
      "step": 2302
    },
    {
      "epoch": 3.9621505376344084,
      "grad_norm": 1.5564561959932177,
      "learning_rate": 0.00013750086056641073,
      "loss": 0.013,
      "step": 2303
    },
    {
      "epoch": 3.9638709677419355,
      "grad_norm": 1.0198095678687158,
      "learning_rate": 0.00013744917198329302,
      "loss": 0.0107,
      "step": 2304
    },
    {
      "epoch": 3.9655913978494626,
      "grad_norm": 0.6666997574596392,
      "learning_rate": 0.00013739747176014499,
      "loss": 0.013,
      "step": 2305
    },
    {
      "epoch": 3.9673118279569892,
      "grad_norm": 2.9670811457424278,
      "learning_rate": 0.00013734575991303615,
      "loss": 0.0445,
      "step": 2306
    },
    {
      "epoch": 3.969032258064516,
      "grad_norm": 1.2954438800099461,
      "learning_rate": 0.00013729403645803968,
      "loss": 0.0141,
      "step": 2307
    },
    {
      "epoch": 3.970752688172043,
      "grad_norm": 0.49345300354542054,
      "learning_rate": 0.0001372423014112324,
      "loss": 0.0032,
      "step": 2308
    },
    {
      "epoch": 3.97247311827957,
      "grad_norm": 1.1513433948480194,
      "learning_rate": 0.00013719055478869478,
      "loss": 0.015,
      "step": 2309
    },
    {
      "epoch": 3.9741935483870967,
      "grad_norm": 2.0884130914013688,
      "learning_rate": 0.00013713879660651068,
      "loss": 0.0392,
      "step": 2310
    },
    {
      "epoch": 3.975913978494624,
      "grad_norm": 0.6427232967897559,
      "learning_rate": 0.00013708702688076775,
      "loss": 0.0068,
      "step": 2311
    },
    {
      "epoch": 3.9776344086021505,
      "grad_norm": 1.5934284158089247,
      "learning_rate": 0.00013703524562755717,
      "loss": 0.046,
      "step": 2312
    },
    {
      "epoch": 3.9793548387096775,
      "grad_norm": 1.234707623427441,
      "learning_rate": 0.00013698345286297368,
      "loss": 0.0197,
      "step": 2313
    },
    {
      "epoch": 3.981075268817204,
      "grad_norm": 0.32071775532944036,
      "learning_rate": 0.00013693164860311565,
      "loss": 0.0032,
      "step": 2314
    },
    {
      "epoch": 3.9827956989247313,
      "grad_norm": 0.260902806952533,
      "learning_rate": 0.00013687983286408495,
      "loss": 0.0028,
      "step": 2315
    },
    {
      "epoch": 3.984516129032258,
      "grad_norm": 1.4590579764723586,
      "learning_rate": 0.00013682800566198707,
      "loss": 0.033,
      "step": 2316
    },
    {
      "epoch": 3.986236559139785,
      "grad_norm": 0.9069997329914029,
      "learning_rate": 0.00013677616701293104,
      "loss": 0.0092,
      "step": 2317
    },
    {
      "epoch": 3.9879569892473117,
      "grad_norm": 1.0863282324307737,
      "learning_rate": 0.00013672431693302948,
      "loss": 0.0096,
      "step": 2318
    },
    {
      "epoch": 3.9896774193548388,
      "grad_norm": 2.202987695561524,
      "learning_rate": 0.00013667245543839854,
      "loss": 0.0381,
      "step": 2319
    },
    {
      "epoch": 3.9913978494623654,
      "grad_norm": 0.9049106726079724,
      "learning_rate": 0.0001366205825451579,
      "loss": 0.0123,
      "step": 2320
    },
    {
      "epoch": 3.9931182795698925,
      "grad_norm": 0.6452663744735897,
      "learning_rate": 0.0001365686982694308,
      "loss": 0.0042,
      "step": 2321
    },
    {
      "epoch": 3.9948387096774196,
      "grad_norm": 0.2851887173667392,
      "learning_rate": 0.00013651680262734403,
      "loss": 0.0056,
      "step": 2322
    },
    {
      "epoch": 3.9965591397849463,
      "grad_norm": 1.04247070390271,
      "learning_rate": 0.0001364648956350279,
      "loss": 0.0086,
      "step": 2323
    },
    {
      "epoch": 3.998279569892473,
      "grad_norm": 1.6371994062346864,
      "learning_rate": 0.00013641297730861629,
      "loss": 0.0262,
      "step": 2324
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.9010941813123673,
      "learning_rate": 0.00013636104766424648,
      "loss": 0.007,
      "step": 2325
    },
    {
      "epoch": 4.001720430107527,
      "grad_norm": 0.41329996834827604,
      "learning_rate": 0.00013630910671805942,
      "loss": 0.0035,
      "step": 2326
    },
    {
      "epoch": 4.003440860215054,
      "grad_norm": 0.19105934625332135,
      "learning_rate": 0.00013625715448619947,
      "loss": 0.0019,
      "step": 2327
    },
    {
      "epoch": 4.00516129032258,
      "grad_norm": 0.20603848265216768,
      "learning_rate": 0.00013620519098481455,
      "loss": 0.0042,
      "step": 2328
    },
    {
      "epoch": 4.0068817204301075,
      "grad_norm": 0.6349703132202897,
      "learning_rate": 0.00013615321623005605,
      "loss": 0.0148,
      "step": 2329
    },
    {
      "epoch": 4.008602150537635,
      "grad_norm": 1.9972025378526919,
      "learning_rate": 0.0001361012302380789,
      "loss": 0.0186,
      "step": 2330
    },
    {
      "epoch": 4.010322580645162,
      "grad_norm": 0.3638818828399747,
      "learning_rate": 0.00013604923302504147,
      "loss": 0.0041,
      "step": 2331
    },
    {
      "epoch": 4.012043010752688,
      "grad_norm": 0.8500165099046526,
      "learning_rate": 0.00013599722460710565,
      "loss": 0.0105,
      "step": 2332
    },
    {
      "epoch": 4.013763440860215,
      "grad_norm": 0.7837088306008616,
      "learning_rate": 0.00013594520500043682,
      "loss": 0.0062,
      "step": 2333
    },
    {
      "epoch": 4.015483870967742,
      "grad_norm": 0.38843313858389,
      "learning_rate": 0.00013589317422120378,
      "loss": 0.003,
      "step": 2334
    },
    {
      "epoch": 4.017204301075269,
      "grad_norm": 0.5627789235888649,
      "learning_rate": 0.00013584113228557886,
      "loss": 0.0035,
      "step": 2335
    },
    {
      "epoch": 4.018924731182795,
      "grad_norm": 0.5976980475863336,
      "learning_rate": 0.0001357890792097379,
      "loss": 0.0155,
      "step": 2336
    },
    {
      "epoch": 4.0206451612903225,
      "grad_norm": 0.41917091139597473,
      "learning_rate": 0.0001357370150098601,
      "loss": 0.0026,
      "step": 2337
    },
    {
      "epoch": 4.0223655913978495,
      "grad_norm": 1.2376651288013962,
      "learning_rate": 0.00013568493970212816,
      "loss": 0.0325,
      "step": 2338
    },
    {
      "epoch": 4.024086021505377,
      "grad_norm": 0.2885503845017664,
      "learning_rate": 0.00013563285330272823,
      "loss": 0.003,
      "step": 2339
    },
    {
      "epoch": 4.025806451612903,
      "grad_norm": 0.699183337026752,
      "learning_rate": 0.00013558075582784996,
      "loss": 0.0061,
      "step": 2340
    },
    {
      "epoch": 4.02752688172043,
      "grad_norm": 0.14924706965980666,
      "learning_rate": 0.00013552864729368634,
      "loss": 0.0018,
      "step": 2341
    },
    {
      "epoch": 4.029247311827957,
      "grad_norm": 0.5145391174197564,
      "learning_rate": 0.00013547652771643388,
      "loss": 0.0019,
      "step": 2342
    },
    {
      "epoch": 4.030967741935484,
      "grad_norm": 1.7020420883897143,
      "learning_rate": 0.00013542439711229252,
      "loss": 0.0091,
      "step": 2343
    },
    {
      "epoch": 4.03268817204301,
      "grad_norm": 0.8194878451238893,
      "learning_rate": 0.00013537225549746556,
      "loss": 0.0083,
      "step": 2344
    },
    {
      "epoch": 4.034408602150537,
      "grad_norm": 0.24838607494644088,
      "learning_rate": 0.0001353201028881598,
      "loss": 0.0029,
      "step": 2345
    },
    {
      "epoch": 4.0361290322580645,
      "grad_norm": 0.5006894134234459,
      "learning_rate": 0.0001352679393005854,
      "loss": 0.0035,
      "step": 2346
    },
    {
      "epoch": 4.037849462365592,
      "grad_norm": 0.4857804614414918,
      "learning_rate": 0.00013521576475095597,
      "loss": 0.0071,
      "step": 2347
    },
    {
      "epoch": 4.039569892473119,
      "grad_norm": 0.2472910699585084,
      "learning_rate": 0.00013516357925548854,
      "loss": 0.0034,
      "step": 2348
    },
    {
      "epoch": 4.041290322580645,
      "grad_norm": 0.44150692981631295,
      "learning_rate": 0.00013511138283040343,
      "loss": 0.0065,
      "step": 2349
    },
    {
      "epoch": 4.043010752688172,
      "grad_norm": 0.029602974035410064,
      "learning_rate": 0.00013505917549192455,
      "loss": 0.0004,
      "step": 2350
    },
    {
      "epoch": 4.044731182795699,
      "grad_norm": 0.3194998277484506,
      "learning_rate": 0.000135006957256279,
      "loss": 0.0036,
      "step": 2351
    },
    {
      "epoch": 4.046451612903226,
      "grad_norm": 0.4744309546615816,
      "learning_rate": 0.00013495472813969744,
      "loss": 0.0051,
      "step": 2352
    },
    {
      "epoch": 4.048172043010752,
      "grad_norm": 0.5611696519061081,
      "learning_rate": 0.0001349024881584138,
      "loss": 0.0128,
      "step": 2353
    },
    {
      "epoch": 4.0498924731182795,
      "grad_norm": 0.14699372476051692,
      "learning_rate": 0.0001348502373286654,
      "loss": 0.0015,
      "step": 2354
    },
    {
      "epoch": 4.051612903225807,
      "grad_norm": 0.9569327250654995,
      "learning_rate": 0.00013479797566669298,
      "loss": 0.0168,
      "step": 2355
    },
    {
      "epoch": 4.053333333333334,
      "grad_norm": 0.5737726582640628,
      "learning_rate": 0.0001347457031887406,
      "loss": 0.0049,
      "step": 2356
    },
    {
      "epoch": 4.05505376344086,
      "grad_norm": 0.9872033087217627,
      "learning_rate": 0.0001346934199110557,
      "loss": 0.0116,
      "step": 2357
    },
    {
      "epoch": 4.056774193548387,
      "grad_norm": 1.4835952591377537,
      "learning_rate": 0.00013464112584988912,
      "loss": 0.0128,
      "step": 2358
    },
    {
      "epoch": 4.058494623655914,
      "grad_norm": 0.07893912315814089,
      "learning_rate": 0.00013458882102149498,
      "loss": 0.0008,
      "step": 2359
    },
    {
      "epoch": 4.060215053763441,
      "grad_norm": 1.1553922584774847,
      "learning_rate": 0.00013453650544213076,
      "loss": 0.0256,
      "step": 2360
    },
    {
      "epoch": 4.061935483870967,
      "grad_norm": 0.11663045262289891,
      "learning_rate": 0.00013448417912805734,
      "loss": 0.0011,
      "step": 2361
    },
    {
      "epoch": 4.0636559139784945,
      "grad_norm": 1.3766040827191128,
      "learning_rate": 0.00013443184209553885,
      "loss": 0.0046,
      "step": 2362
    },
    {
      "epoch": 4.0653763440860216,
      "grad_norm": 0.6429387509595565,
      "learning_rate": 0.00013437949436084283,
      "loss": 0.005,
      "step": 2363
    },
    {
      "epoch": 4.067096774193549,
      "grad_norm": 1.1304816142206098,
      "learning_rate": 0.0001343271359402401,
      "loss": 0.0188,
      "step": 2364
    },
    {
      "epoch": 4.068817204301075,
      "grad_norm": 2.229094842120943,
      "learning_rate": 0.00013427476685000484,
      "loss": 0.0181,
      "step": 2365
    },
    {
      "epoch": 4.070537634408602,
      "grad_norm": 0.12779692825374392,
      "learning_rate": 0.00013422238710641445,
      "loss": 0.0011,
      "step": 2366
    },
    {
      "epoch": 4.072258064516129,
      "grad_norm": 1.9900318869236648,
      "learning_rate": 0.0001341699967257498,
      "loss": 0.0392,
      "step": 2367
    },
    {
      "epoch": 4.073978494623656,
      "grad_norm": 0.39147313412518053,
      "learning_rate": 0.0001341175957242949,
      "loss": 0.0025,
      "step": 2368
    },
    {
      "epoch": 4.075698924731183,
      "grad_norm": 0.43905534467394586,
      "learning_rate": 0.0001340651841183372,
      "loss": 0.0026,
      "step": 2369
    },
    {
      "epoch": 4.077419354838709,
      "grad_norm": 0.39616494352449577,
      "learning_rate": 0.00013401276192416734,
      "loss": 0.0047,
      "step": 2370
    },
    {
      "epoch": 4.0791397849462365,
      "grad_norm": 0.9622191212916332,
      "learning_rate": 0.00013396032915807932,
      "loss": 0.0093,
      "step": 2371
    },
    {
      "epoch": 4.080860215053764,
      "grad_norm": 1.7945160787376975,
      "learning_rate": 0.0001339078858363704,
      "loss": 0.0126,
      "step": 2372
    },
    {
      "epoch": 4.082580645161291,
      "grad_norm": 1.16161147386279,
      "learning_rate": 0.00013385543197534116,
      "loss": 0.0059,
      "step": 2373
    },
    {
      "epoch": 4.084301075268817,
      "grad_norm": 0.6827696018665839,
      "learning_rate": 0.0001338029675912954,
      "loss": 0.017,
      "step": 2374
    },
    {
      "epoch": 4.086021505376344,
      "grad_norm": 0.2984050312048367,
      "learning_rate": 0.0001337504927005401,
      "loss": 0.0024,
      "step": 2375
    },
    {
      "epoch": 4.087741935483871,
      "grad_norm": 1.4578460360542977,
      "learning_rate": 0.00013369800731938576,
      "loss": 0.0183,
      "step": 2376
    },
    {
      "epoch": 4.089462365591398,
      "grad_norm": 0.4588438988343796,
      "learning_rate": 0.00013364551146414594,
      "loss": 0.0022,
      "step": 2377
    },
    {
      "epoch": 4.091182795698924,
      "grad_norm": 0.8257396605952051,
      "learning_rate": 0.00013359300515113754,
      "loss": 0.0101,
      "step": 2378
    },
    {
      "epoch": 4.0929032258064515,
      "grad_norm": 0.1417014556136374,
      "learning_rate": 0.00013354048839668065,
      "loss": 0.0005,
      "step": 2379
    },
    {
      "epoch": 4.094623655913979,
      "grad_norm": 2.1491700311438113,
      "learning_rate": 0.00013348796121709862,
      "loss": 0.0357,
      "step": 2380
    },
    {
      "epoch": 4.096344086021506,
      "grad_norm": 1.5342106729003153,
      "learning_rate": 0.00013343542362871812,
      "loss": 0.0154,
      "step": 2381
    },
    {
      "epoch": 4.098064516129032,
      "grad_norm": 0.7138519980681635,
      "learning_rate": 0.00013338287564786894,
      "loss": 0.0098,
      "step": 2382
    },
    {
      "epoch": 4.099784946236559,
      "grad_norm": 0.6991011613251129,
      "learning_rate": 0.00013333031729088419,
      "loss": 0.005,
      "step": 2383
    },
    {
      "epoch": 4.101505376344086,
      "grad_norm": 0.7579075919908785,
      "learning_rate": 0.00013327774857410015,
      "loss": 0.0049,
      "step": 2384
    },
    {
      "epoch": 4.103225806451613,
      "grad_norm": 0.9647621980765794,
      "learning_rate": 0.00013322516951385632,
      "loss": 0.0116,
      "step": 2385
    },
    {
      "epoch": 4.104946236559139,
      "grad_norm": 0.03856563598246601,
      "learning_rate": 0.00013317258012649549,
      "loss": 0.0004,
      "step": 2386
    },
    {
      "epoch": 4.1066666666666665,
      "grad_norm": 0.9745623774981581,
      "learning_rate": 0.00013311998042836356,
      "loss": 0.0103,
      "step": 2387
    },
    {
      "epoch": 4.108387096774194,
      "grad_norm": 0.3328256530798722,
      "learning_rate": 0.0001330673704358097,
      "loss": 0.0026,
      "step": 2388
    },
    {
      "epoch": 4.110107526881721,
      "grad_norm": 1.2318263850660551,
      "learning_rate": 0.00013301475016518622,
      "loss": 0.0164,
      "step": 2389
    },
    {
      "epoch": 4.111827956989248,
      "grad_norm": 1.6494071880634313,
      "learning_rate": 0.0001329621196328487,
      "loss": 0.0485,
      "step": 2390
    },
    {
      "epoch": 4.113548387096774,
      "grad_norm": 0.6320535621633229,
      "learning_rate": 0.00013290947885515587,
      "loss": 0.0087,
      "step": 2391
    },
    {
      "epoch": 4.115268817204301,
      "grad_norm": 0.3279111012061397,
      "learning_rate": 0.00013285682784846964,
      "loss": 0.0026,
      "step": 2392
    },
    {
      "epoch": 4.116989247311828,
      "grad_norm": 0.19018218506996462,
      "learning_rate": 0.0001328041666291551,
      "loss": 0.0015,
      "step": 2393
    },
    {
      "epoch": 4.118709677419355,
      "grad_norm": 0.406708405327922,
      "learning_rate": 0.00013275149521358053,
      "loss": 0.004,
      "step": 2394
    },
    {
      "epoch": 4.120430107526881,
      "grad_norm": 0.09468276906307911,
      "learning_rate": 0.00013269881361811737,
      "loss": 0.0008,
      "step": 2395
    },
    {
      "epoch": 4.1221505376344085,
      "grad_norm": 0.5557294426122061,
      "learning_rate": 0.00013264612185914025,
      "loss": 0.0041,
      "step": 2396
    },
    {
      "epoch": 4.123870967741936,
      "grad_norm": 1.0197058118171367,
      "learning_rate": 0.00013259341995302686,
      "loss": 0.0104,
      "step": 2397
    },
    {
      "epoch": 4.125591397849463,
      "grad_norm": 1.0848613251083066,
      "learning_rate": 0.00013254070791615818,
      "loss": 0.0075,
      "step": 2398
    },
    {
      "epoch": 4.127311827956989,
      "grad_norm": 1.0675126530687302,
      "learning_rate": 0.00013248798576491827,
      "loss": 0.0087,
      "step": 2399
    },
    {
      "epoch": 4.129032258064516,
      "grad_norm": 0.15448481563190056,
      "learning_rate": 0.00013243525351569433,
      "loss": 0.0016,
      "step": 2400
    },
    {
      "epoch": 4.130752688172043,
      "grad_norm": 1.070046791427172,
      "learning_rate": 0.0001323825111848767,
      "loss": 0.0058,
      "step": 2401
    },
    {
      "epoch": 4.13247311827957,
      "grad_norm": 1.062607399999796,
      "learning_rate": 0.00013232975878885885,
      "loss": 0.0032,
      "step": 2402
    },
    {
      "epoch": 4.134193548387096,
      "grad_norm": 0.20441708090678348,
      "learning_rate": 0.00013227699634403743,
      "loss": 0.0012,
      "step": 2403
    },
    {
      "epoch": 4.1359139784946235,
      "grad_norm": 0.10611585870583608,
      "learning_rate": 0.00013222422386681215,
      "loss": 0.0004,
      "step": 2404
    },
    {
      "epoch": 4.137634408602151,
      "grad_norm": 1.5387862205416447,
      "learning_rate": 0.0001321714413735859,
      "loss": 0.0257,
      "step": 2405
    },
    {
      "epoch": 4.139354838709678,
      "grad_norm": 0.14617666693192097,
      "learning_rate": 0.00013211864888076457,
      "loss": 0.0006,
      "step": 2406
    },
    {
      "epoch": 4.141075268817204,
      "grad_norm": 0.09968300668050536,
      "learning_rate": 0.00013206584640475727,
      "loss": 0.0009,
      "step": 2407
    },
    {
      "epoch": 4.142795698924731,
      "grad_norm": 0.3865709256120588,
      "learning_rate": 0.00013201303396197621,
      "loss": 0.0025,
      "step": 2408
    },
    {
      "epoch": 4.144516129032258,
      "grad_norm": 0.665374360850315,
      "learning_rate": 0.00013196021156883662,
      "loss": 0.0044,
      "step": 2409
    },
    {
      "epoch": 4.146236559139785,
      "grad_norm": 0.9035727623335414,
      "learning_rate": 0.00013190737924175688,
      "loss": 0.0096,
      "step": 2410
    },
    {
      "epoch": 4.147956989247312,
      "grad_norm": 0.35901976371617683,
      "learning_rate": 0.00013185453699715845,
      "loss": 0.002,
      "step": 2411
    },
    {
      "epoch": 4.1496774193548385,
      "grad_norm": 1.296319300446354,
      "learning_rate": 0.00013180168485146592,
      "loss": 0.0123,
      "step": 2412
    },
    {
      "epoch": 4.151397849462366,
      "grad_norm": 0.4970895676892349,
      "learning_rate": 0.0001317488228211068,
      "loss": 0.0021,
      "step": 2413
    },
    {
      "epoch": 4.153118279569893,
      "grad_norm": 1.6025199430284511,
      "learning_rate": 0.00013169595092251183,
      "loss": 0.0119,
      "step": 2414
    },
    {
      "epoch": 4.15483870967742,
      "grad_norm": 0.4062921193097184,
      "learning_rate": 0.00013164306917211476,
      "loss": 0.002,
      "step": 2415
    },
    {
      "epoch": 4.156559139784946,
      "grad_norm": 0.11716789489360682,
      "learning_rate": 0.00013159017758635245,
      "loss": 0.0004,
      "step": 2416
    },
    {
      "epoch": 4.158279569892473,
      "grad_norm": 0.06338039383363023,
      "learning_rate": 0.00013153727618166468,
      "loss": 0.0007,
      "step": 2417
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.1232946420276897,
      "learning_rate": 0.00013148436497449446,
      "loss": 0.0061,
      "step": 2418
    },
    {
      "epoch": 4.161720430107527,
      "grad_norm": 0.4337694329957357,
      "learning_rate": 0.00013143144398128774,
      "loss": 0.0038,
      "step": 2419
    },
    {
      "epoch": 4.163440860215053,
      "grad_norm": 0.07079574154029056,
      "learning_rate": 0.0001313785132184935,
      "loss": 0.0005,
      "step": 2420
    },
    {
      "epoch": 4.1651612903225805,
      "grad_norm": 1.4716952895010076,
      "learning_rate": 0.00013132557270256382,
      "loss": 0.0078,
      "step": 2421
    },
    {
      "epoch": 4.166881720430108,
      "grad_norm": 0.37768978924918534,
      "learning_rate": 0.00013127262244995382,
      "loss": 0.0022,
      "step": 2422
    },
    {
      "epoch": 4.168602150537635,
      "grad_norm": 0.13417716545040131,
      "learning_rate": 0.00013121966247712155,
      "loss": 0.0012,
      "step": 2423
    },
    {
      "epoch": 4.170322580645161,
      "grad_norm": 0.693858189512559,
      "learning_rate": 0.00013116669280052815,
      "loss": 0.0032,
      "step": 2424
    },
    {
      "epoch": 4.172043010752688,
      "grad_norm": 0.7480815893876679,
      "learning_rate": 0.00013111371343663776,
      "loss": 0.006,
      "step": 2425
    },
    {
      "epoch": 4.173763440860215,
      "grad_norm": 1.4880785045154057,
      "learning_rate": 0.00013106072440191758,
      "loss": 0.0127,
      "step": 2426
    },
    {
      "epoch": 4.175483870967742,
      "grad_norm": 0.07431099997211783,
      "learning_rate": 0.00013100772571283774,
      "loss": 0.0006,
      "step": 2427
    },
    {
      "epoch": 4.177204301075268,
      "grad_norm": 2.0966281201553603,
      "learning_rate": 0.0001309547173858714,
      "loss": 0.0202,
      "step": 2428
    },
    {
      "epoch": 4.1789247311827955,
      "grad_norm": 1.5062933065291457,
      "learning_rate": 0.00013090169943749476,
      "loss": 0.0077,
      "step": 2429
    },
    {
      "epoch": 4.180645161290323,
      "grad_norm": 0.5619750818261878,
      "learning_rate": 0.0001308486718841869,
      "loss": 0.0054,
      "step": 2430
    },
    {
      "epoch": 4.18236559139785,
      "grad_norm": 1.5230403476781575,
      "learning_rate": 0.00013079563474243001,
      "loss": 0.0107,
      "step": 2431
    },
    {
      "epoch": 4.184086021505376,
      "grad_norm": 0.12458806533966567,
      "learning_rate": 0.0001307425880287092,
      "loss": 0.0005,
      "step": 2432
    },
    {
      "epoch": 4.185806451612903,
      "grad_norm": 0.18586612791794005,
      "learning_rate": 0.00013068953175951258,
      "loss": 0.0008,
      "step": 2433
    },
    {
      "epoch": 4.18752688172043,
      "grad_norm": 1.40534185408818,
      "learning_rate": 0.00013063646595133112,
      "loss": 0.0049,
      "step": 2434
    },
    {
      "epoch": 4.189247311827957,
      "grad_norm": 1.4665677816011002,
      "learning_rate": 0.00013058339062065895,
      "loss": 0.0156,
      "step": 2435
    },
    {
      "epoch": 4.190967741935484,
      "grad_norm": 0.5747888962579697,
      "learning_rate": 0.000130530305783993,
      "loss": 0.0049,
      "step": 2436
    },
    {
      "epoch": 4.1926881720430105,
      "grad_norm": 0.04190593499156763,
      "learning_rate": 0.00013047721145783325,
      "loss": 0.0003,
      "step": 2437
    },
    {
      "epoch": 4.194408602150538,
      "grad_norm": 1.3552612283818581,
      "learning_rate": 0.00013042410765868253,
      "loss": 0.0333,
      "step": 2438
    },
    {
      "epoch": 4.196129032258065,
      "grad_norm": 1.037356879595984,
      "learning_rate": 0.00013037099440304676,
      "loss": 0.0088,
      "step": 2439
    },
    {
      "epoch": 4.197849462365592,
      "grad_norm": 1.2015355468315034,
      "learning_rate": 0.0001303178717074346,
      "loss": 0.0069,
      "step": 2440
    },
    {
      "epoch": 4.199569892473118,
      "grad_norm": 0.43454333679627755,
      "learning_rate": 0.00013026473958835787,
      "loss": 0.0024,
      "step": 2441
    },
    {
      "epoch": 4.201290322580645,
      "grad_norm": 0.2451534794016674,
      "learning_rate": 0.00013021159806233116,
      "loss": 0.0014,
      "step": 2442
    },
    {
      "epoch": 4.203010752688172,
      "grad_norm": 0.9761196287500424,
      "learning_rate": 0.00013015844714587202,
      "loss": 0.0109,
      "step": 2443
    },
    {
      "epoch": 4.204731182795699,
      "grad_norm": 0.31397499585469385,
      "learning_rate": 0.00013010528685550093,
      "loss": 0.0022,
      "step": 2444
    },
    {
      "epoch": 4.2064516129032254,
      "grad_norm": 0.849032286681124,
      "learning_rate": 0.00013005211720774128,
      "loss": 0.0084,
      "step": 2445
    },
    {
      "epoch": 4.2081720430107525,
      "grad_norm": 2.3180930079208175,
      "learning_rate": 0.0001299989382191194,
      "loss": 0.0262,
      "step": 2446
    },
    {
      "epoch": 4.20989247311828,
      "grad_norm": 0.12401138890388606,
      "learning_rate": 0.00012994574990616447,
      "loss": 0.0006,
      "step": 2447
    },
    {
      "epoch": 4.211612903225807,
      "grad_norm": 0.02719241802560323,
      "learning_rate": 0.00012989255228540865,
      "loss": 0.0002,
      "step": 2448
    },
    {
      "epoch": 4.213333333333333,
      "grad_norm": 0.7169473511090805,
      "learning_rate": 0.00012983934537338685,
      "loss": 0.0057,
      "step": 2449
    },
    {
      "epoch": 4.21505376344086,
      "grad_norm": 1.954616715680389,
      "learning_rate": 0.000129786129186637,
      "loss": 0.0444,
      "step": 2450
    },
    {
      "epoch": 4.216774193548387,
      "grad_norm": 0.062282503086726386,
      "learning_rate": 0.00012973290374169985,
      "loss": 0.0002,
      "step": 2451
    },
    {
      "epoch": 4.218494623655914,
      "grad_norm": 0.8283102050506002,
      "learning_rate": 0.00012967966905511906,
      "loss": 0.0066,
      "step": 2452
    },
    {
      "epoch": 4.220215053763441,
      "grad_norm": 0.1827239087637157,
      "learning_rate": 0.00012962642514344116,
      "loss": 0.0013,
      "step": 2453
    },
    {
      "epoch": 4.2219354838709675,
      "grad_norm": 1.6862116570239354,
      "learning_rate": 0.0001295731720232155,
      "loss": 0.0305,
      "step": 2454
    },
    {
      "epoch": 4.223655913978495,
      "grad_norm": 1.2782244634613922,
      "learning_rate": 0.00012951990971099434,
      "loss": 0.0049,
      "step": 2455
    },
    {
      "epoch": 4.225376344086022,
      "grad_norm": 3.6904767299983168,
      "learning_rate": 0.0001294666382233328,
      "loss": 0.0558,
      "step": 2456
    },
    {
      "epoch": 4.227096774193549,
      "grad_norm": 1.072964534289559,
      "learning_rate": 0.00012941335757678883,
      "loss": 0.0105,
      "step": 2457
    },
    {
      "epoch": 4.228817204301075,
      "grad_norm": 0.924956004838206,
      "learning_rate": 0.0001293600677879232,
      "loss": 0.0013,
      "step": 2458
    },
    {
      "epoch": 4.230537634408602,
      "grad_norm": 0.6612682317601202,
      "learning_rate": 0.0001293067688732996,
      "loss": 0.006,
      "step": 2459
    },
    {
      "epoch": 4.232258064516129,
      "grad_norm": 0.8867392727279013,
      "learning_rate": 0.00012925346084948451,
      "loss": 0.0077,
      "step": 2460
    },
    {
      "epoch": 4.233978494623656,
      "grad_norm": 0.5149525753921448,
      "learning_rate": 0.00012920014373304716,
      "loss": 0.0028,
      "step": 2461
    },
    {
      "epoch": 4.2356989247311825,
      "grad_norm": 0.4048171734207775,
      "learning_rate": 0.00012914681754055979,
      "loss": 0.0021,
      "step": 2462
    },
    {
      "epoch": 4.23741935483871,
      "grad_norm": 0.02609589006247894,
      "learning_rate": 0.00012909348228859732,
      "loss": 0.0003,
      "step": 2463
    },
    {
      "epoch": 4.239139784946237,
      "grad_norm": 2.2085993952423655,
      "learning_rate": 0.00012904013799373756,
      "loss": 0.0174,
      "step": 2464
    },
    {
      "epoch": 4.240860215053764,
      "grad_norm": 0.19429703518670585,
      "learning_rate": 0.000128986784672561,
      "loss": 0.0007,
      "step": 2465
    },
    {
      "epoch": 4.24258064516129,
      "grad_norm": 0.40350840420452266,
      "learning_rate": 0.0001289334223416511,
      "loss": 0.003,
      "step": 2466
    },
    {
      "epoch": 4.244301075268817,
      "grad_norm": 1.0266166099495668,
      "learning_rate": 0.0001288800510175941,
      "loss": 0.0068,
      "step": 2467
    },
    {
      "epoch": 4.246021505376344,
      "grad_norm": 0.82166302197549,
      "learning_rate": 0.00012882667071697888,
      "loss": 0.0049,
      "step": 2468
    },
    {
      "epoch": 4.247741935483871,
      "grad_norm": 1.9707025773300169,
      "learning_rate": 0.00012877328145639725,
      "loss": 0.0186,
      "step": 2469
    },
    {
      "epoch": 4.2494623655913975,
      "grad_norm": 0.9583418014822989,
      "learning_rate": 0.00012871988325244385,
      "loss": 0.0285,
      "step": 2470
    },
    {
      "epoch": 4.2511827956989245,
      "grad_norm": 0.2958047317679536,
      "learning_rate": 0.00012866647612171594,
      "loss": 0.0026,
      "step": 2471
    },
    {
      "epoch": 4.252903225806452,
      "grad_norm": 2.9334878569818814,
      "learning_rate": 0.00012861306008081367,
      "loss": 0.0329,
      "step": 2472
    },
    {
      "epoch": 4.254623655913979,
      "grad_norm": 0.7744157759359236,
      "learning_rate": 0.0001285596351463399,
      "loss": 0.0089,
      "step": 2473
    },
    {
      "epoch": 4.256344086021505,
      "grad_norm": 0.6195275130428766,
      "learning_rate": 0.00012850620133490027,
      "loss": 0.0038,
      "step": 2474
    },
    {
      "epoch": 4.258064516129032,
      "grad_norm": 0.8205085626161516,
      "learning_rate": 0.00012845275866310324,
      "loss": 0.0046,
      "step": 2475
    },
    {
      "epoch": 4.259784946236559,
      "grad_norm": 0.9391519800807911,
      "learning_rate": 0.00012839930714755998,
      "loss": 0.011,
      "step": 2476
    },
    {
      "epoch": 4.261505376344086,
      "grad_norm": 1.7769901146322968,
      "learning_rate": 0.00012834584680488436,
      "loss": 0.0055,
      "step": 2477
    },
    {
      "epoch": 4.263225806451613,
      "grad_norm": 2.05970455614046,
      "learning_rate": 0.000128292377651693,
      "loss": 0.031,
      "step": 2478
    },
    {
      "epoch": 4.2649462365591395,
      "grad_norm": 0.24915247385753087,
      "learning_rate": 0.0001282388997046054,
      "loss": 0.0029,
      "step": 2479
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 0.8786356913025613,
      "learning_rate": 0.00012818541298024357,
      "loss": 0.0038,
      "step": 2480
    },
    {
      "epoch": 4.268387096774194,
      "grad_norm": 0.4225079733052949,
      "learning_rate": 0.0001281319174952325,
      "loss": 0.0034,
      "step": 2481
    },
    {
      "epoch": 4.270107526881721,
      "grad_norm": 1.3666399107123341,
      "learning_rate": 0.00012807841326619967,
      "loss": 0.0131,
      "step": 2482
    },
    {
      "epoch": 4.271827956989247,
      "grad_norm": 0.8164266437551804,
      "learning_rate": 0.00012802490030977537,
      "loss": 0.0086,
      "step": 2483
    },
    {
      "epoch": 4.273548387096774,
      "grad_norm": 0.1078329230191854,
      "learning_rate": 0.00012797137864259267,
      "loss": 0.0007,
      "step": 2484
    },
    {
      "epoch": 4.275268817204301,
      "grad_norm": 0.7503298515490989,
      "learning_rate": 0.00012791784828128724,
      "loss": 0.005,
      "step": 2485
    },
    {
      "epoch": 4.276989247311828,
      "grad_norm": 0.8146907582963241,
      "learning_rate": 0.00012786430924249754,
      "loss": 0.0209,
      "step": 2486
    },
    {
      "epoch": 4.2787096774193545,
      "grad_norm": 1.9302367516589063,
      "learning_rate": 0.00012781076154286467,
      "loss": 0.0178,
      "step": 2487
    },
    {
      "epoch": 4.280430107526882,
      "grad_norm": 3.5449666338513244,
      "learning_rate": 0.00012775720519903242,
      "loss": 0.0274,
      "step": 2488
    },
    {
      "epoch": 4.282150537634409,
      "grad_norm": 0.7664922751871499,
      "learning_rate": 0.0001277036402276473,
      "loss": 0.0057,
      "step": 2489
    },
    {
      "epoch": 4.283870967741936,
      "grad_norm": 0.10427367454706031,
      "learning_rate": 0.0001276500666453585,
      "loss": 0.0011,
      "step": 2490
    },
    {
      "epoch": 4.285591397849462,
      "grad_norm": 1.2859275064773699,
      "learning_rate": 0.00012759648446881788,
      "loss": 0.0312,
      "step": 2491
    },
    {
      "epoch": 4.287311827956989,
      "grad_norm": 1.5241560525848243,
      "learning_rate": 0.00012754289371467986,
      "loss": 0.0142,
      "step": 2492
    },
    {
      "epoch": 4.289032258064516,
      "grad_norm": 1.6263935259784956,
      "learning_rate": 0.00012748929439960178,
      "loss": 0.0097,
      "step": 2493
    },
    {
      "epoch": 4.290752688172043,
      "grad_norm": 0.8284962324916854,
      "learning_rate": 0.00012743568654024343,
      "loss": 0.0117,
      "step": 2494
    },
    {
      "epoch": 4.29247311827957,
      "grad_norm": 1.1181020469125977,
      "learning_rate": 0.0001273820701532673,
      "loss": 0.0289,
      "step": 2495
    },
    {
      "epoch": 4.2941935483870965,
      "grad_norm": 0.7350488433361925,
      "learning_rate": 0.00012732844525533852,
      "loss": 0.0039,
      "step": 2496
    },
    {
      "epoch": 4.295913978494624,
      "grad_norm": 2.5645551273022176,
      "learning_rate": 0.00012727481186312501,
      "loss": 0.0507,
      "step": 2497
    },
    {
      "epoch": 4.297634408602151,
      "grad_norm": 1.1633885027833888,
      "learning_rate": 0.00012722116999329712,
      "loss": 0.0206,
      "step": 2498
    },
    {
      "epoch": 4.299354838709678,
      "grad_norm": 0.493262782761096,
      "learning_rate": 0.00012716751966252796,
      "loss": 0.0029,
      "step": 2499
    },
    {
      "epoch": 4.301075268817204,
      "grad_norm": 0.45688901138528876,
      "learning_rate": 0.0001271138608874932,
      "loss": 0.0053,
      "step": 2500
    },
    {
      "epoch": 4.302795698924731,
      "grad_norm": 0.6618155522395935,
      "learning_rate": 0.00012706019368487122,
      "loss": 0.0058,
      "step": 2501
    },
    {
      "epoch": 4.304516129032258,
      "grad_norm": 0.33793366149512194,
      "learning_rate": 0.00012700651807134292,
      "loss": 0.0025,
      "step": 2502
    },
    {
      "epoch": 4.306236559139785,
      "grad_norm": 1.144333055970949,
      "learning_rate": 0.00012695283406359193,
      "loss": 0.0262,
      "step": 2503
    },
    {
      "epoch": 4.3079569892473115,
      "grad_norm": 1.4901974098285564,
      "learning_rate": 0.0001268991416783044,
      "loss": 0.0121,
      "step": 2504
    },
    {
      "epoch": 4.309677419354839,
      "grad_norm": 0.4393573416373057,
      "learning_rate": 0.00012684544093216908,
      "loss": 0.0048,
      "step": 2505
    },
    {
      "epoch": 4.311397849462366,
      "grad_norm": 1.0357452991647036,
      "learning_rate": 0.00012679173184187737,
      "loss": 0.0119,
      "step": 2506
    },
    {
      "epoch": 4.313118279569893,
      "grad_norm": 0.15427675275729394,
      "learning_rate": 0.0001267380144241233,
      "loss": 0.0017,
      "step": 2507
    },
    {
      "epoch": 4.314838709677419,
      "grad_norm": 0.9456206458860826,
      "learning_rate": 0.00012668428869560335,
      "loss": 0.0048,
      "step": 2508
    },
    {
      "epoch": 4.316559139784946,
      "grad_norm": 0.8360794007398191,
      "learning_rate": 0.0001266305546730167,
      "loss": 0.0085,
      "step": 2509
    },
    {
      "epoch": 4.318279569892473,
      "grad_norm": 0.5715725673470129,
      "learning_rate": 0.00012657681237306502,
      "loss": 0.0056,
      "step": 2510
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.33401960608210157,
      "learning_rate": 0.0001265230618124527,
      "loss": 0.0026,
      "step": 2511
    },
    {
      "epoch": 4.3217204301075265,
      "grad_norm": 0.11676181084696734,
      "learning_rate": 0.00012646930300788656,
      "loss": 0.0012,
      "step": 2512
    },
    {
      "epoch": 4.323440860215054,
      "grad_norm": 2.4753208973941803,
      "learning_rate": 0.00012641553597607597,
      "loss": 0.0097,
      "step": 2513
    },
    {
      "epoch": 4.325161290322581,
      "grad_norm": 0.19348217214013033,
      "learning_rate": 0.00012636176073373297,
      "loss": 0.0017,
      "step": 2514
    },
    {
      "epoch": 4.326881720430108,
      "grad_norm": 1.5723906571986184,
      "learning_rate": 0.0001263079772975721,
      "loss": 0.0237,
      "step": 2515
    },
    {
      "epoch": 4.328602150537634,
      "grad_norm": 0.5061304303247071,
      "learning_rate": 0.0001262541856843104,
      "loss": 0.0034,
      "step": 2516
    },
    {
      "epoch": 4.330322580645161,
      "grad_norm": 0.41401440191060457,
      "learning_rate": 0.00012620038591066755,
      "loss": 0.0052,
      "step": 2517
    },
    {
      "epoch": 4.332043010752688,
      "grad_norm": 0.1583308359377099,
      "learning_rate": 0.00012614657799336562,
      "loss": 0.0009,
      "step": 2518
    },
    {
      "epoch": 4.333763440860215,
      "grad_norm": 0.5552191213452506,
      "learning_rate": 0.0001260927619491294,
      "loss": 0.0044,
      "step": 2519
    },
    {
      "epoch": 4.335483870967742,
      "grad_norm": 0.17637091417558107,
      "learning_rate": 0.00012603893779468604,
      "loss": 0.0011,
      "step": 2520
    },
    {
      "epoch": 4.3372043010752686,
      "grad_norm": 1.5320066343418275,
      "learning_rate": 0.0001259851055467653,
      "loss": 0.0151,
      "step": 2521
    },
    {
      "epoch": 4.338924731182796,
      "grad_norm": 0.6231890262224951,
      "learning_rate": 0.00012593126522209943,
      "loss": 0.0051,
      "step": 2522
    },
    {
      "epoch": 4.340645161290323,
      "grad_norm": 0.9641345259294137,
      "learning_rate": 0.00012587741683742318,
      "loss": 0.0073,
      "step": 2523
    },
    {
      "epoch": 4.34236559139785,
      "grad_norm": 0.9526984608115259,
      "learning_rate": 0.00012582356040947382,
      "loss": 0.005,
      "step": 2524
    },
    {
      "epoch": 4.344086021505376,
      "grad_norm": 0.023043238515509983,
      "learning_rate": 0.00012576969595499117,
      "loss": 0.0002,
      "step": 2525
    },
    {
      "epoch": 4.345806451612903,
      "grad_norm": 2.073643077587412,
      "learning_rate": 0.00012571582349071744,
      "loss": 0.0178,
      "step": 2526
    },
    {
      "epoch": 4.34752688172043,
      "grad_norm": 1.7741041768597623,
      "learning_rate": 0.00012566194303339739,
      "loss": 0.0144,
      "step": 2527
    },
    {
      "epoch": 4.349247311827957,
      "grad_norm": 2.311609388891411,
      "learning_rate": 0.0001256080545997782,
      "loss": 0.024,
      "step": 2528
    },
    {
      "epoch": 4.3509677419354835,
      "grad_norm": 0.0729216106524614,
      "learning_rate": 0.00012555415820660973,
      "loss": 0.0004,
      "step": 2529
    },
    {
      "epoch": 4.352688172043011,
      "grad_norm": 1.077725592202213,
      "learning_rate": 0.00012550025387064406,
      "loss": 0.0088,
      "step": 2530
    },
    {
      "epoch": 4.354408602150538,
      "grad_norm": 1.7304688249384823,
      "learning_rate": 0.00012544634160863586,
      "loss": 0.0061,
      "step": 2531
    },
    {
      "epoch": 4.356129032258065,
      "grad_norm": 1.4868013634943562,
      "learning_rate": 0.0001253924214373423,
      "loss": 0.0113,
      "step": 2532
    },
    {
      "epoch": 4.357849462365591,
      "grad_norm": 1.3259763217335596,
      "learning_rate": 0.0001253384933735229,
      "loss": 0.0067,
      "step": 2533
    },
    {
      "epoch": 4.359569892473118,
      "grad_norm": 0.10169476677084929,
      "learning_rate": 0.00012528455743393972,
      "loss": 0.0009,
      "step": 2534
    },
    {
      "epoch": 4.361290322580645,
      "grad_norm": 2.004226282144454,
      "learning_rate": 0.00012523061363535725,
      "loss": 0.0142,
      "step": 2535
    },
    {
      "epoch": 4.363010752688172,
      "grad_norm": 1.7386083509927788,
      "learning_rate": 0.00012517666199454244,
      "loss": 0.0083,
      "step": 2536
    },
    {
      "epoch": 4.364731182795699,
      "grad_norm": 0.9628424587321436,
      "learning_rate": 0.0001251227025282646,
      "loss": 0.0262,
      "step": 2537
    },
    {
      "epoch": 4.366451612903226,
      "grad_norm": 0.22171129836366907,
      "learning_rate": 0.00012506873525329555,
      "loss": 0.0009,
      "step": 2538
    },
    {
      "epoch": 4.368172043010753,
      "grad_norm": 1.4125306795857722,
      "learning_rate": 0.00012501476018640951,
      "loss": 0.0072,
      "step": 2539
    },
    {
      "epoch": 4.36989247311828,
      "grad_norm": 2.874589599828002,
      "learning_rate": 0.00012496077734438314,
      "loss": 0.0123,
      "step": 2540
    },
    {
      "epoch": 4.371612903225807,
      "grad_norm": 0.3188350023619934,
      "learning_rate": 0.00012490678674399543,
      "loss": 0.0019,
      "step": 2541
    },
    {
      "epoch": 4.373333333333333,
      "grad_norm": 0.37229937576137295,
      "learning_rate": 0.00012485278840202796,
      "loss": 0.0041,
      "step": 2542
    },
    {
      "epoch": 4.37505376344086,
      "grad_norm": 0.9566453487715669,
      "learning_rate": 0.00012479878233526454,
      "loss": 0.0041,
      "step": 2543
    },
    {
      "epoch": 4.376774193548387,
      "grad_norm": 0.13923621727081645,
      "learning_rate": 0.00012474476856049144,
      "loss": 0.0007,
      "step": 2544
    },
    {
      "epoch": 4.378494623655914,
      "grad_norm": 0.21721266047020177,
      "learning_rate": 0.0001246907470944974,
      "loss": 0.0006,
      "step": 2545
    },
    {
      "epoch": 4.380215053763441,
      "grad_norm": 1.4909783396922764,
      "learning_rate": 0.0001246367179540734,
      "loss": 0.0072,
      "step": 2546
    },
    {
      "epoch": 4.381935483870968,
      "grad_norm": 1.5068273131462955,
      "learning_rate": 0.00012458268115601298,
      "loss": 0.0207,
      "step": 2547
    },
    {
      "epoch": 4.383655913978495,
      "grad_norm": 0.8482509312300273,
      "learning_rate": 0.00012452863671711187,
      "loss": 0.0044,
      "step": 2548
    },
    {
      "epoch": 4.385376344086022,
      "grad_norm": 3.104486585069833,
      "learning_rate": 0.00012447458465416838,
      "loss": 0.01,
      "step": 2549
    },
    {
      "epoch": 4.387096774193548,
      "grad_norm": 0.5944970051659837,
      "learning_rate": 0.00012442052498398302,
      "loss": 0.003,
      "step": 2550
    },
    {
      "epoch": 4.388817204301075,
      "grad_norm": 1.0997627301291069,
      "learning_rate": 0.00012436645772335875,
      "loss": 0.008,
      "step": 2551
    },
    {
      "epoch": 4.390537634408602,
      "grad_norm": 1.6335387684643459,
      "learning_rate": 0.00012431238288910086,
      "loss": 0.0169,
      "step": 2552
    },
    {
      "epoch": 4.392258064516129,
      "grad_norm": 0.8474311747805031,
      "learning_rate": 0.00012425830049801704,
      "loss": 0.0077,
      "step": 2553
    },
    {
      "epoch": 4.3939784946236555,
      "grad_norm": 3.6650948291728795,
      "learning_rate": 0.00012420421056691725,
      "loss": 0.0478,
      "step": 2554
    },
    {
      "epoch": 4.395698924731183,
      "grad_norm": 1.3863111826671632,
      "learning_rate": 0.0001241501131126138,
      "loss": 0.0092,
      "step": 2555
    },
    {
      "epoch": 4.39741935483871,
      "grad_norm": 0.030316766102585053,
      "learning_rate": 0.0001240960081519215,
      "loss": 0.0002,
      "step": 2556
    },
    {
      "epoch": 4.399139784946237,
      "grad_norm": 0.8323603388837838,
      "learning_rate": 0.00012404189570165724,
      "loss": 0.0073,
      "step": 2557
    },
    {
      "epoch": 4.400860215053763,
      "grad_norm": 5.243012317258173,
      "learning_rate": 0.00012398777577864046,
      "loss": 0.0108,
      "step": 2558
    },
    {
      "epoch": 4.40258064516129,
      "grad_norm": 1.0744581893343632,
      "learning_rate": 0.00012393364839969275,
      "loss": 0.0145,
      "step": 2559
    },
    {
      "epoch": 4.404301075268817,
      "grad_norm": 0.13392664474614727,
      "learning_rate": 0.00012387951358163815,
      "loss": 0.0008,
      "step": 2560
    },
    {
      "epoch": 4.406021505376344,
      "grad_norm": 0.8665589899799502,
      "learning_rate": 0.0001238253713413029,
      "loss": 0.0034,
      "step": 2561
    },
    {
      "epoch": 4.407741935483871,
      "grad_norm": 2.996029816056972,
      "learning_rate": 0.00012377122169551568,
      "loss": 0.0226,
      "step": 2562
    },
    {
      "epoch": 4.409462365591398,
      "grad_norm": 0.2965289684796574,
      "learning_rate": 0.00012371706466110738,
      "loss": 0.0019,
      "step": 2563
    },
    {
      "epoch": 4.411182795698925,
      "grad_norm": 0.38818237832931995,
      "learning_rate": 0.00012366290025491117,
      "loss": 0.0015,
      "step": 2564
    },
    {
      "epoch": 4.412903225806452,
      "grad_norm": 0.0640666702738156,
      "learning_rate": 0.00012360872849376256,
      "loss": 0.0004,
      "step": 2565
    },
    {
      "epoch": 4.414623655913979,
      "grad_norm": 0.5614039766515815,
      "learning_rate": 0.0001235545493944993,
      "loss": 0.0051,
      "step": 2566
    },
    {
      "epoch": 4.416344086021505,
      "grad_norm": 1.4911810680271664,
      "learning_rate": 0.00012350036297396154,
      "loss": 0.022,
      "step": 2567
    },
    {
      "epoch": 4.418064516129032,
      "grad_norm": 0.5553722408822818,
      "learning_rate": 0.0001234461692489915,
      "loss": 0.0023,
      "step": 2568
    },
    {
      "epoch": 4.419784946236559,
      "grad_norm": 1.115278275860612,
      "learning_rate": 0.00012339196823643386,
      "loss": 0.0166,
      "step": 2569
    },
    {
      "epoch": 4.421505376344086,
      "grad_norm": 0.33411254981689287,
      "learning_rate": 0.0001233377599531355,
      "loss": 0.0019,
      "step": 2570
    },
    {
      "epoch": 4.423225806451613,
      "grad_norm": 0.09335533595913373,
      "learning_rate": 0.00012328354441594553,
      "loss": 0.0008,
      "step": 2571
    },
    {
      "epoch": 4.42494623655914,
      "grad_norm": 0.9701010640415599,
      "learning_rate": 0.00012322932164171533,
      "loss": 0.0104,
      "step": 2572
    },
    {
      "epoch": 4.426666666666667,
      "grad_norm": 0.5667306137714427,
      "learning_rate": 0.00012317509164729853,
      "loss": 0.0046,
      "step": 2573
    },
    {
      "epoch": 4.428387096774194,
      "grad_norm": 0.29089904292444685,
      "learning_rate": 0.00012312085444955104,
      "loss": 0.0018,
      "step": 2574
    },
    {
      "epoch": 4.43010752688172,
      "grad_norm": 1.6348379914512006,
      "learning_rate": 0.00012306661006533095,
      "loss": 0.016,
      "step": 2575
    },
    {
      "epoch": 4.431827956989247,
      "grad_norm": 1.6694095182257607,
      "learning_rate": 0.00012301235851149865,
      "loss": 0.015,
      "step": 2576
    },
    {
      "epoch": 4.433548387096774,
      "grad_norm": 1.8567229530611356,
      "learning_rate": 0.00012295809980491672,
      "loss": 0.0165,
      "step": 2577
    },
    {
      "epoch": 4.435268817204301,
      "grad_norm": 2.393535529075809,
      "learning_rate": 0.00012290383396244988,
      "loss": 0.0389,
      "step": 2578
    },
    {
      "epoch": 4.436989247311828,
      "grad_norm": 0.9053805650885745,
      "learning_rate": 0.00012284956100096526,
      "loss": 0.0046,
      "step": 2579
    },
    {
      "epoch": 4.438709677419355,
      "grad_norm": 1.2423850598294113,
      "learning_rate": 0.00012279528093733208,
      "loss": 0.0235,
      "step": 2580
    },
    {
      "epoch": 4.440430107526882,
      "grad_norm": 1.106603109493754,
      "learning_rate": 0.00012274099378842173,
      "loss": 0.0115,
      "step": 2581
    },
    {
      "epoch": 4.442150537634409,
      "grad_norm": 0.19487645533419234,
      "learning_rate": 0.00012268669957110788,
      "loss": 0.0012,
      "step": 2582
    },
    {
      "epoch": 4.443870967741935,
      "grad_norm": 1.1460611605226318,
      "learning_rate": 0.0001226323983022664,
      "loss": 0.0073,
      "step": 2583
    },
    {
      "epoch": 4.445591397849462,
      "grad_norm": 0.6664160459839569,
      "learning_rate": 0.0001225780899987753,
      "loss": 0.0048,
      "step": 2584
    },
    {
      "epoch": 4.447311827956989,
      "grad_norm": 0.6259282221574819,
      "learning_rate": 0.0001225237746775148,
      "loss": 0.0032,
      "step": 2585
    },
    {
      "epoch": 4.449032258064516,
      "grad_norm": 1.8526495617140903,
      "learning_rate": 0.0001224694523553673,
      "loss": 0.0263,
      "step": 2586
    },
    {
      "epoch": 4.450752688172043,
      "grad_norm": 0.372175722788994,
      "learning_rate": 0.0001224151230492174,
      "loss": 0.0031,
      "step": 2587
    },
    {
      "epoch": 4.45247311827957,
      "grad_norm": 0.7751007497932922,
      "learning_rate": 0.0001223607867759518,
      "loss": 0.0051,
      "step": 2588
    },
    {
      "epoch": 4.454193548387097,
      "grad_norm": 0.5769185837189853,
      "learning_rate": 0.00012230644355245947,
      "loss": 0.0063,
      "step": 2589
    },
    {
      "epoch": 4.455913978494624,
      "grad_norm": 0.6020093321355893,
      "learning_rate": 0.00012225209339563145,
      "loss": 0.0053,
      "step": 2590
    },
    {
      "epoch": 4.457634408602151,
      "grad_norm": 0.17872157223746363,
      "learning_rate": 0.000122197736322361,
      "loss": 0.0016,
      "step": 2591
    },
    {
      "epoch": 4.459354838709677,
      "grad_norm": 0.70398611259309,
      "learning_rate": 0.00012214337234954346,
      "loss": 0.0064,
      "step": 2592
    },
    {
      "epoch": 4.461075268817204,
      "grad_norm": 1.577388541359164,
      "learning_rate": 0.0001220890014940764,
      "loss": 0.0138,
      "step": 2593
    },
    {
      "epoch": 4.462795698924731,
      "grad_norm": 0.9401064949855896,
      "learning_rate": 0.00012203462377285947,
      "loss": 0.0151,
      "step": 2594
    },
    {
      "epoch": 4.464516129032258,
      "grad_norm": 1.194301846557672,
      "learning_rate": 0.00012198023920279442,
      "loss": 0.0094,
      "step": 2595
    },
    {
      "epoch": 4.466236559139785,
      "grad_norm": 1.0960566181719522,
      "learning_rate": 0.00012192584780078522,
      "loss": 0.021,
      "step": 2596
    },
    {
      "epoch": 4.467956989247312,
      "grad_norm": 0.7090885804565031,
      "learning_rate": 0.00012187144958373793,
      "loss": 0.0138,
      "step": 2597
    },
    {
      "epoch": 4.469677419354839,
      "grad_norm": 0.43340219925466805,
      "learning_rate": 0.00012181704456856073,
      "loss": 0.0034,
      "step": 2598
    },
    {
      "epoch": 4.471397849462366,
      "grad_norm": 2.0267005194833003,
      "learning_rate": 0.00012176263277216384,
      "loss": 0.0075,
      "step": 2599
    },
    {
      "epoch": 4.473118279569892,
      "grad_norm": 0.9761366710812199,
      "learning_rate": 0.00012170821421145965,
      "loss": 0.0087,
      "step": 2600
    },
    {
      "epoch": 4.474838709677419,
      "grad_norm": 0.9233077195447786,
      "learning_rate": 0.00012165378890336277,
      "loss": 0.0065,
      "step": 2601
    },
    {
      "epoch": 4.476559139784946,
      "grad_norm": 0.9950349231194011,
      "learning_rate": 0.00012159935686478964,
      "loss": 0.014,
      "step": 2602
    },
    {
      "epoch": 4.478279569892473,
      "grad_norm": 1.1612701211867642,
      "learning_rate": 0.00012154491811265902,
      "loss": 0.0164,
      "step": 2603
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.33265762585189784,
      "learning_rate": 0.00012149047266389166,
      "loss": 0.0006,
      "step": 2604
    },
    {
      "epoch": 4.481720430107527,
      "grad_norm": 0.42360093637106466,
      "learning_rate": 0.00012143602053541042,
      "loss": 0.004,
      "step": 2605
    },
    {
      "epoch": 4.483440860215054,
      "grad_norm": 1.36959333139166,
      "learning_rate": 0.0001213815617441402,
      "loss": 0.0095,
      "step": 2606
    },
    {
      "epoch": 4.485161290322581,
      "grad_norm": 0.38593008044032967,
      "learning_rate": 0.00012132709630700801,
      "loss": 0.0025,
      "step": 2607
    },
    {
      "epoch": 4.486881720430108,
      "grad_norm": 0.17856746518367336,
      "learning_rate": 0.00012127262424094294,
      "loss": 0.0015,
      "step": 2608
    },
    {
      "epoch": 4.488602150537634,
      "grad_norm": 1.7225447793796669,
      "learning_rate": 0.00012121814556287603,
      "loss": 0.0313,
      "step": 2609
    },
    {
      "epoch": 4.490322580645161,
      "grad_norm": 0.20659122722236134,
      "learning_rate": 0.00012116366028974056,
      "loss": 0.0021,
      "step": 2610
    },
    {
      "epoch": 4.492043010752688,
      "grad_norm": 0.13228513444376414,
      "learning_rate": 0.00012110916843847172,
      "loss": 0.001,
      "step": 2611
    },
    {
      "epoch": 4.493763440860215,
      "grad_norm": 0.9830365663127333,
      "learning_rate": 0.00012105467002600672,
      "loss": 0.0064,
      "step": 2612
    },
    {
      "epoch": 4.495483870967742,
      "grad_norm": 1.3219576532123682,
      "learning_rate": 0.00012100016506928493,
      "loss": 0.0323,
      "step": 2613
    },
    {
      "epoch": 4.497204301075269,
      "grad_norm": 0.05916306364477994,
      "learning_rate": 0.00012094565358524769,
      "loss": 0.0006,
      "step": 2614
    },
    {
      "epoch": 4.498924731182796,
      "grad_norm": 1.6024790935710904,
      "learning_rate": 0.00012089113559083842,
      "loss": 0.0366,
      "step": 2615
    },
    {
      "epoch": 4.500645161290323,
      "grad_norm": 1.1798399598842937,
      "learning_rate": 0.00012083661110300244,
      "loss": 0.0049,
      "step": 2616
    },
    {
      "epoch": 4.502365591397849,
      "grad_norm": 0.4028486210713065,
      "learning_rate": 0.00012078208013868719,
      "loss": 0.0051,
      "step": 2617
    },
    {
      "epoch": 4.504086021505376,
      "grad_norm": 1.2899508059218343,
      "learning_rate": 0.00012072754271484207,
      "loss": 0.0174,
      "step": 2618
    },
    {
      "epoch": 4.505806451612903,
      "grad_norm": 0.22339849294239308,
      "learning_rate": 0.00012067299884841861,
      "loss": 0.0019,
      "step": 2619
    },
    {
      "epoch": 4.50752688172043,
      "grad_norm": 1.2325682832797176,
      "learning_rate": 0.00012061844855637015,
      "loss": 0.014,
      "step": 2620
    },
    {
      "epoch": 4.5092473118279575,
      "grad_norm": 0.12091740464125601,
      "learning_rate": 0.00012056389185565217,
      "loss": 0.0014,
      "step": 2621
    },
    {
      "epoch": 4.510967741935484,
      "grad_norm": 0.2291741638164556,
      "learning_rate": 0.00012050932876322211,
      "loss": 0.002,
      "step": 2622
    },
    {
      "epoch": 4.512688172043011,
      "grad_norm": 0.13288858890451616,
      "learning_rate": 0.00012045475929603936,
      "loss": 0.0015,
      "step": 2623
    },
    {
      "epoch": 4.514408602150538,
      "grad_norm": 1.7177922116948086,
      "learning_rate": 0.00012040018347106533,
      "loss": 0.0123,
      "step": 2624
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.22657007079569186,
      "learning_rate": 0.0001203456013052634,
      "loss": 0.0019,
      "step": 2625
    },
    {
      "epoch": 4.517849462365591,
      "grad_norm": 0.9349343563140154,
      "learning_rate": 0.00012029101281559889,
      "loss": 0.0057,
      "step": 2626
    },
    {
      "epoch": 4.519569892473118,
      "grad_norm": 0.24598810678563382,
      "learning_rate": 0.0001202364180190391,
      "loss": 0.0018,
      "step": 2627
    },
    {
      "epoch": 4.521290322580645,
      "grad_norm": 0.3682912107193176,
      "learning_rate": 0.00012018181693255335,
      "loss": 0.0039,
      "step": 2628
    },
    {
      "epoch": 4.523010752688172,
      "grad_norm": 0.7317549426454761,
      "learning_rate": 0.00012012720957311283,
      "loss": 0.0062,
      "step": 2629
    },
    {
      "epoch": 4.524731182795699,
      "grad_norm": 0.43804226090896536,
      "learning_rate": 0.00012007259595769072,
      "loss": 0.0026,
      "step": 2630
    },
    {
      "epoch": 4.526451612903226,
      "grad_norm": 0.26289212450733357,
      "learning_rate": 0.00012001797610326211,
      "loss": 0.0027,
      "step": 2631
    },
    {
      "epoch": 4.528172043010753,
      "grad_norm": 0.6605534542055151,
      "learning_rate": 0.00011996335002680412,
      "loss": 0.005,
      "step": 2632
    },
    {
      "epoch": 4.52989247311828,
      "grad_norm": 0.819389555328351,
      "learning_rate": 0.00011990871774529571,
      "loss": 0.0069,
      "step": 2633
    },
    {
      "epoch": 4.531612903225806,
      "grad_norm": 0.3969231661040933,
      "learning_rate": 0.0001198540792757178,
      "loss": 0.004,
      "step": 2634
    },
    {
      "epoch": 4.533333333333333,
      "grad_norm": 0.6941266780207456,
      "learning_rate": 0.00011979943463505319,
      "loss": 0.007,
      "step": 2635
    },
    {
      "epoch": 4.53505376344086,
      "grad_norm": 2.1117349751944734,
      "learning_rate": 0.00011974478384028672,
      "loss": 0.0159,
      "step": 2636
    },
    {
      "epoch": 4.536774193548387,
      "grad_norm": 2.300340794508639,
      "learning_rate": 0.00011969012690840502,
      "loss": 0.0268,
      "step": 2637
    },
    {
      "epoch": 4.538494623655914,
      "grad_norm": 0.2111136537254528,
      "learning_rate": 0.0001196354638563967,
      "loss": 0.0013,
      "step": 2638
    },
    {
      "epoch": 4.540215053763441,
      "grad_norm": 0.02456071729491133,
      "learning_rate": 0.00011958079470125224,
      "loss": 0.0002,
      "step": 2639
    },
    {
      "epoch": 4.541935483870968,
      "grad_norm": 0.34186897874516226,
      "learning_rate": 0.00011952611945996394,
      "loss": 0.0019,
      "step": 2640
    },
    {
      "epoch": 4.543655913978495,
      "grad_norm": 2.0914691216646966,
      "learning_rate": 0.00011947143814952619,
      "loss": 0.0278,
      "step": 2641
    },
    {
      "epoch": 4.545376344086021,
      "grad_norm": 0.2547641847189499,
      "learning_rate": 0.0001194167507869351,
      "loss": 0.0019,
      "step": 2642
    },
    {
      "epoch": 4.547096774193548,
      "grad_norm": 0.09038610492743679,
      "learning_rate": 0.00011936205738918871,
      "loss": 0.0008,
      "step": 2643
    },
    {
      "epoch": 4.548817204301075,
      "grad_norm": 0.52818550821903,
      "learning_rate": 0.00011930735797328693,
      "loss": 0.0034,
      "step": 2644
    },
    {
      "epoch": 4.550537634408602,
      "grad_norm": 1.4572727285242706,
      "learning_rate": 0.00011925265255623155,
      "loss": 0.046,
      "step": 2645
    },
    {
      "epoch": 4.5522580645161295,
      "grad_norm": 4.072214624608653,
      "learning_rate": 0.00011919794115502627,
      "loss": 0.0125,
      "step": 2646
    },
    {
      "epoch": 4.553978494623656,
      "grad_norm": 0.5364484543203196,
      "learning_rate": 0.00011914322378667652,
      "loss": 0.0022,
      "step": 2647
    },
    {
      "epoch": 4.555698924731183,
      "grad_norm": 0.6294431328813888,
      "learning_rate": 0.00011908850046818974,
      "loss": 0.0033,
      "step": 2648
    },
    {
      "epoch": 4.55741935483871,
      "grad_norm": 2.4840053577572916,
      "learning_rate": 0.00011903377121657511,
      "loss": 0.0363,
      "step": 2649
    },
    {
      "epoch": 4.559139784946236,
      "grad_norm": 0.10304278236346723,
      "learning_rate": 0.00011897903604884368,
      "loss": 0.0006,
      "step": 2650
    },
    {
      "epoch": 4.560860215053763,
      "grad_norm": 0.9017882699155195,
      "learning_rate": 0.00011892429498200839,
      "loss": 0.0086,
      "step": 2651
    },
    {
      "epoch": 4.56258064516129,
      "grad_norm": 0.09976519618196211,
      "learning_rate": 0.00011886954803308395,
      "loss": 0.0005,
      "step": 2652
    },
    {
      "epoch": 4.564301075268817,
      "grad_norm": 0.24148343875411732,
      "learning_rate": 0.00011881479521908694,
      "loss": 0.0018,
      "step": 2653
    },
    {
      "epoch": 4.566021505376344,
      "grad_norm": 1.076338620467621,
      "learning_rate": 0.00011876003655703567,
      "loss": 0.0089,
      "step": 2654
    },
    {
      "epoch": 4.567741935483871,
      "grad_norm": 1.2354005421621106,
      "learning_rate": 0.00011870527206395044,
      "loss": 0.0067,
      "step": 2655
    },
    {
      "epoch": 4.569462365591398,
      "grad_norm": 1.182315929447217,
      "learning_rate": 0.00011865050175685324,
      "loss": 0.0142,
      "step": 2656
    },
    {
      "epoch": 4.571182795698925,
      "grad_norm": 0.41289349410062526,
      "learning_rate": 0.00011859572565276784,
      "loss": 0.0023,
      "step": 2657
    },
    {
      "epoch": 4.572903225806452,
      "grad_norm": 0.016708759256742985,
      "learning_rate": 0.00011854094376871991,
      "loss": 0.0001,
      "step": 2658
    },
    {
      "epoch": 4.574623655913978,
      "grad_norm": 0.07302357165890118,
      "learning_rate": 0.00011848615612173688,
      "loss": 0.0008,
      "step": 2659
    },
    {
      "epoch": 4.576344086021505,
      "grad_norm": 0.7232435764529307,
      "learning_rate": 0.00011843136272884794,
      "loss": 0.0131,
      "step": 2660
    },
    {
      "epoch": 4.578064516129032,
      "grad_norm": 0.3211671735839678,
      "learning_rate": 0.00011837656360708406,
      "loss": 0.0039,
      "step": 2661
    },
    {
      "epoch": 4.579784946236559,
      "grad_norm": 0.8566804439491793,
      "learning_rate": 0.00011832175877347808,
      "loss": 0.005,
      "step": 2662
    },
    {
      "epoch": 4.5815053763440865,
      "grad_norm": 0.14671158092975006,
      "learning_rate": 0.00011826694824506452,
      "loss": 0.0012,
      "step": 2663
    },
    {
      "epoch": 4.583225806451613,
      "grad_norm": 0.8779938467138161,
      "learning_rate": 0.00011821213203887971,
      "loss": 0.007,
      "step": 2664
    },
    {
      "epoch": 4.58494623655914,
      "grad_norm": 0.7173526274492471,
      "learning_rate": 0.00011815731017196172,
      "loss": 0.0095,
      "step": 2665
    },
    {
      "epoch": 4.586666666666667,
      "grad_norm": 0.24747031326856983,
      "learning_rate": 0.00011810248266135042,
      "loss": 0.0012,
      "step": 2666
    },
    {
      "epoch": 4.588387096774193,
      "grad_norm": 0.7153041475897844,
      "learning_rate": 0.0001180476495240874,
      "loss": 0.0077,
      "step": 2667
    },
    {
      "epoch": 4.59010752688172,
      "grad_norm": 0.1821530942004695,
      "learning_rate": 0.000117992810777216,
      "loss": 0.0009,
      "step": 2668
    },
    {
      "epoch": 4.591827956989247,
      "grad_norm": 0.2842195320384708,
      "learning_rate": 0.00011793796643778137,
      "loss": 0.0013,
      "step": 2669
    },
    {
      "epoch": 4.593548387096774,
      "grad_norm": 0.039817648743603586,
      "learning_rate": 0.00011788311652283028,
      "loss": 0.0003,
      "step": 2670
    },
    {
      "epoch": 4.5952688172043015,
      "grad_norm": 0.41011928826037547,
      "learning_rate": 0.00011782826104941133,
      "loss": 0.0033,
      "step": 2671
    },
    {
      "epoch": 4.596989247311828,
      "grad_norm": 0.615119458826143,
      "learning_rate": 0.00011777340003457476,
      "loss": 0.0063,
      "step": 2672
    },
    {
      "epoch": 4.598709677419355,
      "grad_norm": 1.9864739525014798,
      "learning_rate": 0.00011771853349537268,
      "loss": 0.0242,
      "step": 2673
    },
    {
      "epoch": 4.600430107526882,
      "grad_norm": 0.04100508664398735,
      "learning_rate": 0.00011766366144885877,
      "loss": 0.0002,
      "step": 2674
    },
    {
      "epoch": 4.602150537634409,
      "grad_norm": 0.9419177885610337,
      "learning_rate": 0.00011760878391208844,
      "loss": 0.0117,
      "step": 2675
    },
    {
      "epoch": 4.603870967741935,
      "grad_norm": 0.009349619645087001,
      "learning_rate": 0.00011755390090211889,
      "loss": 0.0001,
      "step": 2676
    },
    {
      "epoch": 4.605591397849462,
      "grad_norm": 3.262529339589515,
      "learning_rate": 0.00011749901243600896,
      "loss": 0.0258,
      "step": 2677
    },
    {
      "epoch": 4.607311827956989,
      "grad_norm": 0.26880414231510774,
      "learning_rate": 0.00011744411853081923,
      "loss": 0.0015,
      "step": 2678
    },
    {
      "epoch": 4.609032258064516,
      "grad_norm": 0.2149243561463865,
      "learning_rate": 0.00011738921920361186,
      "loss": 0.001,
      "step": 2679
    },
    {
      "epoch": 4.610752688172043,
      "grad_norm": 0.16396970373724948,
      "learning_rate": 0.00011733431447145087,
      "loss": 0.0008,
      "step": 2680
    },
    {
      "epoch": 4.61247311827957,
      "grad_norm": 2.9983984577767173,
      "learning_rate": 0.00011727940435140177,
      "loss": 0.0511,
      "step": 2681
    },
    {
      "epoch": 4.614193548387097,
      "grad_norm": 1.6985922044559634,
      "learning_rate": 0.0001172244888605319,
      "loss": 0.0379,
      "step": 2682
    },
    {
      "epoch": 4.615913978494624,
      "grad_norm": 1.2224438226861098,
      "learning_rate": 0.00011716956801591019,
      "loss": 0.0111,
      "step": 2683
    },
    {
      "epoch": 4.61763440860215,
      "grad_norm": 0.06561296666126275,
      "learning_rate": 0.0001171146418346073,
      "loss": 0.0005,
      "step": 2684
    },
    {
      "epoch": 4.619354838709677,
      "grad_norm": 0.22582353247436251,
      "learning_rate": 0.00011705971033369538,
      "loss": 0.0015,
      "step": 2685
    },
    {
      "epoch": 4.621075268817204,
      "grad_norm": 0.7628691729493997,
      "learning_rate": 0.00011700477353024847,
      "loss": 0.0051,
      "step": 2686
    },
    {
      "epoch": 4.622795698924731,
      "grad_norm": 0.5523092495841347,
      "learning_rate": 0.00011694983144134215,
      "loss": 0.0055,
      "step": 2687
    },
    {
      "epoch": 4.6245161290322585,
      "grad_norm": 0.5560354400727543,
      "learning_rate": 0.00011689488408405353,
      "loss": 0.0353,
      "step": 2688
    },
    {
      "epoch": 4.626236559139785,
      "grad_norm": 1.2326556646343985,
      "learning_rate": 0.00011683993147546155,
      "loss": 0.0161,
      "step": 2689
    },
    {
      "epoch": 4.627956989247312,
      "grad_norm": 0.13126109957302534,
      "learning_rate": 0.00011678497363264665,
      "loss": 0.0007,
      "step": 2690
    },
    {
      "epoch": 4.629677419354839,
      "grad_norm": 0.9426108140855786,
      "learning_rate": 0.00011673001057269097,
      "loss": 0.0064,
      "step": 2691
    },
    {
      "epoch": 4.631397849462365,
      "grad_norm": 0.9071402357183072,
      "learning_rate": 0.00011667504231267823,
      "loss": 0.0118,
      "step": 2692
    },
    {
      "epoch": 4.633118279569892,
      "grad_norm": 0.14020019926772573,
      "learning_rate": 0.0001166200688696938,
      "loss": 0.0008,
      "step": 2693
    },
    {
      "epoch": 4.634838709677419,
      "grad_norm": 0.5141342256119816,
      "learning_rate": 0.0001165650902608246,
      "loss": 0.0131,
      "step": 2694
    },
    {
      "epoch": 4.636559139784946,
      "grad_norm": 2.1699028470394843,
      "learning_rate": 0.00011651010650315923,
      "loss": 0.0193,
      "step": 2695
    },
    {
      "epoch": 4.6382795698924735,
      "grad_norm": 0.45577667618858964,
      "learning_rate": 0.00011645511761378785,
      "loss": 0.0028,
      "step": 2696
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.09047522596206091,
      "learning_rate": 0.00011640012360980224,
      "loss": 0.0007,
      "step": 2697
    },
    {
      "epoch": 4.641720430107527,
      "grad_norm": 0.8611612642360518,
      "learning_rate": 0.00011634512450829573,
      "loss": 0.0038,
      "step": 2698
    },
    {
      "epoch": 4.643440860215054,
      "grad_norm": 0.7968358770727887,
      "learning_rate": 0.00011629012032636324,
      "loss": 0.0062,
      "step": 2699
    },
    {
      "epoch": 4.645161290322581,
      "grad_norm": 0.8294762529345509,
      "learning_rate": 0.0001162351110811013,
      "loss": 0.0144,
      "step": 2700
    },
    {
      "epoch": 4.646881720430107,
      "grad_norm": 0.5429077639738549,
      "learning_rate": 0.00011618009678960804,
      "loss": 0.0051,
      "step": 2701
    },
    {
      "epoch": 4.648602150537634,
      "grad_norm": 0.36732588630557655,
      "learning_rate": 0.00011612507746898307,
      "loss": 0.0028,
      "step": 2702
    },
    {
      "epoch": 4.650322580645161,
      "grad_norm": 1.5242828937382744,
      "learning_rate": 0.00011607005313632759,
      "loss": 0.0207,
      "step": 2703
    },
    {
      "epoch": 4.6520430107526884,
      "grad_norm": 0.11725756235623097,
      "learning_rate": 0.00011601502380874445,
      "loss": 0.0008,
      "step": 2704
    },
    {
      "epoch": 4.6537634408602155,
      "grad_norm": 0.12037873886788218,
      "learning_rate": 0.00011595998950333793,
      "loss": 0.0007,
      "step": 2705
    },
    {
      "epoch": 4.655483870967742,
      "grad_norm": 1.0561921278275705,
      "learning_rate": 0.00011590495023721393,
      "loss": 0.0093,
      "step": 2706
    },
    {
      "epoch": 4.657204301075269,
      "grad_norm": 1.4912910056125213,
      "learning_rate": 0.00011584990602747984,
      "loss": 0.013,
      "step": 2707
    },
    {
      "epoch": 4.658924731182796,
      "grad_norm": 0.6610806031600273,
      "learning_rate": 0.00011579485689124467,
      "loss": 0.0024,
      "step": 2708
    },
    {
      "epoch": 4.660645161290322,
      "grad_norm": 0.6564281789213688,
      "learning_rate": 0.00011573980284561885,
      "loss": 0.0036,
      "step": 2709
    },
    {
      "epoch": 4.662365591397849,
      "grad_norm": 0.7953189151467042,
      "learning_rate": 0.00011568474390771444,
      "loss": 0.0041,
      "step": 2710
    },
    {
      "epoch": 4.664086021505376,
      "grad_norm": 0.8127289444477128,
      "learning_rate": 0.00011562968009464496,
      "loss": 0.0131,
      "step": 2711
    },
    {
      "epoch": 4.665806451612903,
      "grad_norm": 0.9267662573809491,
      "learning_rate": 0.00011557461142352543,
      "loss": 0.0123,
      "step": 2712
    },
    {
      "epoch": 4.6675268817204305,
      "grad_norm": 2.8597748629264497,
      "learning_rate": 0.00011551953791147245,
      "loss": 0.0142,
      "step": 2713
    },
    {
      "epoch": 4.669247311827957,
      "grad_norm": 0.12666187043410218,
      "learning_rate": 0.00011546445957560407,
      "loss": 0.0013,
      "step": 2714
    },
    {
      "epoch": 4.670967741935484,
      "grad_norm": 1.2281842929825557,
      "learning_rate": 0.00011540937643303988,
      "loss": 0.0155,
      "step": 2715
    },
    {
      "epoch": 4.672688172043011,
      "grad_norm": 1.3265299016765097,
      "learning_rate": 0.00011535428850090091,
      "loss": 0.0158,
      "step": 2716
    },
    {
      "epoch": 4.674408602150538,
      "grad_norm": 0.47517422844476964,
      "learning_rate": 0.00011529919579630966,
      "loss": 0.0037,
      "step": 2717
    },
    {
      "epoch": 4.676129032258064,
      "grad_norm": 0.21557777519624677,
      "learning_rate": 0.00011524409833639027,
      "loss": 0.0012,
      "step": 2718
    },
    {
      "epoch": 4.677849462365591,
      "grad_norm": 0.917997639296477,
      "learning_rate": 0.00011518899613826817,
      "loss": 0.0147,
      "step": 2719
    },
    {
      "epoch": 4.679569892473118,
      "grad_norm": 0.1624899337275909,
      "learning_rate": 0.00011513388921907036,
      "loss": 0.0007,
      "step": 2720
    },
    {
      "epoch": 4.6812903225806455,
      "grad_norm": 0.9615193338259423,
      "learning_rate": 0.00011507877759592527,
      "loss": 0.0176,
      "step": 2721
    },
    {
      "epoch": 4.683010752688172,
      "grad_norm": 1.2396616842257275,
      "learning_rate": 0.00011502366128596285,
      "loss": 0.0219,
      "step": 2722
    },
    {
      "epoch": 4.684731182795699,
      "grad_norm": 1.2606705586892255,
      "learning_rate": 0.00011496854030631443,
      "loss": 0.0123,
      "step": 2723
    },
    {
      "epoch": 4.686451612903226,
      "grad_norm": 2.060660483917261,
      "learning_rate": 0.00011491341467411285,
      "loss": 0.0155,
      "step": 2724
    },
    {
      "epoch": 4.688172043010753,
      "grad_norm": 0.14715880659210703,
      "learning_rate": 0.0001148582844064924,
      "loss": 0.0015,
      "step": 2725
    },
    {
      "epoch": 4.689892473118279,
      "grad_norm": 0.22123212677824355,
      "learning_rate": 0.0001148031495205887,
      "loss": 0.0019,
      "step": 2726
    },
    {
      "epoch": 4.691612903225806,
      "grad_norm": 0.9093710569045756,
      "learning_rate": 0.00011474801003353899,
      "loss": 0.022,
      "step": 2727
    },
    {
      "epoch": 4.693333333333333,
      "grad_norm": 0.9153731082188987,
      "learning_rate": 0.00011469286596248181,
      "loss": 0.0079,
      "step": 2728
    },
    {
      "epoch": 4.6950537634408605,
      "grad_norm": 2.368420119591825,
      "learning_rate": 0.00011463771732455713,
      "loss": 0.0168,
      "step": 2729
    },
    {
      "epoch": 4.6967741935483875,
      "grad_norm": 0.41942158242567995,
      "learning_rate": 0.00011458256413690633,
      "loss": 0.003,
      "step": 2730
    },
    {
      "epoch": 4.698494623655914,
      "grad_norm": 1.0254127333373069,
      "learning_rate": 0.00011452740641667234,
      "loss": 0.012,
      "step": 2731
    },
    {
      "epoch": 4.700215053763441,
      "grad_norm": 0.5061036757893036,
      "learning_rate": 0.00011447224418099935,
      "loss": 0.0039,
      "step": 2732
    },
    {
      "epoch": 4.701935483870968,
      "grad_norm": 0.0248968600191747,
      "learning_rate": 0.00011441707744703301,
      "loss": 0.0003,
      "step": 2733
    },
    {
      "epoch": 4.703655913978494,
      "grad_norm": 0.05587981666376597,
      "learning_rate": 0.00011436190623192034,
      "loss": 0.0006,
      "step": 2734
    },
    {
      "epoch": 4.705376344086021,
      "grad_norm": 1.731441236706932,
      "learning_rate": 0.00011430673055280976,
      "loss": 0.0106,
      "step": 2735
    },
    {
      "epoch": 4.707096774193548,
      "grad_norm": 0.2057457515029117,
      "learning_rate": 0.00011425155042685114,
      "loss": 0.0022,
      "step": 2736
    },
    {
      "epoch": 4.708817204301075,
      "grad_norm": 0.21169810891498003,
      "learning_rate": 0.00011419636587119562,
      "loss": 0.0015,
      "step": 2737
    },
    {
      "epoch": 4.7105376344086025,
      "grad_norm": 0.49726854190496195,
      "learning_rate": 0.00011414117690299586,
      "loss": 0.0046,
      "step": 2738
    },
    {
      "epoch": 4.712258064516129,
      "grad_norm": 0.593154574805465,
      "learning_rate": 0.00011408598353940574,
      "loss": 0.005,
      "step": 2739
    },
    {
      "epoch": 4.713978494623656,
      "grad_norm": 0.886758972830293,
      "learning_rate": 0.00011403078579758061,
      "loss": 0.0093,
      "step": 2740
    },
    {
      "epoch": 4.715698924731183,
      "grad_norm": 1.8918687119180098,
      "learning_rate": 0.00011397558369467715,
      "loss": 0.0201,
      "step": 2741
    },
    {
      "epoch": 4.71741935483871,
      "grad_norm": 0.4743591973506058,
      "learning_rate": 0.0001139203772478534,
      "loss": 0.0029,
      "step": 2742
    },
    {
      "epoch": 4.719139784946236,
      "grad_norm": 0.7677271001793315,
      "learning_rate": 0.00011386516647426873,
      "loss": 0.0066,
      "step": 2743
    },
    {
      "epoch": 4.720860215053763,
      "grad_norm": 0.7126075349375368,
      "learning_rate": 0.00011380995139108384,
      "loss": 0.0056,
      "step": 2744
    },
    {
      "epoch": 4.72258064516129,
      "grad_norm": 1.04419038787486,
      "learning_rate": 0.00011375473201546086,
      "loss": 0.0242,
      "step": 2745
    },
    {
      "epoch": 4.7243010752688175,
      "grad_norm": 0.7011085113359629,
      "learning_rate": 0.00011369950836456313,
      "loss": 0.005,
      "step": 2746
    },
    {
      "epoch": 4.726021505376345,
      "grad_norm": 0.4475351110304355,
      "learning_rate": 0.00011364428045555544,
      "loss": 0.0044,
      "step": 2747
    },
    {
      "epoch": 4.727741935483871,
      "grad_norm": 0.08643378404706013,
      "learning_rate": 0.00011358904830560378,
      "loss": 0.0005,
      "step": 2748
    },
    {
      "epoch": 4.729462365591398,
      "grad_norm": 1.1187111189201056,
      "learning_rate": 0.0001135338119318756,
      "loss": 0.0008,
      "step": 2749
    },
    {
      "epoch": 4.731182795698925,
      "grad_norm": 0.5810394462288561,
      "learning_rate": 0.00011347857135153953,
      "loss": 0.005,
      "step": 2750
    },
    {
      "epoch": 4.732903225806451,
      "grad_norm": 0.27319313682713753,
      "learning_rate": 0.00011342332658176555,
      "loss": 0.0016,
      "step": 2751
    },
    {
      "epoch": 4.734623655913978,
      "grad_norm": 0.532631088994766,
      "learning_rate": 0.00011336807763972501,
      "loss": 0.0023,
      "step": 2752
    },
    {
      "epoch": 4.736344086021505,
      "grad_norm": 0.6201918490239411,
      "learning_rate": 0.00011331282454259047,
      "loss": 0.0054,
      "step": 2753
    },
    {
      "epoch": 4.7380645161290325,
      "grad_norm": 0.025400830576361704,
      "learning_rate": 0.00011325756730753583,
      "loss": 0.0003,
      "step": 2754
    },
    {
      "epoch": 4.7397849462365595,
      "grad_norm": 2.3683255712004407,
      "learning_rate": 0.00011320230595173624,
      "loss": 0.0187,
      "step": 2755
    },
    {
      "epoch": 4.741505376344086,
      "grad_norm": 0.13777581482446158,
      "learning_rate": 0.00011314704049236817,
      "loss": 0.0014,
      "step": 2756
    },
    {
      "epoch": 4.743225806451613,
      "grad_norm": 0.2520127387794432,
      "learning_rate": 0.00011309177094660932,
      "loss": 0.0013,
      "step": 2757
    },
    {
      "epoch": 4.74494623655914,
      "grad_norm": 0.5957759629691519,
      "learning_rate": 0.0001130364973316387,
      "loss": 0.0022,
      "step": 2758
    },
    {
      "epoch": 4.746666666666667,
      "grad_norm": 0.09083623869923925,
      "learning_rate": 0.00011298121966463661,
      "loss": 0.0007,
      "step": 2759
    },
    {
      "epoch": 4.748387096774193,
      "grad_norm": 1.1516277169489149,
      "learning_rate": 0.00011292593796278452,
      "loss": 0.0086,
      "step": 2760
    },
    {
      "epoch": 4.75010752688172,
      "grad_norm": 1.0417984153598916,
      "learning_rate": 0.00011287065224326521,
      "loss": 0.0052,
      "step": 2761
    },
    {
      "epoch": 4.751827956989247,
      "grad_norm": 0.12311168778933675,
      "learning_rate": 0.00011281536252326272,
      "loss": 0.0008,
      "step": 2762
    },
    {
      "epoch": 4.7535483870967745,
      "grad_norm": 0.3043362105841226,
      "learning_rate": 0.0001127600688199623,
      "loss": 0.0027,
      "step": 2763
    },
    {
      "epoch": 4.755268817204301,
      "grad_norm": 0.06944116411410572,
      "learning_rate": 0.00011270477115055048,
      "loss": 0.0004,
      "step": 2764
    },
    {
      "epoch": 4.756989247311828,
      "grad_norm": 1.1716417091504403,
      "learning_rate": 0.00011264946953221496,
      "loss": 0.0063,
      "step": 2765
    },
    {
      "epoch": 4.758709677419355,
      "grad_norm": 1.88950910378675,
      "learning_rate": 0.00011259416398214476,
      "loss": 0.0232,
      "step": 2766
    },
    {
      "epoch": 4.760430107526882,
      "grad_norm": 0.3558262374200105,
      "learning_rate": 0.00011253885451752999,
      "loss": 0.003,
      "step": 2767
    },
    {
      "epoch": 4.762150537634408,
      "grad_norm": 0.04575857706701867,
      "learning_rate": 0.00011248354115556215,
      "loss": 0.0002,
      "step": 2768
    },
    {
      "epoch": 4.763870967741935,
      "grad_norm": 1.182054625090524,
      "learning_rate": 0.00011242822391343378,
      "loss": 0.0368,
      "step": 2769
    },
    {
      "epoch": 4.765591397849462,
      "grad_norm": 0.17784645998268525,
      "learning_rate": 0.00011237290280833875,
      "loss": 0.001,
      "step": 2770
    },
    {
      "epoch": 4.7673118279569895,
      "grad_norm": 2.1250648108037926,
      "learning_rate": 0.00011231757785747201,
      "loss": 0.0125,
      "step": 2771
    },
    {
      "epoch": 4.769032258064517,
      "grad_norm": 1.822243898087937,
      "learning_rate": 0.00011226224907802985,
      "loss": 0.0445,
      "step": 2772
    },
    {
      "epoch": 4.770752688172043,
      "grad_norm": 0.5414587888889353,
      "learning_rate": 0.0001122069164872097,
      "loss": 0.0012,
      "step": 2773
    },
    {
      "epoch": 4.77247311827957,
      "grad_norm": 0.8879870055623788,
      "learning_rate": 0.00011215158010221005,
      "loss": 0.0019,
      "step": 2774
    },
    {
      "epoch": 4.774193548387097,
      "grad_norm": 0.06291080689045586,
      "learning_rate": 0.00011209623994023073,
      "loss": 0.0004,
      "step": 2775
    },
    {
      "epoch": 4.775913978494623,
      "grad_norm": 0.07214953366339205,
      "learning_rate": 0.00011204089601847272,
      "loss": 0.0005,
      "step": 2776
    },
    {
      "epoch": 4.77763440860215,
      "grad_norm": 1.5991329401416405,
      "learning_rate": 0.00011198554835413806,
      "loss": 0.0128,
      "step": 2777
    },
    {
      "epoch": 4.779354838709677,
      "grad_norm": 1.4722155343524166,
      "learning_rate": 0.00011193019696443008,
      "loss": 0.008,
      "step": 2778
    },
    {
      "epoch": 4.7810752688172045,
      "grad_norm": 1.32868222413615,
      "learning_rate": 0.00011187484186655319,
      "loss": 0.0117,
      "step": 2779
    },
    {
      "epoch": 4.7827956989247316,
      "grad_norm": 0.8050212671407594,
      "learning_rate": 0.00011181948307771301,
      "loss": 0.0067,
      "step": 2780
    },
    {
      "epoch": 4.784516129032258,
      "grad_norm": 0.6692580764025822,
      "learning_rate": 0.00011176412061511622,
      "loss": 0.0052,
      "step": 2781
    },
    {
      "epoch": 4.786236559139785,
      "grad_norm": 0.07261392334046621,
      "learning_rate": 0.00011170875449597078,
      "loss": 0.0005,
      "step": 2782
    },
    {
      "epoch": 4.787956989247312,
      "grad_norm": 1.168470423182673,
      "learning_rate": 0.00011165338473748561,
      "loss": 0.0232,
      "step": 2783
    },
    {
      "epoch": 4.789677419354839,
      "grad_norm": 1.7676686438749203,
      "learning_rate": 0.00011159801135687091,
      "loss": 0.0071,
      "step": 2784
    },
    {
      "epoch": 4.791397849462365,
      "grad_norm": 0.7618803151109027,
      "learning_rate": 0.00011154263437133794,
      "loss": 0.0048,
      "step": 2785
    },
    {
      "epoch": 4.793118279569892,
      "grad_norm": 0.22739850755391622,
      "learning_rate": 0.0001114872537980991,
      "loss": 0.0027,
      "step": 2786
    },
    {
      "epoch": 4.794838709677419,
      "grad_norm": 0.6416191368010329,
      "learning_rate": 0.0001114318696543679,
      "loss": 0.0038,
      "step": 2787
    },
    {
      "epoch": 4.7965591397849465,
      "grad_norm": 0.8803133062550867,
      "learning_rate": 0.00011137648195735892,
      "loss": 0.0248,
      "step": 2788
    },
    {
      "epoch": 4.798279569892474,
      "grad_norm": 0.6145799106472606,
      "learning_rate": 0.00011132109072428786,
      "loss": 0.0035,
      "step": 2789
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.778151592370185,
      "learning_rate": 0.00011126569597237167,
      "loss": 0.0027,
      "step": 2790
    },
    {
      "epoch": 4.801720430107527,
      "grad_norm": 0.8036397135610225,
      "learning_rate": 0.00011121029771882812,
      "loss": 0.0048,
      "step": 2791
    },
    {
      "epoch": 4.803440860215054,
      "grad_norm": 1.0036839947243568,
      "learning_rate": 0.00011115489598087627,
      "loss": 0.0084,
      "step": 2792
    },
    {
      "epoch": 4.80516129032258,
      "grad_norm": 0.2886385164600721,
      "learning_rate": 0.00011109949077573623,
      "loss": 0.0013,
      "step": 2793
    },
    {
      "epoch": 4.806881720430107,
      "grad_norm": 0.8261113877275481,
      "learning_rate": 0.0001110440821206291,
      "loss": 0.0034,
      "step": 2794
    },
    {
      "epoch": 4.808602150537634,
      "grad_norm": 1.6292882181409276,
      "learning_rate": 0.00011098867003277717,
      "loss": 0.0173,
      "step": 2795
    },
    {
      "epoch": 4.8103225806451615,
      "grad_norm": 0.1099498399906328,
      "learning_rate": 0.0001109332545294037,
      "loss": 0.0009,
      "step": 2796
    },
    {
      "epoch": 4.812043010752689,
      "grad_norm": 1.2141439609046591,
      "learning_rate": 0.00011087783562773311,
      "loss": 0.0105,
      "step": 2797
    },
    {
      "epoch": 4.813763440860215,
      "grad_norm": 0.3562986994209162,
      "learning_rate": 0.00011082241334499075,
      "loss": 0.003,
      "step": 2798
    },
    {
      "epoch": 4.815483870967742,
      "grad_norm": 0.26247710839956784,
      "learning_rate": 0.00011076698769840313,
      "loss": 0.0019,
      "step": 2799
    },
    {
      "epoch": 4.817204301075269,
      "grad_norm": 0.732549495636653,
      "learning_rate": 0.00011071155870519777,
      "loss": 0.0028,
      "step": 2800
    },
    {
      "epoch": 4.818924731182796,
      "grad_norm": 0.21982364910090316,
      "learning_rate": 0.00011065612638260321,
      "loss": 0.0014,
      "step": 2801
    },
    {
      "epoch": 4.820645161290322,
      "grad_norm": 0.7154606825264825,
      "learning_rate": 0.00011060069074784902,
      "loss": 0.0064,
      "step": 2802
    },
    {
      "epoch": 4.822365591397849,
      "grad_norm": 0.18696793200441927,
      "learning_rate": 0.00011054525181816587,
      "loss": 0.0018,
      "step": 2803
    },
    {
      "epoch": 4.8240860215053765,
      "grad_norm": 1.3170006546917277,
      "learning_rate": 0.00011048980961078541,
      "loss": 0.0178,
      "step": 2804
    },
    {
      "epoch": 4.825806451612904,
      "grad_norm": 0.9630007248658181,
      "learning_rate": 0.00011043436414294024,
      "loss": 0.0065,
      "step": 2805
    },
    {
      "epoch": 4.82752688172043,
      "grad_norm": 0.20888293410763914,
      "learning_rate": 0.0001103789154318641,
      "loss": 0.0011,
      "step": 2806
    },
    {
      "epoch": 4.829247311827957,
      "grad_norm": 1.9773879015633518,
      "learning_rate": 0.00011032346349479161,
      "loss": 0.0411,
      "step": 2807
    },
    {
      "epoch": 4.830967741935484,
      "grad_norm": 0.41057204334471425,
      "learning_rate": 0.00011026800834895852,
      "loss": 0.0013,
      "step": 2808
    },
    {
      "epoch": 4.832688172043011,
      "grad_norm": 0.6538616601661784,
      "learning_rate": 0.00011021255001160147,
      "loss": 0.0042,
      "step": 2809
    },
    {
      "epoch": 4.834408602150537,
      "grad_norm": 0.39806842676006793,
      "learning_rate": 0.00011015708849995818,
      "loss": 0.0031,
      "step": 2810
    },
    {
      "epoch": 4.836129032258064,
      "grad_norm": 0.16545128767209033,
      "learning_rate": 0.00011010162383126728,
      "loss": 0.0012,
      "step": 2811
    },
    {
      "epoch": 4.837849462365591,
      "grad_norm": 0.06769538760907397,
      "learning_rate": 0.00011004615602276842,
      "loss": 0.0004,
      "step": 2812
    },
    {
      "epoch": 4.8395698924731185,
      "grad_norm": 0.9526376592346801,
      "learning_rate": 0.00010999068509170222,
      "loss": 0.0057,
      "step": 2813
    },
    {
      "epoch": 4.841290322580646,
      "grad_norm": 1.2914063390878183,
      "learning_rate": 0.00010993521105531032,
      "loss": 0.0123,
      "step": 2814
    },
    {
      "epoch": 4.843010752688172,
      "grad_norm": 4.295154541122712,
      "learning_rate": 0.0001098797339308352,
      "loss": 0.0417,
      "step": 2815
    },
    {
      "epoch": 4.844731182795699,
      "grad_norm": 0.9492699973640758,
      "learning_rate": 0.00010982425373552039,
      "loss": 0.0043,
      "step": 2816
    },
    {
      "epoch": 4.846451612903226,
      "grad_norm": 0.02517574760833972,
      "learning_rate": 0.00010976877048661041,
      "loss": 0.0002,
      "step": 2817
    },
    {
      "epoch": 4.848172043010752,
      "grad_norm": 0.9941435351900971,
      "learning_rate": 0.00010971328420135067,
      "loss": 0.0436,
      "step": 2818
    },
    {
      "epoch": 4.849892473118279,
      "grad_norm": 0.3807548091695344,
      "learning_rate": 0.00010965779489698749,
      "loss": 0.0036,
      "step": 2819
    },
    {
      "epoch": 4.851612903225806,
      "grad_norm": 0.02594361940429776,
      "learning_rate": 0.00010960230259076818,
      "loss": 0.0001,
      "step": 2820
    },
    {
      "epoch": 4.8533333333333335,
      "grad_norm": 0.6033168530841854,
      "learning_rate": 0.00010954680729994102,
      "loss": 0.0045,
      "step": 2821
    },
    {
      "epoch": 4.855053763440861,
      "grad_norm": 0.15859867263431945,
      "learning_rate": 0.00010949130904175516,
      "loss": 0.0012,
      "step": 2822
    },
    {
      "epoch": 4.856774193548387,
      "grad_norm": 1.4671391502278013,
      "learning_rate": 0.00010943580783346063,
      "loss": 0.0294,
      "step": 2823
    },
    {
      "epoch": 4.858494623655914,
      "grad_norm": 0.5025240047008781,
      "learning_rate": 0.0001093803036923085,
      "loss": 0.0066,
      "step": 2824
    },
    {
      "epoch": 4.860215053763441,
      "grad_norm": 0.8364599586853835,
      "learning_rate": 0.00010932479663555064,
      "loss": 0.0097,
      "step": 2825
    },
    {
      "epoch": 4.861935483870968,
      "grad_norm": 1.054649691247876,
      "learning_rate": 0.0001092692866804399,
      "loss": 0.0095,
      "step": 2826
    },
    {
      "epoch": 4.863655913978494,
      "grad_norm": 1.1478088977340692,
      "learning_rate": 0.00010921377384423,
      "loss": 0.0155,
      "step": 2827
    },
    {
      "epoch": 4.865376344086021,
      "grad_norm": 1.7950019709382243,
      "learning_rate": 0.00010915825814417555,
      "loss": 0.0068,
      "step": 2828
    },
    {
      "epoch": 4.8670967741935485,
      "grad_norm": 2.1080436020098827,
      "learning_rate": 0.00010910273959753201,
      "loss": 0.0182,
      "step": 2829
    },
    {
      "epoch": 4.868817204301076,
      "grad_norm": 0.24706944281995735,
      "learning_rate": 0.00010904721822155583,
      "loss": 0.0017,
      "step": 2830
    },
    {
      "epoch": 4.870537634408602,
      "grad_norm": 1.75858801961785,
      "learning_rate": 0.00010899169403350429,
      "loss": 0.026,
      "step": 2831
    },
    {
      "epoch": 4.872258064516129,
      "grad_norm": 1.362222493633417,
      "learning_rate": 0.00010893616705063548,
      "loss": 0.0113,
      "step": 2832
    },
    {
      "epoch": 4.873978494623656,
      "grad_norm": 0.2901886033655211,
      "learning_rate": 0.00010888063729020843,
      "loss": 0.0042,
      "step": 2833
    },
    {
      "epoch": 4.875698924731183,
      "grad_norm": 0.7828567358541785,
      "learning_rate": 0.00010882510476948305,
      "loss": 0.0031,
      "step": 2834
    },
    {
      "epoch": 4.877419354838709,
      "grad_norm": 2.462665320586777,
      "learning_rate": 0.00010876956950572006,
      "loss": 0.0272,
      "step": 2835
    },
    {
      "epoch": 4.879139784946236,
      "grad_norm": 1.900680495948482,
      "learning_rate": 0.00010871403151618105,
      "loss": 0.0185,
      "step": 2836
    },
    {
      "epoch": 4.880860215053763,
      "grad_norm": 0.39673345047242187,
      "learning_rate": 0.00010865849081812842,
      "loss": 0.0031,
      "step": 2837
    },
    {
      "epoch": 4.8825806451612905,
      "grad_norm": 0.43328150970093665,
      "learning_rate": 0.00010860294742882548,
      "loss": 0.0026,
      "step": 2838
    },
    {
      "epoch": 4.884301075268818,
      "grad_norm": 0.49329634855521953,
      "learning_rate": 0.00010854740136553634,
      "loss": 0.006,
      "step": 2839
    },
    {
      "epoch": 4.886021505376344,
      "grad_norm": 1.6916416214119392,
      "learning_rate": 0.00010849185264552592,
      "loss": 0.019,
      "step": 2840
    },
    {
      "epoch": 4.887741935483871,
      "grad_norm": 0.9468754225808874,
      "learning_rate": 0.00010843630128606004,
      "loss": 0.0096,
      "step": 2841
    },
    {
      "epoch": 4.889462365591398,
      "grad_norm": 1.3074322959320293,
      "learning_rate": 0.00010838074730440524,
      "loss": 0.023,
      "step": 2842
    },
    {
      "epoch": 4.891182795698925,
      "grad_norm": 0.5663600499341888,
      "learning_rate": 0.00010832519071782894,
      "loss": 0.0047,
      "step": 2843
    },
    {
      "epoch": 4.892903225806451,
      "grad_norm": 0.495546214502275,
      "learning_rate": 0.00010826963154359937,
      "loss": 0.0055,
      "step": 2844
    },
    {
      "epoch": 4.894623655913978,
      "grad_norm": 0.7269032431808229,
      "learning_rate": 0.00010821406979898557,
      "loss": 0.0073,
      "step": 2845
    },
    {
      "epoch": 4.8963440860215055,
      "grad_norm": 1.262456201307462,
      "learning_rate": 0.00010815850550125728,
      "loss": 0.0132,
      "step": 2846
    },
    {
      "epoch": 4.898064516129033,
      "grad_norm": 0.6426232480481171,
      "learning_rate": 0.00010810293866768515,
      "loss": 0.0042,
      "step": 2847
    },
    {
      "epoch": 4.899784946236559,
      "grad_norm": 1.3970427191961787,
      "learning_rate": 0.00010804736931554065,
      "loss": 0.023,
      "step": 2848
    },
    {
      "epoch": 4.901505376344086,
      "grad_norm": 0.09024276485666542,
      "learning_rate": 0.00010799179746209587,
      "loss": 0.0009,
      "step": 2849
    },
    {
      "epoch": 4.903225806451613,
      "grad_norm": 0.16456954542341196,
      "learning_rate": 0.00010793622312462379,
      "loss": 0.0017,
      "step": 2850
    },
    {
      "epoch": 4.90494623655914,
      "grad_norm": 1.0155929313373047,
      "learning_rate": 0.00010788064632039814,
      "loss": 0.0091,
      "step": 2851
    },
    {
      "epoch": 4.906666666666666,
      "grad_norm": 2.15955039921427,
      "learning_rate": 0.00010782506706669349,
      "loss": 0.0231,
      "step": 2852
    },
    {
      "epoch": 4.908387096774193,
      "grad_norm": 0.9923167675454352,
      "learning_rate": 0.000107769485380785,
      "loss": 0.0356,
      "step": 2853
    },
    {
      "epoch": 4.9101075268817205,
      "grad_norm": 1.3286408305287951,
      "learning_rate": 0.00010771390127994876,
      "loss": 0.0143,
      "step": 2854
    },
    {
      "epoch": 4.911827956989248,
      "grad_norm": 1.681055288350503,
      "learning_rate": 0.0001076583147814615,
      "loss": 0.0147,
      "step": 2855
    },
    {
      "epoch": 4.913548387096775,
      "grad_norm": 0.5008081172751603,
      "learning_rate": 0.00010760272590260071,
      "loss": 0.0046,
      "step": 2856
    },
    {
      "epoch": 4.915268817204301,
      "grad_norm": 0.8391005432917382,
      "learning_rate": 0.0001075471346606447,
      "loss": 0.0033,
      "step": 2857
    },
    {
      "epoch": 4.916989247311828,
      "grad_norm": 0.4971570161176031,
      "learning_rate": 0.00010749154107287242,
      "loss": 0.0028,
      "step": 2858
    },
    {
      "epoch": 4.918709677419355,
      "grad_norm": 0.6990970846360799,
      "learning_rate": 0.00010743594515656363,
      "loss": 0.0044,
      "step": 2859
    },
    {
      "epoch": 4.920430107526881,
      "grad_norm": 0.009458716690106622,
      "learning_rate": 0.00010738034692899868,
      "loss": 0.0001,
      "step": 2860
    },
    {
      "epoch": 4.922150537634408,
      "grad_norm": 0.5391136523490677,
      "learning_rate": 0.0001073247464074588,
      "loss": 0.0029,
      "step": 2861
    },
    {
      "epoch": 4.9238709677419354,
      "grad_norm": 0.12459507979846103,
      "learning_rate": 0.00010726914360922589,
      "loss": 0.0012,
      "step": 2862
    },
    {
      "epoch": 4.9255913978494625,
      "grad_norm": 1.6250538242970896,
      "learning_rate": 0.00010721353855158243,
      "loss": 0.0129,
      "step": 2863
    },
    {
      "epoch": 4.92731182795699,
      "grad_norm": 0.2512195868583801,
      "learning_rate": 0.00010715793125181177,
      "loss": 0.0012,
      "step": 2864
    },
    {
      "epoch": 4.929032258064516,
      "grad_norm": 0.9032309954056553,
      "learning_rate": 0.00010710232172719785,
      "loss": 0.0118,
      "step": 2865
    },
    {
      "epoch": 4.930752688172043,
      "grad_norm": 0.24813615550719004,
      "learning_rate": 0.0001070467099950254,
      "loss": 0.0016,
      "step": 2866
    },
    {
      "epoch": 4.93247311827957,
      "grad_norm": 1.2524740006825927,
      "learning_rate": 0.00010699109607257971,
      "loss": 0.0256,
      "step": 2867
    },
    {
      "epoch": 4.934193548387097,
      "grad_norm": 0.7317285120106118,
      "learning_rate": 0.00010693547997714686,
      "loss": 0.0061,
      "step": 2868
    },
    {
      "epoch": 4.935913978494623,
      "grad_norm": 1.2098102168758167,
      "learning_rate": 0.00010687986172601352,
      "loss": 0.0072,
      "step": 2869
    },
    {
      "epoch": 4.93763440860215,
      "grad_norm": 0.21765751589040128,
      "learning_rate": 0.0001068242413364671,
      "loss": 0.0007,
      "step": 2870
    },
    {
      "epoch": 4.9393548387096775,
      "grad_norm": 1.6859253790592197,
      "learning_rate": 0.00010676861882579565,
      "loss": 0.0338,
      "step": 2871
    },
    {
      "epoch": 4.941075268817205,
      "grad_norm": 1.1233822406354323,
      "learning_rate": 0.00010671299421128786,
      "loss": 0.0071,
      "step": 2872
    },
    {
      "epoch": 4.942795698924731,
      "grad_norm": 0.7500987732684211,
      "learning_rate": 0.00010665736751023315,
      "loss": 0.0301,
      "step": 2873
    },
    {
      "epoch": 4.944516129032258,
      "grad_norm": 1.1722146745790634,
      "learning_rate": 0.00010660173873992139,
      "loss": 0.0209,
      "step": 2874
    },
    {
      "epoch": 4.946236559139785,
      "grad_norm": 2.4602815411583796,
      "learning_rate": 0.00010654610791764335,
      "loss": 0.0137,
      "step": 2875
    },
    {
      "epoch": 4.947956989247312,
      "grad_norm": 0.2079442055848342,
      "learning_rate": 0.00010649047506069032,
      "loss": 0.0015,
      "step": 2876
    },
    {
      "epoch": 4.949677419354838,
      "grad_norm": 1.3920427704428393,
      "learning_rate": 0.00010643484018635417,
      "loss": 0.0056,
      "step": 2877
    },
    {
      "epoch": 4.951397849462365,
      "grad_norm": 0.2859736617314352,
      "learning_rate": 0.00010637920331192741,
      "loss": 0.0021,
      "step": 2878
    },
    {
      "epoch": 4.9531182795698925,
      "grad_norm": 0.5224811532857722,
      "learning_rate": 0.00010632356445470335,
      "loss": 0.0025,
      "step": 2879
    },
    {
      "epoch": 4.95483870967742,
      "grad_norm": 0.3552302287854402,
      "learning_rate": 0.00010626792363197563,
      "loss": 0.0026,
      "step": 2880
    },
    {
      "epoch": 4.956559139784947,
      "grad_norm": 0.5512753907332153,
      "learning_rate": 0.00010621228086103876,
      "loss": 0.0022,
      "step": 2881
    },
    {
      "epoch": 4.958279569892473,
      "grad_norm": 0.06098868340000976,
      "learning_rate": 0.00010615663615918766,
      "loss": 0.0004,
      "step": 2882
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.29033005162382547,
      "learning_rate": 0.00010610098954371797,
      "loss": 0.0022,
      "step": 2883
    },
    {
      "epoch": 4.961720430107527,
      "grad_norm": 0.44488598264526386,
      "learning_rate": 0.00010604534103192589,
      "loss": 0.0029,
      "step": 2884
    },
    {
      "epoch": 4.963440860215054,
      "grad_norm": 0.02276803917335346,
      "learning_rate": 0.00010598969064110819,
      "loss": 0.0003,
      "step": 2885
    },
    {
      "epoch": 4.96516129032258,
      "grad_norm": 2.582285553067261,
      "learning_rate": 0.00010593403838856229,
      "loss": 0.0158,
      "step": 2886
    },
    {
      "epoch": 4.9668817204301074,
      "grad_norm": 1.5108972241947167,
      "learning_rate": 0.00010587838429158608,
      "loss": 0.0112,
      "step": 2887
    },
    {
      "epoch": 4.9686021505376345,
      "grad_norm": 1.6443433001458274,
      "learning_rate": 0.00010582272836747808,
      "loss": 0.0144,
      "step": 2888
    },
    {
      "epoch": 4.970322580645162,
      "grad_norm": 0.9839062093505965,
      "learning_rate": 0.00010576707063353746,
      "loss": 0.0084,
      "step": 2889
    },
    {
      "epoch": 4.972043010752688,
      "grad_norm": 1.185768546231966,
      "learning_rate": 0.00010571141110706381,
      "loss": 0.0069,
      "step": 2890
    },
    {
      "epoch": 4.973763440860215,
      "grad_norm": 2.694141435814435,
      "learning_rate": 0.00010565574980535733,
      "loss": 0.0314,
      "step": 2891
    },
    {
      "epoch": 4.975483870967742,
      "grad_norm": 1.3316988990277292,
      "learning_rate": 0.0001056000867457188,
      "loss": 0.0172,
      "step": 2892
    },
    {
      "epoch": 4.977204301075269,
      "grad_norm": 0.8164831220310457,
      "learning_rate": 0.00010554442194544957,
      "loss": 0.0052,
      "step": 2893
    },
    {
      "epoch": 4.978924731182795,
      "grad_norm": 0.26986103359027896,
      "learning_rate": 0.00010548875542185143,
      "loss": 0.0032,
      "step": 2894
    },
    {
      "epoch": 4.980645161290322,
      "grad_norm": 2.159272283049234,
      "learning_rate": 0.00010543308719222679,
      "loss": 0.0144,
      "step": 2895
    },
    {
      "epoch": 4.9823655913978495,
      "grad_norm": 1.8558899185621238,
      "learning_rate": 0.0001053774172738786,
      "loss": 0.0261,
      "step": 2896
    },
    {
      "epoch": 4.984086021505377,
      "grad_norm": 0.17192784403420125,
      "learning_rate": 0.00010532174568411023,
      "loss": 0.0016,
      "step": 2897
    },
    {
      "epoch": 4.985806451612904,
      "grad_norm": 1.4118377322955185,
      "learning_rate": 0.00010526607244022571,
      "loss": 0.0091,
      "step": 2898
    },
    {
      "epoch": 4.98752688172043,
      "grad_norm": 1.315211107166796,
      "learning_rate": 0.00010521039755952946,
      "loss": 0.0121,
      "step": 2899
    },
    {
      "epoch": 4.989247311827957,
      "grad_norm": 0.25465687738378334,
      "learning_rate": 0.00010515472105932651,
      "loss": 0.0018,
      "step": 2900
    },
    {
      "epoch": 4.990967741935484,
      "grad_norm": 1.6018581277095914,
      "learning_rate": 0.0001050990429569223,
      "loss": 0.0262,
      "step": 2901
    },
    {
      "epoch": 4.99268817204301,
      "grad_norm": 0.49329189568514215,
      "learning_rate": 0.00010504336326962283,
      "loss": 0.0036,
      "step": 2902
    },
    {
      "epoch": 4.994408602150537,
      "grad_norm": 1.2639580840566174,
      "learning_rate": 0.00010498768201473461,
      "loss": 0.0056,
      "step": 2903
    },
    {
      "epoch": 4.9961290322580645,
      "grad_norm": 0.9583131197047646,
      "learning_rate": 0.0001049319992095646,
      "loss": 0.0053,
      "step": 2904
    },
    {
      "epoch": 4.997849462365592,
      "grad_norm": 0.7114202374959655,
      "learning_rate": 0.00010487631487142017,
      "loss": 0.0051,
      "step": 2905
    },
    {
      "epoch": 4.999569892473119,
      "grad_norm": 1.006300074732447,
      "learning_rate": 0.00010482062901760934,
      "loss": 0.0144,
      "step": 2906
    },
    {
      "epoch": 5.001290322580645,
      "grad_norm": 0.11044163349816669,
      "learning_rate": 0.00010476494166544049,
      "loss": 0.001,
      "step": 2907
    },
    {
      "epoch": 5.003010752688172,
      "grad_norm": 2.7087173657320522,
      "learning_rate": 0.00010470925283222242,
      "loss": 0.0115,
      "step": 2908
    },
    {
      "epoch": 5.004731182795699,
      "grad_norm": 0.14983686306106803,
      "learning_rate": 0.00010465356253526448,
      "loss": 0.001,
      "step": 2909
    },
    {
      "epoch": 5.006451612903226,
      "grad_norm": 1.5166834304539,
      "learning_rate": 0.00010459787079187646,
      "loss": 0.008,
      "step": 2910
    },
    {
      "epoch": 5.008172043010752,
      "grad_norm": 0.2609801472412699,
      "learning_rate": 0.00010454217761936857,
      "loss": 0.0027,
      "step": 2911
    },
    {
      "epoch": 5.0098924731182795,
      "grad_norm": 0.07670568258195062,
      "learning_rate": 0.00010448648303505151,
      "loss": 0.0003,
      "step": 2912
    },
    {
      "epoch": 5.0116129032258065,
      "grad_norm": 0.08666465472037341,
      "learning_rate": 0.00010443078705623632,
      "loss": 0.0009,
      "step": 2913
    },
    {
      "epoch": 5.013333333333334,
      "grad_norm": 0.4292978981798499,
      "learning_rate": 0.00010437508970023462,
      "loss": 0.0032,
      "step": 2914
    },
    {
      "epoch": 5.01505376344086,
      "grad_norm": 0.7198739205735947,
      "learning_rate": 0.00010431939098435832,
      "loss": 0.0012,
      "step": 2915
    },
    {
      "epoch": 5.016774193548387,
      "grad_norm": 0.524207098896123,
      "learning_rate": 0.00010426369092591983,
      "loss": 0.0036,
      "step": 2916
    },
    {
      "epoch": 5.018494623655914,
      "grad_norm": 0.07621895649299765,
      "learning_rate": 0.00010420798954223198,
      "loss": 0.0005,
      "step": 2917
    },
    {
      "epoch": 5.020215053763441,
      "grad_norm": 0.2456451484947025,
      "learning_rate": 0.00010415228685060798,
      "loss": 0.001,
      "step": 2918
    },
    {
      "epoch": 5.021935483870967,
      "grad_norm": 2.840975749377597,
      "learning_rate": 0.00010409658286836143,
      "loss": 0.0181,
      "step": 2919
    },
    {
      "epoch": 5.023655913978494,
      "grad_norm": 0.047670107234814456,
      "learning_rate": 0.00010404087761280639,
      "loss": 0.0003,
      "step": 2920
    },
    {
      "epoch": 5.0253763440860215,
      "grad_norm": 0.02415285698925701,
      "learning_rate": 0.0001039851711012573,
      "loss": 0.0003,
      "step": 2921
    },
    {
      "epoch": 5.027096774193549,
      "grad_norm": 0.24005310080777745,
      "learning_rate": 0.0001039294633510289,
      "loss": 0.0014,
      "step": 2922
    },
    {
      "epoch": 5.028817204301076,
      "grad_norm": 0.6183930478753471,
      "learning_rate": 0.00010387375437943647,
      "loss": 0.0014,
      "step": 2923
    },
    {
      "epoch": 5.030537634408602,
      "grad_norm": 0.08787455491189579,
      "learning_rate": 0.00010381804420379557,
      "loss": 0.0006,
      "step": 2924
    },
    {
      "epoch": 5.032258064516129,
      "grad_norm": 1.4293286858073269,
      "learning_rate": 0.00010376233284142214,
      "loss": 0.0026,
      "step": 2925
    },
    {
      "epoch": 5.033978494623656,
      "grad_norm": 0.9726614146462694,
      "learning_rate": 0.00010370662030963249,
      "loss": 0.0038,
      "step": 2926
    },
    {
      "epoch": 5.035698924731183,
      "grad_norm": 0.5368672910273302,
      "learning_rate": 0.00010365090662574335,
      "loss": 0.0011,
      "step": 2927
    },
    {
      "epoch": 5.037419354838709,
      "grad_norm": 1.4822680966634936,
      "learning_rate": 0.00010359519180707172,
      "loss": 0.0084,
      "step": 2928
    },
    {
      "epoch": 5.0391397849462365,
      "grad_norm": 0.025566817108451483,
      "learning_rate": 0.000103539475870935,
      "loss": 0.0001,
      "step": 2929
    },
    {
      "epoch": 5.040860215053764,
      "grad_norm": 0.03450178796367527,
      "learning_rate": 0.00010348375883465098,
      "loss": 0.0002,
      "step": 2930
    },
    {
      "epoch": 5.042580645161291,
      "grad_norm": 0.10618651610092836,
      "learning_rate": 0.00010342804071553771,
      "loss": 0.0007,
      "step": 2931
    },
    {
      "epoch": 5.044301075268817,
      "grad_norm": 0.06317142490447737,
      "learning_rate": 0.00010337232153091359,
      "loss": 0.0004,
      "step": 2932
    },
    {
      "epoch": 5.046021505376344,
      "grad_norm": 0.4936853453471493,
      "learning_rate": 0.00010331660129809741,
      "loss": 0.0049,
      "step": 2933
    },
    {
      "epoch": 5.047741935483871,
      "grad_norm": 0.3488784298813864,
      "learning_rate": 0.00010326088003440826,
      "loss": 0.002,
      "step": 2934
    },
    {
      "epoch": 5.049462365591398,
      "grad_norm": 0.4261745225812845,
      "learning_rate": 0.00010320515775716555,
      "loss": 0.0016,
      "step": 2935
    },
    {
      "epoch": 5.051182795698924,
      "grad_norm": 1.0172367900391481,
      "learning_rate": 0.00010314943448368892,
      "loss": 0.0024,
      "step": 2936
    },
    {
      "epoch": 5.0529032258064515,
      "grad_norm": 2.991143568081078,
      "learning_rate": 0.00010309371023129844,
      "loss": 0.0029,
      "step": 2937
    },
    {
      "epoch": 5.0546236559139786,
      "grad_norm": 0.06631490375704426,
      "learning_rate": 0.00010303798501731447,
      "loss": 0.0002,
      "step": 2938
    },
    {
      "epoch": 5.056344086021506,
      "grad_norm": 1.0659558259153852,
      "learning_rate": 0.00010298225885905761,
      "loss": 0.0164,
      "step": 2939
    },
    {
      "epoch": 5.058064516129032,
      "grad_norm": 0.349492789251536,
      "learning_rate": 0.00010292653177384876,
      "loss": 0.002,
      "step": 2940
    },
    {
      "epoch": 5.059784946236559,
      "grad_norm": 0.09253743578135494,
      "learning_rate": 0.00010287080377900917,
      "loss": 0.0008,
      "step": 2941
    },
    {
      "epoch": 5.061505376344086,
      "grad_norm": 1.3791718884310393,
      "learning_rate": 0.0001028150748918603,
      "loss": 0.0105,
      "step": 2942
    },
    {
      "epoch": 5.063225806451613,
      "grad_norm": 0.017671240216214853,
      "learning_rate": 0.00010275934512972396,
      "loss": 0.0001,
      "step": 2943
    },
    {
      "epoch": 5.064946236559139,
      "grad_norm": 1.0633565544387569,
      "learning_rate": 0.00010270361450992214,
      "loss": 0.0118,
      "step": 2944
    },
    {
      "epoch": 5.066666666666666,
      "grad_norm": 0.0997353441636601,
      "learning_rate": 0.00010264788304977722,
      "loss": 0.0002,
      "step": 2945
    },
    {
      "epoch": 5.0683870967741935,
      "grad_norm": 2.2261029202401237,
      "learning_rate": 0.00010259215076661166,
      "loss": 0.0057,
      "step": 2946
    },
    {
      "epoch": 5.070107526881721,
      "grad_norm": 0.2419886869481796,
      "learning_rate": 0.00010253641767774838,
      "loss": 0.0012,
      "step": 2947
    },
    {
      "epoch": 5.071827956989248,
      "grad_norm": 1.4219849086964438,
      "learning_rate": 0.00010248068380051043,
      "loss": 0.0073,
      "step": 2948
    },
    {
      "epoch": 5.073548387096774,
      "grad_norm": 0.4520886961531958,
      "learning_rate": 0.00010242494915222114,
      "loss": 0.0015,
      "step": 2949
    },
    {
      "epoch": 5.075268817204301,
      "grad_norm": 1.2063135510162957,
      "learning_rate": 0.000102369213750204,
      "loss": 0.0058,
      "step": 2950
    },
    {
      "epoch": 5.076989247311828,
      "grad_norm": 0.2847452644993671,
      "learning_rate": 0.0001023134776117829,
      "loss": 0.0019,
      "step": 2951
    },
    {
      "epoch": 5.078709677419355,
      "grad_norm": 2.1599360175130133,
      "learning_rate": 0.00010225774075428185,
      "loss": 0.0134,
      "step": 2952
    },
    {
      "epoch": 5.080430107526881,
      "grad_norm": 0.04287297090900006,
      "learning_rate": 0.00010220200319502504,
      "loss": 0.0003,
      "step": 2953
    },
    {
      "epoch": 5.0821505376344085,
      "grad_norm": 0.03461551409233381,
      "learning_rate": 0.00010214626495133697,
      "loss": 0.0001,
      "step": 2954
    },
    {
      "epoch": 5.083870967741936,
      "grad_norm": 1.5960377661604972,
      "learning_rate": 0.00010209052604054232,
      "loss": 0.0086,
      "step": 2955
    },
    {
      "epoch": 5.085591397849463,
      "grad_norm": 1.9715805779739581,
      "learning_rate": 0.00010203478647996598,
      "loss": 0.0128,
      "step": 2956
    },
    {
      "epoch": 5.087311827956989,
      "grad_norm": 0.7022177821746577,
      "learning_rate": 0.00010197904628693302,
      "loss": 0.0032,
      "step": 2957
    },
    {
      "epoch": 5.089032258064516,
      "grad_norm": 1.3331816024735001,
      "learning_rate": 0.00010192330547876871,
      "loss": 0.01,
      "step": 2958
    },
    {
      "epoch": 5.090752688172043,
      "grad_norm": 0.5133895074144275,
      "learning_rate": 0.00010186756407279858,
      "loss": 0.0035,
      "step": 2959
    },
    {
      "epoch": 5.09247311827957,
      "grad_norm": 1.7827814831598758,
      "learning_rate": 0.00010181182208634825,
      "loss": 0.0172,
      "step": 2960
    },
    {
      "epoch": 5.094193548387096,
      "grad_norm": 0.009363924302946388,
      "learning_rate": 0.00010175607953674357,
      "loss": 0.0001,
      "step": 2961
    },
    {
      "epoch": 5.0959139784946235,
      "grad_norm": 0.9479649427329767,
      "learning_rate": 0.00010170033644131058,
      "loss": 0.0054,
      "step": 2962
    },
    {
      "epoch": 5.097634408602151,
      "grad_norm": 1.3902549193631941,
      "learning_rate": 0.00010164459281737542,
      "loss": 0.0097,
      "step": 2963
    },
    {
      "epoch": 5.099354838709678,
      "grad_norm": 0.1267886145318685,
      "learning_rate": 0.00010158884868226444,
      "loss": 0.001,
      "step": 2964
    },
    {
      "epoch": 5.101075268817205,
      "grad_norm": 0.028351121691857835,
      "learning_rate": 0.00010153310405330423,
      "loss": 0.0002,
      "step": 2965
    },
    {
      "epoch": 5.102795698924731,
      "grad_norm": 2.707299158706291,
      "learning_rate": 0.00010147735894782135,
      "loss": 0.0049,
      "step": 2966
    },
    {
      "epoch": 5.104516129032258,
      "grad_norm": 1.3716307811519317,
      "learning_rate": 0.00010142161338314266,
      "loss": 0.0102,
      "step": 2967
    },
    {
      "epoch": 5.106236559139785,
      "grad_norm": 0.04632326477757235,
      "learning_rate": 0.0001013658673765951,
      "loss": 0.0004,
      "step": 2968
    },
    {
      "epoch": 5.107956989247312,
      "grad_norm": 0.13927451374553734,
      "learning_rate": 0.0001013101209455058,
      "loss": 0.0012,
      "step": 2969
    },
    {
      "epoch": 5.109677419354838,
      "grad_norm": 0.38128578833430665,
      "learning_rate": 0.00010125437410720195,
      "loss": 0.0011,
      "step": 2970
    },
    {
      "epoch": 5.1113978494623655,
      "grad_norm": 3.2532410632982343,
      "learning_rate": 0.00010119862687901089,
      "loss": 0.0077,
      "step": 2971
    },
    {
      "epoch": 5.113118279569893,
      "grad_norm": 0.8311468570064224,
      "learning_rate": 0.00010114287927826012,
      "loss": 0.004,
      "step": 2972
    },
    {
      "epoch": 5.11483870967742,
      "grad_norm": 0.037522800744367917,
      "learning_rate": 0.00010108713132227718,
      "loss": 0.0002,
      "step": 2973
    },
    {
      "epoch": 5.116559139784946,
      "grad_norm": 0.24568433144925944,
      "learning_rate": 0.00010103138302838984,
      "loss": 0.0017,
      "step": 2974
    },
    {
      "epoch": 5.118279569892473,
      "grad_norm": 0.0945985553236049,
      "learning_rate": 0.00010097563441392581,
      "loss": 0.0005,
      "step": 2975
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.016257403550362072,
      "learning_rate": 0.0001009198854962131,
      "loss": 0.0002,
      "step": 2976
    },
    {
      "epoch": 5.121720430107527,
      "grad_norm": 0.1715854685803646,
      "learning_rate": 0.00010086413629257959,
      "loss": 0.0009,
      "step": 2977
    },
    {
      "epoch": 5.123440860215053,
      "grad_norm": 0.09395806315893959,
      "learning_rate": 0.00010080838682035343,
      "loss": 0.0004,
      "step": 2978
    },
    {
      "epoch": 5.1251612903225805,
      "grad_norm": 0.008417208203519478,
      "learning_rate": 0.00010075263709686283,
      "loss": 0.0001,
      "step": 2979
    },
    {
      "epoch": 5.126881720430108,
      "grad_norm": 0.003634073358906056,
      "learning_rate": 0.00010069688713943593,
      "loss": 0.0,
      "step": 2980
    },
    {
      "epoch": 5.128602150537635,
      "grad_norm": 0.024377421686476483,
      "learning_rate": 0.00010064113696540111,
      "loss": 0.0001,
      "step": 2981
    },
    {
      "epoch": 5.130322580645161,
      "grad_norm": 1.337331562890602,
      "learning_rate": 0.00010058538659208678,
      "loss": 0.009,
      "step": 2982
    },
    {
      "epoch": 5.132043010752688,
      "grad_norm": 0.32605619687361687,
      "learning_rate": 0.00010052963603682133,
      "loss": 0.0016,
      "step": 2983
    },
    {
      "epoch": 5.133763440860215,
      "grad_norm": 0.37508324108036784,
      "learning_rate": 0.00010047388531693331,
      "loss": 0.0026,
      "step": 2984
    },
    {
      "epoch": 5.135483870967742,
      "grad_norm": 0.1428154799656126,
      "learning_rate": 0.00010041813444975126,
      "loss": 0.0007,
      "step": 2985
    },
    {
      "epoch": 5.137204301075268,
      "grad_norm": 0.5664940388288372,
      "learning_rate": 0.00010036238345260376,
      "loss": 0.0026,
      "step": 2986
    },
    {
      "epoch": 5.1389247311827955,
      "grad_norm": 0.5776186816281333,
      "learning_rate": 0.00010030663234281949,
      "loss": 0.0023,
      "step": 2987
    },
    {
      "epoch": 5.140645161290323,
      "grad_norm": 0.08204992900547321,
      "learning_rate": 0.00010025088113772711,
      "loss": 0.0004,
      "step": 2988
    },
    {
      "epoch": 5.14236559139785,
      "grad_norm": 0.9331186358772723,
      "learning_rate": 0.00010019512985465533,
      "loss": 0.003,
      "step": 2989
    },
    {
      "epoch": 5.144086021505377,
      "grad_norm": 0.1816995520391828,
      "learning_rate": 0.0001001393785109329,
      "loss": 0.0012,
      "step": 2990
    },
    {
      "epoch": 5.145806451612903,
      "grad_norm": 0.6662905706581796,
      "learning_rate": 0.0001000836271238885,
      "loss": 0.0033,
      "step": 2991
    },
    {
      "epoch": 5.14752688172043,
      "grad_norm": 0.7888329897975016,
      "learning_rate": 0.00010002787571085097,
      "loss": 0.0046,
      "step": 2992
    },
    {
      "epoch": 5.149247311827957,
      "grad_norm": 0.038795585641923126,
      "learning_rate": 9.997212428914904e-05,
      "loss": 0.0002,
      "step": 2993
    },
    {
      "epoch": 5.150967741935484,
      "grad_norm": 0.08341207179700193,
      "learning_rate": 9.99163728761115e-05,
      "loss": 0.0003,
      "step": 2994
    },
    {
      "epoch": 5.15268817204301,
      "grad_norm": 0.5633359467760708,
      "learning_rate": 9.986062148906713e-05,
      "loss": 0.0021,
      "step": 2995
    },
    {
      "epoch": 5.1544086021505375,
      "grad_norm": 0.11620510901188513,
      "learning_rate": 9.980487014534469e-05,
      "loss": 0.0006,
      "step": 2996
    },
    {
      "epoch": 5.156129032258065,
      "grad_norm": 0.09762369890315643,
      "learning_rate": 9.97491188622729e-05,
      "loss": 0.0004,
      "step": 2997
    },
    {
      "epoch": 5.157849462365592,
      "grad_norm": 0.13333052181028154,
      "learning_rate": 9.969336765718052e-05,
      "loss": 0.0004,
      "step": 2998
    },
    {
      "epoch": 5.159569892473118,
      "grad_norm": 0.16760787463957522,
      "learning_rate": 9.963761654739625e-05,
      "loss": 0.0005,
      "step": 2999
    },
    {
      "epoch": 5.161290322580645,
      "grad_norm": 0.005638967502077688,
      "learning_rate": 9.958186555024879e-05,
      "loss": 0.0001,
      "step": 3000
    },
    {
      "epoch": 5.163010752688172,
      "grad_norm": 0.6397929714947289,
      "learning_rate": 9.952611468306672e-05,
      "loss": 0.0018,
      "step": 3001
    },
    {
      "epoch": 5.164731182795699,
      "grad_norm": 0.10676430830749127,
      "learning_rate": 9.947036396317865e-05,
      "loss": 0.0004,
      "step": 3002
    },
    {
      "epoch": 5.166451612903225,
      "grad_norm": 0.4822779380269489,
      "learning_rate": 9.941461340791324e-05,
      "loss": 0.0019,
      "step": 3003
    },
    {
      "epoch": 5.1681720430107525,
      "grad_norm": 0.01979146175703424,
      "learning_rate": 9.93588630345989e-05,
      "loss": 0.0001,
      "step": 3004
    },
    {
      "epoch": 5.16989247311828,
      "grad_norm": 0.21804952595580818,
      "learning_rate": 9.930311286056408e-05,
      "loss": 0.0008,
      "step": 3005
    },
    {
      "epoch": 5.171612903225807,
      "grad_norm": 0.8456901331109961,
      "learning_rate": 9.92473629031372e-05,
      "loss": 0.0142,
      "step": 3006
    },
    {
      "epoch": 5.173333333333334,
      "grad_norm": 2.0087650149580543,
      "learning_rate": 9.919161317964658e-05,
      "loss": 0.0141,
      "step": 3007
    },
    {
      "epoch": 5.17505376344086,
      "grad_norm": 0.04719499107402836,
      "learning_rate": 9.913586370742044e-05,
      "loss": 0.0003,
      "step": 3008
    },
    {
      "epoch": 5.176774193548387,
      "grad_norm": 0.08987552569493962,
      "learning_rate": 9.908011450378695e-05,
      "loss": 0.0006,
      "step": 3009
    },
    {
      "epoch": 5.178494623655914,
      "grad_norm": 1.1499082735230928,
      "learning_rate": 9.90243655860742e-05,
      "loss": 0.0083,
      "step": 3010
    },
    {
      "epoch": 5.180215053763441,
      "grad_norm": 0.02661614314839564,
      "learning_rate": 9.896861697161017e-05,
      "loss": 0.0002,
      "step": 3011
    },
    {
      "epoch": 5.1819354838709675,
      "grad_norm": 0.42719461358240773,
      "learning_rate": 9.89128686777228e-05,
      "loss": 0.0021,
      "step": 3012
    },
    {
      "epoch": 5.183655913978495,
      "grad_norm": 0.4052082784894719,
      "learning_rate": 9.88571207217399e-05,
      "loss": 0.0016,
      "step": 3013
    },
    {
      "epoch": 5.185376344086022,
      "grad_norm": 0.2716739346181649,
      "learning_rate": 9.880137312098912e-05,
      "loss": 0.0005,
      "step": 3014
    },
    {
      "epoch": 5.187096774193549,
      "grad_norm": 1.0349621187390816,
      "learning_rate": 9.874562589279807e-05,
      "loss": 0.0244,
      "step": 3015
    },
    {
      "epoch": 5.188817204301075,
      "grad_norm": 0.4057090263825825,
      "learning_rate": 9.868987905449421e-05,
      "loss": 0.0014,
      "step": 3016
    },
    {
      "epoch": 5.190537634408602,
      "grad_norm": 0.04429262387763198,
      "learning_rate": 9.863413262340491e-05,
      "loss": 0.0002,
      "step": 3017
    },
    {
      "epoch": 5.192258064516129,
      "grad_norm": 0.03484008924183855,
      "learning_rate": 9.857838661685737e-05,
      "loss": 0.0002,
      "step": 3018
    },
    {
      "epoch": 5.193978494623656,
      "grad_norm": 1.2495255259419162,
      "learning_rate": 9.852264105217868e-05,
      "loss": 0.0059,
      "step": 3019
    },
    {
      "epoch": 5.1956989247311824,
      "grad_norm": 0.990900590519359,
      "learning_rate": 9.84668959466958e-05,
      "loss": 0.0033,
      "step": 3020
    },
    {
      "epoch": 5.1974193548387095,
      "grad_norm": 0.6343907988738167,
      "learning_rate": 9.841115131773555e-05,
      "loss": 0.0029,
      "step": 3021
    },
    {
      "epoch": 5.199139784946237,
      "grad_norm": 0.05268611171020658,
      "learning_rate": 9.835540718262459e-05,
      "loss": 0.0002,
      "step": 3022
    },
    {
      "epoch": 5.200860215053764,
      "grad_norm": 0.7434924836273594,
      "learning_rate": 9.829966355868944e-05,
      "loss": 0.0061,
      "step": 3023
    },
    {
      "epoch": 5.20258064516129,
      "grad_norm": 0.0367331886419142,
      "learning_rate": 9.824392046325644e-05,
      "loss": 0.0002,
      "step": 3024
    },
    {
      "epoch": 5.204301075268817,
      "grad_norm": 0.011577883762081525,
      "learning_rate": 9.818817791365176e-05,
      "loss": 0.0001,
      "step": 3025
    },
    {
      "epoch": 5.206021505376344,
      "grad_norm": 0.24419566859417166,
      "learning_rate": 9.813243592720144e-05,
      "loss": 0.001,
      "step": 3026
    },
    {
      "epoch": 5.207741935483871,
      "grad_norm": 1.2141057746094783,
      "learning_rate": 9.80766945212313e-05,
      "loss": 0.0065,
      "step": 3027
    },
    {
      "epoch": 5.209462365591397,
      "grad_norm": 0.1911236774297643,
      "learning_rate": 9.802095371306703e-05,
      "loss": 0.0009,
      "step": 3028
    },
    {
      "epoch": 5.2111827956989245,
      "grad_norm": 0.02273984112921889,
      "learning_rate": 9.796521352003403e-05,
      "loss": 0.0002,
      "step": 3029
    },
    {
      "epoch": 5.212903225806452,
      "grad_norm": 1.973411706117025,
      "learning_rate": 9.79094739594577e-05,
      "loss": 0.0075,
      "step": 3030
    },
    {
      "epoch": 5.214623655913979,
      "grad_norm": 0.13871633671343994,
      "learning_rate": 9.785373504866304e-05,
      "loss": 0.0005,
      "step": 3031
    },
    {
      "epoch": 5.216344086021506,
      "grad_norm": 0.004272316428985921,
      "learning_rate": 9.779799680497497e-05,
      "loss": 0.0,
      "step": 3032
    },
    {
      "epoch": 5.218064516129032,
      "grad_norm": 0.7720518149065031,
      "learning_rate": 9.774225924571818e-05,
      "loss": 0.0051,
      "step": 3033
    },
    {
      "epoch": 5.219784946236559,
      "grad_norm": 0.03482642380938425,
      "learning_rate": 9.768652238821711e-05,
      "loss": 0.0002,
      "step": 3034
    },
    {
      "epoch": 5.221505376344086,
      "grad_norm": 0.45088485559904246,
      "learning_rate": 9.763078624979602e-05,
      "loss": 0.0015,
      "step": 3035
    },
    {
      "epoch": 5.223225806451613,
      "grad_norm": 0.5640055140053443,
      "learning_rate": 9.757505084777891e-05,
      "loss": 0.0034,
      "step": 3036
    },
    {
      "epoch": 5.2249462365591395,
      "grad_norm": 2.5540236660007074,
      "learning_rate": 9.75193161994896e-05,
      "loss": 0.011,
      "step": 3037
    },
    {
      "epoch": 5.226666666666667,
      "grad_norm": 0.7067893745142588,
      "learning_rate": 9.746358232225163e-05,
      "loss": 0.0033,
      "step": 3038
    },
    {
      "epoch": 5.228387096774194,
      "grad_norm": 1.1572823775466974,
      "learning_rate": 9.740784923338833e-05,
      "loss": 0.0092,
      "step": 3039
    },
    {
      "epoch": 5.230107526881721,
      "grad_norm": 0.06981833494079401,
      "learning_rate": 9.735211695022281e-05,
      "loss": 0.0003,
      "step": 3040
    },
    {
      "epoch": 5.231827956989247,
      "grad_norm": 1.8117507680640585,
      "learning_rate": 9.729638549007789e-05,
      "loss": 0.0134,
      "step": 3041
    },
    {
      "epoch": 5.233548387096774,
      "grad_norm": 0.2924479948973929,
      "learning_rate": 9.724065487027606e-05,
      "loss": 0.0017,
      "step": 3042
    },
    {
      "epoch": 5.235268817204301,
      "grad_norm": 0.08520224543555217,
      "learning_rate": 9.718492510813971e-05,
      "loss": 0.0005,
      "step": 3043
    },
    {
      "epoch": 5.236989247311828,
      "grad_norm": 0.7196896038670242,
      "learning_rate": 9.712919622099084e-05,
      "loss": 0.0027,
      "step": 3044
    },
    {
      "epoch": 5.2387096774193544,
      "grad_norm": 0.18649759351729694,
      "learning_rate": 9.707346822615128e-05,
      "loss": 0.0008,
      "step": 3045
    },
    {
      "epoch": 5.2404301075268815,
      "grad_norm": 0.6933004707153819,
      "learning_rate": 9.701774114094244e-05,
      "loss": 0.0065,
      "step": 3046
    },
    {
      "epoch": 5.242150537634409,
      "grad_norm": 2.2824322878111034,
      "learning_rate": 9.696201498268554e-05,
      "loss": 0.0437,
      "step": 3047
    },
    {
      "epoch": 5.243870967741936,
      "grad_norm": 1.2562406823089478,
      "learning_rate": 9.690628976870156e-05,
      "loss": 0.0077,
      "step": 3048
    },
    {
      "epoch": 5.245591397849463,
      "grad_norm": 0.7161061027804548,
      "learning_rate": 9.68505655163111e-05,
      "loss": 0.0019,
      "step": 3049
    },
    {
      "epoch": 5.247311827956989,
      "grad_norm": 0.2551814775090621,
      "learning_rate": 9.679484224283449e-05,
      "loss": 0.0009,
      "step": 3050
    },
    {
      "epoch": 5.249032258064516,
      "grad_norm": 0.22074966353581277,
      "learning_rate": 9.673911996559176e-05,
      "loss": 0.0009,
      "step": 3051
    },
    {
      "epoch": 5.250752688172043,
      "grad_norm": 0.08855721493052865,
      "learning_rate": 9.668339870190261e-05,
      "loss": 0.0004,
      "step": 3052
    },
    {
      "epoch": 5.25247311827957,
      "grad_norm": 0.6439685103803587,
      "learning_rate": 9.662767846908644e-05,
      "loss": 0.0026,
      "step": 3053
    },
    {
      "epoch": 5.2541935483870965,
      "grad_norm": 2.3217810742632063,
      "learning_rate": 9.657195928446234e-05,
      "loss": 0.0175,
      "step": 3054
    },
    {
      "epoch": 5.255913978494624,
      "grad_norm": 0.11776050097752935,
      "learning_rate": 9.651624116534905e-05,
      "loss": 0.0004,
      "step": 3055
    },
    {
      "epoch": 5.257634408602151,
      "grad_norm": 0.04604124132425129,
      "learning_rate": 9.6460524129065e-05,
      "loss": 0.0003,
      "step": 3056
    },
    {
      "epoch": 5.259354838709678,
      "grad_norm": 0.6456060909621122,
      "learning_rate": 9.640480819292829e-05,
      "loss": 0.0046,
      "step": 3057
    },
    {
      "epoch": 5.261075268817204,
      "grad_norm": 0.0427521937125516,
      "learning_rate": 9.634909337425669e-05,
      "loss": 0.0004,
      "step": 3058
    },
    {
      "epoch": 5.262795698924731,
      "grad_norm": 1.5378117539256113,
      "learning_rate": 9.629337969036752e-05,
      "loss": 0.0157,
      "step": 3059
    },
    {
      "epoch": 5.264516129032258,
      "grad_norm": 1.8013295978282622,
      "learning_rate": 9.623766715857789e-05,
      "loss": 0.0216,
      "step": 3060
    },
    {
      "epoch": 5.266236559139785,
      "grad_norm": 1.1084844079858864,
      "learning_rate": 9.618195579620445e-05,
      "loss": 0.007,
      "step": 3061
    },
    {
      "epoch": 5.2679569892473115,
      "grad_norm": 0.9518887539029732,
      "learning_rate": 9.612624562056356e-05,
      "loss": 0.0136,
      "step": 3062
    },
    {
      "epoch": 5.269677419354839,
      "grad_norm": 0.34265039047314794,
      "learning_rate": 9.607053664897112e-05,
      "loss": 0.0014,
      "step": 3063
    },
    {
      "epoch": 5.271397849462366,
      "grad_norm": 2.21249343109921,
      "learning_rate": 9.601482889874275e-05,
      "loss": 0.009,
      "step": 3064
    },
    {
      "epoch": 5.273118279569893,
      "grad_norm": 0.04099697336702548,
      "learning_rate": 9.595912238719361e-05,
      "loss": 0.0004,
      "step": 3065
    },
    {
      "epoch": 5.274838709677419,
      "grad_norm": 2.4476021148151603,
      "learning_rate": 9.590341713163858e-05,
      "loss": 0.0382,
      "step": 3066
    },
    {
      "epoch": 5.276559139784946,
      "grad_norm": 0.03472365906413217,
      "learning_rate": 9.584771314939204e-05,
      "loss": 0.0003,
      "step": 3067
    },
    {
      "epoch": 5.278279569892473,
      "grad_norm": 2.347621019512724,
      "learning_rate": 9.579201045776804e-05,
      "loss": 0.0162,
      "step": 3068
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.7346570425367512,
      "learning_rate": 9.573630907408019e-05,
      "loss": 0.0022,
      "step": 3069
    },
    {
      "epoch": 5.2817204301075265,
      "grad_norm": 0.27386373553818527,
      "learning_rate": 9.56806090156417e-05,
      "loss": 0.0015,
      "step": 3070
    },
    {
      "epoch": 5.2834408602150535,
      "grad_norm": 0.8422931969992221,
      "learning_rate": 9.562491029976541e-05,
      "loss": 0.012,
      "step": 3071
    },
    {
      "epoch": 5.285161290322581,
      "grad_norm": 0.44412011471301993,
      "learning_rate": 9.556921294376369e-05,
      "loss": 0.0021,
      "step": 3072
    },
    {
      "epoch": 5.286881720430108,
      "grad_norm": 0.01146796308367726,
      "learning_rate": 9.551351696494854e-05,
      "loss": 0.0001,
      "step": 3073
    },
    {
      "epoch": 5.288602150537635,
      "grad_norm": 0.5326401730597503,
      "learning_rate": 9.545782238063141e-05,
      "loss": 0.0049,
      "step": 3074
    },
    {
      "epoch": 5.290322580645161,
      "grad_norm": 0.8693005462741243,
      "learning_rate": 9.540212920812355e-05,
      "loss": 0.0064,
      "step": 3075
    },
    {
      "epoch": 5.292043010752688,
      "grad_norm": 0.9374306069261009,
      "learning_rate": 9.534643746473553e-05,
      "loss": 0.0085,
      "step": 3076
    },
    {
      "epoch": 5.293763440860215,
      "grad_norm": 0.4829545258945183,
      "learning_rate": 9.529074716777759e-05,
      "loss": 0.0035,
      "step": 3077
    },
    {
      "epoch": 5.295483870967742,
      "grad_norm": 0.9990859357156041,
      "learning_rate": 9.523505833455953e-05,
      "loss": 0.0096,
      "step": 3078
    },
    {
      "epoch": 5.2972043010752685,
      "grad_norm": 3.1282450554299537,
      "learning_rate": 9.517937098239067e-05,
      "loss": 0.0268,
      "step": 3079
    },
    {
      "epoch": 5.298924731182796,
      "grad_norm": 0.04317315066771101,
      "learning_rate": 9.512368512857984e-05,
      "loss": 0.0004,
      "step": 3080
    },
    {
      "epoch": 5.300645161290323,
      "grad_norm": 0.18576086596083263,
      "learning_rate": 9.506800079043544e-05,
      "loss": 0.0015,
      "step": 3081
    },
    {
      "epoch": 5.30236559139785,
      "grad_norm": 0.21788709109004456,
      "learning_rate": 9.501231798526542e-05,
      "loss": 0.0011,
      "step": 3082
    },
    {
      "epoch": 5.304086021505376,
      "grad_norm": 0.4795123645410986,
      "learning_rate": 9.495663673037715e-05,
      "loss": 0.0047,
      "step": 3083
    },
    {
      "epoch": 5.305806451612903,
      "grad_norm": 0.29077645948655223,
      "learning_rate": 9.490095704307771e-05,
      "loss": 0.0011,
      "step": 3084
    },
    {
      "epoch": 5.30752688172043,
      "grad_norm": 1.6514367365228042,
      "learning_rate": 9.484527894067351e-05,
      "loss": 0.0194,
      "step": 3085
    },
    {
      "epoch": 5.309247311827957,
      "grad_norm": 0.1599706676884347,
      "learning_rate": 9.478960244047056e-05,
      "loss": 0.0011,
      "step": 3086
    },
    {
      "epoch": 5.3109677419354835,
      "grad_norm": 0.4037846973633584,
      "learning_rate": 9.473392755977431e-05,
      "loss": 0.0016,
      "step": 3087
    },
    {
      "epoch": 5.312688172043011,
      "grad_norm": 1.9575287236663592,
      "learning_rate": 9.467825431588978e-05,
      "loss": 0.0073,
      "step": 3088
    },
    {
      "epoch": 5.314408602150538,
      "grad_norm": 0.17731764638221958,
      "learning_rate": 9.462258272612143e-05,
      "loss": 0.0022,
      "step": 3089
    },
    {
      "epoch": 5.316129032258065,
      "grad_norm": 0.22143811422959297,
      "learning_rate": 9.456691280777323e-05,
      "loss": 0.0016,
      "step": 3090
    },
    {
      "epoch": 5.317849462365592,
      "grad_norm": 1.6309092768626783,
      "learning_rate": 9.45112445781486e-05,
      "loss": 0.012,
      "step": 3091
    },
    {
      "epoch": 5.319569892473118,
      "grad_norm": 0.18639054659429385,
      "learning_rate": 9.445557805455045e-05,
      "loss": 0.0019,
      "step": 3092
    },
    {
      "epoch": 5.321290322580645,
      "grad_norm": 0.4743564654723874,
      "learning_rate": 9.43999132542812e-05,
      "loss": 0.0036,
      "step": 3093
    },
    {
      "epoch": 5.323010752688172,
      "grad_norm": 0.2158479328176492,
      "learning_rate": 9.434425019464268e-05,
      "loss": 0.0017,
      "step": 3094
    },
    {
      "epoch": 5.3247311827956985,
      "grad_norm": 1.2837314300383718,
      "learning_rate": 9.428858889293621e-05,
      "loss": 0.0042,
      "step": 3095
    },
    {
      "epoch": 5.3264516129032256,
      "grad_norm": 0.4628456783470557,
      "learning_rate": 9.423292936646257e-05,
      "loss": 0.0042,
      "step": 3096
    },
    {
      "epoch": 5.328172043010753,
      "grad_norm": 0.4027007787140344,
      "learning_rate": 9.417727163252193e-05,
      "loss": 0.0016,
      "step": 3097
    },
    {
      "epoch": 5.32989247311828,
      "grad_norm": 0.6497661907594792,
      "learning_rate": 9.412161570841396e-05,
      "loss": 0.0034,
      "step": 3098
    },
    {
      "epoch": 5.331612903225807,
      "grad_norm": 0.3420144963981522,
      "learning_rate": 9.406596161143774e-05,
      "loss": 0.0014,
      "step": 3099
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.033333967600642,
      "learning_rate": 9.401030935889183e-05,
      "loss": 0.0108,
      "step": 3100
    },
    {
      "epoch": 5.33505376344086,
      "grad_norm": 0.32205479726363506,
      "learning_rate": 9.39546589680741e-05,
      "loss": 0.0027,
      "step": 3101
    },
    {
      "epoch": 5.336774193548387,
      "grad_norm": 0.30857591864908224,
      "learning_rate": 9.389901045628202e-05,
      "loss": 0.0022,
      "step": 3102
    },
    {
      "epoch": 5.338494623655914,
      "grad_norm": 1.087868317920245,
      "learning_rate": 9.384336384081235e-05,
      "loss": 0.013,
      "step": 3103
    },
    {
      "epoch": 5.3402150537634405,
      "grad_norm": 0.07311100783194319,
      "learning_rate": 9.378771913896127e-05,
      "loss": 0.0003,
      "step": 3104
    },
    {
      "epoch": 5.341935483870968,
      "grad_norm": 0.04176565036697586,
      "learning_rate": 9.373207636802437e-05,
      "loss": 0.0004,
      "step": 3105
    },
    {
      "epoch": 5.343655913978495,
      "grad_norm": 0.061884294595019596,
      "learning_rate": 9.367643554529668e-05,
      "loss": 0.0004,
      "step": 3106
    },
    {
      "epoch": 5.345376344086022,
      "grad_norm": 0.03988541252176727,
      "learning_rate": 9.36207966880726e-05,
      "loss": 0.0002,
      "step": 3107
    },
    {
      "epoch": 5.347096774193548,
      "grad_norm": 0.04482720803209186,
      "learning_rate": 9.356515981364588e-05,
      "loss": 0.0003,
      "step": 3108
    },
    {
      "epoch": 5.348817204301075,
      "grad_norm": 0.10260145146535461,
      "learning_rate": 9.350952493930973e-05,
      "loss": 0.0006,
      "step": 3109
    },
    {
      "epoch": 5.350537634408602,
      "grad_norm": 0.708565149494427,
      "learning_rate": 9.345389208235665e-05,
      "loss": 0.0065,
      "step": 3110
    },
    {
      "epoch": 5.352258064516129,
      "grad_norm": 0.243807061623104,
      "learning_rate": 9.339826126007861e-05,
      "loss": 0.0012,
      "step": 3111
    },
    {
      "epoch": 5.3539784946236555,
      "grad_norm": 0.4251878047326302,
      "learning_rate": 9.334263248976689e-05,
      "loss": 0.003,
      "step": 3112
    },
    {
      "epoch": 5.355698924731183,
      "grad_norm": 0.03385413096422346,
      "learning_rate": 9.328700578871215e-05,
      "loss": 0.0003,
      "step": 3113
    },
    {
      "epoch": 5.35741935483871,
      "grad_norm": 0.013521089257299201,
      "learning_rate": 9.323138117420437e-05,
      "loss": 0.0001,
      "step": 3114
    },
    {
      "epoch": 5.359139784946237,
      "grad_norm": 0.043249642991550784,
      "learning_rate": 9.317575866353292e-05,
      "loss": 0.0003,
      "step": 3115
    },
    {
      "epoch": 5.360860215053764,
      "grad_norm": 0.8010016919724061,
      "learning_rate": 9.31201382739865e-05,
      "loss": 0.0028,
      "step": 3116
    },
    {
      "epoch": 5.36258064516129,
      "grad_norm": 0.06556422283229471,
      "learning_rate": 9.306452002285319e-05,
      "loss": 0.0004,
      "step": 3117
    },
    {
      "epoch": 5.364301075268817,
      "grad_norm": 0.321428492779239,
      "learning_rate": 9.300890392742033e-05,
      "loss": 0.0011,
      "step": 3118
    },
    {
      "epoch": 5.366021505376344,
      "grad_norm": 0.13080645802408672,
      "learning_rate": 9.29532900049746e-05,
      "loss": 0.0008,
      "step": 3119
    },
    {
      "epoch": 5.367741935483871,
      "grad_norm": 0.9275804842087169,
      "learning_rate": 9.289767827280214e-05,
      "loss": 0.0071,
      "step": 3120
    },
    {
      "epoch": 5.369462365591398,
      "grad_norm": 0.17261281830339548,
      "learning_rate": 9.284206874818824e-05,
      "loss": 0.0006,
      "step": 3121
    },
    {
      "epoch": 5.371182795698925,
      "grad_norm": 0.46680319049719354,
      "learning_rate": 9.278646144841758e-05,
      "loss": 0.0017,
      "step": 3122
    },
    {
      "epoch": 5.372903225806452,
      "grad_norm": 0.15707807460157677,
      "learning_rate": 9.273085639077415e-05,
      "loss": 0.0011,
      "step": 3123
    },
    {
      "epoch": 5.374623655913979,
      "grad_norm": 0.899695351762947,
      "learning_rate": 9.267525359254122e-05,
      "loss": 0.0056,
      "step": 3124
    },
    {
      "epoch": 5.376344086021505,
      "grad_norm": 0.04151776596335066,
      "learning_rate": 9.261965307100135e-05,
      "loss": 0.0002,
      "step": 3125
    },
    {
      "epoch": 5.378064516129032,
      "grad_norm": 0.07553006468170242,
      "learning_rate": 9.256405484343642e-05,
      "loss": 0.0004,
      "step": 3126
    },
    {
      "epoch": 5.379784946236559,
      "grad_norm": 0.33919716169856967,
      "learning_rate": 9.25084589271276e-05,
      "loss": 0.001,
      "step": 3127
    },
    {
      "epoch": 5.381505376344086,
      "grad_norm": 0.05018186768522819,
      "learning_rate": 9.24528653393553e-05,
      "loss": 0.0002,
      "step": 3128
    },
    {
      "epoch": 5.3832258064516125,
      "grad_norm": 0.09632209592889245,
      "learning_rate": 9.23972740973993e-05,
      "loss": 0.0002,
      "step": 3129
    },
    {
      "epoch": 5.38494623655914,
      "grad_norm": 0.025858905624632292,
      "learning_rate": 9.234168521853854e-05,
      "loss": 0.0003,
      "step": 3130
    },
    {
      "epoch": 5.386666666666667,
      "grad_norm": 0.04359729168524323,
      "learning_rate": 9.228609872005128e-05,
      "loss": 0.0002,
      "step": 3131
    },
    {
      "epoch": 5.388387096774194,
      "grad_norm": 1.094182445787559,
      "learning_rate": 9.223051461921502e-05,
      "loss": 0.0159,
      "step": 3132
    },
    {
      "epoch": 5.390107526881721,
      "grad_norm": 0.35686961399625045,
      "learning_rate": 9.217493293330654e-05,
      "loss": 0.0012,
      "step": 3133
    },
    {
      "epoch": 5.391827956989247,
      "grad_norm": 0.006460032598872262,
      "learning_rate": 9.211935367960189e-05,
      "loss": 0.0,
      "step": 3134
    },
    {
      "epoch": 5.393548387096774,
      "grad_norm": 0.32151730176669463,
      "learning_rate": 9.206377687537625e-05,
      "loss": 0.001,
      "step": 3135
    },
    {
      "epoch": 5.395268817204301,
      "grad_norm": 0.41880588882758013,
      "learning_rate": 9.200820253790419e-05,
      "loss": 0.0017,
      "step": 3136
    },
    {
      "epoch": 5.3969892473118275,
      "grad_norm": 0.39106176350051,
      "learning_rate": 9.195263068445937e-05,
      "loss": 0.0023,
      "step": 3137
    },
    {
      "epoch": 5.398709677419355,
      "grad_norm": 0.25773000147677344,
      "learning_rate": 9.189706133231484e-05,
      "loss": 0.0012,
      "step": 3138
    },
    {
      "epoch": 5.400430107526882,
      "grad_norm": 0.03201654496406939,
      "learning_rate": 9.184149449874273e-05,
      "loss": 0.0001,
      "step": 3139
    },
    {
      "epoch": 5.402150537634409,
      "grad_norm": 2.480564494513269,
      "learning_rate": 9.178593020101446e-05,
      "loss": 0.0275,
      "step": 3140
    },
    {
      "epoch": 5.403870967741936,
      "grad_norm": 0.10656841095472858,
      "learning_rate": 9.173036845640065e-05,
      "loss": 0.0004,
      "step": 3141
    },
    {
      "epoch": 5.405591397849462,
      "grad_norm": 0.01882121701294154,
      "learning_rate": 9.167480928217108e-05,
      "loss": 0.0001,
      "step": 3142
    },
    {
      "epoch": 5.407311827956989,
      "grad_norm": 0.024413570250095752,
      "learning_rate": 9.161925269559479e-05,
      "loss": 0.0002,
      "step": 3143
    },
    {
      "epoch": 5.409032258064516,
      "grad_norm": 0.027416925338399317,
      "learning_rate": 9.156369871394e-05,
      "loss": 0.0002,
      "step": 3144
    },
    {
      "epoch": 5.410752688172043,
      "grad_norm": 0.16347166607235408,
      "learning_rate": 9.150814735447411e-05,
      "loss": 0.0009,
      "step": 3145
    },
    {
      "epoch": 5.41247311827957,
      "grad_norm": 0.6493673274267157,
      "learning_rate": 9.145259863446367e-05,
      "loss": 0.0057,
      "step": 3146
    },
    {
      "epoch": 5.414193548387097,
      "grad_norm": 0.13777412312378956,
      "learning_rate": 9.139705257117455e-05,
      "loss": 0.0007,
      "step": 3147
    },
    {
      "epoch": 5.415913978494624,
      "grad_norm": 0.23004193447936144,
      "learning_rate": 9.134150918187161e-05,
      "loss": 0.0017,
      "step": 3148
    },
    {
      "epoch": 5.417634408602151,
      "grad_norm": 3.1173850741536917,
      "learning_rate": 9.128596848381898e-05,
      "loss": 0.0125,
      "step": 3149
    },
    {
      "epoch": 5.419354838709677,
      "grad_norm": 0.02170256926518614,
      "learning_rate": 9.123043049427995e-05,
      "loss": 0.0001,
      "step": 3150
    },
    {
      "epoch": 5.421075268817204,
      "grad_norm": 0.10269351426820734,
      "learning_rate": 9.117489523051697e-05,
      "loss": 0.0005,
      "step": 3151
    },
    {
      "epoch": 5.422795698924731,
      "grad_norm": 0.055072033950618514,
      "learning_rate": 9.111936270979158e-05,
      "loss": 0.0003,
      "step": 3152
    },
    {
      "epoch": 5.424516129032258,
      "grad_norm": 0.03259329897622712,
      "learning_rate": 9.106383294936456e-05,
      "loss": 0.0002,
      "step": 3153
    },
    {
      "epoch": 5.4262365591397845,
      "grad_norm": 1.918479855144851,
      "learning_rate": 9.100830596649576e-05,
      "loss": 0.0068,
      "step": 3154
    },
    {
      "epoch": 5.427956989247312,
      "grad_norm": 0.05542127768618692,
      "learning_rate": 9.095278177844418e-05,
      "loss": 0.0002,
      "step": 3155
    },
    {
      "epoch": 5.429677419354839,
      "grad_norm": 2.2021220840386024,
      "learning_rate": 9.0897260402468e-05,
      "loss": 0.0079,
      "step": 3156
    },
    {
      "epoch": 5.431397849462366,
      "grad_norm": 0.18295595462093867,
      "learning_rate": 9.084174185582449e-05,
      "loss": 0.0005,
      "step": 3157
    },
    {
      "epoch": 5.433118279569893,
      "grad_norm": 0.03671799068322232,
      "learning_rate": 9.078622615577004e-05,
      "loss": 0.0002,
      "step": 3158
    },
    {
      "epoch": 5.434838709677419,
      "grad_norm": 0.03654672544858557,
      "learning_rate": 9.073071331956011e-05,
      "loss": 0.0001,
      "step": 3159
    },
    {
      "epoch": 5.436559139784946,
      "grad_norm": 1.4081779029164003,
      "learning_rate": 9.067520336444938e-05,
      "loss": 0.0074,
      "step": 3160
    },
    {
      "epoch": 5.438279569892473,
      "grad_norm": 1.3574243192884712,
      "learning_rate": 9.061969630769153e-05,
      "loss": 0.0052,
      "step": 3161
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.010563413551459358,
      "learning_rate": 9.05641921665394e-05,
      "loss": 0.0,
      "step": 3162
    },
    {
      "epoch": 5.441720430107527,
      "grad_norm": 2.9047397641939976,
      "learning_rate": 9.05086909582449e-05,
      "loss": 0.0082,
      "step": 3163
    },
    {
      "epoch": 5.443440860215054,
      "grad_norm": 0.8373956115767001,
      "learning_rate": 9.0453192700059e-05,
      "loss": 0.008,
      "step": 3164
    },
    {
      "epoch": 5.445161290322581,
      "grad_norm": 0.004270543076674923,
      "learning_rate": 9.039769740923183e-05,
      "loss": 0.0,
      "step": 3165
    },
    {
      "epoch": 5.446881720430108,
      "grad_norm": 1.2253182558307434,
      "learning_rate": 9.034220510301253e-05,
      "loss": 0.0339,
      "step": 3166
    },
    {
      "epoch": 5.448602150537634,
      "grad_norm": 1.492138570551796,
      "learning_rate": 9.028671579864935e-05,
      "loss": 0.0096,
      "step": 3167
    },
    {
      "epoch": 5.450322580645161,
      "grad_norm": 0.09489373787043513,
      "learning_rate": 9.023122951338961e-05,
      "loss": 0.0002,
      "step": 3168
    },
    {
      "epoch": 5.452043010752688,
      "grad_norm": 0.04813574945021114,
      "learning_rate": 9.017574626447964e-05,
      "loss": 0.0003,
      "step": 3169
    },
    {
      "epoch": 5.453763440860215,
      "grad_norm": 0.15457152768514787,
      "learning_rate": 9.012026606916484e-05,
      "loss": 0.0009,
      "step": 3170
    },
    {
      "epoch": 5.455483870967742,
      "grad_norm": 1.3440458686075965,
      "learning_rate": 9.006478894468973e-05,
      "loss": 0.0038,
      "step": 3171
    },
    {
      "epoch": 5.457204301075269,
      "grad_norm": 0.2140290837583817,
      "learning_rate": 9.000931490829781e-05,
      "loss": 0.001,
      "step": 3172
    },
    {
      "epoch": 5.458924731182796,
      "grad_norm": 0.07177907220758432,
      "learning_rate": 8.995384397723159e-05,
      "loss": 0.0004,
      "step": 3173
    },
    {
      "epoch": 5.460645161290323,
      "grad_norm": 0.4194656195968973,
      "learning_rate": 8.989837616873272e-05,
      "loss": 0.0025,
      "step": 3174
    },
    {
      "epoch": 5.462365591397849,
      "grad_norm": 1.3256825349907408,
      "learning_rate": 8.984291150004185e-05,
      "loss": 0.0019,
      "step": 3175
    },
    {
      "epoch": 5.464086021505376,
      "grad_norm": 0.06057038625793981,
      "learning_rate": 8.978744998839854e-05,
      "loss": 0.0003,
      "step": 3176
    },
    {
      "epoch": 5.465806451612903,
      "grad_norm": 0.384659570201248,
      "learning_rate": 8.973199165104151e-05,
      "loss": 0.0025,
      "step": 3177
    },
    {
      "epoch": 5.46752688172043,
      "grad_norm": 0.248598442583169,
      "learning_rate": 8.967653650520841e-05,
      "loss": 0.0013,
      "step": 3178
    },
    {
      "epoch": 5.4692473118279565,
      "grad_norm": 0.02582893292500798,
      "learning_rate": 8.962108456813596e-05,
      "loss": 0.0001,
      "step": 3179
    },
    {
      "epoch": 5.470967741935484,
      "grad_norm": 0.15109384568879447,
      "learning_rate": 8.95656358570598e-05,
      "loss": 0.0006,
      "step": 3180
    },
    {
      "epoch": 5.472688172043011,
      "grad_norm": 0.2852535019411315,
      "learning_rate": 8.951019038921464e-05,
      "loss": 0.0012,
      "step": 3181
    },
    {
      "epoch": 5.474408602150538,
      "grad_norm": 0.007651115409568122,
      "learning_rate": 8.945474818183413e-05,
      "loss": 0.0,
      "step": 3182
    },
    {
      "epoch": 5.476129032258065,
      "grad_norm": 1.0025627143187963,
      "learning_rate": 8.939930925215098e-05,
      "loss": 0.0075,
      "step": 3183
    },
    {
      "epoch": 5.477849462365591,
      "grad_norm": 1.636557637198387,
      "learning_rate": 8.934387361739681e-05,
      "loss": 0.005,
      "step": 3184
    },
    {
      "epoch": 5.479569892473118,
      "grad_norm": 0.07611496906160838,
      "learning_rate": 8.928844129480227e-05,
      "loss": 0.0002,
      "step": 3185
    },
    {
      "epoch": 5.481290322580645,
      "grad_norm": 0.033155117227116684,
      "learning_rate": 8.923301230159689e-05,
      "loss": 0.0002,
      "step": 3186
    },
    {
      "epoch": 5.483010752688172,
      "grad_norm": 1.571815012799525,
      "learning_rate": 8.917758665500928e-05,
      "loss": 0.0091,
      "step": 3187
    },
    {
      "epoch": 5.484731182795699,
      "grad_norm": 0.09511069536630963,
      "learning_rate": 8.912216437226693e-05,
      "loss": 0.0006,
      "step": 3188
    },
    {
      "epoch": 5.486451612903226,
      "grad_norm": 1.1546067407941647,
      "learning_rate": 8.906674547059631e-05,
      "loss": 0.0068,
      "step": 3189
    },
    {
      "epoch": 5.488172043010753,
      "grad_norm": 0.5616460883818253,
      "learning_rate": 8.901132996722288e-05,
      "loss": 0.0026,
      "step": 3190
    },
    {
      "epoch": 5.48989247311828,
      "grad_norm": 1.2201008400484257,
      "learning_rate": 8.89559178793709e-05,
      "loss": 0.0141,
      "step": 3191
    },
    {
      "epoch": 5.491612903225806,
      "grad_norm": 0.23600599640134504,
      "learning_rate": 8.890050922426381e-05,
      "loss": 0.0017,
      "step": 3192
    },
    {
      "epoch": 5.493333333333333,
      "grad_norm": 0.320168223881883,
      "learning_rate": 8.884510401912374e-05,
      "loss": 0.0013,
      "step": 3193
    },
    {
      "epoch": 5.49505376344086,
      "grad_norm": 0.08793096493189165,
      "learning_rate": 8.878970228117189e-05,
      "loss": 0.0002,
      "step": 3194
    },
    {
      "epoch": 5.496774193548387,
      "grad_norm": 0.005138034215772159,
      "learning_rate": 8.873430402762836e-05,
      "loss": 0.0,
      "step": 3195
    },
    {
      "epoch": 5.498494623655914,
      "grad_norm": 0.3824840122082431,
      "learning_rate": 8.867890927571215e-05,
      "loss": 0.0017,
      "step": 3196
    },
    {
      "epoch": 5.500215053763441,
      "grad_norm": 0.06074994146541929,
      "learning_rate": 8.862351804264113e-05,
      "loss": 0.0005,
      "step": 3197
    },
    {
      "epoch": 5.501935483870968,
      "grad_norm": 0.14483915536981862,
      "learning_rate": 8.856813034563215e-05,
      "loss": 0.0005,
      "step": 3198
    },
    {
      "epoch": 5.503655913978495,
      "grad_norm": 0.06298087281744737,
      "learning_rate": 8.851274620190092e-05,
      "loss": 0.0003,
      "step": 3199
    },
    {
      "epoch": 5.505376344086022,
      "grad_norm": 0.41652780494669883,
      "learning_rate": 8.845736562866204e-05,
      "loss": 0.0011,
      "step": 3200
    },
    {
      "epoch": 5.507096774193548,
      "grad_norm": 0.05569249302311747,
      "learning_rate": 8.840198864312908e-05,
      "loss": 0.0003,
      "step": 3201
    },
    {
      "epoch": 5.508817204301075,
      "grad_norm": 0.22631561211404885,
      "learning_rate": 8.834661526251441e-05,
      "loss": 0.0016,
      "step": 3202
    },
    {
      "epoch": 5.510537634408602,
      "grad_norm": 0.2552977352770709,
      "learning_rate": 8.829124550402925e-05,
      "loss": 0.0006,
      "step": 3203
    },
    {
      "epoch": 5.5122580645161285,
      "grad_norm": 2.494603823723076,
      "learning_rate": 8.823587938488378e-05,
      "loss": 0.0267,
      "step": 3204
    },
    {
      "epoch": 5.513978494623656,
      "grad_norm": 0.01866975244798185,
      "learning_rate": 8.818051692228701e-05,
      "loss": 0.0002,
      "step": 3205
    },
    {
      "epoch": 5.515698924731183,
      "grad_norm": 1.1137794048700034,
      "learning_rate": 8.812515813344682e-05,
      "loss": 0.0074,
      "step": 3206
    },
    {
      "epoch": 5.51741935483871,
      "grad_norm": 0.05624988817670762,
      "learning_rate": 8.806980303556997e-05,
      "loss": 0.0004,
      "step": 3207
    },
    {
      "epoch": 5.519139784946237,
      "grad_norm": 0.6969931881487765,
      "learning_rate": 8.801445164586199e-05,
      "loss": 0.0036,
      "step": 3208
    },
    {
      "epoch": 5.520860215053763,
      "grad_norm": 0.836213681169245,
      "learning_rate": 8.795910398152732e-05,
      "loss": 0.0029,
      "step": 3209
    },
    {
      "epoch": 5.52258064516129,
      "grad_norm": 1.616129558103795,
      "learning_rate": 8.790376005976927e-05,
      "loss": 0.0211,
      "step": 3210
    },
    {
      "epoch": 5.524301075268817,
      "grad_norm": 0.04031574112614102,
      "learning_rate": 8.784841989778996e-05,
      "loss": 0.0003,
      "step": 3211
    },
    {
      "epoch": 5.526021505376344,
      "grad_norm": 0.023370143221408193,
      "learning_rate": 8.779308351279034e-05,
      "loss": 0.0002,
      "step": 3212
    },
    {
      "epoch": 5.527741935483871,
      "grad_norm": 0.6036954741597067,
      "learning_rate": 8.773775092197017e-05,
      "loss": 0.0042,
      "step": 3213
    },
    {
      "epoch": 5.529462365591398,
      "grad_norm": 0.6781225298775692,
      "learning_rate": 8.768242214252802e-05,
      "loss": 0.0016,
      "step": 3214
    },
    {
      "epoch": 5.531182795698925,
      "grad_norm": 0.3341873952166025,
      "learning_rate": 8.76270971916613e-05,
      "loss": 0.002,
      "step": 3215
    },
    {
      "epoch": 5.532903225806452,
      "grad_norm": 0.5906956970578688,
      "learning_rate": 8.757177608656626e-05,
      "loss": 0.0045,
      "step": 3216
    },
    {
      "epoch": 5.534623655913979,
      "grad_norm": 1.3616194455638526,
      "learning_rate": 8.751645884443792e-05,
      "loss": 0.0095,
      "step": 3217
    },
    {
      "epoch": 5.536344086021505,
      "grad_norm": 0.17199386102121086,
      "learning_rate": 8.746114548246999e-05,
      "loss": 0.0004,
      "step": 3218
    },
    {
      "epoch": 5.538064516129032,
      "grad_norm": 0.22520883665044203,
      "learning_rate": 8.740583601785528e-05,
      "loss": 0.0009,
      "step": 3219
    },
    {
      "epoch": 5.539784946236559,
      "grad_norm": 1.635414426288745,
      "learning_rate": 8.735053046778506e-05,
      "loss": 0.0203,
      "step": 3220
    },
    {
      "epoch": 5.541505376344086,
      "grad_norm": 0.4468363196887869,
      "learning_rate": 8.729522884944956e-05,
      "loss": 0.003,
      "step": 3221
    },
    {
      "epoch": 5.543225806451613,
      "grad_norm": 0.26460353137418996,
      "learning_rate": 8.723993118003772e-05,
      "loss": 0.0016,
      "step": 3222
    },
    {
      "epoch": 5.54494623655914,
      "grad_norm": 0.41277392659289075,
      "learning_rate": 8.71846374767373e-05,
      "loss": 0.0012,
      "step": 3223
    },
    {
      "epoch": 5.546666666666667,
      "grad_norm": 3.1388148278860397,
      "learning_rate": 8.712934775673484e-05,
      "loss": 0.0076,
      "step": 3224
    },
    {
      "epoch": 5.548387096774194,
      "grad_norm": 0.01056233421305461,
      "learning_rate": 8.707406203721553e-05,
      "loss": 0.0001,
      "step": 3225
    },
    {
      "epoch": 5.55010752688172,
      "grad_norm": 0.7168236592044566,
      "learning_rate": 8.701878033536342e-05,
      "loss": 0.0054,
      "step": 3226
    },
    {
      "epoch": 5.551827956989247,
      "grad_norm": 1.1857194522207177,
      "learning_rate": 8.696350266836128e-05,
      "loss": 0.0264,
      "step": 3227
    },
    {
      "epoch": 5.553548387096774,
      "grad_norm": 0.18520918352651253,
      "learning_rate": 8.690822905339069e-05,
      "loss": 0.0004,
      "step": 3228
    },
    {
      "epoch": 5.555268817204301,
      "grad_norm": 1.587674157366511,
      "learning_rate": 8.685295950763184e-05,
      "loss": 0.0113,
      "step": 3229
    },
    {
      "epoch": 5.556989247311828,
      "grad_norm": 1.1038167195865476,
      "learning_rate": 8.679769404826378e-05,
      "loss": 0.0021,
      "step": 3230
    },
    {
      "epoch": 5.558709677419355,
      "grad_norm": 0.04510796109654608,
      "learning_rate": 8.674243269246419e-05,
      "loss": 0.0002,
      "step": 3231
    },
    {
      "epoch": 5.560430107526882,
      "grad_norm": 1.675335249062237,
      "learning_rate": 8.668717545740954e-05,
      "loss": 0.0043,
      "step": 3232
    },
    {
      "epoch": 5.562150537634409,
      "grad_norm": 1.4675938050676232,
      "learning_rate": 8.663192236027501e-05,
      "loss": 0.0068,
      "step": 3233
    },
    {
      "epoch": 5.563870967741935,
      "grad_norm": 0.3674826409898017,
      "learning_rate": 8.657667341823448e-05,
      "loss": 0.0014,
      "step": 3234
    },
    {
      "epoch": 5.565591397849462,
      "grad_norm": 0.15040016431794506,
      "learning_rate": 8.652142864846054e-05,
      "loss": 0.0008,
      "step": 3235
    },
    {
      "epoch": 5.567311827956989,
      "grad_norm": 1.7139136740074894,
      "learning_rate": 8.646618806812441e-05,
      "loss": 0.0062,
      "step": 3236
    },
    {
      "epoch": 5.569032258064516,
      "grad_norm": 1.669862570011615,
      "learning_rate": 8.641095169439623e-05,
      "loss": 0.0045,
      "step": 3237
    },
    {
      "epoch": 5.570752688172043,
      "grad_norm": 0.21931725123735027,
      "learning_rate": 8.635571954444459e-05,
      "loss": 0.0014,
      "step": 3238
    },
    {
      "epoch": 5.57247311827957,
      "grad_norm": 0.21742901414865334,
      "learning_rate": 8.630049163543688e-05,
      "loss": 0.0016,
      "step": 3239
    },
    {
      "epoch": 5.574193548387097,
      "grad_norm": 0.01425879331291501,
      "learning_rate": 8.624526798453917e-05,
      "loss": 0.0001,
      "step": 3240
    },
    {
      "epoch": 5.575913978494624,
      "grad_norm": 1.3280270183086302,
      "learning_rate": 8.619004860891618e-05,
      "loss": 0.0154,
      "step": 3241
    },
    {
      "epoch": 5.577634408602151,
      "grad_norm": 0.39007625088797887,
      "learning_rate": 8.613483352573132e-05,
      "loss": 0.0018,
      "step": 3242
    },
    {
      "epoch": 5.579354838709677,
      "grad_norm": 0.021499196666860152,
      "learning_rate": 8.607962275214663e-05,
      "loss": 0.0001,
      "step": 3243
    },
    {
      "epoch": 5.581075268817204,
      "grad_norm": 0.1742339796798738,
      "learning_rate": 8.602441630532286e-05,
      "loss": 0.0014,
      "step": 3244
    },
    {
      "epoch": 5.582795698924731,
      "grad_norm": 0.028122379442630206,
      "learning_rate": 8.596921420241938e-05,
      "loss": 0.0003,
      "step": 3245
    },
    {
      "epoch": 5.584516129032258,
      "grad_norm": 0.9806275327073645,
      "learning_rate": 8.591401646059424e-05,
      "loss": 0.0083,
      "step": 3246
    },
    {
      "epoch": 5.586236559139785,
      "grad_norm": 1.179738863322695,
      "learning_rate": 8.585882309700417e-05,
      "loss": 0.0069,
      "step": 3247
    },
    {
      "epoch": 5.587956989247312,
      "grad_norm": 0.5978605549515694,
      "learning_rate": 8.580363412880439e-05,
      "loss": 0.0021,
      "step": 3248
    },
    {
      "epoch": 5.589677419354839,
      "grad_norm": 1.4492364440997283,
      "learning_rate": 8.57484495731489e-05,
      "loss": 0.0171,
      "step": 3249
    },
    {
      "epoch": 5.591397849462366,
      "grad_norm": 0.05402219700159583,
      "learning_rate": 8.569326944719026e-05,
      "loss": 0.0003,
      "step": 3250
    },
    {
      "epoch": 5.593118279569892,
      "grad_norm": 0.012094080890235094,
      "learning_rate": 8.563809376807972e-05,
      "loss": 0.0001,
      "step": 3251
    },
    {
      "epoch": 5.594838709677419,
      "grad_norm": 2.171658836345041,
      "learning_rate": 8.558292255296704e-05,
      "loss": 0.0068,
      "step": 3252
    },
    {
      "epoch": 5.596559139784946,
      "grad_norm": 0.9843590773593694,
      "learning_rate": 8.552775581900067e-05,
      "loss": 0.0063,
      "step": 3253
    },
    {
      "epoch": 5.598279569892473,
      "grad_norm": 0.20095441922348414,
      "learning_rate": 8.547259358332766e-05,
      "loss": 0.0016,
      "step": 3254
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.23003746927795185,
      "learning_rate": 8.541743586309365e-05,
      "loss": 0.0013,
      "step": 3255
    },
    {
      "epoch": 5.601720430107527,
      "grad_norm": 0.061692743800393426,
      "learning_rate": 8.53622826754429e-05,
      "loss": 0.0005,
      "step": 3256
    },
    {
      "epoch": 5.603440860215054,
      "grad_norm": 0.7733813985122102,
      "learning_rate": 8.530713403751821e-05,
      "loss": 0.0017,
      "step": 3257
    },
    {
      "epoch": 5.605161290322581,
      "grad_norm": 0.17817804485494584,
      "learning_rate": 8.525198996646102e-05,
      "loss": 0.0005,
      "step": 3258
    },
    {
      "epoch": 5.606881720430108,
      "grad_norm": 0.03405378669125615,
      "learning_rate": 8.51968504794113e-05,
      "loss": 0.0003,
      "step": 3259
    },
    {
      "epoch": 5.608602150537634,
      "grad_norm": 0.8720278432600796,
      "learning_rate": 8.514171559350763e-05,
      "loss": 0.0071,
      "step": 3260
    },
    {
      "epoch": 5.610322580645161,
      "grad_norm": 0.15686295913374515,
      "learning_rate": 8.508658532588716e-05,
      "loss": 0.0008,
      "step": 3261
    },
    {
      "epoch": 5.612043010752688,
      "grad_norm": 0.20670540034698426,
      "learning_rate": 8.503145969368562e-05,
      "loss": 0.0008,
      "step": 3262
    },
    {
      "epoch": 5.613763440860215,
      "grad_norm": 0.9855549615246038,
      "learning_rate": 8.497633871403715e-05,
      "loss": 0.0201,
      "step": 3263
    },
    {
      "epoch": 5.615483870967742,
      "grad_norm": 0.054212765294024814,
      "learning_rate": 8.492122240407475e-05,
      "loss": 0.0004,
      "step": 3264
    },
    {
      "epoch": 5.617204301075269,
      "grad_norm": 0.42942992379598494,
      "learning_rate": 8.486611078092967e-05,
      "loss": 0.0007,
      "step": 3265
    },
    {
      "epoch": 5.618924731182796,
      "grad_norm": 1.4671356029319544,
      "learning_rate": 8.481100386173186e-05,
      "loss": 0.0105,
      "step": 3266
    },
    {
      "epoch": 5.620645161290323,
      "grad_norm": 1.0448524249663758,
      "learning_rate": 8.475590166360975e-05,
      "loss": 0.0068,
      "step": 3267
    },
    {
      "epoch": 5.622365591397849,
      "grad_norm": 0.04464584567631944,
      "learning_rate": 8.470080420369035e-05,
      "loss": 0.0003,
      "step": 3268
    },
    {
      "epoch": 5.624086021505376,
      "grad_norm": 1.3730480171511499,
      "learning_rate": 8.464571149909914e-05,
      "loss": 0.0018,
      "step": 3269
    },
    {
      "epoch": 5.625806451612903,
      "grad_norm": 0.5513114551147459,
      "learning_rate": 8.459062356696015e-05,
      "loss": 0.0026,
      "step": 3270
    },
    {
      "epoch": 5.6275268817204305,
      "grad_norm": 2.048259475447386,
      "learning_rate": 8.453554042439594e-05,
      "loss": 0.0152,
      "step": 3271
    },
    {
      "epoch": 5.629247311827957,
      "grad_norm": 0.9929942765226173,
      "learning_rate": 8.448046208852755e-05,
      "loss": 0.015,
      "step": 3272
    },
    {
      "epoch": 5.630967741935484,
      "grad_norm": 0.18188164938074375,
      "learning_rate": 8.442538857647458e-05,
      "loss": 0.0012,
      "step": 3273
    },
    {
      "epoch": 5.632688172043011,
      "grad_norm": 0.38328132098545675,
      "learning_rate": 8.437031990535506e-05,
      "loss": 0.0021,
      "step": 3274
    },
    {
      "epoch": 5.634408602150538,
      "grad_norm": 0.8905111504699195,
      "learning_rate": 8.431525609228558e-05,
      "loss": 0.0068,
      "step": 3275
    },
    {
      "epoch": 5.636129032258064,
      "grad_norm": 0.7895133012632982,
      "learning_rate": 8.426019715438116e-05,
      "loss": 0.0038,
      "step": 3276
    },
    {
      "epoch": 5.637849462365591,
      "grad_norm": 1.529033491303623,
      "learning_rate": 8.420514310875535e-05,
      "loss": 0.0297,
      "step": 3277
    },
    {
      "epoch": 5.639569892473118,
      "grad_norm": 0.04538187158047868,
      "learning_rate": 8.415009397252017e-05,
      "loss": 0.0001,
      "step": 3278
    },
    {
      "epoch": 5.6412903225806454,
      "grad_norm": 0.014909397207952918,
      "learning_rate": 8.409504976278611e-05,
      "loss": 0.0001,
      "step": 3279
    },
    {
      "epoch": 5.643010752688172,
      "grad_norm": 1.9993013060401326,
      "learning_rate": 8.404001049666211e-05,
      "loss": 0.0086,
      "step": 3280
    },
    {
      "epoch": 5.644731182795699,
      "grad_norm": 1.8771333871873772,
      "learning_rate": 8.398497619125556e-05,
      "loss": 0.0159,
      "step": 3281
    },
    {
      "epoch": 5.646451612903226,
      "grad_norm": 1.321132030262385,
      "learning_rate": 8.392994686367242e-05,
      "loss": 0.0247,
      "step": 3282
    },
    {
      "epoch": 5.648172043010753,
      "grad_norm": 0.23939561272790982,
      "learning_rate": 8.387492253101695e-05,
      "loss": 0.0007,
      "step": 3283
    },
    {
      "epoch": 5.64989247311828,
      "grad_norm": 1.0760611429464486,
      "learning_rate": 8.381990321039198e-05,
      "loss": 0.0057,
      "step": 3284
    },
    {
      "epoch": 5.651612903225806,
      "grad_norm": 0.15913423311254857,
      "learning_rate": 8.376488891889871e-05,
      "loss": 0.0009,
      "step": 3285
    },
    {
      "epoch": 5.653333333333333,
      "grad_norm": 0.14911277077423896,
      "learning_rate": 8.37098796736368e-05,
      "loss": 0.0015,
      "step": 3286
    },
    {
      "epoch": 5.65505376344086,
      "grad_norm": 0.16453368548077055,
      "learning_rate": 8.365487549170432e-05,
      "loss": 0.0008,
      "step": 3287
    },
    {
      "epoch": 5.656774193548387,
      "grad_norm": 0.03293556816131538,
      "learning_rate": 8.35998763901978e-05,
      "loss": 0.0002,
      "step": 3288
    },
    {
      "epoch": 5.658494623655914,
      "grad_norm": 0.5700164405542841,
      "learning_rate": 8.354488238621219e-05,
      "loss": 0.0024,
      "step": 3289
    },
    {
      "epoch": 5.660215053763441,
      "grad_norm": 0.40351777156135,
      "learning_rate": 8.348989349684076e-05,
      "loss": 0.0024,
      "step": 3290
    },
    {
      "epoch": 5.661935483870968,
      "grad_norm": 0.4354907170604423,
      "learning_rate": 8.34349097391754e-05,
      "loss": 0.0017,
      "step": 3291
    },
    {
      "epoch": 5.663655913978495,
      "grad_norm": 0.16871435894892825,
      "learning_rate": 8.337993113030623e-05,
      "loss": 0.0014,
      "step": 3292
    },
    {
      "epoch": 5.665376344086021,
      "grad_norm": 0.2788980788053522,
      "learning_rate": 8.33249576873218e-05,
      "loss": 0.0015,
      "step": 3293
    },
    {
      "epoch": 5.667096774193548,
      "grad_norm": 1.1499499911012314,
      "learning_rate": 8.326998942730906e-05,
      "loss": 0.0033,
      "step": 3294
    },
    {
      "epoch": 5.668817204301075,
      "grad_norm": 0.05682803525338916,
      "learning_rate": 8.321502636735336e-05,
      "loss": 0.0002,
      "step": 3295
    },
    {
      "epoch": 5.6705376344086025,
      "grad_norm": 0.2224882674438634,
      "learning_rate": 8.31600685245385e-05,
      "loss": 0.001,
      "step": 3296
    },
    {
      "epoch": 5.672258064516129,
      "grad_norm": 0.04274680471123506,
      "learning_rate": 8.31051159159465e-05,
      "loss": 0.0003,
      "step": 3297
    },
    {
      "epoch": 5.673978494623656,
      "grad_norm": 0.6645890201407183,
      "learning_rate": 8.30501685586579e-05,
      "loss": 0.0014,
      "step": 3298
    },
    {
      "epoch": 5.675698924731183,
      "grad_norm": 0.36296252329301126,
      "learning_rate": 8.299522646975152e-05,
      "loss": 0.0027,
      "step": 3299
    },
    {
      "epoch": 5.67741935483871,
      "grad_norm": 0.36920635283964853,
      "learning_rate": 8.29402896663046e-05,
      "loss": 0.0017,
      "step": 3300
    },
    {
      "epoch": 5.679139784946237,
      "grad_norm": 0.13636281897522176,
      "learning_rate": 8.288535816539273e-05,
      "loss": 0.0009,
      "step": 3301
    },
    {
      "epoch": 5.680860215053763,
      "grad_norm": 0.5819760128534243,
      "learning_rate": 8.283043198408982e-05,
      "loss": 0.002,
      "step": 3302
    },
    {
      "epoch": 5.68258064516129,
      "grad_norm": 0.05966587506168133,
      "learning_rate": 8.277551113946812e-05,
      "loss": 0.0004,
      "step": 3303
    },
    {
      "epoch": 5.6843010752688174,
      "grad_norm": 0.7877593634514859,
      "learning_rate": 8.272059564859826e-05,
      "loss": 0.0055,
      "step": 3304
    },
    {
      "epoch": 5.686021505376344,
      "grad_norm": 0.2140981055668997,
      "learning_rate": 8.266568552854918e-05,
      "loss": 0.001,
      "step": 3305
    },
    {
      "epoch": 5.687741935483871,
      "grad_norm": 0.11145472261050736,
      "learning_rate": 8.261078079638818e-05,
      "loss": 0.0008,
      "step": 3306
    },
    {
      "epoch": 5.689462365591398,
      "grad_norm": 0.14474097416927456,
      "learning_rate": 8.255588146918083e-05,
      "loss": 0.0004,
      "step": 3307
    },
    {
      "epoch": 5.691182795698925,
      "grad_norm": 0.03534367667921957,
      "learning_rate": 8.250098756399103e-05,
      "loss": 0.0001,
      "step": 3308
    },
    {
      "epoch": 5.692903225806452,
      "grad_norm": 1.994270840029299,
      "learning_rate": 8.244609909788112e-05,
      "loss": 0.0141,
      "step": 3309
    },
    {
      "epoch": 5.694623655913978,
      "grad_norm": 0.8265648630942968,
      "learning_rate": 8.239121608791158e-05,
      "loss": 0.0026,
      "step": 3310
    },
    {
      "epoch": 5.696344086021505,
      "grad_norm": 0.03301307581111143,
      "learning_rate": 8.233633855114127e-05,
      "loss": 0.0001,
      "step": 3311
    },
    {
      "epoch": 5.698064516129032,
      "grad_norm": 0.03808846032429121,
      "learning_rate": 8.228146650462733e-05,
      "loss": 0.0002,
      "step": 3312
    },
    {
      "epoch": 5.6997849462365595,
      "grad_norm": 0.053978799048475516,
      "learning_rate": 8.222659996542525e-05,
      "loss": 0.0003,
      "step": 3313
    },
    {
      "epoch": 5.701505376344086,
      "grad_norm": 0.12844794344227714,
      "learning_rate": 8.217173895058872e-05,
      "loss": 0.0004,
      "step": 3314
    },
    {
      "epoch": 5.703225806451613,
      "grad_norm": 0.010944418617857313,
      "learning_rate": 8.211688347716976e-05,
      "loss": 0.0001,
      "step": 3315
    },
    {
      "epoch": 5.70494623655914,
      "grad_norm": 0.005960429425533268,
      "learning_rate": 8.206203356221867e-05,
      "loss": 0.0,
      "step": 3316
    },
    {
      "epoch": 5.706666666666667,
      "grad_norm": 0.03111146651963956,
      "learning_rate": 8.200718922278398e-05,
      "loss": 0.0002,
      "step": 3317
    },
    {
      "epoch": 5.708387096774193,
      "grad_norm": 0.187064911932932,
      "learning_rate": 8.19523504759126e-05,
      "loss": 0.0004,
      "step": 3318
    },
    {
      "epoch": 5.71010752688172,
      "grad_norm": 0.07435391461333925,
      "learning_rate": 8.189751733864961e-05,
      "loss": 0.0006,
      "step": 3319
    },
    {
      "epoch": 5.711827956989247,
      "grad_norm": 0.09484215831502954,
      "learning_rate": 8.184268982803831e-05,
      "loss": 0.0005,
      "step": 3320
    },
    {
      "epoch": 5.7135483870967745,
      "grad_norm": 1.9709225106880655,
      "learning_rate": 8.178786796112033e-05,
      "loss": 0.0184,
      "step": 3321
    },
    {
      "epoch": 5.715268817204301,
      "grad_norm": 2.2972478415328044,
      "learning_rate": 8.17330517549355e-05,
      "loss": 0.0178,
      "step": 3322
    },
    {
      "epoch": 5.716989247311828,
      "grad_norm": 0.04202137583375398,
      "learning_rate": 8.167824122652195e-05,
      "loss": 0.0001,
      "step": 3323
    },
    {
      "epoch": 5.718709677419355,
      "grad_norm": 0.09375842605261504,
      "learning_rate": 8.162343639291596e-05,
      "loss": 0.0005,
      "step": 3324
    },
    {
      "epoch": 5.720430107526882,
      "grad_norm": 0.06592464945522303,
      "learning_rate": 8.156863727115211e-05,
      "loss": 0.0005,
      "step": 3325
    },
    {
      "epoch": 5.722150537634409,
      "grad_norm": 0.046425518947302874,
      "learning_rate": 8.151384387826313e-05,
      "loss": 0.0005,
      "step": 3326
    },
    {
      "epoch": 5.723870967741935,
      "grad_norm": 0.6234944527528046,
      "learning_rate": 8.14590562312801e-05,
      "loss": 0.0033,
      "step": 3327
    },
    {
      "epoch": 5.725591397849462,
      "grad_norm": 0.033459184713018016,
      "learning_rate": 8.140427434723217e-05,
      "loss": 0.0001,
      "step": 3328
    },
    {
      "epoch": 5.7273118279569895,
      "grad_norm": 0.813695417177705,
      "learning_rate": 8.134949824314678e-05,
      "loss": 0.0018,
      "step": 3329
    },
    {
      "epoch": 5.729032258064516,
      "grad_norm": 1.3644536468636161,
      "learning_rate": 8.129472793604958e-05,
      "loss": 0.0067,
      "step": 3330
    },
    {
      "epoch": 5.730752688172043,
      "grad_norm": 1.5801423949426694,
      "learning_rate": 8.123996344296435e-05,
      "loss": 0.0067,
      "step": 3331
    },
    {
      "epoch": 5.73247311827957,
      "grad_norm": 0.05608815119706756,
      "learning_rate": 8.118520478091311e-05,
      "loss": 0.0002,
      "step": 3332
    },
    {
      "epoch": 5.734193548387097,
      "grad_norm": 0.63055282958255,
      "learning_rate": 8.113045196691607e-05,
      "loss": 0.0142,
      "step": 3333
    },
    {
      "epoch": 5.735913978494624,
      "grad_norm": 0.7059664683491126,
      "learning_rate": 8.107570501799165e-05,
      "loss": 0.0025,
      "step": 3334
    },
    {
      "epoch": 5.73763440860215,
      "grad_norm": 1.0426238654163489,
      "learning_rate": 8.10209639511563e-05,
      "loss": 0.0043,
      "step": 3335
    },
    {
      "epoch": 5.739354838709677,
      "grad_norm": 0.07366721180548991,
      "learning_rate": 8.096622878342491e-05,
      "loss": 0.0002,
      "step": 3336
    },
    {
      "epoch": 5.741075268817204,
      "grad_norm": 0.952279747248321,
      "learning_rate": 8.091149953181027e-05,
      "loss": 0.0027,
      "step": 3337
    },
    {
      "epoch": 5.7427956989247315,
      "grad_norm": 0.011751358075003172,
      "learning_rate": 8.085677621332349e-05,
      "loss": 0.0001,
      "step": 3338
    },
    {
      "epoch": 5.744516129032258,
      "grad_norm": 0.019794507234016323,
      "learning_rate": 8.080205884497375e-05,
      "loss": 0.0001,
      "step": 3339
    },
    {
      "epoch": 5.746236559139785,
      "grad_norm": 0.01563047837013373,
      "learning_rate": 8.074734744376846e-05,
      "loss": 0.0001,
      "step": 3340
    },
    {
      "epoch": 5.747956989247312,
      "grad_norm": 0.15812752359892224,
      "learning_rate": 8.069264202671309e-05,
      "loss": 0.0006,
      "step": 3341
    },
    {
      "epoch": 5.749677419354839,
      "grad_norm": 0.7053490071522198,
      "learning_rate": 8.063794261081133e-05,
      "loss": 0.0033,
      "step": 3342
    },
    {
      "epoch": 5.751397849462365,
      "grad_norm": 0.21583475408125163,
      "learning_rate": 8.058324921306494e-05,
      "loss": 0.0005,
      "step": 3343
    },
    {
      "epoch": 5.753118279569892,
      "grad_norm": 0.042047167657211254,
      "learning_rate": 8.052856185047382e-05,
      "loss": 0.0002,
      "step": 3344
    },
    {
      "epoch": 5.754838709677419,
      "grad_norm": 2.4691229965483554,
      "learning_rate": 8.047388054003607e-05,
      "loss": 0.0209,
      "step": 3345
    },
    {
      "epoch": 5.7565591397849465,
      "grad_norm": 0.12268360295553389,
      "learning_rate": 8.04192052987478e-05,
      "loss": 0.0003,
      "step": 3346
    },
    {
      "epoch": 5.758279569892473,
      "grad_norm": 0.004148238079725288,
      "learning_rate": 8.036453614360333e-05,
      "loss": 0.0,
      "step": 3347
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.06728044873521304,
      "learning_rate": 8.0309873091595e-05,
      "loss": 0.0002,
      "step": 3348
    },
    {
      "epoch": 5.761720430107527,
      "grad_norm": 0.2262772829136518,
      "learning_rate": 8.02552161597133e-05,
      "loss": 0.0004,
      "step": 3349
    },
    {
      "epoch": 5.763440860215054,
      "grad_norm": 0.2326584760925804,
      "learning_rate": 8.020056536494682e-05,
      "loss": 0.0007,
      "step": 3350
    },
    {
      "epoch": 5.765161290322581,
      "grad_norm": 0.057657709250174174,
      "learning_rate": 8.014592072428227e-05,
      "loss": 0.0003,
      "step": 3351
    },
    {
      "epoch": 5.766881720430107,
      "grad_norm": 0.014208939602291167,
      "learning_rate": 8.009128225470429e-05,
      "loss": 0.0,
      "step": 3352
    },
    {
      "epoch": 5.768602150537634,
      "grad_norm": 0.3481404621741555,
      "learning_rate": 8.003664997319589e-05,
      "loss": 0.0016,
      "step": 3353
    },
    {
      "epoch": 5.7703225806451615,
      "grad_norm": 2.427250815149819,
      "learning_rate": 7.99820238967379e-05,
      "loss": 0.0276,
      "step": 3354
    },
    {
      "epoch": 5.7720430107526886,
      "grad_norm": 0.7121012119309992,
      "learning_rate": 7.99274040423093e-05,
      "loss": 0.0023,
      "step": 3355
    },
    {
      "epoch": 5.773763440860215,
      "grad_norm": 0.30699662756937063,
      "learning_rate": 7.987279042688719e-05,
      "loss": 0.0013,
      "step": 3356
    },
    {
      "epoch": 5.775483870967742,
      "grad_norm": 2.61866802780328,
      "learning_rate": 7.981818306744666e-05,
      "loss": 0.0287,
      "step": 3357
    },
    {
      "epoch": 5.777204301075269,
      "grad_norm": 2.1763540044568654,
      "learning_rate": 7.976358198096092e-05,
      "loss": 0.0219,
      "step": 3358
    },
    {
      "epoch": 5.778924731182796,
      "grad_norm": 2.255108663384376,
      "learning_rate": 7.970898718440115e-05,
      "loss": 0.0079,
      "step": 3359
    },
    {
      "epoch": 5.780645161290322,
      "grad_norm": 2.0342185962072894,
      "learning_rate": 7.965439869473664e-05,
      "loss": 0.0105,
      "step": 3360
    },
    {
      "epoch": 5.782365591397849,
      "grad_norm": 0.8413811390590301,
      "learning_rate": 7.959981652893467e-05,
      "loss": 0.0019,
      "step": 3361
    },
    {
      "epoch": 5.784086021505376,
      "grad_norm": 0.3517690084890276,
      "learning_rate": 7.954524070396064e-05,
      "loss": 0.0006,
      "step": 3362
    },
    {
      "epoch": 5.7858064516129035,
      "grad_norm": 2.24856532183835,
      "learning_rate": 7.94906712367779e-05,
      "loss": 0.0064,
      "step": 3363
    },
    {
      "epoch": 5.78752688172043,
      "grad_norm": 0.8313510977108235,
      "learning_rate": 7.943610814434784e-05,
      "loss": 0.0039,
      "step": 3364
    },
    {
      "epoch": 5.789247311827957,
      "grad_norm": 0.3834337320065259,
      "learning_rate": 7.938155144362986e-05,
      "loss": 0.0021,
      "step": 3365
    },
    {
      "epoch": 5.790967741935484,
      "grad_norm": 0.9264489726383328,
      "learning_rate": 7.932700115158143e-05,
      "loss": 0.0054,
      "step": 3366
    },
    {
      "epoch": 5.792688172043011,
      "grad_norm": 4.658869531103978,
      "learning_rate": 7.927245728515794e-05,
      "loss": 0.0157,
      "step": 3367
    },
    {
      "epoch": 5.794408602150538,
      "grad_norm": 2.399987468206031,
      "learning_rate": 7.921791986131286e-05,
      "loss": 0.0072,
      "step": 3368
    },
    {
      "epoch": 5.796129032258064,
      "grad_norm": 0.044863924177861135,
      "learning_rate": 7.916338889699761e-05,
      "loss": 0.0004,
      "step": 3369
    },
    {
      "epoch": 5.797849462365591,
      "grad_norm": 0.20800007612304203,
      "learning_rate": 7.91088644091616e-05,
      "loss": 0.0009,
      "step": 3370
    },
    {
      "epoch": 5.7995698924731185,
      "grad_norm": 1.5047283093137516,
      "learning_rate": 7.905434641475229e-05,
      "loss": 0.0051,
      "step": 3371
    },
    {
      "epoch": 5.801290322580645,
      "grad_norm": 0.4891138202411813,
      "learning_rate": 7.899983493071507e-05,
      "loss": 0.0063,
      "step": 3372
    },
    {
      "epoch": 5.803010752688172,
      "grad_norm": 0.3136055988458547,
      "learning_rate": 7.894532997399329e-05,
      "loss": 0.0007,
      "step": 3373
    },
    {
      "epoch": 5.804731182795699,
      "grad_norm": 0.06367130975308875,
      "learning_rate": 7.889083156152831e-05,
      "loss": 0.0004,
      "step": 3374
    },
    {
      "epoch": 5.806451612903226,
      "grad_norm": 1.1451474847730791,
      "learning_rate": 7.883633971025946e-05,
      "loss": 0.0081,
      "step": 3375
    },
    {
      "epoch": 5.808172043010753,
      "grad_norm": 2.0168712511329834,
      "learning_rate": 7.878185443712398e-05,
      "loss": 0.0078,
      "step": 3376
    },
    {
      "epoch": 5.809892473118279,
      "grad_norm": 0.027957144522664706,
      "learning_rate": 7.87273757590571e-05,
      "loss": 0.0003,
      "step": 3377
    },
    {
      "epoch": 5.811612903225806,
      "grad_norm": 0.2758157202702145,
      "learning_rate": 7.8672903692992e-05,
      "loss": 0.0007,
      "step": 3378
    },
    {
      "epoch": 5.8133333333333335,
      "grad_norm": 0.2630840275979218,
      "learning_rate": 7.861843825585981e-05,
      "loss": 0.0011,
      "step": 3379
    },
    {
      "epoch": 5.815053763440861,
      "grad_norm": 0.0796309911787259,
      "learning_rate": 7.85639794645896e-05,
      "loss": 0.0004,
      "step": 3380
    },
    {
      "epoch": 5.816774193548387,
      "grad_norm": 0.4966272383228884,
      "learning_rate": 7.850952733610836e-05,
      "loss": 0.0161,
      "step": 3381
    },
    {
      "epoch": 5.818494623655914,
      "grad_norm": 0.04355776981457697,
      "learning_rate": 7.8455081887341e-05,
      "loss": 0.0003,
      "step": 3382
    },
    {
      "epoch": 5.820215053763441,
      "grad_norm": 0.34702273479403445,
      "learning_rate": 7.840064313521037e-05,
      "loss": 0.0019,
      "step": 3383
    },
    {
      "epoch": 5.821935483870968,
      "grad_norm": 0.10899595900357247,
      "learning_rate": 7.834621109663725e-05,
      "loss": 0.0006,
      "step": 3384
    },
    {
      "epoch": 5.823655913978494,
      "grad_norm": 0.5659257167114582,
      "learning_rate": 7.829178578854036e-05,
      "loss": 0.0024,
      "step": 3385
    },
    {
      "epoch": 5.825376344086021,
      "grad_norm": 0.057678136408154945,
      "learning_rate": 7.82373672278362e-05,
      "loss": 0.0004,
      "step": 3386
    },
    {
      "epoch": 5.827096774193548,
      "grad_norm": 1.338162518017281,
      "learning_rate": 7.818295543143932e-05,
      "loss": 0.0049,
      "step": 3387
    },
    {
      "epoch": 5.8288172043010755,
      "grad_norm": 3.066109296510897,
      "learning_rate": 7.812855041626206e-05,
      "loss": 0.0163,
      "step": 3388
    },
    {
      "epoch": 5.830537634408602,
      "grad_norm": 0.8033843104023917,
      "learning_rate": 7.807415219921476e-05,
      "loss": 0.0066,
      "step": 3389
    },
    {
      "epoch": 5.832258064516129,
      "grad_norm": 0.02162806152152408,
      "learning_rate": 7.801976079720559e-05,
      "loss": 0.0002,
      "step": 3390
    },
    {
      "epoch": 5.833978494623656,
      "grad_norm": 0.6838386690667894,
      "learning_rate": 7.796537622714055e-05,
      "loss": 0.0024,
      "step": 3391
    },
    {
      "epoch": 5.835698924731183,
      "grad_norm": 0.0008381091948510884,
      "learning_rate": 7.791099850592363e-05,
      "loss": 0.0,
      "step": 3392
    },
    {
      "epoch": 5.83741935483871,
      "grad_norm": 0.3696834048472886,
      "learning_rate": 7.785662765045656e-05,
      "loss": 0.003,
      "step": 3393
    },
    {
      "epoch": 5.839139784946236,
      "grad_norm": 1.8281366170930577,
      "learning_rate": 7.780226367763903e-05,
      "loss": 0.0134,
      "step": 3394
    },
    {
      "epoch": 5.840860215053763,
      "grad_norm": 0.26263556390247783,
      "learning_rate": 7.774790660436858e-05,
      "loss": 0.0011,
      "step": 3395
    },
    {
      "epoch": 5.8425806451612905,
      "grad_norm": 0.7715002940189875,
      "learning_rate": 7.769355644754058e-05,
      "loss": 0.0037,
      "step": 3396
    },
    {
      "epoch": 5.844301075268818,
      "grad_norm": 0.04049656862012433,
      "learning_rate": 7.76392132240482e-05,
      "loss": 0.0002,
      "step": 3397
    },
    {
      "epoch": 5.846021505376344,
      "grad_norm": 0.08773862470751544,
      "learning_rate": 7.758487695078264e-05,
      "loss": 0.0003,
      "step": 3398
    },
    {
      "epoch": 5.847741935483871,
      "grad_norm": 0.0027504369194898907,
      "learning_rate": 7.753054764463272e-05,
      "loss": 0.0,
      "step": 3399
    },
    {
      "epoch": 5.849462365591398,
      "grad_norm": 1.0642497010215508,
      "learning_rate": 7.747622532248521e-05,
      "loss": 0.003,
      "step": 3400
    },
    {
      "epoch": 5.851182795698925,
      "grad_norm": 0.07736840330704799,
      "learning_rate": 7.742191000122471e-05,
      "loss": 0.0006,
      "step": 3401
    },
    {
      "epoch": 5.852903225806451,
      "grad_norm": 0.2812709638631765,
      "learning_rate": 7.736760169773362e-05,
      "loss": 0.0016,
      "step": 3402
    },
    {
      "epoch": 5.854623655913978,
      "grad_norm": 0.022771537532637245,
      "learning_rate": 7.731330042889213e-05,
      "loss": 0.0002,
      "step": 3403
    },
    {
      "epoch": 5.8563440860215055,
      "grad_norm": 1.450920320501037,
      "learning_rate": 7.72590062115783e-05,
      "loss": 0.0051,
      "step": 3404
    },
    {
      "epoch": 5.858064516129033,
      "grad_norm": 0.28073553185463845,
      "learning_rate": 7.720471906266796e-05,
      "loss": 0.0018,
      "step": 3405
    },
    {
      "epoch": 5.859784946236559,
      "grad_norm": 0.8064664224787366,
      "learning_rate": 7.715043899903472e-05,
      "loss": 0.0185,
      "step": 3406
    },
    {
      "epoch": 5.861505376344086,
      "grad_norm": 0.02319434449906607,
      "learning_rate": 7.70961660375501e-05,
      "loss": 0.0002,
      "step": 3407
    },
    {
      "epoch": 5.863225806451613,
      "grad_norm": 0.5268138880093701,
      "learning_rate": 7.704190019508331e-05,
      "loss": 0.0026,
      "step": 3408
    },
    {
      "epoch": 5.86494623655914,
      "grad_norm": 1.3600113099556437,
      "learning_rate": 7.698764148850137e-05,
      "loss": 0.0297,
      "step": 3409
    },
    {
      "epoch": 5.866666666666667,
      "grad_norm": 1.4242146778653886,
      "learning_rate": 7.693338993466907e-05,
      "loss": 0.0067,
      "step": 3410
    },
    {
      "epoch": 5.868387096774193,
      "grad_norm": 0.35457038615063835,
      "learning_rate": 7.687914555044898e-05,
      "loss": 0.002,
      "step": 3411
    },
    {
      "epoch": 5.87010752688172,
      "grad_norm": 0.1893459906547622,
      "learning_rate": 7.682490835270148e-05,
      "loss": 0.0006,
      "step": 3412
    },
    {
      "epoch": 5.8718279569892475,
      "grad_norm": 0.03502348828654675,
      "learning_rate": 7.677067835828473e-05,
      "loss": 0.0002,
      "step": 3413
    },
    {
      "epoch": 5.873548387096774,
      "grad_norm": 0.02705174173418778,
      "learning_rate": 7.671645558405452e-05,
      "loss": 0.0001,
      "step": 3414
    },
    {
      "epoch": 5.875268817204301,
      "grad_norm": 0.28607885295832475,
      "learning_rate": 7.666224004686453e-05,
      "loss": 0.0028,
      "step": 3415
    },
    {
      "epoch": 5.876989247311828,
      "grad_norm": 0.05091584722094717,
      "learning_rate": 7.660803176356615e-05,
      "loss": 0.0001,
      "step": 3416
    },
    {
      "epoch": 5.878709677419355,
      "grad_norm": 0.23602272717215914,
      "learning_rate": 7.655383075100851e-05,
      "loss": 0.0022,
      "step": 3417
    },
    {
      "epoch": 5.880430107526882,
      "grad_norm": 0.6355498108922756,
      "learning_rate": 7.649963702603849e-05,
      "loss": 0.0018,
      "step": 3418
    },
    {
      "epoch": 5.882150537634408,
      "grad_norm": 0.18873978752001916,
      "learning_rate": 7.644545060550071e-05,
      "loss": 0.0009,
      "step": 3419
    },
    {
      "epoch": 5.883870967741935,
      "grad_norm": 0.1934618568744166,
      "learning_rate": 7.639127150623748e-05,
      "loss": 0.0009,
      "step": 3420
    },
    {
      "epoch": 5.8855913978494625,
      "grad_norm": 0.635014929973627,
      "learning_rate": 7.633709974508885e-05,
      "loss": 0.0038,
      "step": 3421
    },
    {
      "epoch": 5.88731182795699,
      "grad_norm": 0.04254048755205169,
      "learning_rate": 7.628293533889264e-05,
      "loss": 0.0002,
      "step": 3422
    },
    {
      "epoch": 5.889032258064516,
      "grad_norm": 1.1296996158861048,
      "learning_rate": 7.622877830448434e-05,
      "loss": 0.0246,
      "step": 3423
    },
    {
      "epoch": 5.890752688172043,
      "grad_norm": 0.5949221173889508,
      "learning_rate": 7.617462865869707e-05,
      "loss": 0.0051,
      "step": 3424
    },
    {
      "epoch": 5.89247311827957,
      "grad_norm": 0.09969726466379605,
      "learning_rate": 7.612048641836186e-05,
      "loss": 0.0006,
      "step": 3425
    },
    {
      "epoch": 5.894193548387097,
      "grad_norm": 0.0037504968774295135,
      "learning_rate": 7.606635160030727e-05,
      "loss": 0.0,
      "step": 3426
    },
    {
      "epoch": 5.895913978494623,
      "grad_norm": 1.3323854226127285,
      "learning_rate": 7.601222422135957e-05,
      "loss": 0.0117,
      "step": 3427
    },
    {
      "epoch": 5.89763440860215,
      "grad_norm": 0.11168733367042152,
      "learning_rate": 7.595810429834277e-05,
      "loss": 0.0005,
      "step": 3428
    },
    {
      "epoch": 5.8993548387096775,
      "grad_norm": 0.1977587948469092,
      "learning_rate": 7.590399184807853e-05,
      "loss": 0.0011,
      "step": 3429
    },
    {
      "epoch": 5.901075268817205,
      "grad_norm": 1.519936851700647,
      "learning_rate": 7.584988688738622e-05,
      "loss": 0.0073,
      "step": 3430
    },
    {
      "epoch": 5.902795698924731,
      "grad_norm": 0.15188058913733402,
      "learning_rate": 7.57957894330828e-05,
      "loss": 0.0012,
      "step": 3431
    },
    {
      "epoch": 5.904516129032258,
      "grad_norm": 1.3314736446624758,
      "learning_rate": 7.5741699501983e-05,
      "loss": 0.0132,
      "step": 3432
    },
    {
      "epoch": 5.906236559139785,
      "grad_norm": 0.02841249674501837,
      "learning_rate": 7.568761711089915e-05,
      "loss": 0.0002,
      "step": 3433
    },
    {
      "epoch": 5.907956989247312,
      "grad_norm": 0.4728822859418144,
      "learning_rate": 7.563354227664126e-05,
      "loss": 0.0041,
      "step": 3434
    },
    {
      "epoch": 5.909677419354839,
      "grad_norm": 1.0381578665393565,
      "learning_rate": 7.557947501601699e-05,
      "loss": 0.0028,
      "step": 3435
    },
    {
      "epoch": 5.911397849462365,
      "grad_norm": 0.021618667888034977,
      "learning_rate": 7.552541534583164e-05,
      "loss": 0.0001,
      "step": 3436
    },
    {
      "epoch": 5.913118279569892,
      "grad_norm": 0.006377371652829451,
      "learning_rate": 7.547136328288814e-05,
      "loss": 0.0,
      "step": 3437
    },
    {
      "epoch": 5.9148387096774195,
      "grad_norm": 0.029011007701972045,
      "learning_rate": 7.541731884398706e-05,
      "loss": 0.0001,
      "step": 3438
    },
    {
      "epoch": 5.916559139784946,
      "grad_norm": 0.05998307334156121,
      "learning_rate": 7.53632820459266e-05,
      "loss": 0.0003,
      "step": 3439
    },
    {
      "epoch": 5.918279569892473,
      "grad_norm": 1.4963550909362202,
      "learning_rate": 7.530925290550266e-05,
      "loss": 0.0156,
      "step": 3440
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.040489521263076554,
      "learning_rate": 7.525523143950859e-05,
      "loss": 0.0001,
      "step": 3441
    },
    {
      "epoch": 5.921720430107527,
      "grad_norm": 0.07781095556599206,
      "learning_rate": 7.520121766473547e-05,
      "loss": 0.0005,
      "step": 3442
    },
    {
      "epoch": 5.923440860215054,
      "grad_norm": 0.1261809653390375,
      "learning_rate": 7.514721159797206e-05,
      "loss": 0.0006,
      "step": 3443
    },
    {
      "epoch": 5.92516129032258,
      "grad_norm": 0.10637429018737965,
      "learning_rate": 7.509321325600456e-05,
      "loss": 0.0006,
      "step": 3444
    },
    {
      "epoch": 5.926881720430107,
      "grad_norm": 0.037873385544566374,
      "learning_rate": 7.50392226556169e-05,
      "loss": 0.0002,
      "step": 3445
    },
    {
      "epoch": 5.9286021505376345,
      "grad_norm": 1.483770788305804,
      "learning_rate": 7.49852398135905e-05,
      "loss": 0.0049,
      "step": 3446
    },
    {
      "epoch": 5.930322580645162,
      "grad_norm": 0.28510332730177745,
      "learning_rate": 7.493126474670449e-05,
      "loss": 0.0005,
      "step": 3447
    },
    {
      "epoch": 5.932043010752688,
      "grad_norm": 2.2059497715206917,
      "learning_rate": 7.487729747173543e-05,
      "loss": 0.0024,
      "step": 3448
    },
    {
      "epoch": 5.933763440860215,
      "grad_norm": 0.03550887353598194,
      "learning_rate": 7.48233380054576e-05,
      "loss": 0.0004,
      "step": 3449
    },
    {
      "epoch": 5.935483870967742,
      "grad_norm": 3.7476035334964024,
      "learning_rate": 7.476938636464276e-05,
      "loss": 0.0198,
      "step": 3450
    },
    {
      "epoch": 5.937204301075269,
      "grad_norm": 0.07675868595618718,
      "learning_rate": 7.471544256606026e-05,
      "loss": 0.0003,
      "step": 3451
    },
    {
      "epoch": 5.938924731182796,
      "grad_norm": 0.7236483809746319,
      "learning_rate": 7.466150662647711e-05,
      "loss": 0.0029,
      "step": 3452
    },
    {
      "epoch": 5.940645161290322,
      "grad_norm": 4.519072956022425,
      "learning_rate": 7.460757856265773e-05,
      "loss": 0.0325,
      "step": 3453
    },
    {
      "epoch": 5.9423655913978495,
      "grad_norm": 0.02785921286610298,
      "learning_rate": 7.455365839136415e-05,
      "loss": 0.0002,
      "step": 3454
    },
    {
      "epoch": 5.944086021505377,
      "grad_norm": 0.05017788756555341,
      "learning_rate": 7.449974612935596e-05,
      "loss": 0.0003,
      "step": 3455
    },
    {
      "epoch": 5.945806451612903,
      "grad_norm": 0.02572845598809879,
      "learning_rate": 7.44458417933903e-05,
      "loss": 0.0002,
      "step": 3456
    },
    {
      "epoch": 5.94752688172043,
      "grad_norm": 0.2711854247115045,
      "learning_rate": 7.439194540022181e-05,
      "loss": 0.0008,
      "step": 3457
    },
    {
      "epoch": 5.949247311827957,
      "grad_norm": 0.05849822798118931,
      "learning_rate": 7.433805696660266e-05,
      "loss": 0.0004,
      "step": 3458
    },
    {
      "epoch": 5.950967741935484,
      "grad_norm": 0.45607177884546685,
      "learning_rate": 7.428417650928261e-05,
      "loss": 0.0031,
      "step": 3459
    },
    {
      "epoch": 5.952688172043011,
      "grad_norm": 0.05208010890956515,
      "learning_rate": 7.423030404500884e-05,
      "loss": 0.0002,
      "step": 3460
    },
    {
      "epoch": 5.954408602150537,
      "grad_norm": 1.1731361944037897,
      "learning_rate": 7.417643959052616e-05,
      "loss": 0.0068,
      "step": 3461
    },
    {
      "epoch": 5.9561290322580644,
      "grad_norm": 1.4742416478730305,
      "learning_rate": 7.412258316257681e-05,
      "loss": 0.0141,
      "step": 3462
    },
    {
      "epoch": 5.9578494623655915,
      "grad_norm": 0.14855853139722694,
      "learning_rate": 7.406873477790058e-05,
      "loss": 0.0009,
      "step": 3463
    },
    {
      "epoch": 5.959569892473119,
      "grad_norm": 1.274810875929716,
      "learning_rate": 7.401489445323473e-05,
      "loss": 0.0057,
      "step": 3464
    },
    {
      "epoch": 5.961290322580645,
      "grad_norm": 0.48610527511912205,
      "learning_rate": 7.396106220531398e-05,
      "loss": 0.0029,
      "step": 3465
    },
    {
      "epoch": 5.963010752688172,
      "grad_norm": 0.4221678109055528,
      "learning_rate": 7.390723805087064e-05,
      "loss": 0.003,
      "step": 3466
    },
    {
      "epoch": 5.964731182795699,
      "grad_norm": 0.023861930589051155,
      "learning_rate": 7.385342200663439e-05,
      "loss": 0.0002,
      "step": 3467
    },
    {
      "epoch": 5.966451612903226,
      "grad_norm": 0.08869747463909085,
      "learning_rate": 7.379961408933252e-05,
      "loss": 0.0004,
      "step": 3468
    },
    {
      "epoch": 5.968172043010752,
      "grad_norm": 3.3532684990130543,
      "learning_rate": 7.374581431568959e-05,
      "loss": 0.0178,
      "step": 3469
    },
    {
      "epoch": 5.969892473118279,
      "grad_norm": 1.6578839522623452,
      "learning_rate": 7.369202270242792e-05,
      "loss": 0.0094,
      "step": 3470
    },
    {
      "epoch": 5.9716129032258065,
      "grad_norm": 0.019209374527957193,
      "learning_rate": 7.363823926626705e-05,
      "loss": 0.0001,
      "step": 3471
    },
    {
      "epoch": 5.973333333333334,
      "grad_norm": 0.2804737484700938,
      "learning_rate": 7.358446402392405e-05,
      "loss": 0.0012,
      "step": 3472
    },
    {
      "epoch": 5.97505376344086,
      "grad_norm": 0.426798691440419,
      "learning_rate": 7.353069699211348e-05,
      "loss": 0.003,
      "step": 3473
    },
    {
      "epoch": 5.976774193548387,
      "grad_norm": 2.8207855756722853,
      "learning_rate": 7.347693818754733e-05,
      "loss": 0.0304,
      "step": 3474
    },
    {
      "epoch": 5.978494623655914,
      "grad_norm": 2.0637582173722766,
      "learning_rate": 7.3423187626935e-05,
      "loss": 0.0337,
      "step": 3475
    },
    {
      "epoch": 5.980215053763441,
      "grad_norm": 2.5615649671868224,
      "learning_rate": 7.336944532698336e-05,
      "loss": 0.005,
      "step": 3476
    },
    {
      "epoch": 5.981935483870968,
      "grad_norm": 0.3210952207585259,
      "learning_rate": 7.331571130439669e-05,
      "loss": 0.0026,
      "step": 3477
    },
    {
      "epoch": 5.983655913978494,
      "grad_norm": 1.6807127748936044,
      "learning_rate": 7.326198557587672e-05,
      "loss": 0.0083,
      "step": 3478
    },
    {
      "epoch": 5.9853763440860215,
      "grad_norm": 0.07354915750653959,
      "learning_rate": 7.320826815812261e-05,
      "loss": 0.0003,
      "step": 3479
    },
    {
      "epoch": 5.987096774193549,
      "grad_norm": 0.04411994368692104,
      "learning_rate": 7.315455906783093e-05,
      "loss": 0.0003,
      "step": 3480
    },
    {
      "epoch": 5.988817204301075,
      "grad_norm": 0.003622044759658601,
      "learning_rate": 7.310085832169565e-05,
      "loss": 0.0001,
      "step": 3481
    },
    {
      "epoch": 5.990537634408602,
      "grad_norm": 0.3213564037582701,
      "learning_rate": 7.304716593640811e-05,
      "loss": 0.0018,
      "step": 3482
    },
    {
      "epoch": 5.992258064516129,
      "grad_norm": 0.044260263339697556,
      "learning_rate": 7.29934819286571e-05,
      "loss": 0.0002,
      "step": 3483
    },
    {
      "epoch": 5.993978494623656,
      "grad_norm": 0.3559126934447213,
      "learning_rate": 7.293980631512883e-05,
      "loss": 0.0006,
      "step": 3484
    },
    {
      "epoch": 5.995698924731183,
      "grad_norm": 0.11569771684158703,
      "learning_rate": 7.288613911250684e-05,
      "loss": 0.0013,
      "step": 3485
    },
    {
      "epoch": 5.997419354838709,
      "grad_norm": 0.7488070859688486,
      "learning_rate": 7.283248033747209e-05,
      "loss": 0.0039,
      "step": 3486
    },
    {
      "epoch": 5.9991397849462365,
      "grad_norm": 0.041410415953793425,
      "learning_rate": 7.27788300067029e-05,
      "loss": 0.0003,
      "step": 3487
    },
    {
      "epoch": 6.0008602150537635,
      "grad_norm": 0.017209365563588885,
      "learning_rate": 7.2725188136875e-05,
      "loss": 0.0002,
      "step": 3488
    },
    {
      "epoch": 6.002580645161291,
      "grad_norm": 0.12734189234873167,
      "learning_rate": 7.267155474466146e-05,
      "loss": 0.0009,
      "step": 3489
    },
    {
      "epoch": 6.004301075268817,
      "grad_norm": 0.11776904547224205,
      "learning_rate": 7.261792984673272e-05,
      "loss": 0.0009,
      "step": 3490
    },
    {
      "epoch": 6.006021505376344,
      "grad_norm": 0.6017051383633997,
      "learning_rate": 7.256431345975661e-05,
      "loss": 0.003,
      "step": 3491
    },
    {
      "epoch": 6.007741935483871,
      "grad_norm": 0.2691708480732593,
      "learning_rate": 7.251070560039824e-05,
      "loss": 0.0011,
      "step": 3492
    },
    {
      "epoch": 6.009462365591398,
      "grad_norm": 0.31713752184766364,
      "learning_rate": 7.245710628532015e-05,
      "loss": 0.0015,
      "step": 3493
    },
    {
      "epoch": 6.011182795698924,
      "grad_norm": 0.6779743316114246,
      "learning_rate": 7.240351553118219e-05,
      "loss": 0.0033,
      "step": 3494
    },
    {
      "epoch": 6.012903225806451,
      "grad_norm": 0.3972497836979425,
      "learning_rate": 7.234993335464153e-05,
      "loss": 0.0041,
      "step": 3495
    },
    {
      "epoch": 6.0146236559139785,
      "grad_norm": 0.006158168321170876,
      "learning_rate": 7.22963597723527e-05,
      "loss": 0.0001,
      "step": 3496
    },
    {
      "epoch": 6.016344086021506,
      "grad_norm": 0.008289016993253935,
      "learning_rate": 7.224279480096758e-05,
      "loss": 0.0001,
      "step": 3497
    },
    {
      "epoch": 6.018064516129032,
      "grad_norm": 0.3028520403521772,
      "learning_rate": 7.218923845713534e-05,
      "loss": 0.0013,
      "step": 3498
    },
    {
      "epoch": 6.019784946236559,
      "grad_norm": 0.0247152781884909,
      "learning_rate": 7.213569075750247e-05,
      "loss": 0.0002,
      "step": 3499
    },
    {
      "epoch": 6.021505376344086,
      "grad_norm": 2.4591458926879577,
      "learning_rate": 7.208215171871277e-05,
      "loss": 0.0064,
      "step": 3500
    },
    {
      "epoch": 6.023225806451613,
      "grad_norm": 0.7846352036619694,
      "learning_rate": 7.202862135740735e-05,
      "loss": 0.0063,
      "step": 3501
    },
    {
      "epoch": 6.02494623655914,
      "grad_norm": 0.047346561567274466,
      "learning_rate": 7.197509969022466e-05,
      "loss": 0.0002,
      "step": 3502
    },
    {
      "epoch": 6.026666666666666,
      "grad_norm": 0.02573574486666772,
      "learning_rate": 7.192158673380038e-05,
      "loss": 0.0001,
      "step": 3503
    },
    {
      "epoch": 6.0283870967741935,
      "grad_norm": 0.1345265783415107,
      "learning_rate": 7.186808250476754e-05,
      "loss": 0.0008,
      "step": 3504
    },
    {
      "epoch": 6.030107526881721,
      "grad_norm": 0.02520605987477509,
      "learning_rate": 7.181458701975641e-05,
      "loss": 0.0001,
      "step": 3505
    },
    {
      "epoch": 6.031827956989248,
      "grad_norm": 0.05809181531420654,
      "learning_rate": 7.176110029539462e-05,
      "loss": 0.0006,
      "step": 3506
    },
    {
      "epoch": 6.033548387096774,
      "grad_norm": 4.7305323833817345,
      "learning_rate": 7.170762234830699e-05,
      "loss": 0.0233,
      "step": 3507
    },
    {
      "epoch": 6.035268817204301,
      "grad_norm": 0.12490006847177443,
      "learning_rate": 7.165415319511567e-05,
      "loss": 0.0003,
      "step": 3508
    },
    {
      "epoch": 6.036989247311828,
      "grad_norm": 0.04436739404945893,
      "learning_rate": 7.160069285244006e-05,
      "loss": 0.0003,
      "step": 3509
    },
    {
      "epoch": 6.038709677419355,
      "grad_norm": 0.21554998037191317,
      "learning_rate": 7.154724133689677e-05,
      "loss": 0.0008,
      "step": 3510
    },
    {
      "epoch": 6.040430107526881,
      "grad_norm": 0.35307688071817994,
      "learning_rate": 7.149379866509974e-05,
      "loss": 0.0008,
      "step": 3511
    },
    {
      "epoch": 6.0421505376344085,
      "grad_norm": 0.907154138139937,
      "learning_rate": 7.144036485366015e-05,
      "loss": 0.0062,
      "step": 3512
    },
    {
      "epoch": 6.0438709677419356,
      "grad_norm": 0.03734696698803467,
      "learning_rate": 7.138693991918638e-05,
      "loss": 0.0003,
      "step": 3513
    },
    {
      "epoch": 6.045591397849463,
      "grad_norm": 0.15269171860961006,
      "learning_rate": 7.133352387828407e-05,
      "loss": 0.0003,
      "step": 3514
    },
    {
      "epoch": 6.047311827956989,
      "grad_norm": 0.03559739233121509,
      "learning_rate": 7.128011674755617e-05,
      "loss": 0.0003,
      "step": 3515
    },
    {
      "epoch": 6.049032258064516,
      "grad_norm": 1.5546853396714884,
      "learning_rate": 7.122671854360275e-05,
      "loss": 0.0077,
      "step": 3516
    },
    {
      "epoch": 6.050752688172043,
      "grad_norm": 0.6236927463111345,
      "learning_rate": 7.117332928302114e-05,
      "loss": 0.0019,
      "step": 3517
    },
    {
      "epoch": 6.05247311827957,
      "grad_norm": 0.18641723800313653,
      "learning_rate": 7.111994898240594e-05,
      "loss": 0.0007,
      "step": 3518
    },
    {
      "epoch": 6.054193548387096,
      "grad_norm": 0.041307655321358654,
      "learning_rate": 7.106657765834892e-05,
      "loss": 0.0003,
      "step": 3519
    },
    {
      "epoch": 6.055913978494623,
      "grad_norm": 0.9278124981619018,
      "learning_rate": 7.101321532743903e-05,
      "loss": 0.0196,
      "step": 3520
    },
    {
      "epoch": 6.0576344086021505,
      "grad_norm": 0.08568481668603672,
      "learning_rate": 7.09598620062625e-05,
      "loss": 0.0005,
      "step": 3521
    },
    {
      "epoch": 6.059354838709678,
      "grad_norm": 0.01821626965843735,
      "learning_rate": 7.090651771140271e-05,
      "loss": 0.0001,
      "step": 3522
    },
    {
      "epoch": 6.061075268817205,
      "grad_norm": 0.17880458426750456,
      "learning_rate": 7.085318245944021e-05,
      "loss": 0.0008,
      "step": 3523
    },
    {
      "epoch": 6.062795698924731,
      "grad_norm": 1.69821310046243,
      "learning_rate": 7.079985626695283e-05,
      "loss": 0.0045,
      "step": 3524
    },
    {
      "epoch": 6.064516129032258,
      "grad_norm": 0.12928286431756467,
      "learning_rate": 7.074653915051552e-05,
      "loss": 0.0008,
      "step": 3525
    },
    {
      "epoch": 6.066236559139785,
      "grad_norm": 0.057996069369524346,
      "learning_rate": 7.069323112670043e-05,
      "loss": 0.0006,
      "step": 3526
    },
    {
      "epoch": 6.067956989247312,
      "grad_norm": 0.11261638878381777,
      "learning_rate": 7.06399322120768e-05,
      "loss": 0.0009,
      "step": 3527
    },
    {
      "epoch": 6.069677419354838,
      "grad_norm": 1.2822626062818219,
      "learning_rate": 7.05866424232112e-05,
      "loss": 0.0054,
      "step": 3528
    },
    {
      "epoch": 6.0713978494623655,
      "grad_norm": 0.016578974080580712,
      "learning_rate": 7.053336177666721e-05,
      "loss": 0.0001,
      "step": 3529
    },
    {
      "epoch": 6.073118279569893,
      "grad_norm": 0.06586929100359402,
      "learning_rate": 7.048009028900569e-05,
      "loss": 0.0005,
      "step": 3530
    },
    {
      "epoch": 6.07483870967742,
      "grad_norm": 0.062040077363342674,
      "learning_rate": 7.042682797678453e-05,
      "loss": 0.0004,
      "step": 3531
    },
    {
      "epoch": 6.076559139784946,
      "grad_norm": 0.05188046230191037,
      "learning_rate": 7.037357485655885e-05,
      "loss": 0.0004,
      "step": 3532
    },
    {
      "epoch": 6.078279569892473,
      "grad_norm": 0.02415205230266562,
      "learning_rate": 7.032033094488095e-05,
      "loss": 0.0001,
      "step": 3533
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.233486829476107,
      "learning_rate": 7.026709625830014e-05,
      "loss": 0.0065,
      "step": 3534
    },
    {
      "epoch": 6.081720430107527,
      "grad_norm": 0.696036535783799,
      "learning_rate": 7.021387081336301e-05,
      "loss": 0.0017,
      "step": 3535
    },
    {
      "epoch": 6.083440860215053,
      "grad_norm": 0.20141070103694933,
      "learning_rate": 7.016065462661318e-05,
      "loss": 0.0007,
      "step": 3536
    },
    {
      "epoch": 6.0851612903225805,
      "grad_norm": 0.1078435125623764,
      "learning_rate": 7.010744771459138e-05,
      "loss": 0.0005,
      "step": 3537
    },
    {
      "epoch": 6.086881720430108,
      "grad_norm": 0.08266829796502519,
      "learning_rate": 7.005425009383552e-05,
      "loss": 0.0006,
      "step": 3538
    },
    {
      "epoch": 6.088602150537635,
      "grad_norm": 0.17992473268769235,
      "learning_rate": 7.00010617808806e-05,
      "loss": 0.0009,
      "step": 3539
    },
    {
      "epoch": 6.090322580645161,
      "grad_norm": 0.03696017257197445,
      "learning_rate": 6.994788279225874e-05,
      "loss": 0.0003,
      "step": 3540
    },
    {
      "epoch": 6.092043010752688,
      "grad_norm": 0.2448101916275722,
      "learning_rate": 6.989471314449907e-05,
      "loss": 0.0008,
      "step": 3541
    },
    {
      "epoch": 6.093763440860215,
      "grad_norm": 0.22235067381768203,
      "learning_rate": 6.9841552854128e-05,
      "loss": 0.0014,
      "step": 3542
    },
    {
      "epoch": 6.095483870967742,
      "grad_norm": 0.13582765413067505,
      "learning_rate": 6.978840193766887e-05,
      "loss": 0.0006,
      "step": 3543
    },
    {
      "epoch": 6.097204301075269,
      "grad_norm": 0.31548625028255617,
      "learning_rate": 6.973526041164213e-05,
      "loss": 0.0015,
      "step": 3544
    },
    {
      "epoch": 6.098924731182795,
      "grad_norm": 0.07864253904863217,
      "learning_rate": 6.96821282925654e-05,
      "loss": 0.0002,
      "step": 3545
    },
    {
      "epoch": 6.1006451612903225,
      "grad_norm": 0.004832232299714298,
      "learning_rate": 6.962900559695327e-05,
      "loss": 0.0,
      "step": 3546
    },
    {
      "epoch": 6.10236559139785,
      "grad_norm": 0.17809307651836848,
      "learning_rate": 6.95758923413175e-05,
      "loss": 0.0009,
      "step": 3547
    },
    {
      "epoch": 6.104086021505377,
      "grad_norm": 0.1275171401854779,
      "learning_rate": 6.952278854216679e-05,
      "loss": 0.0009,
      "step": 3548
    },
    {
      "epoch": 6.105806451612903,
      "grad_norm": 0.007033658952596883,
      "learning_rate": 6.946969421600702e-05,
      "loss": 0.0,
      "step": 3549
    },
    {
      "epoch": 6.10752688172043,
      "grad_norm": 0.03747103539810869,
      "learning_rate": 6.941660937934104e-05,
      "loss": 0.0001,
      "step": 3550
    },
    {
      "epoch": 6.109247311827957,
      "grad_norm": 0.04506890897783832,
      "learning_rate": 6.936353404866886e-05,
      "loss": 0.0002,
      "step": 3551
    },
    {
      "epoch": 6.110967741935484,
      "grad_norm": 0.06290359859539128,
      "learning_rate": 6.931046824048745e-05,
      "loss": 0.0002,
      "step": 3552
    },
    {
      "epoch": 6.11268817204301,
      "grad_norm": 0.2739550739815747,
      "learning_rate": 6.925741197129081e-05,
      "loss": 0.0011,
      "step": 3553
    },
    {
      "epoch": 6.1144086021505375,
      "grad_norm": 0.030541692338670674,
      "learning_rate": 6.920436525757e-05,
      "loss": 0.0001,
      "step": 3554
    },
    {
      "epoch": 6.116129032258065,
      "grad_norm": 0.6387119132659769,
      "learning_rate": 6.915132811581311e-05,
      "loss": 0.0022,
      "step": 3555
    },
    {
      "epoch": 6.117849462365592,
      "grad_norm": 0.016653628920828677,
      "learning_rate": 6.909830056250527e-05,
      "loss": 0.0001,
      "step": 3556
    },
    {
      "epoch": 6.119569892473118,
      "grad_norm": 0.07774167504792275,
      "learning_rate": 6.904528261412862e-05,
      "loss": 0.0002,
      "step": 3557
    },
    {
      "epoch": 6.121290322580645,
      "grad_norm": 0.2748687559370392,
      "learning_rate": 6.89922742871623e-05,
      "loss": 0.0011,
      "step": 3558
    },
    {
      "epoch": 6.123010752688172,
      "grad_norm": 2.4322602949423393,
      "learning_rate": 6.893927559808241e-05,
      "loss": 0.0125,
      "step": 3559
    },
    {
      "epoch": 6.124731182795699,
      "grad_norm": 0.13889009306234978,
      "learning_rate": 6.888628656336225e-05,
      "loss": 0.0007,
      "step": 3560
    },
    {
      "epoch": 6.126451612903226,
      "grad_norm": 0.06523218518862746,
      "learning_rate": 6.883330719947187e-05,
      "loss": 0.0003,
      "step": 3561
    },
    {
      "epoch": 6.1281720430107525,
      "grad_norm": 0.02505462466423833,
      "learning_rate": 6.878033752287846e-05,
      "loss": 0.0002,
      "step": 3562
    },
    {
      "epoch": 6.12989247311828,
      "grad_norm": 0.010404538401677632,
      "learning_rate": 6.87273775500462e-05,
      "loss": 0.0,
      "step": 3563
    },
    {
      "epoch": 6.131612903225807,
      "grad_norm": 0.05437508641202804,
      "learning_rate": 6.867442729743619e-05,
      "loss": 0.0003,
      "step": 3564
    },
    {
      "epoch": 6.133333333333334,
      "grad_norm": 0.05164755770136219,
      "learning_rate": 6.862148678150652e-05,
      "loss": 0.0003,
      "step": 3565
    },
    {
      "epoch": 6.13505376344086,
      "grad_norm": 0.06635393586233802,
      "learning_rate": 6.85685560187123e-05,
      "loss": 0.0002,
      "step": 3566
    },
    {
      "epoch": 6.136774193548387,
      "grad_norm": 0.06991768765478493,
      "learning_rate": 6.851563502550556e-05,
      "loss": 0.0004,
      "step": 3567
    },
    {
      "epoch": 6.138494623655914,
      "grad_norm": 0.019610611287559334,
      "learning_rate": 6.846272381833532e-05,
      "loss": 0.0001,
      "step": 3568
    },
    {
      "epoch": 6.140215053763441,
      "grad_norm": 0.1425042582343777,
      "learning_rate": 6.840982241364757e-05,
      "loss": 0.0007,
      "step": 3569
    },
    {
      "epoch": 6.141935483870967,
      "grad_norm": 0.12910868883032842,
      "learning_rate": 6.835693082788525e-05,
      "loss": 0.0007,
      "step": 3570
    },
    {
      "epoch": 6.1436559139784945,
      "grad_norm": 2.9909019598221525,
      "learning_rate": 6.83040490774882e-05,
      "loss": 0.0188,
      "step": 3571
    },
    {
      "epoch": 6.145376344086022,
      "grad_norm": 3.356155232163719,
      "learning_rate": 6.825117717889323e-05,
      "loss": 0.0057,
      "step": 3572
    },
    {
      "epoch": 6.147096774193549,
      "grad_norm": 0.0010694961268081292,
      "learning_rate": 6.819831514853411e-05,
      "loss": 0.0,
      "step": 3573
    },
    {
      "epoch": 6.148817204301075,
      "grad_norm": 0.1510358670295193,
      "learning_rate": 6.814546300284157e-05,
      "loss": 0.0007,
      "step": 3574
    },
    {
      "epoch": 6.150537634408602,
      "grad_norm": 0.03880167660697935,
      "learning_rate": 6.809262075824315e-05,
      "loss": 0.0002,
      "step": 3575
    },
    {
      "epoch": 6.152258064516129,
      "grad_norm": 0.03442364311037623,
      "learning_rate": 6.80397884311634e-05,
      "loss": 0.0001,
      "step": 3576
    },
    {
      "epoch": 6.153978494623656,
      "grad_norm": 0.030429435341041155,
      "learning_rate": 6.798696603802381e-05,
      "loss": 0.0002,
      "step": 3577
    },
    {
      "epoch": 6.155698924731182,
      "grad_norm": 0.17842680705671876,
      "learning_rate": 6.793415359524273e-05,
      "loss": 0.0007,
      "step": 3578
    },
    {
      "epoch": 6.1574193548387095,
      "grad_norm": 2.466000399582037,
      "learning_rate": 6.788135111923545e-05,
      "loss": 0.0151,
      "step": 3579
    },
    {
      "epoch": 6.159139784946237,
      "grad_norm": 0.02531889288395068,
      "learning_rate": 6.782855862641413e-05,
      "loss": 0.0001,
      "step": 3580
    },
    {
      "epoch": 6.160860215053764,
      "grad_norm": 0.06066702558532993,
      "learning_rate": 6.777577613318786e-05,
      "loss": 0.0002,
      "step": 3581
    },
    {
      "epoch": 6.16258064516129,
      "grad_norm": 0.07727857162947648,
      "learning_rate": 6.772300365596259e-05,
      "loss": 0.0002,
      "step": 3582
    },
    {
      "epoch": 6.164301075268817,
      "grad_norm": 0.04030323221101401,
      "learning_rate": 6.767024121114116e-05,
      "loss": 0.0004,
      "step": 3583
    },
    {
      "epoch": 6.166021505376344,
      "grad_norm": 0.037365223137179576,
      "learning_rate": 6.761748881512333e-05,
      "loss": 0.0001,
      "step": 3584
    },
    {
      "epoch": 6.167741935483871,
      "grad_norm": 0.07048719536309762,
      "learning_rate": 6.756474648430573e-05,
      "loss": 0.0003,
      "step": 3585
    },
    {
      "epoch": 6.169462365591398,
      "grad_norm": 0.020990400491505152,
      "learning_rate": 6.751201423508173e-05,
      "loss": 0.0001,
      "step": 3586
    },
    {
      "epoch": 6.1711827956989245,
      "grad_norm": 0.15022268895003124,
      "learning_rate": 6.745929208384183e-05,
      "loss": 0.0004,
      "step": 3587
    },
    {
      "epoch": 6.172903225806452,
      "grad_norm": 0.35203642004723346,
      "learning_rate": 6.740658004697315e-05,
      "loss": 0.0015,
      "step": 3588
    },
    {
      "epoch": 6.174623655913979,
      "grad_norm": 1.2955093026137643,
      "learning_rate": 6.735387814085978e-05,
      "loss": 0.0042,
      "step": 3589
    },
    {
      "epoch": 6.176344086021506,
      "grad_norm": 0.08949764514707537,
      "learning_rate": 6.730118638188264e-05,
      "loss": 0.0002,
      "step": 3590
    },
    {
      "epoch": 6.178064516129032,
      "grad_norm": 0.04185408041572099,
      "learning_rate": 6.72485047864195e-05,
      "loss": 0.0002,
      "step": 3591
    },
    {
      "epoch": 6.179784946236559,
      "grad_norm": 0.04489000771443959,
      "learning_rate": 6.719583337084493e-05,
      "loss": 0.0002,
      "step": 3592
    },
    {
      "epoch": 6.181505376344086,
      "grad_norm": 0.6278947615642327,
      "learning_rate": 6.714317215153038e-05,
      "loss": 0.0016,
      "step": 3593
    },
    {
      "epoch": 6.183225806451613,
      "grad_norm": 0.24787512084778,
      "learning_rate": 6.709052114484415e-05,
      "loss": 0.0011,
      "step": 3594
    },
    {
      "epoch": 6.184946236559139,
      "grad_norm": 0.05535267302735354,
      "learning_rate": 6.70378803671513e-05,
      "loss": 0.0003,
      "step": 3595
    },
    {
      "epoch": 6.1866666666666665,
      "grad_norm": 0.05367770331062078,
      "learning_rate": 6.698524983481379e-05,
      "loss": 0.0002,
      "step": 3596
    },
    {
      "epoch": 6.188387096774194,
      "grad_norm": 0.12796515321081225,
      "learning_rate": 6.693262956419032e-05,
      "loss": 0.0004,
      "step": 3597
    },
    {
      "epoch": 6.190107526881721,
      "grad_norm": 2.6747265713730983,
      "learning_rate": 6.688001957163646e-05,
      "loss": 0.0224,
      "step": 3598
    },
    {
      "epoch": 6.191827956989247,
      "grad_norm": 0.03133933607211392,
      "learning_rate": 6.682741987350454e-05,
      "loss": 0.0001,
      "step": 3599
    },
    {
      "epoch": 6.193548387096774,
      "grad_norm": 0.17934798083552764,
      "learning_rate": 6.677483048614368e-05,
      "loss": 0.0006,
      "step": 3600
    },
    {
      "epoch": 6.195268817204301,
      "grad_norm": 0.30330693265109965,
      "learning_rate": 6.672225142589988e-05,
      "loss": 0.0009,
      "step": 3601
    },
    {
      "epoch": 6.196989247311828,
      "grad_norm": 0.13310112371228244,
      "learning_rate": 6.666968270911584e-05,
      "loss": 0.0006,
      "step": 3602
    },
    {
      "epoch": 6.198709677419354,
      "grad_norm": 0.1245380912963945,
      "learning_rate": 6.66171243521311e-05,
      "loss": 0.0005,
      "step": 3603
    },
    {
      "epoch": 6.2004301075268815,
      "grad_norm": 0.13942740586972266,
      "learning_rate": 6.65645763712819e-05,
      "loss": 0.0006,
      "step": 3604
    },
    {
      "epoch": 6.202150537634409,
      "grad_norm": 1.903207071794761,
      "learning_rate": 6.651203878290139e-05,
      "loss": 0.0041,
      "step": 3605
    },
    {
      "epoch": 6.203870967741936,
      "grad_norm": 1.044041517652167,
      "learning_rate": 6.645951160331938e-05,
      "loss": 0.0013,
      "step": 3606
    },
    {
      "epoch": 6.205591397849463,
      "grad_norm": 0.02096357322190781,
      "learning_rate": 6.640699484886248e-05,
      "loss": 0.0001,
      "step": 3607
    },
    {
      "epoch": 6.207311827956989,
      "grad_norm": 0.39405178987561873,
      "learning_rate": 6.635448853585409e-05,
      "loss": 0.0012,
      "step": 3608
    },
    {
      "epoch": 6.209032258064516,
      "grad_norm": 0.34276611604215623,
      "learning_rate": 6.630199268061426e-05,
      "loss": 0.0013,
      "step": 3609
    },
    {
      "epoch": 6.210752688172043,
      "grad_norm": 0.48041038442961753,
      "learning_rate": 6.624950729945994e-05,
      "loss": 0.0027,
      "step": 3610
    },
    {
      "epoch": 6.21247311827957,
      "grad_norm": 0.16363267225401093,
      "learning_rate": 6.619703240870467e-05,
      "loss": 0.0009,
      "step": 3611
    },
    {
      "epoch": 6.2141935483870965,
      "grad_norm": 0.131570183857493,
      "learning_rate": 6.61445680246589e-05,
      "loss": 0.0005,
      "step": 3612
    },
    {
      "epoch": 6.215913978494624,
      "grad_norm": 0.00601425309027256,
      "learning_rate": 6.609211416362958e-05,
      "loss": 0.0,
      "step": 3613
    },
    {
      "epoch": 6.217634408602151,
      "grad_norm": 0.0025517655230653585,
      "learning_rate": 6.603967084192066e-05,
      "loss": 0.0,
      "step": 3614
    },
    {
      "epoch": 6.219354838709678,
      "grad_norm": 0.005257643099881424,
      "learning_rate": 6.598723807583268e-05,
      "loss": 0.0,
      "step": 3615
    },
    {
      "epoch": 6.221075268817204,
      "grad_norm": 0.02081329672124768,
      "learning_rate": 6.593481588166283e-05,
      "loss": 0.0001,
      "step": 3616
    },
    {
      "epoch": 6.222795698924731,
      "grad_norm": 0.31655163368760275,
      "learning_rate": 6.58824042757051e-05,
      "loss": 0.0015,
      "step": 3617
    },
    {
      "epoch": 6.224516129032258,
      "grad_norm": 0.03420288077818491,
      "learning_rate": 6.583000327425024e-05,
      "loss": 0.0001,
      "step": 3618
    },
    {
      "epoch": 6.226236559139785,
      "grad_norm": 0.012539870660085725,
      "learning_rate": 6.577761289358558e-05,
      "loss": 0.0,
      "step": 3619
    },
    {
      "epoch": 6.2279569892473114,
      "grad_norm": 0.006624292540032039,
      "learning_rate": 6.572523314999521e-05,
      "loss": 0.0,
      "step": 3620
    },
    {
      "epoch": 6.2296774193548385,
      "grad_norm": 0.818022468378925,
      "learning_rate": 6.567286405975992e-05,
      "loss": 0.0028,
      "step": 3621
    },
    {
      "epoch": 6.231397849462366,
      "grad_norm": 0.004898926134303019,
      "learning_rate": 6.562050563915717e-05,
      "loss": 0.0,
      "step": 3622
    },
    {
      "epoch": 6.233118279569893,
      "grad_norm": 0.02167121051313943,
      "learning_rate": 6.556815790446115e-05,
      "loss": 0.0001,
      "step": 3623
    },
    {
      "epoch": 6.234838709677419,
      "grad_norm": 0.13559546648066656,
      "learning_rate": 6.551582087194266e-05,
      "loss": 0.0005,
      "step": 3624
    },
    {
      "epoch": 6.236559139784946,
      "grad_norm": 0.21937674280691888,
      "learning_rate": 6.546349455786926e-05,
      "loss": 0.0007,
      "step": 3625
    },
    {
      "epoch": 6.238279569892473,
      "grad_norm": 0.3007570230476976,
      "learning_rate": 6.541117897850505e-05,
      "loss": 0.0013,
      "step": 3626
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.2112680213080484,
      "learning_rate": 6.535887415011089e-05,
      "loss": 0.0009,
      "step": 3627
    },
    {
      "epoch": 6.241720430107527,
      "grad_norm": 0.20212441367281112,
      "learning_rate": 6.53065800889443e-05,
      "loss": 0.0008,
      "step": 3628
    },
    {
      "epoch": 6.2434408602150535,
      "grad_norm": 0.050179615273593436,
      "learning_rate": 6.525429681125943e-05,
      "loss": 0.0001,
      "step": 3629
    },
    {
      "epoch": 6.245161290322581,
      "grad_norm": 0.01323919048836139,
      "learning_rate": 6.520202433330706e-05,
      "loss": 0.0,
      "step": 3630
    },
    {
      "epoch": 6.246881720430108,
      "grad_norm": 0.022085079244154406,
      "learning_rate": 6.514976267133461e-05,
      "loss": 0.0001,
      "step": 3631
    },
    {
      "epoch": 6.248602150537635,
      "grad_norm": 0.038175390211517925,
      "learning_rate": 6.509751184158624e-05,
      "loss": 0.0001,
      "step": 3632
    },
    {
      "epoch": 6.250322580645161,
      "grad_norm": 0.006206228463190915,
      "learning_rate": 6.504527186030258e-05,
      "loss": 0.0,
      "step": 3633
    },
    {
      "epoch": 6.252043010752688,
      "grad_norm": 0.0032536917979593396,
      "learning_rate": 6.4993042743721e-05,
      "loss": 0.0,
      "step": 3634
    },
    {
      "epoch": 6.253763440860215,
      "grad_norm": 0.03681628244481378,
      "learning_rate": 6.494082450807546e-05,
      "loss": 0.0001,
      "step": 3635
    },
    {
      "epoch": 6.255483870967742,
      "grad_norm": 0.004034747598357901,
      "learning_rate": 6.488861716959659e-05,
      "loss": 0.0,
      "step": 3636
    },
    {
      "epoch": 6.2572043010752685,
      "grad_norm": 0.014646206162068456,
      "learning_rate": 6.483642074451151e-05,
      "loss": 0.0001,
      "step": 3637
    },
    {
      "epoch": 6.258924731182796,
      "grad_norm": 0.0828403467707228,
      "learning_rate": 6.478423524904405e-05,
      "loss": 0.0002,
      "step": 3638
    },
    {
      "epoch": 6.260645161290323,
      "grad_norm": 0.3877806664872235,
      "learning_rate": 6.473206069941463e-05,
      "loss": 0.0017,
      "step": 3639
    },
    {
      "epoch": 6.26236559139785,
      "grad_norm": 0.13000341400671686,
      "learning_rate": 6.46798971118402e-05,
      "loss": 0.0002,
      "step": 3640
    },
    {
      "epoch": 6.264086021505376,
      "grad_norm": 0.01415316059320924,
      "learning_rate": 6.462774450253444e-05,
      "loss": 0.0,
      "step": 3641
    },
    {
      "epoch": 6.265806451612903,
      "grad_norm": 0.07790702606247245,
      "learning_rate": 6.457560288770751e-05,
      "loss": 0.0003,
      "step": 3642
    },
    {
      "epoch": 6.26752688172043,
      "grad_norm": 0.26479915311964264,
      "learning_rate": 6.452347228356613e-05,
      "loss": 0.0013,
      "step": 3643
    },
    {
      "epoch": 6.269247311827957,
      "grad_norm": 0.0010480751748024114,
      "learning_rate": 6.447135270631369e-05,
      "loss": 0.0,
      "step": 3644
    },
    {
      "epoch": 6.270967741935484,
      "grad_norm": 0.11817830404500031,
      "learning_rate": 6.441924417215006e-05,
      "loss": 0.0004,
      "step": 3645
    },
    {
      "epoch": 6.2726881720430105,
      "grad_norm": 0.08329323099032078,
      "learning_rate": 6.436714669727178e-05,
      "loss": 0.0003,
      "step": 3646
    },
    {
      "epoch": 6.274408602150538,
      "grad_norm": 0.19046253575561797,
      "learning_rate": 6.431506029787189e-05,
      "loss": 0.0005,
      "step": 3647
    },
    {
      "epoch": 6.276129032258065,
      "grad_norm": 0.20107245795615036,
      "learning_rate": 6.426298499013994e-05,
      "loss": 0.0004,
      "step": 3648
    },
    {
      "epoch": 6.277849462365591,
      "grad_norm": 0.010289527132991881,
      "learning_rate": 6.421092079026211e-05,
      "loss": 0.0,
      "step": 3649
    },
    {
      "epoch": 6.279569892473118,
      "grad_norm": 0.031050831812833114,
      "learning_rate": 6.415886771442113e-05,
      "loss": 0.0001,
      "step": 3650
    },
    {
      "epoch": 6.281290322580645,
      "grad_norm": 0.0014491041926045663,
      "learning_rate": 6.410682577879623e-05,
      "loss": 0.0,
      "step": 3651
    },
    {
      "epoch": 6.283010752688172,
      "grad_norm": 0.09828042965830887,
      "learning_rate": 6.405479499956319e-05,
      "loss": 0.0002,
      "step": 3652
    },
    {
      "epoch": 6.284731182795699,
      "grad_norm": 0.02268220746411187,
      "learning_rate": 6.400277539289437e-05,
      "loss": 0.0,
      "step": 3653
    },
    {
      "epoch": 6.2864516129032255,
      "grad_norm": 0.14223133429766305,
      "learning_rate": 6.395076697495854e-05,
      "loss": 0.0005,
      "step": 3654
    },
    {
      "epoch": 6.288172043010753,
      "grad_norm": 0.009666008162398543,
      "learning_rate": 6.38987697619211e-05,
      "loss": 0.0,
      "step": 3655
    },
    {
      "epoch": 6.28989247311828,
      "grad_norm": 0.04241304296653908,
      "learning_rate": 6.384678376994395e-05,
      "loss": 0.0002,
      "step": 3656
    },
    {
      "epoch": 6.291612903225807,
      "grad_norm": 0.016192328502322,
      "learning_rate": 6.379480901518548e-05,
      "loss": 0.0001,
      "step": 3657
    },
    {
      "epoch": 6.293333333333333,
      "grad_norm": 0.09504131402711886,
      "learning_rate": 6.374284551380052e-05,
      "loss": 0.0003,
      "step": 3658
    },
    {
      "epoch": 6.29505376344086,
      "grad_norm": 0.013225403134431187,
      "learning_rate": 6.36908932819406e-05,
      "loss": 0.0001,
      "step": 3659
    },
    {
      "epoch": 6.296774193548387,
      "grad_norm": 0.08677106291751477,
      "learning_rate": 6.363895233575354e-05,
      "loss": 0.0002,
      "step": 3660
    },
    {
      "epoch": 6.298494623655914,
      "grad_norm": 0.013573861387933197,
      "learning_rate": 6.358702269138375e-05,
      "loss": 0.0001,
      "step": 3661
    },
    {
      "epoch": 6.3002150537634405,
      "grad_norm": 0.0018149927554511232,
      "learning_rate": 6.35351043649721e-05,
      "loss": 0.0,
      "step": 3662
    },
    {
      "epoch": 6.301935483870968,
      "grad_norm": 0.006131806051146405,
      "learning_rate": 6.348319737265598e-05,
      "loss": 0.0,
      "step": 3663
    },
    {
      "epoch": 6.303655913978495,
      "grad_norm": 0.0016671611640048836,
      "learning_rate": 6.343130173056924e-05,
      "loss": 0.0,
      "step": 3664
    },
    {
      "epoch": 6.305376344086022,
      "grad_norm": 0.0290988814301382,
      "learning_rate": 6.337941745484216e-05,
      "loss": 0.0001,
      "step": 3665
    },
    {
      "epoch": 6.307096774193548,
      "grad_norm": 0.028074101649674315,
      "learning_rate": 6.33275445616015e-05,
      "loss": 0.0001,
      "step": 3666
    },
    {
      "epoch": 6.308817204301075,
      "grad_norm": 0.02109970563625161,
      "learning_rate": 6.327568306697052e-05,
      "loss": 0.0001,
      "step": 3667
    },
    {
      "epoch": 6.310537634408602,
      "grad_norm": 0.01451861839182961,
      "learning_rate": 6.322383298706897e-05,
      "loss": 0.0001,
      "step": 3668
    },
    {
      "epoch": 6.312258064516129,
      "grad_norm": 0.00742142043536402,
      "learning_rate": 6.317199433801294e-05,
      "loss": 0.0001,
      "step": 3669
    },
    {
      "epoch": 6.313978494623656,
      "grad_norm": 0.0071764158889285725,
      "learning_rate": 6.312016713591509e-05,
      "loss": 0.0,
      "step": 3670
    },
    {
      "epoch": 6.3156989247311826,
      "grad_norm": 0.31976371150665744,
      "learning_rate": 6.306835139688438e-05,
      "loss": 0.0007,
      "step": 3671
    },
    {
      "epoch": 6.31741935483871,
      "grad_norm": 0.005107011862969532,
      "learning_rate": 6.301654713702633e-05,
      "loss": 0.0,
      "step": 3672
    },
    {
      "epoch": 6.319139784946237,
      "grad_norm": 0.0049777408842292935,
      "learning_rate": 6.296475437244285e-05,
      "loss": 0.0,
      "step": 3673
    },
    {
      "epoch": 6.320860215053764,
      "grad_norm": 0.015835725553277374,
      "learning_rate": 6.291297311923227e-05,
      "loss": 0.0001,
      "step": 3674
    },
    {
      "epoch": 6.32258064516129,
      "grad_norm": 0.0029919512266387525,
      "learning_rate": 6.286120339348935e-05,
      "loss": 0.0,
      "step": 3675
    },
    {
      "epoch": 6.324301075268817,
      "grad_norm": 0.0011271130673511237,
      "learning_rate": 6.280944521130523e-05,
      "loss": 0.0,
      "step": 3676
    },
    {
      "epoch": 6.326021505376344,
      "grad_norm": 1.5063115306893737,
      "learning_rate": 6.275769858876757e-05,
      "loss": 0.0025,
      "step": 3677
    },
    {
      "epoch": 6.327741935483871,
      "grad_norm": 0.022281770041017928,
      "learning_rate": 6.270596354196032e-05,
      "loss": 0.0001,
      "step": 3678
    },
    {
      "epoch": 6.3294623655913975,
      "grad_norm": 0.0005135319516811095,
      "learning_rate": 6.265424008696387e-05,
      "loss": 0.0,
      "step": 3679
    },
    {
      "epoch": 6.331182795698925,
      "grad_norm": 0.019003875679438224,
      "learning_rate": 6.260252823985504e-05,
      "loss": 0.0,
      "step": 3680
    },
    {
      "epoch": 6.332903225806452,
      "grad_norm": 0.03480893048134063,
      "learning_rate": 6.2550828016707e-05,
      "loss": 0.0001,
      "step": 3681
    },
    {
      "epoch": 6.334623655913979,
      "grad_norm": 0.007028305357490451,
      "learning_rate": 6.249913943358932e-05,
      "loss": 0.0,
      "step": 3682
    },
    {
      "epoch": 6.336344086021505,
      "grad_norm": 0.17607536422649636,
      "learning_rate": 6.244746250656794e-05,
      "loss": 0.0003,
      "step": 3683
    },
    {
      "epoch": 6.338064516129032,
      "grad_norm": 0.2190913993453104,
      "learning_rate": 6.23957972517052e-05,
      "loss": 0.0006,
      "step": 3684
    },
    {
      "epoch": 6.339784946236559,
      "grad_norm": 0.00878394626048654,
      "learning_rate": 6.23441436850598e-05,
      "loss": 0.0,
      "step": 3685
    },
    {
      "epoch": 6.341505376344086,
      "grad_norm": 0.0022800090468138518,
      "learning_rate": 6.229250182268684e-05,
      "loss": 0.0,
      "step": 3686
    },
    {
      "epoch": 6.3432258064516125,
      "grad_norm": 0.057930111730990365,
      "learning_rate": 6.224087168063775e-05,
      "loss": 0.0002,
      "step": 3687
    },
    {
      "epoch": 6.34494623655914,
      "grad_norm": 0.08867299694018163,
      "learning_rate": 6.218925327496027e-05,
      "loss": 0.0002,
      "step": 3688
    },
    {
      "epoch": 6.346666666666667,
      "grad_norm": 0.018271684644139325,
      "learning_rate": 6.213764662169859e-05,
      "loss": 0.0001,
      "step": 3689
    },
    {
      "epoch": 6.348387096774194,
      "grad_norm": 0.0416643977449451,
      "learning_rate": 6.208605173689317e-05,
      "loss": 0.0001,
      "step": 3690
    },
    {
      "epoch": 6.35010752688172,
      "grad_norm": 0.0010322787528856184,
      "learning_rate": 6.203446863658087e-05,
      "loss": 0.0,
      "step": 3691
    },
    {
      "epoch": 6.351827956989247,
      "grad_norm": 0.028318772512438924,
      "learning_rate": 6.198289733679483e-05,
      "loss": 0.0,
      "step": 3692
    },
    {
      "epoch": 6.353548387096774,
      "grad_norm": 0.008727339008961015,
      "learning_rate": 6.193133785356454e-05,
      "loss": 0.0,
      "step": 3693
    },
    {
      "epoch": 6.355268817204301,
      "grad_norm": 0.1390683347352776,
      "learning_rate": 6.187979020291583e-05,
      "loss": 0.0005,
      "step": 3694
    },
    {
      "epoch": 6.356989247311828,
      "grad_norm": 0.00011853232489535087,
      "learning_rate": 6.18282544008709e-05,
      "loss": 0.0,
      "step": 3695
    },
    {
      "epoch": 6.3587096774193546,
      "grad_norm": 0.046435698808664,
      "learning_rate": 6.177673046344816e-05,
      "loss": 0.0,
      "step": 3696
    },
    {
      "epoch": 6.360430107526882,
      "grad_norm": 0.0010465377853653439,
      "learning_rate": 6.172521840666243e-05,
      "loss": 0.0,
      "step": 3697
    },
    {
      "epoch": 6.362150537634409,
      "grad_norm": 1.9546108479994482,
      "learning_rate": 6.167371824652479e-05,
      "loss": 0.0054,
      "step": 3698
    },
    {
      "epoch": 6.363870967741936,
      "grad_norm": 0.03362124121383196,
      "learning_rate": 6.162222999904258e-05,
      "loss": 0.0001,
      "step": 3699
    },
    {
      "epoch": 6.365591397849462,
      "grad_norm": 1.5963643710187831,
      "learning_rate": 6.157075368021953e-05,
      "loss": 0.0018,
      "step": 3700
    },
    {
      "epoch": 6.367311827956989,
      "grad_norm": 0.00217870902405366,
      "learning_rate": 6.151928930605561e-05,
      "loss": 0.0,
      "step": 3701
    },
    {
      "epoch": 6.369032258064516,
      "grad_norm": 0.0020903584645435673,
      "learning_rate": 6.14678368925471e-05,
      "loss": 0.0,
      "step": 3702
    },
    {
      "epoch": 6.370752688172043,
      "grad_norm": 0.0002746798138030643,
      "learning_rate": 6.141639645568646e-05,
      "loss": 0.0,
      "step": 3703
    },
    {
      "epoch": 6.3724731182795695,
      "grad_norm": 0.007865135155914372,
      "learning_rate": 6.136496801146263e-05,
      "loss": 0.0,
      "step": 3704
    },
    {
      "epoch": 6.374193548387097,
      "grad_norm": 0.02225589512331599,
      "learning_rate": 6.131355157586067e-05,
      "loss": 0.0001,
      "step": 3705
    },
    {
      "epoch": 6.375913978494624,
      "grad_norm": 0.00721538750069658,
      "learning_rate": 6.126214716486192e-05,
      "loss": 0.0,
      "step": 3706
    },
    {
      "epoch": 6.377634408602151,
      "grad_norm": 2.403578075099723,
      "learning_rate": 6.121075479444402e-05,
      "loss": 0.0136,
      "step": 3707
    },
    {
      "epoch": 6.379354838709677,
      "grad_norm": 0.5516664887909994,
      "learning_rate": 6.115937448058089e-05,
      "loss": 0.0015,
      "step": 3708
    },
    {
      "epoch": 6.381075268817204,
      "grad_norm": 0.002319844692151596,
      "learning_rate": 6.11080062392426e-05,
      "loss": 0.0,
      "step": 3709
    },
    {
      "epoch": 6.382795698924731,
      "grad_norm": 1.494325899683065,
      "learning_rate": 6.105665008639557e-05,
      "loss": 0.002,
      "step": 3710
    },
    {
      "epoch": 6.384516129032258,
      "grad_norm": 0.08930052510504612,
      "learning_rate": 6.100530603800243e-05,
      "loss": 0.0001,
      "step": 3711
    },
    {
      "epoch": 6.386236559139785,
      "grad_norm": 0.17031258259257262,
      "learning_rate": 6.095397411002202e-05,
      "loss": 0.0004,
      "step": 3712
    },
    {
      "epoch": 6.387956989247312,
      "grad_norm": 0.009517739453626767,
      "learning_rate": 6.090265431840948e-05,
      "loss": 0.0,
      "step": 3713
    },
    {
      "epoch": 6.389677419354839,
      "grad_norm": 0.34705728248484147,
      "learning_rate": 6.0851346679116116e-05,
      "loss": 0.0004,
      "step": 3714
    },
    {
      "epoch": 6.391397849462366,
      "grad_norm": 0.10868351574447666,
      "learning_rate": 6.080005120808949e-05,
      "loss": 0.0002,
      "step": 3715
    },
    {
      "epoch": 6.393118279569893,
      "grad_norm": 2.3585196144279816,
      "learning_rate": 6.074876792127333e-05,
      "loss": 0.0021,
      "step": 3716
    },
    {
      "epoch": 6.394838709677419,
      "grad_norm": 0.08554313638055189,
      "learning_rate": 6.069749683460765e-05,
      "loss": 0.0002,
      "step": 3717
    },
    {
      "epoch": 6.396559139784946,
      "grad_norm": 0.0004489627070959796,
      "learning_rate": 6.064623796402862e-05,
      "loss": 0.0,
      "step": 3718
    },
    {
      "epoch": 6.398279569892473,
      "grad_norm": 0.1687117098185124,
      "learning_rate": 6.059499132546864e-05,
      "loss": 0.0005,
      "step": 3719
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.008422503236242003,
      "learning_rate": 6.05437569348563e-05,
      "loss": 0.0,
      "step": 3720
    },
    {
      "epoch": 6.401720430107527,
      "grad_norm": 0.5371444969968147,
      "learning_rate": 6.049253480811633e-05,
      "loss": 0.002,
      "step": 3721
    },
    {
      "epoch": 6.403440860215054,
      "grad_norm": 0.004678972792969793,
      "learning_rate": 6.044132496116976e-05,
      "loss": 0.0,
      "step": 3722
    },
    {
      "epoch": 6.405161290322581,
      "grad_norm": 4.13038419510123,
      "learning_rate": 6.039012740993375e-05,
      "loss": 0.0144,
      "step": 3723
    },
    {
      "epoch": 6.406881720430108,
      "grad_norm": 1.7137986952731024,
      "learning_rate": 6.033894217032159e-05,
      "loss": 0.0024,
      "step": 3724
    },
    {
      "epoch": 6.408602150537634,
      "grad_norm": 0.00039016185968582533,
      "learning_rate": 6.028776925824282e-05,
      "loss": 0.0,
      "step": 3725
    },
    {
      "epoch": 6.410322580645161,
      "grad_norm": 0.009200554622078508,
      "learning_rate": 6.023660868960308e-05,
      "loss": 0.0,
      "step": 3726
    },
    {
      "epoch": 6.412043010752688,
      "grad_norm": 0.5386510968423679,
      "learning_rate": 6.0185460480304204e-05,
      "loss": 0.0015,
      "step": 3727
    },
    {
      "epoch": 6.413763440860215,
      "grad_norm": 0.6346428809203442,
      "learning_rate": 6.01343246462442e-05,
      "loss": 0.0022,
      "step": 3728
    },
    {
      "epoch": 6.4154838709677415,
      "grad_norm": 0.04756886281578928,
      "learning_rate": 6.008320120331724e-05,
      "loss": 0.0001,
      "step": 3729
    },
    {
      "epoch": 6.417204301075269,
      "grad_norm": 0.6625633194619619,
      "learning_rate": 6.003209016741354e-05,
      "loss": 0.0013,
      "step": 3730
    },
    {
      "epoch": 6.418924731182796,
      "grad_norm": 0.034540907878786414,
      "learning_rate": 5.998099155441962e-05,
      "loss": 0.0001,
      "step": 3731
    },
    {
      "epoch": 6.420645161290323,
      "grad_norm": 0.00037372436136645773,
      "learning_rate": 5.992990538021806e-05,
      "loss": 0.0,
      "step": 3732
    },
    {
      "epoch": 6.422365591397849,
      "grad_norm": 0.0043402503088240335,
      "learning_rate": 5.9878831660687527e-05,
      "loss": 0.0,
      "step": 3733
    },
    {
      "epoch": 6.424086021505376,
      "grad_norm": 1.783878835110479,
      "learning_rate": 5.9827770411702866e-05,
      "loss": 0.0278,
      "step": 3734
    },
    {
      "epoch": 6.425806451612903,
      "grad_norm": 0.007398468671984591,
      "learning_rate": 5.977672164913506e-05,
      "loss": 0.0,
      "step": 3735
    },
    {
      "epoch": 6.42752688172043,
      "grad_norm": 0.201780410388379,
      "learning_rate": 5.972568538885122e-05,
      "loss": 0.0006,
      "step": 3736
    },
    {
      "epoch": 6.429247311827957,
      "grad_norm": 0.08253160253126202,
      "learning_rate": 5.967466164671448e-05,
      "loss": 0.0001,
      "step": 3737
    },
    {
      "epoch": 6.430967741935484,
      "grad_norm": 0.0018254317012385748,
      "learning_rate": 5.962365043858418e-05,
      "loss": 0.0,
      "step": 3738
    },
    {
      "epoch": 6.432688172043011,
      "grad_norm": 0.0009961562766627615,
      "learning_rate": 5.9572651780315705e-05,
      "loss": 0.0,
      "step": 3739
    },
    {
      "epoch": 6.434408602150538,
      "grad_norm": 0.004145089697315558,
      "learning_rate": 5.952166568776062e-05,
      "loss": 0.0,
      "step": 3740
    },
    {
      "epoch": 6.436129032258065,
      "grad_norm": 1.187732473939576,
      "learning_rate": 5.9470692176766484e-05,
      "loss": 0.0075,
      "step": 3741
    },
    {
      "epoch": 6.437849462365591,
      "grad_norm": 0.7017408366729023,
      "learning_rate": 5.9419731263177034e-05,
      "loss": 0.0057,
      "step": 3742
    },
    {
      "epoch": 6.439569892473118,
      "grad_norm": 1.690763707080548,
      "learning_rate": 5.9368782962832005e-05,
      "loss": 0.0188,
      "step": 3743
    },
    {
      "epoch": 6.441290322580645,
      "grad_norm": 1.1910680109860217,
      "learning_rate": 5.9317847291567265e-05,
      "loss": 0.0093,
      "step": 3744
    },
    {
      "epoch": 6.443010752688172,
      "grad_norm": 0.18582439999507186,
      "learning_rate": 5.926692426521474e-05,
      "loss": 0.0004,
      "step": 3745
    },
    {
      "epoch": 6.444731182795699,
      "grad_norm": 0.007389010074592633,
      "learning_rate": 5.9216013899602474e-05,
      "loss": 0.0,
      "step": 3746
    },
    {
      "epoch": 6.446451612903226,
      "grad_norm": 0.07805759050183289,
      "learning_rate": 5.916511621055449e-05,
      "loss": 0.0003,
      "step": 3747
    },
    {
      "epoch": 6.448172043010753,
      "grad_norm": 0.0048166181834285345,
      "learning_rate": 5.911423121389088e-05,
      "loss": 0.0,
      "step": 3748
    },
    {
      "epoch": 6.44989247311828,
      "grad_norm": 1.4321066539971172,
      "learning_rate": 5.906335892542793e-05,
      "loss": 0.0277,
      "step": 3749
    },
    {
      "epoch": 6.451612903225806,
      "grad_norm": 0.10841074358999932,
      "learning_rate": 5.901249936097779e-05,
      "loss": 0.0005,
      "step": 3750
    },
    {
      "epoch": 6.453333333333333,
      "grad_norm": 0.013106640711095161,
      "learning_rate": 5.8961652536348774e-05,
      "loss": 0.0001,
      "step": 3751
    },
    {
      "epoch": 6.45505376344086,
      "grad_norm": 0.361271661153928,
      "learning_rate": 5.8910818467345185e-05,
      "loss": 0.0011,
      "step": 3752
    },
    {
      "epoch": 6.456774193548387,
      "grad_norm": 4.659499051234591,
      "learning_rate": 5.88599971697674e-05,
      "loss": 0.0224,
      "step": 3753
    },
    {
      "epoch": 6.458494623655914,
      "grad_norm": 0.19947803718586127,
      "learning_rate": 5.880918865941174e-05,
      "loss": 0.0004,
      "step": 3754
    },
    {
      "epoch": 6.460215053763441,
      "grad_norm": 0.06316120333774194,
      "learning_rate": 5.8758392952070665e-05,
      "loss": 0.0001,
      "step": 3755
    },
    {
      "epoch": 6.461935483870968,
      "grad_norm": 0.013185094353712108,
      "learning_rate": 5.8707610063532595e-05,
      "loss": 0.0,
      "step": 3756
    },
    {
      "epoch": 6.463655913978495,
      "grad_norm": 0.33978771459752516,
      "learning_rate": 5.8656840009581935e-05,
      "loss": 0.0006,
      "step": 3757
    },
    {
      "epoch": 6.465376344086022,
      "grad_norm": 0.002454365511177918,
      "learning_rate": 5.860608280599921e-05,
      "loss": 0.0,
      "step": 3758
    },
    {
      "epoch": 6.467096774193548,
      "grad_norm": 1.1738957763420739,
      "learning_rate": 5.855533846856085e-05,
      "loss": 0.0058,
      "step": 3759
    },
    {
      "epoch": 6.468817204301075,
      "grad_norm": 0.01336871408421493,
      "learning_rate": 5.85046070130393e-05,
      "loss": 0.0001,
      "step": 3760
    },
    {
      "epoch": 6.470537634408602,
      "grad_norm": 0.009012798592667336,
      "learning_rate": 5.8453888455203034e-05,
      "loss": 0.0001,
      "step": 3761
    },
    {
      "epoch": 6.472258064516129,
      "grad_norm": 0.15120500901639256,
      "learning_rate": 5.840318281081647e-05,
      "loss": 0.0005,
      "step": 3762
    },
    {
      "epoch": 6.473978494623656,
      "grad_norm": 0.2773586033500808,
      "learning_rate": 5.835249009564012e-05,
      "loss": 0.0013,
      "step": 3763
    },
    {
      "epoch": 6.475698924731183,
      "grad_norm": 0.06410492930093681,
      "learning_rate": 5.8301810325430294e-05,
      "loss": 0.0001,
      "step": 3764
    },
    {
      "epoch": 6.47741935483871,
      "grad_norm": 0.02091054374330124,
      "learning_rate": 5.825114351593948e-05,
      "loss": 0.0001,
      "step": 3765
    },
    {
      "epoch": 6.479139784946237,
      "grad_norm": 0.22053642918105038,
      "learning_rate": 5.820048968291596e-05,
      "loss": 0.001,
      "step": 3766
    },
    {
      "epoch": 6.480860215053763,
      "grad_norm": 0.0826925728314988,
      "learning_rate": 5.8149848842104105e-05,
      "loss": 0.0003,
      "step": 3767
    },
    {
      "epoch": 6.48258064516129,
      "grad_norm": 0.09849565443248433,
      "learning_rate": 5.809922100924425e-05,
      "loss": 0.0006,
      "step": 3768
    },
    {
      "epoch": 6.484301075268817,
      "grad_norm": 0.04843994000533861,
      "learning_rate": 5.804860620007262e-05,
      "loss": 0.0002,
      "step": 3769
    },
    {
      "epoch": 6.486021505376344,
      "grad_norm": 0.019349886154261097,
      "learning_rate": 5.7998004430321354e-05,
      "loss": 0.0001,
      "step": 3770
    },
    {
      "epoch": 6.487741935483871,
      "grad_norm": 0.012411485517688895,
      "learning_rate": 5.7947415715718664e-05,
      "loss": 0.0,
      "step": 3771
    },
    {
      "epoch": 6.489462365591398,
      "grad_norm": 2.808823272485356,
      "learning_rate": 5.7896840071988646e-05,
      "loss": 0.0082,
      "step": 3772
    },
    {
      "epoch": 6.491182795698925,
      "grad_norm": 0.016969223314146034,
      "learning_rate": 5.7846277514851256e-05,
      "loss": 0.0001,
      "step": 3773
    },
    {
      "epoch": 6.492903225806452,
      "grad_norm": 0.5529111170864407,
      "learning_rate": 5.779572806002256e-05,
      "loss": 0.0014,
      "step": 3774
    },
    {
      "epoch": 6.494623655913978,
      "grad_norm": 0.15686190423919158,
      "learning_rate": 5.7745191723214334e-05,
      "loss": 0.0004,
      "step": 3775
    },
    {
      "epoch": 6.496344086021505,
      "grad_norm": 0.12445655251293766,
      "learning_rate": 5.769466852013443e-05,
      "loss": 0.0003,
      "step": 3776
    },
    {
      "epoch": 6.498064516129032,
      "grad_norm": 0.4542026926060721,
      "learning_rate": 5.7644158466486656e-05,
      "loss": 0.0009,
      "step": 3777
    },
    {
      "epoch": 6.499784946236559,
      "grad_norm": 0.6099752296252068,
      "learning_rate": 5.759366157797057e-05,
      "loss": 0.0037,
      "step": 3778
    },
    {
      "epoch": 6.501505376344086,
      "grad_norm": 0.015074561832441328,
      "learning_rate": 5.754317787028172e-05,
      "loss": 0.0001,
      "step": 3779
    },
    {
      "epoch": 6.503225806451613,
      "grad_norm": 0.001540747040118629,
      "learning_rate": 5.749270735911158e-05,
      "loss": 0.0,
      "step": 3780
    },
    {
      "epoch": 6.50494623655914,
      "grad_norm": 0.008987616339552345,
      "learning_rate": 5.74422500601475e-05,
      "loss": 0.0,
      "step": 3781
    },
    {
      "epoch": 6.506666666666667,
      "grad_norm": 2.1806800764007206,
      "learning_rate": 5.7391805989072724e-05,
      "loss": 0.0629,
      "step": 3782
    },
    {
      "epoch": 6.508387096774194,
      "grad_norm": 0.009970997006124978,
      "learning_rate": 5.734137516156639e-05,
      "loss": 0.0001,
      "step": 3783
    },
    {
      "epoch": 6.51010752688172,
      "grad_norm": 0.39255733187613023,
      "learning_rate": 5.729095759330343e-05,
      "loss": 0.0009,
      "step": 3784
    },
    {
      "epoch": 6.511827956989247,
      "grad_norm": 1.5591165302356846,
      "learning_rate": 5.72405532999549e-05,
      "loss": 0.0017,
      "step": 3785
    },
    {
      "epoch": 6.513548387096774,
      "grad_norm": 0.10556730888999104,
      "learning_rate": 5.7190162297187475e-05,
      "loss": 0.0004,
      "step": 3786
    },
    {
      "epoch": 6.515268817204301,
      "grad_norm": 0.15475788879653105,
      "learning_rate": 5.713978460066376e-05,
      "loss": 0.0005,
      "step": 3787
    },
    {
      "epoch": 6.516989247311828,
      "grad_norm": 0.17112859801923966,
      "learning_rate": 5.708942022604232e-05,
      "loss": 0.0004,
      "step": 3788
    },
    {
      "epoch": 6.518709677419355,
      "grad_norm": 0.8848359863377717,
      "learning_rate": 5.70390691889775e-05,
      "loss": 0.0029,
      "step": 3789
    },
    {
      "epoch": 6.520430107526882,
      "grad_norm": 0.04542483172089354,
      "learning_rate": 5.6988731505119475e-05,
      "loss": 0.0001,
      "step": 3790
    },
    {
      "epoch": 6.522150537634409,
      "grad_norm": 0.002601809784992008,
      "learning_rate": 5.693840719011437e-05,
      "loss": 0.0,
      "step": 3791
    },
    {
      "epoch": 6.523870967741935,
      "grad_norm": 0.13551537233335906,
      "learning_rate": 5.688809625960403e-05,
      "loss": 0.0005,
      "step": 3792
    },
    {
      "epoch": 6.525591397849462,
      "grad_norm": 0.1198970790600635,
      "learning_rate": 5.6837798729226244e-05,
      "loss": 0.0006,
      "step": 3793
    },
    {
      "epoch": 6.527311827956989,
      "grad_norm": 0.003093848056732268,
      "learning_rate": 5.6787514614614624e-05,
      "loss": 0.0,
      "step": 3794
    },
    {
      "epoch": 6.529032258064516,
      "grad_norm": 0.5243907061711925,
      "learning_rate": 5.673724393139857e-05,
      "loss": 0.0021,
      "step": 3795
    },
    {
      "epoch": 6.5307526881720435,
      "grad_norm": 0.20370742330167607,
      "learning_rate": 5.6686986695203236e-05,
      "loss": 0.001,
      "step": 3796
    },
    {
      "epoch": 6.53247311827957,
      "grad_norm": 6.279756822529863,
      "learning_rate": 5.66367429216498e-05,
      "loss": 0.0039,
      "step": 3797
    },
    {
      "epoch": 6.534193548387097,
      "grad_norm": 0.8443127489345632,
      "learning_rate": 5.658651262635506e-05,
      "loss": 0.0017,
      "step": 3798
    },
    {
      "epoch": 6.535913978494624,
      "grad_norm": 0.03782738587667123,
      "learning_rate": 5.653629582493175e-05,
      "loss": 0.0002,
      "step": 3799
    },
    {
      "epoch": 6.53763440860215,
      "grad_norm": 0.022964193195640477,
      "learning_rate": 5.6486092532988346e-05,
      "loss": 0.0001,
      "step": 3800
    },
    {
      "epoch": 6.539354838709677,
      "grad_norm": 0.11950338359502367,
      "learning_rate": 5.643590276612909e-05,
      "loss": 0.0004,
      "step": 3801
    },
    {
      "epoch": 6.541075268817204,
      "grad_norm": 0.10688284037744608,
      "learning_rate": 5.638572653995413e-05,
      "loss": 0.0004,
      "step": 3802
    },
    {
      "epoch": 6.542795698924731,
      "grad_norm": 0.0012290709010852729,
      "learning_rate": 5.633556387005936e-05,
      "loss": 0.0,
      "step": 3803
    },
    {
      "epoch": 6.544516129032258,
      "grad_norm": 0.006664669831571615,
      "learning_rate": 5.628541477203638e-05,
      "loss": 0.0,
      "step": 3804
    },
    {
      "epoch": 6.546236559139785,
      "grad_norm": 0.013786410773683104,
      "learning_rate": 5.623527926147272e-05,
      "loss": 0.0001,
      "step": 3805
    },
    {
      "epoch": 6.547956989247312,
      "grad_norm": 1.6209152997812994,
      "learning_rate": 5.6185157353951556e-05,
      "loss": 0.0033,
      "step": 3806
    },
    {
      "epoch": 6.549677419354839,
      "grad_norm": 0.009188629737762735,
      "learning_rate": 5.613504906505185e-05,
      "loss": 0.0,
      "step": 3807
    },
    {
      "epoch": 6.551397849462366,
      "grad_norm": 0.2947920191853949,
      "learning_rate": 5.6084954410348455e-05,
      "loss": 0.0005,
      "step": 3808
    },
    {
      "epoch": 6.553118279569892,
      "grad_norm": 0.4172834521303692,
      "learning_rate": 5.60348734054118e-05,
      "loss": 0.0007,
      "step": 3809
    },
    {
      "epoch": 6.554838709677419,
      "grad_norm": 0.12420365125904448,
      "learning_rate": 5.598480606580825e-05,
      "loss": 0.0003,
      "step": 3810
    },
    {
      "epoch": 6.556559139784946,
      "grad_norm": 0.011511464256684171,
      "learning_rate": 5.5934752407099776e-05,
      "loss": 0.0001,
      "step": 3811
    },
    {
      "epoch": 6.558279569892473,
      "grad_norm": 0.003029136711279069,
      "learning_rate": 5.588471244484419e-05,
      "loss": 0.0,
      "step": 3812
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.3068111279410658,
      "learning_rate": 5.583468619459506e-05,
      "loss": 0.0012,
      "step": 3813
    },
    {
      "epoch": 6.561720430107527,
      "grad_norm": 0.6894023059806329,
      "learning_rate": 5.578467367190161e-05,
      "loss": 0.002,
      "step": 3814
    },
    {
      "epoch": 6.563440860215054,
      "grad_norm": 0.022098178058989077,
      "learning_rate": 5.573467489230879e-05,
      "loss": 0.0001,
      "step": 3815
    },
    {
      "epoch": 6.565161290322581,
      "grad_norm": 2.173875447707286,
      "learning_rate": 5.568468987135743e-05,
      "loss": 0.0462,
      "step": 3816
    },
    {
      "epoch": 6.566881720430107,
      "grad_norm": 0.07399089811968158,
      "learning_rate": 5.5634718624583915e-05,
      "loss": 0.0002,
      "step": 3817
    },
    {
      "epoch": 6.568602150537634,
      "grad_norm": 0.21290197784912146,
      "learning_rate": 5.5584761167520386e-05,
      "loss": 0.0007,
      "step": 3818
    },
    {
      "epoch": 6.570322580645161,
      "grad_norm": 0.11561432924751723,
      "learning_rate": 5.553481751569478e-05,
      "loss": 0.0004,
      "step": 3819
    },
    {
      "epoch": 6.572043010752688,
      "grad_norm": 0.003996485096729218,
      "learning_rate": 5.548488768463065e-05,
      "loss": 0.0,
      "step": 3820
    },
    {
      "epoch": 6.5737634408602155,
      "grad_norm": 0.03652143302655018,
      "learning_rate": 5.5434971689847296e-05,
      "loss": 0.0001,
      "step": 3821
    },
    {
      "epoch": 6.575483870967742,
      "grad_norm": 0.02698199354855757,
      "learning_rate": 5.5385069546859766e-05,
      "loss": 0.0001,
      "step": 3822
    },
    {
      "epoch": 6.577204301075269,
      "grad_norm": 0.13843144799085097,
      "learning_rate": 5.5335181271178716e-05,
      "loss": 0.0003,
      "step": 3823
    },
    {
      "epoch": 6.578924731182796,
      "grad_norm": 0.17443574487796024,
      "learning_rate": 5.528530687831046e-05,
      "loss": 0.0005,
      "step": 3824
    },
    {
      "epoch": 6.580645161290323,
      "grad_norm": 0.0772450232943447,
      "learning_rate": 5.523544638375717e-05,
      "loss": 0.0003,
      "step": 3825
    },
    {
      "epoch": 6.582365591397849,
      "grad_norm": 1.2308336554456012,
      "learning_rate": 5.5185599803016493e-05,
      "loss": 0.0032,
      "step": 3826
    },
    {
      "epoch": 6.584086021505376,
      "grad_norm": 1.5798171916713328,
      "learning_rate": 5.513576715158195e-05,
      "loss": 0.0058,
      "step": 3827
    },
    {
      "epoch": 6.585806451612903,
      "grad_norm": 1.7155485514945463,
      "learning_rate": 5.508594844494256e-05,
      "loss": 0.0017,
      "step": 3828
    },
    {
      "epoch": 6.58752688172043,
      "grad_norm": 0.02782064628024206,
      "learning_rate": 5.503614369858301e-05,
      "loss": 0.0001,
      "step": 3829
    },
    {
      "epoch": 6.589247311827957,
      "grad_norm": 0.6911527588739644,
      "learning_rate": 5.498635292798389e-05,
      "loss": 0.0009,
      "step": 3830
    },
    {
      "epoch": 6.590967741935484,
      "grad_norm": 0.26981895465683586,
      "learning_rate": 5.493657614862115e-05,
      "loss": 0.0006,
      "step": 3831
    },
    {
      "epoch": 6.592688172043011,
      "grad_norm": 3.5398930335873717,
      "learning_rate": 5.488681337596653e-05,
      "loss": 0.0148,
      "step": 3832
    },
    {
      "epoch": 6.594408602150538,
      "grad_norm": 1.0115568731864621,
      "learning_rate": 5.4837064625487453e-05,
      "loss": 0.003,
      "step": 3833
    },
    {
      "epoch": 6.596129032258064,
      "grad_norm": 0.037310994574049024,
      "learning_rate": 5.478732991264688e-05,
      "loss": 0.0002,
      "step": 3834
    },
    {
      "epoch": 6.597849462365591,
      "grad_norm": 0.23990001295546384,
      "learning_rate": 5.473760925290343e-05,
      "loss": 0.0005,
      "step": 3835
    },
    {
      "epoch": 6.599569892473118,
      "grad_norm": 0.060881898965919064,
      "learning_rate": 5.468790266171146e-05,
      "loss": 0.0004,
      "step": 3836
    },
    {
      "epoch": 6.601290322580645,
      "grad_norm": 0.0040401248926668345,
      "learning_rate": 5.4638210154520794e-05,
      "loss": 0.0,
      "step": 3837
    },
    {
      "epoch": 6.6030107526881725,
      "grad_norm": 3.1574557781620634,
      "learning_rate": 5.458853174677703e-05,
      "loss": 0.0251,
      "step": 3838
    },
    {
      "epoch": 6.604731182795699,
      "grad_norm": 0.0022322796105662458,
      "learning_rate": 5.4538867453921314e-05,
      "loss": 0.0,
      "step": 3839
    },
    {
      "epoch": 6.606451612903226,
      "grad_norm": 0.5909962759122991,
      "learning_rate": 5.448921729139038e-05,
      "loss": 0.002,
      "step": 3840
    },
    {
      "epoch": 6.608172043010753,
      "grad_norm": 1.6245193890398688,
      "learning_rate": 5.4439581274616566e-05,
      "loss": 0.0061,
      "step": 3841
    },
    {
      "epoch": 6.609892473118279,
      "grad_norm": 0.7019859998095893,
      "learning_rate": 5.438995941902791e-05,
      "loss": 0.0009,
      "step": 3842
    },
    {
      "epoch": 6.611612903225806,
      "grad_norm": 0.22481701836333257,
      "learning_rate": 5.4340351740047914e-05,
      "loss": 0.0007,
      "step": 3843
    },
    {
      "epoch": 6.613333333333333,
      "grad_norm": 0.05220793213779162,
      "learning_rate": 5.429075825309581e-05,
      "loss": 0.0001,
      "step": 3844
    },
    {
      "epoch": 6.61505376344086,
      "grad_norm": 0.031204881287203542,
      "learning_rate": 5.4241178973586315e-05,
      "loss": 0.0001,
      "step": 3845
    },
    {
      "epoch": 6.6167741935483875,
      "grad_norm": 0.278901228251101,
      "learning_rate": 5.419161391692973e-05,
      "loss": 0.0011,
      "step": 3846
    },
    {
      "epoch": 6.618494623655914,
      "grad_norm": 0.02257192466937156,
      "learning_rate": 5.4142063098532005e-05,
      "loss": 0.0001,
      "step": 3847
    },
    {
      "epoch": 6.620215053763441,
      "grad_norm": 0.1733991153889359,
      "learning_rate": 5.409252653379466e-05,
      "loss": 0.0003,
      "step": 3848
    },
    {
      "epoch": 6.621935483870968,
      "grad_norm": 0.08062994995360794,
      "learning_rate": 5.404300423811469e-05,
      "loss": 0.0003,
      "step": 3849
    },
    {
      "epoch": 6.623655913978495,
      "grad_norm": 0.004726914634017913,
      "learning_rate": 5.399349622688479e-05,
      "loss": 0.0,
      "step": 3850
    },
    {
      "epoch": 6.625376344086021,
      "grad_norm": 0.5084491803985036,
      "learning_rate": 5.394400251549312e-05,
      "loss": 0.0019,
      "step": 3851
    },
    {
      "epoch": 6.627096774193548,
      "grad_norm": 0.09800880189553941,
      "learning_rate": 5.389452311932335e-05,
      "loss": 0.0003,
      "step": 3852
    },
    {
      "epoch": 6.628817204301075,
      "grad_norm": 0.0061913900268796085,
      "learning_rate": 5.384505805375487e-05,
      "loss": 0.0,
      "step": 3853
    },
    {
      "epoch": 6.630537634408602,
      "grad_norm": 0.09156109695968295,
      "learning_rate": 5.3795607334162436e-05,
      "loss": 0.0001,
      "step": 3854
    },
    {
      "epoch": 6.632258064516129,
      "grad_norm": 0.5752625470797914,
      "learning_rate": 5.37461709759165e-05,
      "loss": 0.0013,
      "step": 3855
    },
    {
      "epoch": 6.633978494623656,
      "grad_norm": 0.021742157392332352,
      "learning_rate": 5.369674899438288e-05,
      "loss": 0.0001,
      "step": 3856
    },
    {
      "epoch": 6.635698924731183,
      "grad_norm": 0.009892532032320902,
      "learning_rate": 5.3647341404923134e-05,
      "loss": 0.0,
      "step": 3857
    },
    {
      "epoch": 6.63741935483871,
      "grad_norm": 0.01621127875480533,
      "learning_rate": 5.359794822289412e-05,
      "loss": 0.0002,
      "step": 3858
    },
    {
      "epoch": 6.639139784946236,
      "grad_norm": 1.3154327231057452,
      "learning_rate": 5.354856946364843e-05,
      "loss": 0.0024,
      "step": 3859
    },
    {
      "epoch": 6.640860215053763,
      "grad_norm": 0.1365434743732873,
      "learning_rate": 5.349920514253399e-05,
      "loss": 0.0003,
      "step": 3860
    },
    {
      "epoch": 6.64258064516129,
      "grad_norm": 1.3190048022317917,
      "learning_rate": 5.3449855274894414e-05,
      "loss": 0.008,
      "step": 3861
    },
    {
      "epoch": 6.644301075268817,
      "grad_norm": 0.024869866463674128,
      "learning_rate": 5.3400519876068664e-05,
      "loss": 0.0001,
      "step": 3862
    },
    {
      "epoch": 6.6460215053763445,
      "grad_norm": 0.055373387744717374,
      "learning_rate": 5.3351198961391245e-05,
      "loss": 0.0002,
      "step": 3863
    },
    {
      "epoch": 6.647741935483871,
      "grad_norm": 0.3556972428070332,
      "learning_rate": 5.3301892546192266e-05,
      "loss": 0.0033,
      "step": 3864
    },
    {
      "epoch": 6.649462365591398,
      "grad_norm": 1.7307190141934268,
      "learning_rate": 5.3252600645797176e-05,
      "loss": 0.0041,
      "step": 3865
    },
    {
      "epoch": 6.651182795698925,
      "grad_norm": 0.2860193121425302,
      "learning_rate": 5.320332327552704e-05,
      "loss": 0.0006,
      "step": 3866
    },
    {
      "epoch": 6.652903225806452,
      "grad_norm": 0.015424931316722039,
      "learning_rate": 5.315406045069836e-05,
      "loss": 0.0002,
      "step": 3867
    },
    {
      "epoch": 6.654623655913978,
      "grad_norm": 0.012139895848294736,
      "learning_rate": 5.3104812186623096e-05,
      "loss": 0.0,
      "step": 3868
    },
    {
      "epoch": 6.656344086021505,
      "grad_norm": 0.04896171194455466,
      "learning_rate": 5.305557849860865e-05,
      "loss": 0.0002,
      "step": 3869
    },
    {
      "epoch": 6.658064516129032,
      "grad_norm": 0.0349531773347502,
      "learning_rate": 5.300635940195802e-05,
      "loss": 0.0001,
      "step": 3870
    },
    {
      "epoch": 6.6597849462365595,
      "grad_norm": 0.00333516501633472,
      "learning_rate": 5.295715491196951e-05,
      "loss": 0.0,
      "step": 3871
    },
    {
      "epoch": 6.661505376344086,
      "grad_norm": 0.038681900062061694,
      "learning_rate": 5.290796504393705e-05,
      "loss": 0.0001,
      "step": 3872
    },
    {
      "epoch": 6.663225806451613,
      "grad_norm": 0.004537118150061313,
      "learning_rate": 5.285878981314988e-05,
      "loss": 0.0,
      "step": 3873
    },
    {
      "epoch": 6.66494623655914,
      "grad_norm": 0.08788716931235,
      "learning_rate": 5.280962923489272e-05,
      "loss": 0.0004,
      "step": 3874
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.10276004822683411,
      "learning_rate": 5.276048332444581e-05,
      "loss": 0.0004,
      "step": 3875
    },
    {
      "epoch": 6.668387096774193,
      "grad_norm": 0.03566677916904081,
      "learning_rate": 5.271135209708482e-05,
      "loss": 0.0001,
      "step": 3876
    },
    {
      "epoch": 6.67010752688172,
      "grad_norm": 0.03942369842014197,
      "learning_rate": 5.266223556808073e-05,
      "loss": 0.0001,
      "step": 3877
    },
    {
      "epoch": 6.671827956989247,
      "grad_norm": 0.08563850949022915,
      "learning_rate": 5.261313375270014e-05,
      "loss": 0.0005,
      "step": 3878
    },
    {
      "epoch": 6.6735483870967744,
      "grad_norm": 1.2069670408980815,
      "learning_rate": 5.256404666620494e-05,
      "loss": 0.0054,
      "step": 3879
    },
    {
      "epoch": 6.6752688172043015,
      "grad_norm": 0.610683489850166,
      "learning_rate": 5.251497432385242e-05,
      "loss": 0.0016,
      "step": 3880
    },
    {
      "epoch": 6.676989247311828,
      "grad_norm": 0.0710325233116546,
      "learning_rate": 5.246591674089545e-05,
      "loss": 0.0002,
      "step": 3881
    },
    {
      "epoch": 6.678709677419355,
      "grad_norm": 0.2587278112627778,
      "learning_rate": 5.2416873932582166e-05,
      "loss": 0.0008,
      "step": 3882
    },
    {
      "epoch": 6.680430107526882,
      "grad_norm": 0.16689301020497926,
      "learning_rate": 5.2367845914156066e-05,
      "loss": 0.0005,
      "step": 3883
    },
    {
      "epoch": 6.682150537634408,
      "grad_norm": 0.0022126575430424615,
      "learning_rate": 5.231883270085631e-05,
      "loss": 0.0,
      "step": 3884
    },
    {
      "epoch": 6.683870967741935,
      "grad_norm": 0.017971059363337,
      "learning_rate": 5.226983430791722e-05,
      "loss": 0.0001,
      "step": 3885
    },
    {
      "epoch": 6.685591397849462,
      "grad_norm": 0.03664347773210311,
      "learning_rate": 5.222085075056853e-05,
      "loss": 0.0002,
      "step": 3886
    },
    {
      "epoch": 6.687311827956989,
      "grad_norm": 0.1935895402296956,
      "learning_rate": 5.217188204403547e-05,
      "loss": 0.0005,
      "step": 3887
    },
    {
      "epoch": 6.6890322580645165,
      "grad_norm": 0.26026953813292364,
      "learning_rate": 5.2122928203538546e-05,
      "loss": 0.0008,
      "step": 3888
    },
    {
      "epoch": 6.690752688172043,
      "grad_norm": 0.007229822497162625,
      "learning_rate": 5.207398924429376e-05,
      "loss": 0.0,
      "step": 3889
    },
    {
      "epoch": 6.69247311827957,
      "grad_norm": 0.00933344313853756,
      "learning_rate": 5.20250651815124e-05,
      "loss": 0.0,
      "step": 3890
    },
    {
      "epoch": 6.694193548387097,
      "grad_norm": 0.08191606208168661,
      "learning_rate": 5.197615603040109e-05,
      "loss": 0.0004,
      "step": 3891
    },
    {
      "epoch": 6.695913978494624,
      "grad_norm": 0.03168849929004878,
      "learning_rate": 5.192726180616191e-05,
      "loss": 0.0,
      "step": 3892
    },
    {
      "epoch": 6.69763440860215,
      "grad_norm": 0.045235617999557415,
      "learning_rate": 5.1878382523992306e-05,
      "loss": 0.0001,
      "step": 3893
    },
    {
      "epoch": 6.699354838709677,
      "grad_norm": 0.06429507140896583,
      "learning_rate": 5.182951819908498e-05,
      "loss": 0.0003,
      "step": 3894
    },
    {
      "epoch": 6.701075268817204,
      "grad_norm": 0.0028161648604760983,
      "learning_rate": 5.178066884662811e-05,
      "loss": 0.0,
      "step": 3895
    },
    {
      "epoch": 6.7027956989247315,
      "grad_norm": 0.022079964237870817,
      "learning_rate": 5.1731834481805105e-05,
      "loss": 0.0001,
      "step": 3896
    },
    {
      "epoch": 6.704516129032258,
      "grad_norm": 0.009223745143537633,
      "learning_rate": 5.168301511979474e-05,
      "loss": 0.0,
      "step": 3897
    },
    {
      "epoch": 6.706236559139785,
      "grad_norm": 0.0005211090031055348,
      "learning_rate": 5.163421077577122e-05,
      "loss": 0.0,
      "step": 3898
    },
    {
      "epoch": 6.707956989247312,
      "grad_norm": 0.004978912271300692,
      "learning_rate": 5.1585421464903994e-05,
      "loss": 0.0,
      "step": 3899
    },
    {
      "epoch": 6.709677419354839,
      "grad_norm": 0.014505476925255981,
      "learning_rate": 5.153664720235779e-05,
      "loss": 0.0001,
      "step": 3900
    },
    {
      "epoch": 6.711397849462365,
      "grad_norm": 0.01570208610749624,
      "learning_rate": 5.148788800329278e-05,
      "loss": 0.0001,
      "step": 3901
    },
    {
      "epoch": 6.713118279569892,
      "grad_norm": 0.9441792726372642,
      "learning_rate": 5.143914388286446e-05,
      "loss": 0.0129,
      "step": 3902
    },
    {
      "epoch": 6.714838709677419,
      "grad_norm": 2.6108911869661067,
      "learning_rate": 5.1390414856223465e-05,
      "loss": 0.0049,
      "step": 3903
    },
    {
      "epoch": 6.7165591397849465,
      "grad_norm": 0.014806536780496236,
      "learning_rate": 5.134170093851596e-05,
      "loss": 0.0001,
      "step": 3904
    },
    {
      "epoch": 6.7182795698924735,
      "grad_norm": 0.015982266971363165,
      "learning_rate": 5.129300214488322e-05,
      "loss": 0.0001,
      "step": 3905
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.002614543716260279,
      "learning_rate": 5.1244318490461976e-05,
      "loss": 0.0,
      "step": 3906
    },
    {
      "epoch": 6.721720430107527,
      "grad_norm": 0.2180753003477375,
      "learning_rate": 5.1195649990384155e-05,
      "loss": 0.0006,
      "step": 3907
    },
    {
      "epoch": 6.723440860215054,
      "grad_norm": 0.8708745519819222,
      "learning_rate": 5.114699665977696e-05,
      "loss": 0.0015,
      "step": 3908
    },
    {
      "epoch": 6.725161290322581,
      "grad_norm": 4.028069163643174,
      "learning_rate": 5.1098358513762986e-05,
      "loss": 0.0035,
      "step": 3909
    },
    {
      "epoch": 6.726881720430107,
      "grad_norm": 0.3198463768708132,
      "learning_rate": 5.104973556746e-05,
      "loss": 0.002,
      "step": 3910
    },
    {
      "epoch": 6.728602150537634,
      "grad_norm": 0.004839724808343326,
      "learning_rate": 5.10011278359811e-05,
      "loss": 0.0,
      "step": 3911
    },
    {
      "epoch": 6.730322580645161,
      "grad_norm": 0.5656439458463675,
      "learning_rate": 5.095253533443469e-05,
      "loss": 0.0026,
      "step": 3912
    },
    {
      "epoch": 6.7320430107526885,
      "grad_norm": 1.440843269618068,
      "learning_rate": 5.0903958077924366e-05,
      "loss": 0.0034,
      "step": 3913
    },
    {
      "epoch": 6.733763440860215,
      "grad_norm": 0.00038363545739643167,
      "learning_rate": 5.085539608154895e-05,
      "loss": 0.0,
      "step": 3914
    },
    {
      "epoch": 6.735483870967742,
      "grad_norm": 0.07938531164219768,
      "learning_rate": 5.080684936040266e-05,
      "loss": 0.0002,
      "step": 3915
    },
    {
      "epoch": 6.737204301075269,
      "grad_norm": 0.3894149014256154,
      "learning_rate": 5.075831792957484e-05,
      "loss": 0.0029,
      "step": 3916
    },
    {
      "epoch": 6.738924731182796,
      "grad_norm": 2.3122581371873405,
      "learning_rate": 5.070980180415019e-05,
      "loss": 0.0089,
      "step": 3917
    },
    {
      "epoch": 6.740645161290322,
      "grad_norm": 0.007052616109291624,
      "learning_rate": 5.066130099920856e-05,
      "loss": 0.0,
      "step": 3918
    },
    {
      "epoch": 6.742365591397849,
      "grad_norm": 0.03992635376848695,
      "learning_rate": 5.061281552982504e-05,
      "loss": 0.0002,
      "step": 3919
    },
    {
      "epoch": 6.744086021505376,
      "grad_norm": 0.006702714966292889,
      "learning_rate": 5.0564345411070025e-05,
      "loss": 0.0001,
      "step": 3920
    },
    {
      "epoch": 6.7458064516129035,
      "grad_norm": 0.003909540984228214,
      "learning_rate": 5.051589065800911e-05,
      "loss": 0.0,
      "step": 3921
    },
    {
      "epoch": 6.747526881720431,
      "grad_norm": 0.028854920569882866,
      "learning_rate": 5.046745128570306e-05,
      "loss": 0.0002,
      "step": 3922
    },
    {
      "epoch": 6.749247311827957,
      "grad_norm": 0.03886577241966681,
      "learning_rate": 5.0419027309207954e-05,
      "loss": 0.0002,
      "step": 3923
    },
    {
      "epoch": 6.750967741935484,
      "grad_norm": 0.012972759872695448,
      "learning_rate": 5.0370618743575026e-05,
      "loss": 0.0,
      "step": 3924
    },
    {
      "epoch": 6.752688172043011,
      "grad_norm": 0.0019170306167596261,
      "learning_rate": 5.032222560385066e-05,
      "loss": 0.0,
      "step": 3925
    },
    {
      "epoch": 6.754408602150537,
      "grad_norm": 0.048121330391152614,
      "learning_rate": 5.027384790507661e-05,
      "loss": 0.0001,
      "step": 3926
    },
    {
      "epoch": 6.756129032258064,
      "grad_norm": 0.3113553704906499,
      "learning_rate": 5.022548566228968e-05,
      "loss": 0.0008,
      "step": 3927
    },
    {
      "epoch": 6.757849462365591,
      "grad_norm": 0.6929781801639325,
      "learning_rate": 5.017713889052184e-05,
      "loss": 0.0028,
      "step": 3928
    },
    {
      "epoch": 6.7595698924731185,
      "grad_norm": 0.0006991210201086784,
      "learning_rate": 5.012880760480053e-05,
      "loss": 0.0,
      "step": 3929
    },
    {
      "epoch": 6.7612903225806456,
      "grad_norm": 0.6182386642663343,
      "learning_rate": 5.0080491820148065e-05,
      "loss": 0.0015,
      "step": 3930
    },
    {
      "epoch": 6.763010752688172,
      "grad_norm": 0.09398539427614513,
      "learning_rate": 5.003219155158204e-05,
      "loss": 0.0005,
      "step": 3931
    },
    {
      "epoch": 6.764731182795699,
      "grad_norm": 0.3015089800232611,
      "learning_rate": 4.998390681411531e-05,
      "loss": 0.0012,
      "step": 3932
    },
    {
      "epoch": 6.766451612903226,
      "grad_norm": 0.5659240415275361,
      "learning_rate": 4.993563762275577e-05,
      "loss": 0.0015,
      "step": 3933
    },
    {
      "epoch": 6.768172043010753,
      "grad_norm": 0.0019359872284043758,
      "learning_rate": 4.9887383992506634e-05,
      "loss": 0.0,
      "step": 3934
    },
    {
      "epoch": 6.769892473118279,
      "grad_norm": 0.006181831833702382,
      "learning_rate": 4.9839145938366137e-05,
      "loss": 0.0,
      "step": 3935
    },
    {
      "epoch": 6.771612903225806,
      "grad_norm": 0.024933260741094174,
      "learning_rate": 4.9790923475327725e-05,
      "loss": 0.0001,
      "step": 3936
    },
    {
      "epoch": 6.773333333333333,
      "grad_norm": 4.073536407216771,
      "learning_rate": 4.974271661838001e-05,
      "loss": 0.0072,
      "step": 3937
    },
    {
      "epoch": 6.7750537634408605,
      "grad_norm": 0.0025994034002817293,
      "learning_rate": 4.9694525382506816e-05,
      "loss": 0.0,
      "step": 3938
    },
    {
      "epoch": 6.776774193548387,
      "grad_norm": 0.12106753281625915,
      "learning_rate": 4.964634978268695e-05,
      "loss": 0.0005,
      "step": 3939
    },
    {
      "epoch": 6.778494623655914,
      "grad_norm": 0.04196252858226769,
      "learning_rate": 4.959818983389454e-05,
      "loss": 0.0002,
      "step": 3940
    },
    {
      "epoch": 6.780215053763441,
      "grad_norm": 0.02944305964627857,
      "learning_rate": 4.955004555109871e-05,
      "loss": 0.0001,
      "step": 3941
    },
    {
      "epoch": 6.781935483870968,
      "grad_norm": 0.04162541205062159,
      "learning_rate": 4.950191694926375e-05,
      "loss": 0.0003,
      "step": 3942
    },
    {
      "epoch": 6.783655913978494,
      "grad_norm": 0.011991879620980753,
      "learning_rate": 4.945380404334915e-05,
      "loss": 0.0001,
      "step": 3943
    },
    {
      "epoch": 6.785376344086021,
      "grad_norm": 0.021952340328963225,
      "learning_rate": 4.940570684830944e-05,
      "loss": 0.0001,
      "step": 3944
    },
    {
      "epoch": 6.787096774193548,
      "grad_norm": 0.006279482787585316,
      "learning_rate": 4.935762537909424e-05,
      "loss": 0.0,
      "step": 3945
    },
    {
      "epoch": 6.7888172043010755,
      "grad_norm": 0.06066948382238481,
      "learning_rate": 4.9309559650648386e-05,
      "loss": 0.0002,
      "step": 3946
    },
    {
      "epoch": 6.790537634408603,
      "grad_norm": 0.12771011328760315,
      "learning_rate": 4.92615096779118e-05,
      "loss": 0.0002,
      "step": 3947
    },
    {
      "epoch": 6.792258064516129,
      "grad_norm": 0.07758098958419864,
      "learning_rate": 4.921347547581939e-05,
      "loss": 0.0002,
      "step": 3948
    },
    {
      "epoch": 6.793978494623656,
      "grad_norm": 1.9529328772517516,
      "learning_rate": 4.9165457059301344e-05,
      "loss": 0.0084,
      "step": 3949
    },
    {
      "epoch": 6.795698924731183,
      "grad_norm": 1.173778940549093,
      "learning_rate": 4.911745444328275e-05,
      "loss": 0.0035,
      "step": 3950
    },
    {
      "epoch": 6.797419354838709,
      "grad_norm": 0.007021628647881088,
      "learning_rate": 4.906946764268398e-05,
      "loss": 0.0,
      "step": 3951
    },
    {
      "epoch": 6.799139784946236,
      "grad_norm": 0.012367289118336148,
      "learning_rate": 4.902149667242033e-05,
      "loss": 0.0001,
      "step": 3952
    },
    {
      "epoch": 6.800860215053763,
      "grad_norm": 0.001039829366110009,
      "learning_rate": 4.8973541547402225e-05,
      "loss": 0.0,
      "step": 3953
    },
    {
      "epoch": 6.8025806451612905,
      "grad_norm": 1.9203256846737005,
      "learning_rate": 4.892560228253523e-05,
      "loss": 0.0063,
      "step": 3954
    },
    {
      "epoch": 6.8043010752688176,
      "grad_norm": 0.0023618369089805657,
      "learning_rate": 4.8877678892719866e-05,
      "loss": 0.0,
      "step": 3955
    },
    {
      "epoch": 6.806021505376344,
      "grad_norm": 0.10988234936069345,
      "learning_rate": 4.882977139285182e-05,
      "loss": 0.0004,
      "step": 3956
    },
    {
      "epoch": 6.807741935483871,
      "grad_norm": 0.15882290818921896,
      "learning_rate": 4.878187979782184e-05,
      "loss": 0.0005,
      "step": 3957
    },
    {
      "epoch": 6.809462365591398,
      "grad_norm": 0.6853099087085642,
      "learning_rate": 4.873400412251564e-05,
      "loss": 0.001,
      "step": 3958
    },
    {
      "epoch": 6.811182795698925,
      "grad_norm": 1.1104294699902884,
      "learning_rate": 4.8686144381814014e-05,
      "loss": 0.004,
      "step": 3959
    },
    {
      "epoch": 6.812903225806451,
      "grad_norm": 0.12870577770951472,
      "learning_rate": 4.86383005905929e-05,
      "loss": 0.0003,
      "step": 3960
    },
    {
      "epoch": 6.814623655913978,
      "grad_norm": 0.0033785717101578547,
      "learning_rate": 4.859047276372317e-05,
      "loss": 0.0,
      "step": 3961
    },
    {
      "epoch": 6.816344086021505,
      "grad_norm": 0.017651225686071536,
      "learning_rate": 4.8542660916070736e-05,
      "loss": 0.0,
      "step": 3962
    },
    {
      "epoch": 6.8180645161290325,
      "grad_norm": 0.06289687673947116,
      "learning_rate": 4.849486506249664e-05,
      "loss": 0.0002,
      "step": 3963
    },
    {
      "epoch": 6.81978494623656,
      "grad_norm": 1.7680500490784177,
      "learning_rate": 4.8447085217856825e-05,
      "loss": 0.0057,
      "step": 3964
    },
    {
      "epoch": 6.821505376344086,
      "grad_norm": 0.0015797224352669533,
      "learning_rate": 4.839932139700235e-05,
      "loss": 0.0,
      "step": 3965
    },
    {
      "epoch": 6.823225806451613,
      "grad_norm": 0.3734643530163889,
      "learning_rate": 4.835157361477931e-05,
      "loss": 0.0007,
      "step": 3966
    },
    {
      "epoch": 6.82494623655914,
      "grad_norm": 0.03466220619991253,
      "learning_rate": 4.83038418860287e-05,
      "loss": 0.0001,
      "step": 3967
    },
    {
      "epoch": 6.826666666666666,
      "grad_norm": 0.2688447681413306,
      "learning_rate": 4.8256126225586664e-05,
      "loss": 0.0008,
      "step": 3968
    },
    {
      "epoch": 6.828387096774193,
      "grad_norm": 0.08198774893191924,
      "learning_rate": 4.8208426648284244e-05,
      "loss": 0.0002,
      "step": 3969
    },
    {
      "epoch": 6.83010752688172,
      "grad_norm": 0.08086491734576799,
      "learning_rate": 4.8160743168947496e-05,
      "loss": 0.0002,
      "step": 3970
    },
    {
      "epoch": 6.8318279569892475,
      "grad_norm": 0.025938785059268988,
      "learning_rate": 4.811307580239758e-05,
      "loss": 0.0001,
      "step": 3971
    },
    {
      "epoch": 6.833548387096775,
      "grad_norm": 0.0036472589644039074,
      "learning_rate": 4.80654245634505e-05,
      "loss": 0.0,
      "step": 3972
    },
    {
      "epoch": 6.835268817204301,
      "grad_norm": 0.3042722667325595,
      "learning_rate": 4.801778946691727e-05,
      "loss": 0.001,
      "step": 3973
    },
    {
      "epoch": 6.836989247311828,
      "grad_norm": 0.0009016482097906983,
      "learning_rate": 4.7970170527604065e-05,
      "loss": 0.0,
      "step": 3974
    },
    {
      "epoch": 6.838709677419355,
      "grad_norm": 0.5703885729368867,
      "learning_rate": 4.7922567760311834e-05,
      "loss": 0.0004,
      "step": 3975
    },
    {
      "epoch": 6.840430107526882,
      "grad_norm": 0.08513328854693238,
      "learning_rate": 4.787498117983653e-05,
      "loss": 0.0001,
      "step": 3976
    },
    {
      "epoch": 6.842150537634408,
      "grad_norm": 0.04062616014888338,
      "learning_rate": 4.7827410800969184e-05,
      "loss": 0.0002,
      "step": 3977
    },
    {
      "epoch": 6.843870967741935,
      "grad_norm": 0.004653352908514703,
      "learning_rate": 4.77798566384957e-05,
      "loss": 0.0,
      "step": 3978
    },
    {
      "epoch": 6.8455913978494625,
      "grad_norm": 0.10290747722969741,
      "learning_rate": 4.77323187071969e-05,
      "loss": 0.0002,
      "step": 3979
    },
    {
      "epoch": 6.84731182795699,
      "grad_norm": 0.04799215023947081,
      "learning_rate": 4.768479702184873e-05,
      "loss": 0.0002,
      "step": 3980
    },
    {
      "epoch": 6.849032258064516,
      "grad_norm": 1.932708525297389,
      "learning_rate": 4.763729159722188e-05,
      "loss": 0.0057,
      "step": 3981
    },
    {
      "epoch": 6.850752688172043,
      "grad_norm": 0.009541664669297978,
      "learning_rate": 4.758980244808212e-05,
      "loss": 0.0001,
      "step": 3982
    },
    {
      "epoch": 6.85247311827957,
      "grad_norm": 0.005547016633682624,
      "learning_rate": 4.7542329589190195e-05,
      "loss": 0.0,
      "step": 3983
    },
    {
      "epoch": 6.854193548387097,
      "grad_norm": 0.004977926253933088,
      "learning_rate": 4.7494873035301614e-05,
      "loss": 0.0,
      "step": 3984
    },
    {
      "epoch": 6.855913978494623,
      "grad_norm": 0.062186255055469215,
      "learning_rate": 4.744743280116701e-05,
      "loss": 0.0001,
      "step": 3985
    },
    {
      "epoch": 6.85763440860215,
      "grad_norm": 0.07236765327638373,
      "learning_rate": 4.7400008901531815e-05,
      "loss": 0.0002,
      "step": 3986
    },
    {
      "epoch": 6.859354838709677,
      "grad_norm": 0.020052966910710214,
      "learning_rate": 4.735260135113639e-05,
      "loss": 0.0,
      "step": 3987
    },
    {
      "epoch": 6.8610752688172045,
      "grad_norm": 0.34390588084985935,
      "learning_rate": 4.730521016471613e-05,
      "loss": 0.001,
      "step": 3988
    },
    {
      "epoch": 6.862795698924732,
      "grad_norm": 0.1333730370387262,
      "learning_rate": 4.725783535700122e-05,
      "loss": 0.0003,
      "step": 3989
    },
    {
      "epoch": 6.864516129032258,
      "grad_norm": 0.00184303921112339,
      "learning_rate": 4.721047694271676e-05,
      "loss": 0.0,
      "step": 3990
    },
    {
      "epoch": 6.866236559139785,
      "grad_norm": 0.11048694488110415,
      "learning_rate": 4.716313493658283e-05,
      "loss": 0.0003,
      "step": 3991
    },
    {
      "epoch": 6.867956989247312,
      "grad_norm": 0.4905928484026991,
      "learning_rate": 4.711580935331441e-05,
      "loss": 0.0008,
      "step": 3992
    },
    {
      "epoch": 6.869677419354838,
      "grad_norm": 0.10326454580255054,
      "learning_rate": 4.706850020762126e-05,
      "loss": 0.0002,
      "step": 3993
    },
    {
      "epoch": 6.871397849462365,
      "grad_norm": 0.09189532667109283,
      "learning_rate": 4.7021207514208185e-05,
      "loss": 0.0004,
      "step": 3994
    },
    {
      "epoch": 6.873118279569892,
      "grad_norm": 0.007306985157815927,
      "learning_rate": 4.697393128777477e-05,
      "loss": 0.0,
      "step": 3995
    },
    {
      "epoch": 6.8748387096774195,
      "grad_norm": 0.1954716152904427,
      "learning_rate": 4.692667154301544e-05,
      "loss": 0.0003,
      "step": 3996
    },
    {
      "epoch": 6.876559139784947,
      "grad_norm": 0.030341848452207505,
      "learning_rate": 4.687942829461969e-05,
      "loss": 0.0001,
      "step": 3997
    },
    {
      "epoch": 6.878279569892473,
      "grad_norm": 0.007471580232782725,
      "learning_rate": 4.683220155727166e-05,
      "loss": 0.0,
      "step": 3998
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.0031624947362503667,
      "learning_rate": 4.678499134565055e-05,
      "loss": 0.0,
      "step": 3999
    },
    {
      "epoch": 6.881720430107527,
      "grad_norm": 0.00993628909031251,
      "learning_rate": 4.673779767443026e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 6.883440860215054,
      "grad_norm": 0.011074321531280162,
      "learning_rate": 4.6690620558279664e-05,
      "loss": 0.0001,
      "step": 4001
    },
    {
      "epoch": 6.88516129032258,
      "grad_norm": 0.0003329474491654527,
      "learning_rate": 4.6643460011862485e-05,
      "loss": 0.0,
      "step": 4002
    },
    {
      "epoch": 6.886881720430107,
      "grad_norm": 4.341917933050615,
      "learning_rate": 4.659631604983724e-05,
      "loss": 0.0061,
      "step": 4003
    },
    {
      "epoch": 6.8886021505376345,
      "grad_norm": 1.1077314699340661,
      "learning_rate": 4.654918868685726e-05,
      "loss": 0.0032,
      "step": 4004
    },
    {
      "epoch": 6.890322580645162,
      "grad_norm": 0.04924462093845774,
      "learning_rate": 4.6502077937570856e-05,
      "loss": 0.0003,
      "step": 4005
    },
    {
      "epoch": 6.892043010752689,
      "grad_norm": 0.07747086111624707,
      "learning_rate": 4.6454983816621044e-05,
      "loss": 0.0004,
      "step": 4006
    },
    {
      "epoch": 6.893763440860215,
      "grad_norm": 0.07278591825978939,
      "learning_rate": 4.640790633864569e-05,
      "loss": 0.0003,
      "step": 4007
    },
    {
      "epoch": 6.895483870967742,
      "grad_norm": 0.06332100133273667,
      "learning_rate": 4.636084551827758e-05,
      "loss": 0.0001,
      "step": 4008
    },
    {
      "epoch": 6.897204301075269,
      "grad_norm": 0.06554033015383819,
      "learning_rate": 4.6313801370144195e-05,
      "loss": 0.0002,
      "step": 4009
    },
    {
      "epoch": 6.898924731182795,
      "grad_norm": 0.06998459188754567,
      "learning_rate": 4.626677390886792e-05,
      "loss": 0.0003,
      "step": 4010
    },
    {
      "epoch": 6.900645161290322,
      "grad_norm": 0.01870418740339919,
      "learning_rate": 4.6219763149065974e-05,
      "loss": 0.0001,
      "step": 4011
    },
    {
      "epoch": 6.902365591397849,
      "grad_norm": 0.0028615948827488092,
      "learning_rate": 4.6172769105350314e-05,
      "loss": 0.0,
      "step": 4012
    },
    {
      "epoch": 6.9040860215053765,
      "grad_norm": 0.010446075940663498,
      "learning_rate": 4.612579179232766e-05,
      "loss": 0.0,
      "step": 4013
    },
    {
      "epoch": 6.905806451612904,
      "grad_norm": 0.044231353810351454,
      "learning_rate": 4.6078831224599705e-05,
      "loss": 0.0001,
      "step": 4014
    },
    {
      "epoch": 6.90752688172043,
      "grad_norm": 0.009201473665317615,
      "learning_rate": 4.6031887416762734e-05,
      "loss": 0.0,
      "step": 4015
    },
    {
      "epoch": 6.909247311827957,
      "grad_norm": 0.01319632421395915,
      "learning_rate": 4.5984960383408005e-05,
      "loss": 0.0001,
      "step": 4016
    },
    {
      "epoch": 6.910967741935484,
      "grad_norm": 0.11918702191364955,
      "learning_rate": 4.5938050139121445e-05,
      "loss": 0.0001,
      "step": 4017
    },
    {
      "epoch": 6.912688172043011,
      "grad_norm": 0.1673864393036836,
      "learning_rate": 4.5891156698483716e-05,
      "loss": 0.0002,
      "step": 4018
    },
    {
      "epoch": 6.914408602150537,
      "grad_norm": 0.3898215341121787,
      "learning_rate": 4.584428007607048e-05,
      "loss": 0.0009,
      "step": 4019
    },
    {
      "epoch": 6.916129032258064,
      "grad_norm": 0.17267885267361333,
      "learning_rate": 4.5797420286451944e-05,
      "loss": 0.0005,
      "step": 4020
    },
    {
      "epoch": 6.9178494623655915,
      "grad_norm": 0.3591116742595997,
      "learning_rate": 4.575057734419316e-05,
      "loss": 0.0012,
      "step": 4021
    },
    {
      "epoch": 6.919569892473119,
      "grad_norm": 0.012844770724206965,
      "learning_rate": 4.570375126385399e-05,
      "loss": 0.0,
      "step": 4022
    },
    {
      "epoch": 6.921290322580645,
      "grad_norm": 0.0058029665980104395,
      "learning_rate": 4.5656942059988996e-05,
      "loss": 0.0,
      "step": 4023
    },
    {
      "epoch": 6.923010752688172,
      "grad_norm": 0.013381180025870703,
      "learning_rate": 4.561014974714748e-05,
      "loss": 0.0001,
      "step": 4024
    },
    {
      "epoch": 6.924731182795699,
      "grad_norm": 2.90470353973839,
      "learning_rate": 4.556337433987359e-05,
      "loss": 0.0105,
      "step": 4025
    },
    {
      "epoch": 6.926451612903226,
      "grad_norm": 0.0031322258532785513,
      "learning_rate": 4.551661585270608e-05,
      "loss": 0.0,
      "step": 4026
    },
    {
      "epoch": 6.928172043010752,
      "grad_norm": 0.0116296802108335,
      "learning_rate": 4.5469874300178575e-05,
      "loss": 0.0,
      "step": 4027
    },
    {
      "epoch": 6.929892473118279,
      "grad_norm": 0.03401094562499281,
      "learning_rate": 4.542314969681939e-05,
      "loss": 0.0001,
      "step": 4028
    },
    {
      "epoch": 6.9316129032258065,
      "grad_norm": 0.048604516874277706,
      "learning_rate": 4.537644205715157e-05,
      "loss": 0.0001,
      "step": 4029
    },
    {
      "epoch": 6.933333333333334,
      "grad_norm": 0.0011574294612125295,
      "learning_rate": 4.532975139569281e-05,
      "loss": 0.0,
      "step": 4030
    },
    {
      "epoch": 6.935053763440861,
      "grad_norm": 2.358801859340936,
      "learning_rate": 4.5283077726955684e-05,
      "loss": 0.0238,
      "step": 4031
    },
    {
      "epoch": 6.936774193548387,
      "grad_norm": 0.010285487381868474,
      "learning_rate": 4.523642106544732e-05,
      "loss": 0.0,
      "step": 4032
    },
    {
      "epoch": 6.938494623655914,
      "grad_norm": 0.015117838785030849,
      "learning_rate": 4.518978142566973e-05,
      "loss": 0.0,
      "step": 4033
    },
    {
      "epoch": 6.940215053763441,
      "grad_norm": 0.32705054857820465,
      "learning_rate": 4.51431588221195e-05,
      "loss": 0.0008,
      "step": 4034
    },
    {
      "epoch": 6.941935483870967,
      "grad_norm": 0.027996880434972834,
      "learning_rate": 4.5096553269287924e-05,
      "loss": 0.0001,
      "step": 4035
    },
    {
      "epoch": 6.943655913978494,
      "grad_norm": 0.09268407233819183,
      "learning_rate": 4.504996478166108e-05,
      "loss": 0.0003,
      "step": 4036
    },
    {
      "epoch": 6.9453763440860214,
      "grad_norm": 0.08995272471911485,
      "learning_rate": 4.500339337371973e-05,
      "loss": 0.0004,
      "step": 4037
    },
    {
      "epoch": 6.9470967741935485,
      "grad_norm": 0.00026160335923065576,
      "learning_rate": 4.4956839059939226e-05,
      "loss": 0.0,
      "step": 4038
    },
    {
      "epoch": 6.948817204301076,
      "grad_norm": 0.002936335801895894,
      "learning_rate": 4.491030185478976e-05,
      "loss": 0.0,
      "step": 4039
    },
    {
      "epoch": 6.950537634408602,
      "grad_norm": 0.010073108903631542,
      "learning_rate": 4.4863781772736066e-05,
      "loss": 0.0,
      "step": 4040
    },
    {
      "epoch": 6.952258064516129,
      "grad_norm": 0.23272111394039954,
      "learning_rate": 4.4817278828237606e-05,
      "loss": 0.0002,
      "step": 4041
    },
    {
      "epoch": 6.953978494623656,
      "grad_norm": 0.2190183870686018,
      "learning_rate": 4.477079303574858e-05,
      "loss": 0.0007,
      "step": 4042
    },
    {
      "epoch": 6.955698924731183,
      "grad_norm": 0.18205228704980908,
      "learning_rate": 4.4724324409717725e-05,
      "loss": 0.0004,
      "step": 4043
    },
    {
      "epoch": 6.957419354838709,
      "grad_norm": 0.071836098144458,
      "learning_rate": 4.467787296458858e-05,
      "loss": 0.0003,
      "step": 4044
    },
    {
      "epoch": 6.959139784946236,
      "grad_norm": 0.001298792179274001,
      "learning_rate": 4.463143871479924e-05,
      "loss": 0.0,
      "step": 4045
    },
    {
      "epoch": 6.9608602150537635,
      "grad_norm": 0.007241297508026771,
      "learning_rate": 4.4585021674782534e-05,
      "loss": 0.0001,
      "step": 4046
    },
    {
      "epoch": 6.962580645161291,
      "grad_norm": 0.13754143399731011,
      "learning_rate": 4.453862185896586e-05,
      "loss": 0.0004,
      "step": 4047
    },
    {
      "epoch": 6.964301075268818,
      "grad_norm": 0.19310601355797405,
      "learning_rate": 4.4492239281771365e-05,
      "loss": 0.0005,
      "step": 4048
    },
    {
      "epoch": 6.966021505376344,
      "grad_norm": 0.0969560930259126,
      "learning_rate": 4.4445873957615694e-05,
      "loss": 0.0002,
      "step": 4049
    },
    {
      "epoch": 6.967741935483871,
      "grad_norm": 0.006491576514234989,
      "learning_rate": 4.439952590091031e-05,
      "loss": 0.0,
      "step": 4050
    },
    {
      "epoch": 6.969462365591398,
      "grad_norm": 0.35725815009651857,
      "learning_rate": 4.435319512606116e-05,
      "loss": 0.001,
      "step": 4051
    },
    {
      "epoch": 6.971182795698924,
      "grad_norm": 0.0027598113726759175,
      "learning_rate": 4.4306881647468857e-05,
      "loss": 0.0,
      "step": 4052
    },
    {
      "epoch": 6.972903225806451,
      "grad_norm": 1.357920650832213,
      "learning_rate": 4.426058547952867e-05,
      "loss": 0.0056,
      "step": 4053
    },
    {
      "epoch": 6.9746236559139785,
      "grad_norm": 0.7769264615162355,
      "learning_rate": 4.421430663663052e-05,
      "loss": 0.0035,
      "step": 4054
    },
    {
      "epoch": 6.976344086021506,
      "grad_norm": 0.07494768776596243,
      "learning_rate": 4.416804513315881e-05,
      "loss": 0.0001,
      "step": 4055
    },
    {
      "epoch": 6.978064516129033,
      "grad_norm": 0.001532526743000866,
      "learning_rate": 4.412180098349272e-05,
      "loss": 0.0,
      "step": 4056
    },
    {
      "epoch": 6.979784946236559,
      "grad_norm": 0.10500167513296392,
      "learning_rate": 4.407557420200591e-05,
      "loss": 0.0001,
      "step": 4057
    },
    {
      "epoch": 6.981505376344086,
      "grad_norm": 0.007596220884267364,
      "learning_rate": 4.402936480306666e-05,
      "loss": 0.0,
      "step": 4058
    },
    {
      "epoch": 6.983225806451613,
      "grad_norm": 0.018288243561291124,
      "learning_rate": 4.398317280103793e-05,
      "loss": 0.0001,
      "step": 4059
    },
    {
      "epoch": 6.98494623655914,
      "grad_norm": 0.006262097420798597,
      "learning_rate": 4.393699821027716e-05,
      "loss": 0.0,
      "step": 4060
    },
    {
      "epoch": 6.986666666666666,
      "grad_norm": 0.09684383131897563,
      "learning_rate": 4.389084104513649e-05,
      "loss": 0.0003,
      "step": 4061
    },
    {
      "epoch": 6.9883870967741935,
      "grad_norm": 0.0007443026542732451,
      "learning_rate": 4.384470131996252e-05,
      "loss": 0.0,
      "step": 4062
    },
    {
      "epoch": 6.9901075268817205,
      "grad_norm": 0.011948095198207493,
      "learning_rate": 4.379857904909658e-05,
      "loss": 0.0,
      "step": 4063
    },
    {
      "epoch": 6.991827956989248,
      "grad_norm": 0.008058124834329987,
      "learning_rate": 4.375247424687441e-05,
      "loss": 0.0,
      "step": 4064
    },
    {
      "epoch": 6.993548387096774,
      "grad_norm": 0.0037658091603537495,
      "learning_rate": 4.3706386927626466e-05,
      "loss": 0.0,
      "step": 4065
    },
    {
      "epoch": 6.995268817204301,
      "grad_norm": 0.03109775760244333,
      "learning_rate": 4.366031710567764e-05,
      "loss": 0.0,
      "step": 4066
    },
    {
      "epoch": 6.996989247311828,
      "grad_norm": 0.0010830945569930478,
      "learning_rate": 4.361426479534753e-05,
      "loss": 0.0,
      "step": 4067
    },
    {
      "epoch": 6.998709677419355,
      "grad_norm": 0.004170960737142161,
      "learning_rate": 4.356823001095016e-05,
      "loss": 0.0,
      "step": 4068
    },
    {
      "epoch": 7.000430107526881,
      "grad_norm": 0.004309545006471583,
      "learning_rate": 4.3522212766794134e-05,
      "loss": 0.0,
      "step": 4069
    },
    {
      "epoch": 7.002150537634408,
      "grad_norm": 0.08259681662570216,
      "learning_rate": 4.3476213077182704e-05,
      "loss": 0.0001,
      "step": 4070
    },
    {
      "epoch": 7.0038709677419355,
      "grad_norm": 0.08025861807435182,
      "learning_rate": 4.343023095641351e-05,
      "loss": 0.0003,
      "step": 4071
    },
    {
      "epoch": 7.005591397849463,
      "grad_norm": 0.005141733539496235,
      "learning_rate": 4.338426641877884e-05,
      "loss": 0.0,
      "step": 4072
    },
    {
      "epoch": 7.007311827956989,
      "grad_norm": 0.0036070134293516524,
      "learning_rate": 4.333831947856555e-05,
      "loss": 0.0,
      "step": 4073
    },
    {
      "epoch": 7.009032258064516,
      "grad_norm": 0.010735317602631597,
      "learning_rate": 4.3292390150054894e-05,
      "loss": 0.0,
      "step": 4074
    },
    {
      "epoch": 7.010752688172043,
      "grad_norm": 0.016729918950642426,
      "learning_rate": 4.324647844752272e-05,
      "loss": 0.0,
      "step": 4075
    },
    {
      "epoch": 7.01247311827957,
      "grad_norm": 0.0006488851740611532,
      "learning_rate": 4.320058438523945e-05,
      "loss": 0.0,
      "step": 4076
    },
    {
      "epoch": 7.014193548387097,
      "grad_norm": 0.0024055059044311277,
      "learning_rate": 4.315470797746991e-05,
      "loss": 0.0,
      "step": 4077
    },
    {
      "epoch": 7.015913978494623,
      "grad_norm": 0.025362865272136582,
      "learning_rate": 4.310884923847358e-05,
      "loss": 0.0001,
      "step": 4078
    },
    {
      "epoch": 7.0176344086021505,
      "grad_norm": 0.01059362426353631,
      "learning_rate": 4.3063008182504314e-05,
      "loss": 0.0,
      "step": 4079
    },
    {
      "epoch": 7.019354838709678,
      "grad_norm": 0.0028652298385302235,
      "learning_rate": 4.301718482381051e-05,
      "loss": 0.0,
      "step": 4080
    },
    {
      "epoch": 7.021075268817205,
      "grad_norm": 0.043679703540401967,
      "learning_rate": 4.2971379176635097e-05,
      "loss": 0.0001,
      "step": 4081
    },
    {
      "epoch": 7.022795698924731,
      "grad_norm": 0.003214415363692676,
      "learning_rate": 4.2925591255215536e-05,
      "loss": 0.0,
      "step": 4082
    },
    {
      "epoch": 7.024516129032258,
      "grad_norm": 0.0035834359623422634,
      "learning_rate": 4.287982107378363e-05,
      "loss": 0.0,
      "step": 4083
    },
    {
      "epoch": 7.026236559139785,
      "grad_norm": 0.00188746512972628,
      "learning_rate": 4.283406864656587e-05,
      "loss": 0.0,
      "step": 4084
    },
    {
      "epoch": 7.027956989247312,
      "grad_norm": 0.8304575920158562,
      "learning_rate": 4.278833398778306e-05,
      "loss": 0.0017,
      "step": 4085
    },
    {
      "epoch": 7.029677419354838,
      "grad_norm": 1.0425433455238498,
      "learning_rate": 4.274261711165051e-05,
      "loss": 0.0029,
      "step": 4086
    },
    {
      "epoch": 7.0313978494623655,
      "grad_norm": 0.0010028309259775966,
      "learning_rate": 4.2696918032378116e-05,
      "loss": 0.0,
      "step": 4087
    },
    {
      "epoch": 7.0331182795698926,
      "grad_norm": 0.02062142117664562,
      "learning_rate": 4.265123676417008e-05,
      "loss": 0.0001,
      "step": 4088
    },
    {
      "epoch": 7.03483870967742,
      "grad_norm": 0.004177644786482083,
      "learning_rate": 4.260557332122519e-05,
      "loss": 0.0,
      "step": 4089
    },
    {
      "epoch": 7.036559139784946,
      "grad_norm": 0.04823554075526187,
      "learning_rate": 4.2559927717736694e-05,
      "loss": 0.0001,
      "step": 4090
    },
    {
      "epoch": 7.038279569892473,
      "grad_norm": 4.046291535081578,
      "learning_rate": 4.2514299967892214e-05,
      "loss": 0.013,
      "step": 4091
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.34206609491099715,
      "learning_rate": 4.246869008587382e-05,
      "loss": 0.0004,
      "step": 4092
    },
    {
      "epoch": 7.041720430107527,
      "grad_norm": 0.009957012040844064,
      "learning_rate": 4.242309808585816e-05,
      "loss": 0.0,
      "step": 4093
    },
    {
      "epoch": 7.043440860215053,
      "grad_norm": 0.08390131320875929,
      "learning_rate": 4.237752398201614e-05,
      "loss": 0.0002,
      "step": 4094
    },
    {
      "epoch": 7.04516129032258,
      "grad_norm": 0.023174130660979578,
      "learning_rate": 4.2331967788513295e-05,
      "loss": 0.0,
      "step": 4095
    },
    {
      "epoch": 7.0468817204301075,
      "grad_norm": 0.06166868187524802,
      "learning_rate": 4.228642951950945e-05,
      "loss": 0.0002,
      "step": 4096
    },
    {
      "epoch": 7.048602150537635,
      "grad_norm": 0.0010612199532499607,
      "learning_rate": 4.224090918915887e-05,
      "loss": 0.0,
      "step": 4097
    },
    {
      "epoch": 7.050322580645162,
      "grad_norm": 0.018130988910037674,
      "learning_rate": 4.2195406811610316e-05,
      "loss": 0.0001,
      "step": 4098
    },
    {
      "epoch": 7.052043010752688,
      "grad_norm": 0.004041361662758351,
      "learning_rate": 4.214992240100697e-05,
      "loss": 0.0,
      "step": 4099
    },
    {
      "epoch": 7.053763440860215,
      "grad_norm": 0.22923625221141536,
      "learning_rate": 4.210445597148631e-05,
      "loss": 0.0004,
      "step": 4100
    },
    {
      "epoch": 7.055483870967742,
      "grad_norm": 0.016647942902243487,
      "learning_rate": 4.20590075371804e-05,
      "loss": 0.0,
      "step": 4101
    },
    {
      "epoch": 7.057204301075269,
      "grad_norm": 0.003447013529181086,
      "learning_rate": 4.2013577112215566e-05,
      "loss": 0.0,
      "step": 4102
    },
    {
      "epoch": 7.058924731182795,
      "grad_norm": 0.0026100980595439964,
      "learning_rate": 4.1968164710712546e-05,
      "loss": 0.0,
      "step": 4103
    },
    {
      "epoch": 7.0606451612903225,
      "grad_norm": 0.7850314295958094,
      "learning_rate": 4.192277034678661e-05,
      "loss": 0.0014,
      "step": 4104
    },
    {
      "epoch": 7.06236559139785,
      "grad_norm": 0.09950006710880413,
      "learning_rate": 4.1877394034547245e-05,
      "loss": 0.0002,
      "step": 4105
    },
    {
      "epoch": 7.064086021505377,
      "grad_norm": 0.44322958097355714,
      "learning_rate": 4.183203578809848e-05,
      "loss": 0.0014,
      "step": 4106
    },
    {
      "epoch": 7.065806451612903,
      "grad_norm": 0.006365599326953954,
      "learning_rate": 4.17866956215386e-05,
      "loss": 0.0,
      "step": 4107
    },
    {
      "epoch": 7.06752688172043,
      "grad_norm": 0.005306450158282279,
      "learning_rate": 4.1741373548960406e-05,
      "loss": 0.0,
      "step": 4108
    },
    {
      "epoch": 7.069247311827957,
      "grad_norm": 0.0030598882189888515,
      "learning_rate": 4.16960695844509e-05,
      "loss": 0.0,
      "step": 4109
    },
    {
      "epoch": 7.070967741935484,
      "grad_norm": 0.034277178855779904,
      "learning_rate": 4.165078374209166e-05,
      "loss": 0.0001,
      "step": 4110
    },
    {
      "epoch": 7.07268817204301,
      "grad_norm": 0.08521236684284987,
      "learning_rate": 4.160551603595845e-05,
      "loss": 0.0004,
      "step": 4111
    },
    {
      "epoch": 7.0744086021505375,
      "grad_norm": 0.008069928697906441,
      "learning_rate": 4.156026648012153e-05,
      "loss": 0.0,
      "step": 4112
    },
    {
      "epoch": 7.0761290322580646,
      "grad_norm": 0.4244102335539603,
      "learning_rate": 4.151503508864543e-05,
      "loss": 0.0009,
      "step": 4113
    },
    {
      "epoch": 7.077849462365592,
      "grad_norm": 0.0001508526876770838,
      "learning_rate": 4.1469821875589035e-05,
      "loss": 0.0,
      "step": 4114
    },
    {
      "epoch": 7.079569892473118,
      "grad_norm": 0.0192074442266077,
      "learning_rate": 4.1424626855005676e-05,
      "loss": 0.0001,
      "step": 4115
    },
    {
      "epoch": 7.081290322580645,
      "grad_norm": 0.008565733591973525,
      "learning_rate": 4.1379450040942905e-05,
      "loss": 0.0,
      "step": 4116
    },
    {
      "epoch": 7.083010752688172,
      "grad_norm": 0.0831219701843953,
      "learning_rate": 4.13342914474427e-05,
      "loss": 0.0001,
      "step": 4117
    },
    {
      "epoch": 7.084731182795699,
      "grad_norm": 1.9392532723029434,
      "learning_rate": 4.128915108854139e-05,
      "loss": 0.0053,
      "step": 4118
    },
    {
      "epoch": 7.086451612903226,
      "grad_norm": 0.0016915789020839588,
      "learning_rate": 4.124402897826955e-05,
      "loss": 0.0,
      "step": 4119
    },
    {
      "epoch": 7.088172043010752,
      "grad_norm": 0.0017791979089666879,
      "learning_rate": 4.119892513065212e-05,
      "loss": 0.0,
      "step": 4120
    },
    {
      "epoch": 7.0898924731182795,
      "grad_norm": 0.001889899478909769,
      "learning_rate": 4.115383955970842e-05,
      "loss": 0.0,
      "step": 4121
    },
    {
      "epoch": 7.091612903225807,
      "grad_norm": 0.09096179088924485,
      "learning_rate": 4.110877227945198e-05,
      "loss": 0.0001,
      "step": 4122
    },
    {
      "epoch": 7.093333333333334,
      "grad_norm": 0.7950092511002543,
      "learning_rate": 4.1063723303890763e-05,
      "loss": 0.0023,
      "step": 4123
    },
    {
      "epoch": 7.09505376344086,
      "grad_norm": 0.004447665951943742,
      "learning_rate": 4.101869264702698e-05,
      "loss": 0.0,
      "step": 4124
    },
    {
      "epoch": 7.096774193548387,
      "grad_norm": 0.02103188216226304,
      "learning_rate": 4.0973680322857086e-05,
      "loss": 0.0001,
      "step": 4125
    },
    {
      "epoch": 7.098494623655914,
      "grad_norm": 0.001410146648245989,
      "learning_rate": 4.092868634537197e-05,
      "loss": 0.0,
      "step": 4126
    },
    {
      "epoch": 7.100215053763441,
      "grad_norm": 0.00025645667958427624,
      "learning_rate": 4.088371072855678e-05,
      "loss": 0.0,
      "step": 4127
    },
    {
      "epoch": 7.101935483870967,
      "grad_norm": 0.0004823771600544959,
      "learning_rate": 4.0838753486390846e-05,
      "loss": 0.0,
      "step": 4128
    },
    {
      "epoch": 7.1036559139784945,
      "grad_norm": 0.0015107033828704738,
      "learning_rate": 4.079381463284797e-05,
      "loss": 0.0,
      "step": 4129
    },
    {
      "epoch": 7.105376344086022,
      "grad_norm": 0.0003066159244786699,
      "learning_rate": 4.074889418189608e-05,
      "loss": 0.0,
      "step": 4130
    },
    {
      "epoch": 7.107096774193549,
      "grad_norm": 0.01897856675612166,
      "learning_rate": 4.0703992147497425e-05,
      "loss": 0.0001,
      "step": 4131
    },
    {
      "epoch": 7.108817204301075,
      "grad_norm": 0.0012878524530955202,
      "learning_rate": 4.065910854360863e-05,
      "loss": 0.0,
      "step": 4132
    },
    {
      "epoch": 7.110537634408602,
      "grad_norm": 0.0018685881942303285,
      "learning_rate": 4.061424338418045e-05,
      "loss": 0.0,
      "step": 4133
    },
    {
      "epoch": 7.112258064516129,
      "grad_norm": 8.744691494580963e-05,
      "learning_rate": 4.056939668315791e-05,
      "loss": 0.0,
      "step": 4134
    },
    {
      "epoch": 7.113978494623656,
      "grad_norm": 0.022159157771221728,
      "learning_rate": 4.0524568454480496e-05,
      "loss": 0.0001,
      "step": 4135
    },
    {
      "epoch": 7.115698924731182,
      "grad_norm": 0.00027517860963242224,
      "learning_rate": 4.047975871208175e-05,
      "loss": 0.0,
      "step": 4136
    },
    {
      "epoch": 7.1174193548387095,
      "grad_norm": 0.003626912662738278,
      "learning_rate": 4.0434967469889486e-05,
      "loss": 0.0,
      "step": 4137
    },
    {
      "epoch": 7.119139784946237,
      "grad_norm": 0.07983929750192034,
      "learning_rate": 4.039019474182588e-05,
      "loss": 0.0002,
      "step": 4138
    },
    {
      "epoch": 7.120860215053764,
      "grad_norm": 0.002439655522028872,
      "learning_rate": 4.0345440541807225e-05,
      "loss": 0.0,
      "step": 4139
    },
    {
      "epoch": 7.122580645161291,
      "grad_norm": 0.000693239588829107,
      "learning_rate": 4.0300704883744164e-05,
      "loss": 0.0,
      "step": 4140
    },
    {
      "epoch": 7.124301075268817,
      "grad_norm": 0.004049841265681008,
      "learning_rate": 4.0255987781541525e-05,
      "loss": 0.0,
      "step": 4141
    },
    {
      "epoch": 7.126021505376344,
      "grad_norm": 0.0002697545948778464,
      "learning_rate": 4.0211289249098325e-05,
      "loss": 0.0,
      "step": 4142
    },
    {
      "epoch": 7.127741935483871,
      "grad_norm": 0.0031358594340809122,
      "learning_rate": 4.0166609300307875e-05,
      "loss": 0.0,
      "step": 4143
    },
    {
      "epoch": 7.129462365591398,
      "grad_norm": 0.13621200140404924,
      "learning_rate": 4.012194794905775e-05,
      "loss": 0.0002,
      "step": 4144
    },
    {
      "epoch": 7.131182795698924,
      "grad_norm": 0.024114589606695946,
      "learning_rate": 4.0077305209229596e-05,
      "loss": 0.0001,
      "step": 4145
    },
    {
      "epoch": 7.1329032258064515,
      "grad_norm": 0.013407777432847892,
      "learning_rate": 4.0032681094699444e-05,
      "loss": 0.0,
      "step": 4146
    },
    {
      "epoch": 7.134623655913979,
      "grad_norm": 0.01752817759769056,
      "learning_rate": 3.9988075619337415e-05,
      "loss": 0.0,
      "step": 4147
    },
    {
      "epoch": 7.136344086021506,
      "grad_norm": 0.030830682022310377,
      "learning_rate": 3.994348879700785e-05,
      "loss": 0.0001,
      "step": 4148
    },
    {
      "epoch": 7.138064516129032,
      "grad_norm": 0.10387171818768362,
      "learning_rate": 3.989892064156936e-05,
      "loss": 0.0003,
      "step": 4149
    },
    {
      "epoch": 7.139784946236559,
      "grad_norm": 0.0027447809904618,
      "learning_rate": 3.9854371166874716e-05,
      "loss": 0.0,
      "step": 4150
    },
    {
      "epoch": 7.141505376344086,
      "grad_norm": 0.016439619343514716,
      "learning_rate": 3.9809840386770825e-05,
      "loss": 0.0,
      "step": 4151
    },
    {
      "epoch": 7.143225806451613,
      "grad_norm": 0.010569180871765322,
      "learning_rate": 3.976532831509887e-05,
      "loss": 0.0,
      "step": 4152
    },
    {
      "epoch": 7.144946236559139,
      "grad_norm": 0.002222017772097843,
      "learning_rate": 3.9720834965694234e-05,
      "loss": 0.0,
      "step": 4153
    },
    {
      "epoch": 7.1466666666666665,
      "grad_norm": 0.00035412345875311137,
      "learning_rate": 3.9676360352386356e-05,
      "loss": 0.0,
      "step": 4154
    },
    {
      "epoch": 7.148387096774194,
      "grad_norm": 0.009296288773538308,
      "learning_rate": 3.963190448899899e-05,
      "loss": 0.0,
      "step": 4155
    },
    {
      "epoch": 7.150107526881721,
      "grad_norm": 0.17618103778181413,
      "learning_rate": 3.958746738934995e-05,
      "loss": 0.0002,
      "step": 4156
    },
    {
      "epoch": 7.151827956989247,
      "grad_norm": 0.009957633818806152,
      "learning_rate": 3.9543049067251324e-05,
      "loss": 0.0,
      "step": 4157
    },
    {
      "epoch": 7.153548387096774,
      "grad_norm": 0.07618815244422576,
      "learning_rate": 3.949864953650929e-05,
      "loss": 0.0001,
      "step": 4158
    },
    {
      "epoch": 7.155268817204301,
      "grad_norm": 0.004275533027799511,
      "learning_rate": 3.945426881092414e-05,
      "loss": 0.0,
      "step": 4159
    },
    {
      "epoch": 7.156989247311828,
      "grad_norm": 0.0006295307044156785,
      "learning_rate": 3.9409906904290484e-05,
      "loss": 0.0,
      "step": 4160
    },
    {
      "epoch": 7.158709677419355,
      "grad_norm": 0.00042327012474161087,
      "learning_rate": 3.936556383039689e-05,
      "loss": 0.0,
      "step": 4161
    },
    {
      "epoch": 7.1604301075268815,
      "grad_norm": 0.005594089870940067,
      "learning_rate": 3.9321239603026213e-05,
      "loss": 0.0,
      "step": 4162
    },
    {
      "epoch": 7.162150537634409,
      "grad_norm": 0.0006129893259904804,
      "learning_rate": 3.9276934235955444e-05,
      "loss": 0.0,
      "step": 4163
    },
    {
      "epoch": 7.163870967741936,
      "grad_norm": 0.22187740602256376,
      "learning_rate": 3.923264774295562e-05,
      "loss": 0.0012,
      "step": 4164
    },
    {
      "epoch": 7.165591397849463,
      "grad_norm": 1.4270334693849906,
      "learning_rate": 3.9188380137791936e-05,
      "loss": 0.0027,
      "step": 4165
    },
    {
      "epoch": 7.167311827956989,
      "grad_norm": 0.0006327597116094501,
      "learning_rate": 3.9144131434223805e-05,
      "loss": 0.0,
      "step": 4166
    },
    {
      "epoch": 7.169032258064516,
      "grad_norm": 0.0031995839168397935,
      "learning_rate": 3.909990164600468e-05,
      "loss": 0.0,
      "step": 4167
    },
    {
      "epoch": 7.170752688172043,
      "grad_norm": 0.0009806571987121245,
      "learning_rate": 3.905569078688211e-05,
      "loss": 0.0,
      "step": 4168
    },
    {
      "epoch": 7.17247311827957,
      "grad_norm": 0.018702960330815886,
      "learning_rate": 3.901149887059786e-05,
      "loss": 0.0,
      "step": 4169
    },
    {
      "epoch": 7.174193548387096,
      "grad_norm": 0.0005862198383802743,
      "learning_rate": 3.896732591088773e-05,
      "loss": 0.0,
      "step": 4170
    },
    {
      "epoch": 7.1759139784946235,
      "grad_norm": 0.0019674607668730766,
      "learning_rate": 3.892317192148165e-05,
      "loss": 0.0,
      "step": 4171
    },
    {
      "epoch": 7.177634408602151,
      "grad_norm": 0.0016321307592452707,
      "learning_rate": 3.8879036916103704e-05,
      "loss": 0.0,
      "step": 4172
    },
    {
      "epoch": 7.179354838709678,
      "grad_norm": 0.02269280044136774,
      "learning_rate": 3.883492090847196e-05,
      "loss": 0.0001,
      "step": 4173
    },
    {
      "epoch": 7.181075268817204,
      "grad_norm": 4.488199147762541e-05,
      "learning_rate": 3.879082391229871e-05,
      "loss": 0.0,
      "step": 4174
    },
    {
      "epoch": 7.182795698924731,
      "grad_norm": 0.00023349774604987188,
      "learning_rate": 3.8746745941290255e-05,
      "loss": 0.0,
      "step": 4175
    },
    {
      "epoch": 7.184516129032258,
      "grad_norm": 0.10533875761102826,
      "learning_rate": 3.870268700914694e-05,
      "loss": 0.0005,
      "step": 4176
    },
    {
      "epoch": 7.186236559139785,
      "grad_norm": 0.0018178192660952127,
      "learning_rate": 3.8658647129563364e-05,
      "loss": 0.0,
      "step": 4177
    },
    {
      "epoch": 7.187956989247311,
      "grad_norm": 0.014528153163107396,
      "learning_rate": 3.861462631622802e-05,
      "loss": 0.0,
      "step": 4178
    },
    {
      "epoch": 7.1896774193548385,
      "grad_norm": 0.0007173329814099706,
      "learning_rate": 3.85706245828235e-05,
      "loss": 0.0,
      "step": 4179
    },
    {
      "epoch": 7.191397849462366,
      "grad_norm": 0.014488696709355924,
      "learning_rate": 3.852664194302665e-05,
      "loss": 0.0,
      "step": 4180
    },
    {
      "epoch": 7.193118279569893,
      "grad_norm": 0.0010417137097024133,
      "learning_rate": 3.8482678410508185e-05,
      "loss": 0.0,
      "step": 4181
    },
    {
      "epoch": 7.19483870967742,
      "grad_norm": 0.004617459116039004,
      "learning_rate": 3.843873399893291e-05,
      "loss": 0.0,
      "step": 4182
    },
    {
      "epoch": 7.196559139784946,
      "grad_norm": 5.232941374923968e-05,
      "learning_rate": 3.839480872195976e-05,
      "loss": 0.0,
      "step": 4183
    },
    {
      "epoch": 7.198279569892473,
      "grad_norm": 0.01245335631278587,
      "learning_rate": 3.835090259324169e-05,
      "loss": 0.0,
      "step": 4184
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.011670115388686694,
      "learning_rate": 3.830701562642563e-05,
      "loss": 0.0,
      "step": 4185
    },
    {
      "epoch": 7.201720430107527,
      "grad_norm": 0.00027209988456445894,
      "learning_rate": 3.826314783515269e-05,
      "loss": 0.0,
      "step": 4186
    },
    {
      "epoch": 7.2034408602150535,
      "grad_norm": 0.009825043039885071,
      "learning_rate": 3.8219299233057896e-05,
      "loss": 0.0,
      "step": 4187
    },
    {
      "epoch": 7.205161290322581,
      "grad_norm": 0.003547894613896224,
      "learning_rate": 3.8175469833770386e-05,
      "loss": 0.0,
      "step": 4188
    },
    {
      "epoch": 7.206881720430108,
      "grad_norm": 0.003107141463407437,
      "learning_rate": 3.813165965091333e-05,
      "loss": 0.0,
      "step": 4189
    },
    {
      "epoch": 7.208602150537635,
      "grad_norm": 0.0012620655124562631,
      "learning_rate": 3.8087868698103865e-05,
      "loss": 0.0,
      "step": 4190
    },
    {
      "epoch": 7.210322580645161,
      "grad_norm": 0.0003547094651726403,
      "learning_rate": 3.804409698895323e-05,
      "loss": 0.0,
      "step": 4191
    },
    {
      "epoch": 7.212043010752688,
      "grad_norm": 0.507903702795536,
      "learning_rate": 3.80003445370666e-05,
      "loss": 0.0014,
      "step": 4192
    },
    {
      "epoch": 7.213763440860215,
      "grad_norm": 0.006745214454096745,
      "learning_rate": 3.795661135604319e-05,
      "loss": 0.0,
      "step": 4193
    },
    {
      "epoch": 7.215483870967742,
      "grad_norm": 0.009426076188157044,
      "learning_rate": 3.79128974594763e-05,
      "loss": 0.0,
      "step": 4194
    },
    {
      "epoch": 7.2172043010752684,
      "grad_norm": 8.796775338495215e-05,
      "learning_rate": 3.7869202860953146e-05,
      "loss": 0.0,
      "step": 4195
    },
    {
      "epoch": 7.2189247311827955,
      "grad_norm": 0.00040208528589979553,
      "learning_rate": 3.782552757405493e-05,
      "loss": 0.0,
      "step": 4196
    },
    {
      "epoch": 7.220645161290323,
      "grad_norm": 0.029517758953631623,
      "learning_rate": 3.778187161235693e-05,
      "loss": 0.0,
      "step": 4197
    },
    {
      "epoch": 7.22236559139785,
      "grad_norm": 0.00018258848215237482,
      "learning_rate": 3.7738234989428425e-05,
      "loss": 0.0,
      "step": 4198
    },
    {
      "epoch": 7.224086021505376,
      "grad_norm": 0.0008564786196288901,
      "learning_rate": 3.769461771883257e-05,
      "loss": 0.0,
      "step": 4199
    },
    {
      "epoch": 7.225806451612903,
      "grad_norm": 0.0010063934789258145,
      "learning_rate": 3.7651019814126654e-05,
      "loss": 0.0,
      "step": 4200
    },
    {
      "epoch": 7.22752688172043,
      "grad_norm": 0.004847771363775114,
      "learning_rate": 3.7607441288861824e-05,
      "loss": 0.0,
      "step": 4201
    },
    {
      "epoch": 7.229247311827957,
      "grad_norm": 0.0006180424358870939,
      "learning_rate": 3.756388215658322e-05,
      "loss": 0.0,
      "step": 4202
    },
    {
      "epoch": 7.230967741935483,
      "grad_norm": 0.0014867973658609012,
      "learning_rate": 3.752034243083005e-05,
      "loss": 0.0,
      "step": 4203
    },
    {
      "epoch": 7.2326881720430105,
      "grad_norm": 0.14405304887996,
      "learning_rate": 3.7476822125135356e-05,
      "loss": 0.0002,
      "step": 4204
    },
    {
      "epoch": 7.234408602150538,
      "grad_norm": 0.16826324418159982,
      "learning_rate": 3.7433321253026275e-05,
      "loss": 0.0009,
      "step": 4205
    },
    {
      "epoch": 7.236129032258065,
      "grad_norm": 0.00017122782932494322,
      "learning_rate": 3.738983982802378e-05,
      "loss": 0.0,
      "step": 4206
    },
    {
      "epoch": 7.237849462365592,
      "grad_norm": 0.03681510537312442,
      "learning_rate": 3.734637786364288e-05,
      "loss": 0.0001,
      "step": 4207
    },
    {
      "epoch": 7.239569892473118,
      "grad_norm": 0.20866334121878236,
      "learning_rate": 3.7302935373392554e-05,
      "loss": 0.0004,
      "step": 4208
    },
    {
      "epoch": 7.241290322580645,
      "grad_norm": 1.410039876728302,
      "learning_rate": 3.725951237077566e-05,
      "loss": 0.0018,
      "step": 4209
    },
    {
      "epoch": 7.243010752688172,
      "grad_norm": 0.0005159330133579266,
      "learning_rate": 3.721610886928899e-05,
      "loss": 0.0,
      "step": 4210
    },
    {
      "epoch": 7.244731182795699,
      "grad_norm": 0.009536812504424704,
      "learning_rate": 3.717272488242337e-05,
      "loss": 0.0,
      "step": 4211
    },
    {
      "epoch": 7.2464516129032255,
      "grad_norm": 0.05639630516519763,
      "learning_rate": 3.7129360423663486e-05,
      "loss": 0.0001,
      "step": 4212
    },
    {
      "epoch": 7.248172043010753,
      "grad_norm": 0.0012239073690542676,
      "learning_rate": 3.708601550648792e-05,
      "loss": 0.0,
      "step": 4213
    },
    {
      "epoch": 7.24989247311828,
      "grad_norm": 0.012269272560343629,
      "learning_rate": 3.704269014436932e-05,
      "loss": 0.0,
      "step": 4214
    },
    {
      "epoch": 7.251612903225807,
      "grad_norm": 0.003869750860232623,
      "learning_rate": 3.699938435077407e-05,
      "loss": 0.0,
      "step": 4215
    },
    {
      "epoch": 7.253333333333333,
      "grad_norm": 0.020646779293441213,
      "learning_rate": 3.695609813916261e-05,
      "loss": 0.0001,
      "step": 4216
    },
    {
      "epoch": 7.25505376344086,
      "grad_norm": 0.0034619794740441755,
      "learning_rate": 3.69128315229893e-05,
      "loss": 0.0,
      "step": 4217
    },
    {
      "epoch": 7.256774193548387,
      "grad_norm": 0.007276164355602082,
      "learning_rate": 3.68695845157023e-05,
      "loss": 0.0,
      "step": 4218
    },
    {
      "epoch": 7.258494623655914,
      "grad_norm": 1.3795753246299223,
      "learning_rate": 3.6826357130743736e-05,
      "loss": 0.0075,
      "step": 4219
    },
    {
      "epoch": 7.2602150537634405,
      "grad_norm": 0.0016647790744317792,
      "learning_rate": 3.6783149381549675e-05,
      "loss": 0.0,
      "step": 4220
    },
    {
      "epoch": 7.2619354838709675,
      "grad_norm": 0.09520583616576885,
      "learning_rate": 3.6739961281549995e-05,
      "loss": 0.0002,
      "step": 4221
    },
    {
      "epoch": 7.263655913978495,
      "grad_norm": 0.0002750493581996662,
      "learning_rate": 3.669679284416856e-05,
      "loss": 0.0,
      "step": 4222
    },
    {
      "epoch": 7.265376344086022,
      "grad_norm": 7.120950623682707,
      "learning_rate": 3.665364408282305e-05,
      "loss": 0.0265,
      "step": 4223
    },
    {
      "epoch": 7.267096774193549,
      "grad_norm": 0.014632872863202888,
      "learning_rate": 3.6610515010924976e-05,
      "loss": 0.0,
      "step": 4224
    },
    {
      "epoch": 7.268817204301075,
      "grad_norm": 0.00967511256538541,
      "learning_rate": 3.6567405641879946e-05,
      "loss": 0.0,
      "step": 4225
    },
    {
      "epoch": 7.270537634408602,
      "grad_norm": 0.0036621373768566967,
      "learning_rate": 3.652431598908726e-05,
      "loss": 0.0,
      "step": 4226
    },
    {
      "epoch": 7.272258064516129,
      "grad_norm": 4.40178530437156,
      "learning_rate": 3.648124606594007e-05,
      "loss": 0.0109,
      "step": 4227
    },
    {
      "epoch": 7.273978494623656,
      "grad_norm": 8.187515060397674e-05,
      "learning_rate": 3.643819588582553e-05,
      "loss": 0.0,
      "step": 4228
    },
    {
      "epoch": 7.2756989247311825,
      "grad_norm": 0.0009312974680053916,
      "learning_rate": 3.639516546212458e-05,
      "loss": 0.0,
      "step": 4229
    },
    {
      "epoch": 7.27741935483871,
      "grad_norm": 0.0005787879127769367,
      "learning_rate": 3.635215480821197e-05,
      "loss": 0.0,
      "step": 4230
    },
    {
      "epoch": 7.279139784946237,
      "grad_norm": 0.0015438909962782474,
      "learning_rate": 3.630916393745644e-05,
      "loss": 0.0,
      "step": 4231
    },
    {
      "epoch": 7.280860215053764,
      "grad_norm": 0.001541963390922407,
      "learning_rate": 3.626619286322042e-05,
      "loss": 0.0,
      "step": 4232
    },
    {
      "epoch": 7.28258064516129,
      "grad_norm": 0.01892266684343136,
      "learning_rate": 3.622324159886031e-05,
      "loss": 0.0001,
      "step": 4233
    },
    {
      "epoch": 7.284301075268817,
      "grad_norm": 0.03382238683286139,
      "learning_rate": 3.618031015772637e-05,
      "loss": 0.0001,
      "step": 4234
    },
    {
      "epoch": 7.286021505376344,
      "grad_norm": 0.009667060306398861,
      "learning_rate": 3.613739855316257e-05,
      "loss": 0.0,
      "step": 4235
    },
    {
      "epoch": 7.287741935483871,
      "grad_norm": 0.014548395168393414,
      "learning_rate": 3.6094506798506776e-05,
      "loss": 0.0,
      "step": 4236
    },
    {
      "epoch": 7.2894623655913975,
      "grad_norm": 0.01919869139969091,
      "learning_rate": 3.605163490709076e-05,
      "loss": 0.0001,
      "step": 4237
    },
    {
      "epoch": 7.291182795698925,
      "grad_norm": 0.0004172455329220609,
      "learning_rate": 3.600878289223997e-05,
      "loss": 0.0,
      "step": 4238
    },
    {
      "epoch": 7.292903225806452,
      "grad_norm": 0.01183215233608252,
      "learning_rate": 3.5965950767273835e-05,
      "loss": 0.0,
      "step": 4239
    },
    {
      "epoch": 7.294623655913979,
      "grad_norm": 0.006651364307567083,
      "learning_rate": 3.59231385455055e-05,
      "loss": 0.0,
      "step": 4240
    },
    {
      "epoch": 7.296344086021505,
      "grad_norm": 0.8757665386316051,
      "learning_rate": 3.5880346240241903e-05,
      "loss": 0.0014,
      "step": 4241
    },
    {
      "epoch": 7.298064516129032,
      "grad_norm": 0.0015889503638791714,
      "learning_rate": 3.583757386478389e-05,
      "loss": 0.0,
      "step": 4242
    },
    {
      "epoch": 7.299784946236559,
      "grad_norm": 0.012074347160399904,
      "learning_rate": 3.579482143242607e-05,
      "loss": 0.0,
      "step": 4243
    },
    {
      "epoch": 7.301505376344086,
      "grad_norm": 0.029302440955975145,
      "learning_rate": 3.57520889564568e-05,
      "loss": 0.0001,
      "step": 4244
    },
    {
      "epoch": 7.3032258064516125,
      "grad_norm": 0.023723135830766406,
      "learning_rate": 3.5709376450158325e-05,
      "loss": 0.0,
      "step": 4245
    },
    {
      "epoch": 7.3049462365591395,
      "grad_norm": 0.0013429655196671975,
      "learning_rate": 3.566668392680662e-05,
      "loss": 0.0,
      "step": 4246
    },
    {
      "epoch": 7.306666666666667,
      "grad_norm": 0.01109525268077144,
      "learning_rate": 3.562401139967142e-05,
      "loss": 0.0,
      "step": 4247
    },
    {
      "epoch": 7.308387096774194,
      "grad_norm": 0.0005386194762289416,
      "learning_rate": 3.558135888201636e-05,
      "loss": 0.0,
      "step": 4248
    },
    {
      "epoch": 7.310107526881721,
      "grad_norm": 0.0021761688557908367,
      "learning_rate": 3.553872638709871e-05,
      "loss": 0.0,
      "step": 4249
    },
    {
      "epoch": 7.311827956989247,
      "grad_norm": 0.04735136019296214,
      "learning_rate": 3.549611392816968e-05,
      "loss": 0.0001,
      "step": 4250
    },
    {
      "epoch": 7.313548387096774,
      "grad_norm": 0.0037847709517477945,
      "learning_rate": 3.545352151847408e-05,
      "loss": 0.0,
      "step": 4251
    },
    {
      "epoch": 7.315268817204301,
      "grad_norm": 0.00029178816061055027,
      "learning_rate": 3.5410949171250605e-05,
      "loss": 0.0,
      "step": 4252
    },
    {
      "epoch": 7.316989247311828,
      "grad_norm": 3.8868766205194365e-05,
      "learning_rate": 3.5368396899731726e-05,
      "loss": 0.0,
      "step": 4253
    },
    {
      "epoch": 7.3187096774193545,
      "grad_norm": 0.020972046762524118,
      "learning_rate": 3.5325864717143584e-05,
      "loss": 0.0001,
      "step": 4254
    },
    {
      "epoch": 7.320430107526882,
      "grad_norm": 0.14736575336181137,
      "learning_rate": 3.5283352636706105e-05,
      "loss": 0.0004,
      "step": 4255
    },
    {
      "epoch": 7.322150537634409,
      "grad_norm": 0.005155785077488477,
      "learning_rate": 3.5240860671633024e-05,
      "loss": 0.0,
      "step": 4256
    },
    {
      "epoch": 7.323870967741936,
      "grad_norm": 0.001693233098926148,
      "learning_rate": 3.519838883513177e-05,
      "loss": 0.0,
      "step": 4257
    },
    {
      "epoch": 7.325591397849462,
      "grad_norm": 0.000784274386550884,
      "learning_rate": 3.515593714040349e-05,
      "loss": 0.0,
      "step": 4258
    },
    {
      "epoch": 7.327311827956989,
      "grad_norm": 0.03783226272215698,
      "learning_rate": 3.511350560064318e-05,
      "loss": 0.0001,
      "step": 4259
    },
    {
      "epoch": 7.329032258064516,
      "grad_norm": 0.006865893073677957,
      "learning_rate": 3.5071094229039424e-05,
      "loss": 0.0,
      "step": 4260
    },
    {
      "epoch": 7.330752688172043,
      "grad_norm": 0.0038091139984808217,
      "learning_rate": 3.5028703038774655e-05,
      "loss": 0.0,
      "step": 4261
    },
    {
      "epoch": 7.3324731182795695,
      "grad_norm": 0.054070195715803744,
      "learning_rate": 3.498633204302501e-05,
      "loss": 0.0002,
      "step": 4262
    },
    {
      "epoch": 7.334193548387097,
      "grad_norm": 0.005542557821934002,
      "learning_rate": 3.494398125496032e-05,
      "loss": 0.0,
      "step": 4263
    },
    {
      "epoch": 7.335913978494624,
      "grad_norm": 0.008321207330922922,
      "learning_rate": 3.4901650687744114e-05,
      "loss": 0.0,
      "step": 4264
    },
    {
      "epoch": 7.337634408602151,
      "grad_norm": 0.0026426448987222086,
      "learning_rate": 3.485934035453371e-05,
      "loss": 0.0,
      "step": 4265
    },
    {
      "epoch": 7.339354838709678,
      "grad_norm": 0.0061052715148007634,
      "learning_rate": 3.4817050268480034e-05,
      "loss": 0.0,
      "step": 4266
    },
    {
      "epoch": 7.341075268817204,
      "grad_norm": 0.006850344117389758,
      "learning_rate": 3.477478044272786e-05,
      "loss": 0.0,
      "step": 4267
    },
    {
      "epoch": 7.342795698924731,
      "grad_norm": 9.881136104947183e-05,
      "learning_rate": 3.473253089041555e-05,
      "loss": 0.0,
      "step": 4268
    },
    {
      "epoch": 7.344516129032258,
      "grad_norm": 0.0008463775184384035,
      "learning_rate": 3.469030162467513e-05,
      "loss": 0.0,
      "step": 4269
    },
    {
      "epoch": 7.346236559139785,
      "grad_norm": 0.0028938183852730936,
      "learning_rate": 3.46480926586325e-05,
      "loss": 0.0,
      "step": 4270
    },
    {
      "epoch": 7.3479569892473116,
      "grad_norm": 0.193937110452581,
      "learning_rate": 3.46059040054071e-05,
      "loss": 0.0006,
      "step": 4271
    },
    {
      "epoch": 7.349677419354839,
      "grad_norm": 0.02693220817146418,
      "learning_rate": 3.456373567811205e-05,
      "loss": 0.0001,
      "step": 4272
    },
    {
      "epoch": 7.351397849462366,
      "grad_norm": 1.1701812497171185,
      "learning_rate": 3.452158768985427e-05,
      "loss": 0.0025,
      "step": 4273
    },
    {
      "epoch": 7.353118279569893,
      "grad_norm": 0.0020973249250914,
      "learning_rate": 3.447946005373426e-05,
      "loss": 0.0,
      "step": 4274
    },
    {
      "epoch": 7.354838709677419,
      "grad_norm": 0.05116841732421129,
      "learning_rate": 3.443735278284618e-05,
      "loss": 0.0001,
      "step": 4275
    },
    {
      "epoch": 7.356559139784946,
      "grad_norm": 0.08993239672874567,
      "learning_rate": 3.439526589027795e-05,
      "loss": 0.0003,
      "step": 4276
    },
    {
      "epoch": 7.358279569892473,
      "grad_norm": 0.00565139390260707,
      "learning_rate": 3.4353199389111065e-05,
      "loss": 0.0,
      "step": 4277
    },
    {
      "epoch": 7.36,
      "grad_norm": 2.9481057662363344,
      "learning_rate": 3.431115329242075e-05,
      "loss": 0.0114,
      "step": 4278
    },
    {
      "epoch": 7.3617204301075265,
      "grad_norm": 0.003528685858923667,
      "learning_rate": 3.426912761327588e-05,
      "loss": 0.0,
      "step": 4279
    },
    {
      "epoch": 7.363440860215054,
      "grad_norm": 0.008659277265585689,
      "learning_rate": 3.422712236473895e-05,
      "loss": 0.0,
      "step": 4280
    },
    {
      "epoch": 7.365161290322581,
      "grad_norm": 0.01071212019709486,
      "learning_rate": 3.4185137559866085e-05,
      "loss": 0.0,
      "step": 4281
    },
    {
      "epoch": 7.366881720430108,
      "grad_norm": 0.2213594540733701,
      "learning_rate": 3.4143173211707145e-05,
      "loss": 0.0001,
      "step": 4282
    },
    {
      "epoch": 7.368602150537634,
      "grad_norm": 0.0013839189864470977,
      "learning_rate": 3.410122933330552e-05,
      "loss": 0.0,
      "step": 4283
    },
    {
      "epoch": 7.370322580645161,
      "grad_norm": 0.0017511112321862124,
      "learning_rate": 3.405930593769836e-05,
      "loss": 0.0,
      "step": 4284
    },
    {
      "epoch": 7.372043010752688,
      "grad_norm": 0.0015000122438335254,
      "learning_rate": 3.401740303791634e-05,
      "loss": 0.0,
      "step": 4285
    },
    {
      "epoch": 7.373763440860215,
      "grad_norm": 1.0199862922765786,
      "learning_rate": 3.397552064698379e-05,
      "loss": 0.0036,
      "step": 4286
    },
    {
      "epoch": 7.3754838709677415,
      "grad_norm": 0.0012773315124555522,
      "learning_rate": 3.3933658777918706e-05,
      "loss": 0.0,
      "step": 4287
    },
    {
      "epoch": 7.377204301075269,
      "grad_norm": 0.004312307033858318,
      "learning_rate": 3.389181744373271e-05,
      "loss": 0.0,
      "step": 4288
    },
    {
      "epoch": 7.378924731182796,
      "grad_norm": 1.6154493606689706,
      "learning_rate": 3.384999665743096e-05,
      "loss": 0.0049,
      "step": 4289
    },
    {
      "epoch": 7.380645161290323,
      "grad_norm": 0.06568728090574782,
      "learning_rate": 3.380819643201234e-05,
      "loss": 0.0001,
      "step": 4290
    },
    {
      "epoch": 7.38236559139785,
      "grad_norm": 0.006767887266123178,
      "learning_rate": 3.3766416780469256e-05,
      "loss": 0.0,
      "step": 4291
    },
    {
      "epoch": 7.384086021505376,
      "grad_norm": 0.0019677770414938713,
      "learning_rate": 3.372465771578771e-05,
      "loss": 0.0,
      "step": 4292
    },
    {
      "epoch": 7.385806451612903,
      "grad_norm": 2.465742908021308,
      "learning_rate": 3.3682919250947396e-05,
      "loss": 0.027,
      "step": 4293
    },
    {
      "epoch": 7.38752688172043,
      "grad_norm": 0.006989258782869144,
      "learning_rate": 3.3641201398921505e-05,
      "loss": 0.0,
      "step": 4294
    },
    {
      "epoch": 7.389247311827957,
      "grad_norm": 0.07821703664956202,
      "learning_rate": 3.359950417267693e-05,
      "loss": 0.0003,
      "step": 4295
    },
    {
      "epoch": 7.390967741935484,
      "grad_norm": 0.00615206206446531,
      "learning_rate": 3.355782758517402e-05,
      "loss": 0.0,
      "step": 4296
    },
    {
      "epoch": 7.392688172043011,
      "grad_norm": 0.0012646069961945322,
      "learning_rate": 3.351617164936685e-05,
      "loss": 0.0,
      "step": 4297
    },
    {
      "epoch": 7.394408602150538,
      "grad_norm": 0.001821860145850989,
      "learning_rate": 3.3474536378202926e-05,
      "loss": 0.0,
      "step": 4298
    },
    {
      "epoch": 7.396129032258065,
      "grad_norm": 0.00839550194695025,
      "learning_rate": 3.343292178462349e-05,
      "loss": 0.0,
      "step": 4299
    },
    {
      "epoch": 7.397849462365591,
      "grad_norm": 0.00027595329264979904,
      "learning_rate": 3.3391327881563215e-05,
      "loss": 0.0,
      "step": 4300
    },
    {
      "epoch": 7.399569892473118,
      "grad_norm": 0.04478739782389101,
      "learning_rate": 3.334975468195045e-05,
      "loss": 0.0001,
      "step": 4301
    },
    {
      "epoch": 7.401290322580645,
      "grad_norm": 0.044660511518983925,
      "learning_rate": 3.3308202198707065e-05,
      "loss": 0.0001,
      "step": 4302
    },
    {
      "epoch": 7.403010752688172,
      "grad_norm": 0.013592259676683802,
      "learning_rate": 3.3266670444748414e-05,
      "loss": 0.0,
      "step": 4303
    },
    {
      "epoch": 7.4047311827956985,
      "grad_norm": 0.005083727363871294,
      "learning_rate": 3.322515943298359e-05,
      "loss": 0.0,
      "step": 4304
    },
    {
      "epoch": 7.406451612903226,
      "grad_norm": 0.010549361746552358,
      "learning_rate": 3.3183669176315045e-05,
      "loss": 0.0,
      "step": 4305
    },
    {
      "epoch": 7.408172043010753,
      "grad_norm": 0.0655823548637744,
      "learning_rate": 3.314219968763891e-05,
      "loss": 0.0001,
      "step": 4306
    },
    {
      "epoch": 7.40989247311828,
      "grad_norm": 0.002343848418249923,
      "learning_rate": 3.310075097984485e-05,
      "loss": 0.0,
      "step": 4307
    },
    {
      "epoch": 7.411612903225807,
      "grad_norm": 0.714508108649164,
      "learning_rate": 3.305932306581599e-05,
      "loss": 0.0019,
      "step": 4308
    },
    {
      "epoch": 7.413333333333333,
      "grad_norm": 0.060831990569508415,
      "learning_rate": 3.3017915958429044e-05,
      "loss": 0.0002,
      "step": 4309
    },
    {
      "epoch": 7.41505376344086,
      "grad_norm": 0.0033453827364238113,
      "learning_rate": 3.297652967055429e-05,
      "loss": 0.0,
      "step": 4310
    },
    {
      "epoch": 7.416774193548387,
      "grad_norm": 0.28596398618924623,
      "learning_rate": 3.293516421505545e-05,
      "loss": 0.0004,
      "step": 4311
    },
    {
      "epoch": 7.418494623655914,
      "grad_norm": 0.0004260186954793048,
      "learning_rate": 3.289381960478988e-05,
      "loss": 0.0,
      "step": 4312
    },
    {
      "epoch": 7.420215053763441,
      "grad_norm": 0.0014937013158016575,
      "learning_rate": 3.2852495852608366e-05,
      "loss": 0.0,
      "step": 4313
    },
    {
      "epoch": 7.421935483870968,
      "grad_norm": 0.0008759713299104026,
      "learning_rate": 3.281119297135522e-05,
      "loss": 0.0,
      "step": 4314
    },
    {
      "epoch": 7.423655913978495,
      "grad_norm": 0.002911000609098035,
      "learning_rate": 3.276991097386831e-05,
      "loss": 0.0,
      "step": 4315
    },
    {
      "epoch": 7.425376344086022,
      "grad_norm": 0.34545220325957343,
      "learning_rate": 3.272864987297905e-05,
      "loss": 0.0001,
      "step": 4316
    },
    {
      "epoch": 7.427096774193548,
      "grad_norm": 0.0032897445404323857,
      "learning_rate": 3.2687409681512206e-05,
      "loss": 0.0,
      "step": 4317
    },
    {
      "epoch": 7.428817204301075,
      "grad_norm": 0.012895064561982977,
      "learning_rate": 3.2646190412286225e-05,
      "loss": 0.0,
      "step": 4318
    },
    {
      "epoch": 7.430537634408602,
      "grad_norm": 0.00010507237308938838,
      "learning_rate": 3.2604992078112926e-05,
      "loss": 0.0,
      "step": 4319
    },
    {
      "epoch": 7.432258064516129,
      "grad_norm": 0.012756274105849605,
      "learning_rate": 3.256381469179763e-05,
      "loss": 0.0,
      "step": 4320
    },
    {
      "epoch": 7.433978494623656,
      "grad_norm": 0.021333991239492773,
      "learning_rate": 3.252265826613926e-05,
      "loss": 0.0,
      "step": 4321
    },
    {
      "epoch": 7.435698924731183,
      "grad_norm": 0.008276843592430132,
      "learning_rate": 3.248152281393009e-05,
      "loss": 0.0,
      "step": 4322
    },
    {
      "epoch": 7.43741935483871,
      "grad_norm": 0.7497458198374288,
      "learning_rate": 3.2440408347955873e-05,
      "loss": 0.0046,
      "step": 4323
    },
    {
      "epoch": 7.439139784946237,
      "grad_norm": 0.010255537430723162,
      "learning_rate": 3.239931488099601e-05,
      "loss": 0.0,
      "step": 4324
    },
    {
      "epoch": 7.440860215053763,
      "grad_norm": 0.046711474095700194,
      "learning_rate": 3.2358242425823215e-05,
      "loss": 0.0002,
      "step": 4325
    },
    {
      "epoch": 7.44258064516129,
      "grad_norm": 0.00018625603495677802,
      "learning_rate": 3.231719099520367e-05,
      "loss": 0.0,
      "step": 4326
    },
    {
      "epoch": 7.444301075268817,
      "grad_norm": 0.048028664579056704,
      "learning_rate": 3.227616060189713e-05,
      "loss": 0.0001,
      "step": 4327
    },
    {
      "epoch": 7.446021505376344,
      "grad_norm": 2.8421735453493566,
      "learning_rate": 3.2235151258656695e-05,
      "loss": 0.0469,
      "step": 4328
    },
    {
      "epoch": 7.4477419354838705,
      "grad_norm": 0.0009630052713316552,
      "learning_rate": 3.219416297822903e-05,
      "loss": 0.0,
      "step": 4329
    },
    {
      "epoch": 7.449462365591398,
      "grad_norm": 0.032185376750322556,
      "learning_rate": 3.215319577335416e-05,
      "loss": 0.0001,
      "step": 4330
    },
    {
      "epoch": 7.451182795698925,
      "grad_norm": 0.016168559822227105,
      "learning_rate": 3.211224965676558e-05,
      "loss": 0.0001,
      "step": 4331
    },
    {
      "epoch": 7.452903225806452,
      "grad_norm": 0.0024961338497601596,
      "learning_rate": 3.207132464119027e-05,
      "loss": 0.0,
      "step": 4332
    },
    {
      "epoch": 7.454623655913979,
      "grad_norm": 0.07023412301576619,
      "learning_rate": 3.2030420739348665e-05,
      "loss": 0.0002,
      "step": 4333
    },
    {
      "epoch": 7.456344086021505,
      "grad_norm": 0.0017555101347981716,
      "learning_rate": 3.198953796395454e-05,
      "loss": 0.0,
      "step": 4334
    },
    {
      "epoch": 7.458064516129032,
      "grad_norm": 0.016435020872593936,
      "learning_rate": 3.1948676327715234e-05,
      "loss": 0.0,
      "step": 4335
    },
    {
      "epoch": 7.459784946236559,
      "grad_norm": 0.0008350764978302149,
      "learning_rate": 3.19078358433314e-05,
      "loss": 0.0,
      "step": 4336
    },
    {
      "epoch": 7.461505376344086,
      "grad_norm": 0.5507011558763117,
      "learning_rate": 3.186701652349714e-05,
      "loss": 0.0005,
      "step": 4337
    },
    {
      "epoch": 7.463225806451613,
      "grad_norm": 0.00349794367965559,
      "learning_rate": 3.1826218380900064e-05,
      "loss": 0.0,
      "step": 4338
    },
    {
      "epoch": 7.46494623655914,
      "grad_norm": 0.0012342857936019124,
      "learning_rate": 3.1785441428221106e-05,
      "loss": 0.0,
      "step": 4339
    },
    {
      "epoch": 7.466666666666667,
      "grad_norm": 0.0019540011282112297,
      "learning_rate": 3.174468567813461e-05,
      "loss": 0.0,
      "step": 4340
    },
    {
      "epoch": 7.468387096774194,
      "grad_norm": 0.049649312218893384,
      "learning_rate": 3.17039511433084e-05,
      "loss": 0.0001,
      "step": 4341
    },
    {
      "epoch": 7.47010752688172,
      "grad_norm": 0.122029261759194,
      "learning_rate": 3.166323783640368e-05,
      "loss": 0.0003,
      "step": 4342
    },
    {
      "epoch": 7.471827956989247,
      "grad_norm": 0.11412514498693492,
      "learning_rate": 3.162254577007502e-05,
      "loss": 0.0003,
      "step": 4343
    },
    {
      "epoch": 7.473548387096774,
      "grad_norm": 0.004927769359756778,
      "learning_rate": 3.158187495697045e-05,
      "loss": 0.0,
      "step": 4344
    },
    {
      "epoch": 7.475268817204301,
      "grad_norm": 0.000997002740604989,
      "learning_rate": 3.15412254097313e-05,
      "loss": 0.0,
      "step": 4345
    },
    {
      "epoch": 7.476989247311828,
      "grad_norm": 8.50418155898134e-05,
      "learning_rate": 3.1500597140992415e-05,
      "loss": 0.0,
      "step": 4346
    },
    {
      "epoch": 7.478709677419355,
      "grad_norm": 0.011572090156891849,
      "learning_rate": 3.145999016338193e-05,
      "loss": 0.0,
      "step": 4347
    },
    {
      "epoch": 7.480430107526882,
      "grad_norm": 0.002751197300875021,
      "learning_rate": 3.1419404489521344e-05,
      "loss": 0.0,
      "step": 4348
    },
    {
      "epoch": 7.482150537634409,
      "grad_norm": 0.0007168847997369148,
      "learning_rate": 3.137884013202566e-05,
      "loss": 0.0,
      "step": 4349
    },
    {
      "epoch": 7.483870967741936,
      "grad_norm": 0.0061833652850206465,
      "learning_rate": 3.13382971035031e-05,
      "loss": 0.0,
      "step": 4350
    },
    {
      "epoch": 7.485591397849462,
      "grad_norm": 0.8323410235119677,
      "learning_rate": 3.129777541655538e-05,
      "loss": 0.0019,
      "step": 4351
    },
    {
      "epoch": 7.487311827956989,
      "grad_norm": 0.013575229033500018,
      "learning_rate": 3.125727508377757e-05,
      "loss": 0.0001,
      "step": 4352
    },
    {
      "epoch": 7.489032258064516,
      "grad_norm": 0.010199045225483047,
      "learning_rate": 3.1216796117758015e-05,
      "loss": 0.0001,
      "step": 4353
    },
    {
      "epoch": 7.4907526881720425,
      "grad_norm": 0.08300271584140671,
      "learning_rate": 3.117633853107846e-05,
      "loss": 0.0003,
      "step": 4354
    },
    {
      "epoch": 7.49247311827957,
      "grad_norm": 0.0009799099925230273,
      "learning_rate": 3.113590233631407e-05,
      "loss": 0.0,
      "step": 4355
    },
    {
      "epoch": 7.494193548387097,
      "grad_norm": 0.010732337492995745,
      "learning_rate": 3.1095487546033256e-05,
      "loss": 0.0,
      "step": 4356
    },
    {
      "epoch": 7.495913978494624,
      "grad_norm": 0.007337721659989135,
      "learning_rate": 3.105509417279787e-05,
      "loss": 0.0,
      "step": 4357
    },
    {
      "epoch": 7.497634408602151,
      "grad_norm": 0.00670044898699999,
      "learning_rate": 3.101472222916306e-05,
      "loss": 0.0,
      "step": 4358
    },
    {
      "epoch": 7.499354838709677,
      "grad_norm": 0.1405151566680179,
      "learning_rate": 3.097437172767728e-05,
      "loss": 0.0004,
      "step": 4359
    },
    {
      "epoch": 7.501075268817204,
      "grad_norm": 0.06317038897971777,
      "learning_rate": 3.0934042680882367e-05,
      "loss": 0.0002,
      "step": 4360
    },
    {
      "epoch": 7.502795698924731,
      "grad_norm": 0.0041076280620262594,
      "learning_rate": 3.089373510131354e-05,
      "loss": 0.0,
      "step": 4361
    },
    {
      "epoch": 7.504516129032258,
      "grad_norm": 0.1857145591250098,
      "learning_rate": 3.0853449001499214e-05,
      "loss": 0.0004,
      "step": 4362
    },
    {
      "epoch": 7.506236559139785,
      "grad_norm": 0.007522979170385371,
      "learning_rate": 3.0813184393961246e-05,
      "loss": 0.0,
      "step": 4363
    },
    {
      "epoch": 7.507956989247312,
      "grad_norm": 0.00957173609209755,
      "learning_rate": 3.077294129121475e-05,
      "loss": 0.0,
      "step": 4364
    },
    {
      "epoch": 7.509677419354839,
      "grad_norm": 0.024533437904997367,
      "learning_rate": 3.073271970576816e-05,
      "loss": 0.0001,
      "step": 4365
    },
    {
      "epoch": 7.511397849462366,
      "grad_norm": 0.051810507633305095,
      "learning_rate": 3.069251965012324e-05,
      "loss": 0.0002,
      "step": 4366
    },
    {
      "epoch": 7.513118279569892,
      "grad_norm": 0.017217349001908848,
      "learning_rate": 3.065234113677509e-05,
      "loss": 0.0,
      "step": 4367
    },
    {
      "epoch": 7.514838709677419,
      "grad_norm": 0.005256605716411954,
      "learning_rate": 3.0612184178211965e-05,
      "loss": 0.0,
      "step": 4368
    },
    {
      "epoch": 7.516559139784946,
      "grad_norm": 0.3305132557678879,
      "learning_rate": 3.057204878691569e-05,
      "loss": 0.0004,
      "step": 4369
    },
    {
      "epoch": 7.518279569892473,
      "grad_norm": 0.003563670405440162,
      "learning_rate": 3.053193497536117e-05,
      "loss": 0.0,
      "step": 4370
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.001720848372650479,
      "learning_rate": 3.0491842756016607e-05,
      "loss": 0.0,
      "step": 4371
    },
    {
      "epoch": 7.521720430107527,
      "grad_norm": 0.0001551718607445462,
      "learning_rate": 3.0451772141343638e-05,
      "loss": 0.0,
      "step": 4372
    },
    {
      "epoch": 7.523440860215054,
      "grad_norm": 0.0628464508933174,
      "learning_rate": 3.041172314379702e-05,
      "loss": 0.0003,
      "step": 4373
    },
    {
      "epoch": 7.525161290322581,
      "grad_norm": 0.009085408606107147,
      "learning_rate": 3.0371695775824936e-05,
      "loss": 0.0,
      "step": 4374
    },
    {
      "epoch": 7.526881720430108,
      "grad_norm": 0.008905882308051977,
      "learning_rate": 3.033169004986873e-05,
      "loss": 0.0001,
      "step": 4375
    },
    {
      "epoch": 7.528602150537634,
      "grad_norm": 0.0011154885365102644,
      "learning_rate": 3.029170597836306e-05,
      "loss": 0.0,
      "step": 4376
    },
    {
      "epoch": 7.530322580645161,
      "grad_norm": 0.004962462996502984,
      "learning_rate": 3.025174357373588e-05,
      "loss": 0.0,
      "step": 4377
    },
    {
      "epoch": 7.532043010752688,
      "grad_norm": 0.005289027563069586,
      "learning_rate": 3.021180284840841e-05,
      "loss": 0.0,
      "step": 4378
    },
    {
      "epoch": 7.533763440860215,
      "grad_norm": 0.0010976675255262068,
      "learning_rate": 3.0171883814795055e-05,
      "loss": 0.0,
      "step": 4379
    },
    {
      "epoch": 7.535483870967742,
      "grad_norm": 0.034117159593484846,
      "learning_rate": 3.0131986485303597e-05,
      "loss": 0.0001,
      "step": 4380
    },
    {
      "epoch": 7.537204301075269,
      "grad_norm": 0.03472276989206905,
      "learning_rate": 3.0092110872334977e-05,
      "loss": 0.0,
      "step": 4381
    },
    {
      "epoch": 7.538924731182796,
      "grad_norm": 0.014782313613761023,
      "learning_rate": 3.005225698828338e-05,
      "loss": 0.0001,
      "step": 4382
    },
    {
      "epoch": 7.540645161290323,
      "grad_norm": 0.1773713666697932,
      "learning_rate": 3.0012424845536335e-05,
      "loss": 0.0002,
      "step": 4383
    },
    {
      "epoch": 7.542365591397849,
      "grad_norm": 0.28812718766249057,
      "learning_rate": 2.9972614456474536e-05,
      "loss": 0.0008,
      "step": 4384
    },
    {
      "epoch": 7.544086021505376,
      "grad_norm": 0.0007781738715705102,
      "learning_rate": 2.993282583347188e-05,
      "loss": 0.0,
      "step": 4385
    },
    {
      "epoch": 7.545806451612903,
      "grad_norm": 0.04627871408708537,
      "learning_rate": 2.9893058988895596e-05,
      "loss": 0.0001,
      "step": 4386
    },
    {
      "epoch": 7.54752688172043,
      "grad_norm": 0.007932159227914563,
      "learning_rate": 2.9853313935106132e-05,
      "loss": 0.0,
      "step": 4387
    },
    {
      "epoch": 7.549247311827957,
      "grad_norm": 0.014957718807632497,
      "learning_rate": 2.981359068445705e-05,
      "loss": 0.0,
      "step": 4388
    },
    {
      "epoch": 7.550967741935484,
      "grad_norm": 0.0009327483019056509,
      "learning_rate": 2.9773889249295294e-05,
      "loss": 0.0,
      "step": 4389
    },
    {
      "epoch": 7.552688172043011,
      "grad_norm": 0.006317128147162747,
      "learning_rate": 2.9734209641960875e-05,
      "loss": 0.0,
      "step": 4390
    },
    {
      "epoch": 7.554408602150538,
      "grad_norm": 0.02911283301666055,
      "learning_rate": 2.969455187478716e-05,
      "loss": 0.0001,
      "step": 4391
    },
    {
      "epoch": 7.556129032258065,
      "grad_norm": 0.0016634794665358738,
      "learning_rate": 2.9654915960100625e-05,
      "loss": 0.0,
      "step": 4392
    },
    {
      "epoch": 7.557849462365591,
      "grad_norm": 0.008652186792640557,
      "learning_rate": 2.961530191022096e-05,
      "loss": 0.0,
      "step": 4393
    },
    {
      "epoch": 7.559569892473118,
      "grad_norm": 0.0033513160420109867,
      "learning_rate": 2.9575709737461145e-05,
      "loss": 0.0,
      "step": 4394
    },
    {
      "epoch": 7.561290322580645,
      "grad_norm": 0.017271989003031455,
      "learning_rate": 2.953613945412724e-05,
      "loss": 0.0,
      "step": 4395
    },
    {
      "epoch": 7.563010752688172,
      "grad_norm": 0.009140901751864784,
      "learning_rate": 2.9496591072518597e-05,
      "loss": 0.0,
      "step": 4396
    },
    {
      "epoch": 7.564731182795699,
      "grad_norm": 0.025132256400935443,
      "learning_rate": 2.9457064604927764e-05,
      "loss": 0.0001,
      "step": 4397
    },
    {
      "epoch": 7.566451612903226,
      "grad_norm": 0.02331847711710742,
      "learning_rate": 2.9417560063640403e-05,
      "loss": 0.0,
      "step": 4398
    },
    {
      "epoch": 7.568172043010753,
      "grad_norm": 0.011514111254455004,
      "learning_rate": 2.937807746093537e-05,
      "loss": 0.0,
      "step": 4399
    },
    {
      "epoch": 7.56989247311828,
      "grad_norm": 0.00034530462705015003,
      "learning_rate": 2.9338616809084785e-05,
      "loss": 0.0,
      "step": 4400
    },
    {
      "epoch": 7.571612903225806,
      "grad_norm": 0.006861834670080575,
      "learning_rate": 2.9299178120353877e-05,
      "loss": 0.0,
      "step": 4401
    },
    {
      "epoch": 7.573333333333333,
      "grad_norm": 0.0006981627980434278,
      "learning_rate": 2.925976140700102e-05,
      "loss": 0.0,
      "step": 4402
    },
    {
      "epoch": 7.57505376344086,
      "grad_norm": 0.003070833035027171,
      "learning_rate": 2.9220366681277855e-05,
      "loss": 0.0,
      "step": 4403
    },
    {
      "epoch": 7.576774193548387,
      "grad_norm": 0.0001682051407723469,
      "learning_rate": 2.918099395542907e-05,
      "loss": 0.0,
      "step": 4404
    },
    {
      "epoch": 7.578494623655914,
      "grad_norm": 0.001100670071848099,
      "learning_rate": 2.914164324169263e-05,
      "loss": 0.0,
      "step": 4405
    },
    {
      "epoch": 7.580215053763441,
      "grad_norm": 0.0009939478541238127,
      "learning_rate": 2.9102314552299626e-05,
      "loss": 0.0,
      "step": 4406
    },
    {
      "epoch": 7.581935483870968,
      "grad_norm": 0.00613648936577174,
      "learning_rate": 2.9063007899474216e-05,
      "loss": 0.0,
      "step": 4407
    },
    {
      "epoch": 7.583655913978495,
      "grad_norm": 0.002229443546376253,
      "learning_rate": 2.9023723295433848e-05,
      "loss": 0.0,
      "step": 4408
    },
    {
      "epoch": 7.585376344086021,
      "grad_norm": 0.001967309980619277,
      "learning_rate": 2.898446075238901e-05,
      "loss": 0.0,
      "step": 4409
    },
    {
      "epoch": 7.587096774193548,
      "grad_norm": 0.0199740071624752,
      "learning_rate": 2.894522028254334e-05,
      "loss": 0.0001,
      "step": 4410
    },
    {
      "epoch": 7.588817204301075,
      "grad_norm": 0.007153409068803686,
      "learning_rate": 2.8906001898093693e-05,
      "loss": 0.0,
      "step": 4411
    },
    {
      "epoch": 7.590537634408602,
      "grad_norm": 0.0018469202913880844,
      "learning_rate": 2.8866805611229996e-05,
      "loss": 0.0,
      "step": 4412
    },
    {
      "epoch": 7.592258064516129,
      "grad_norm": 0.531525286566061,
      "learning_rate": 2.8827631434135248e-05,
      "loss": 0.001,
      "step": 4413
    },
    {
      "epoch": 7.593978494623656,
      "grad_norm": 0.0027583818250031533,
      "learning_rate": 2.878847937898579e-05,
      "loss": 0.0,
      "step": 4414
    },
    {
      "epoch": 7.595698924731183,
      "grad_norm": 0.03974267463524815,
      "learning_rate": 2.8749349457950857e-05,
      "loss": 0.0001,
      "step": 4415
    },
    {
      "epoch": 7.59741935483871,
      "grad_norm": 0.0009962898573143105,
      "learning_rate": 2.8710241683192872e-05,
      "loss": 0.0,
      "step": 4416
    },
    {
      "epoch": 7.599139784946237,
      "grad_norm": 0.015024072271141505,
      "learning_rate": 2.8671156066867465e-05,
      "loss": 0.0,
      "step": 4417
    },
    {
      "epoch": 7.600860215053763,
      "grad_norm": 0.10152634241128314,
      "learning_rate": 2.8632092621123285e-05,
      "loss": 0.0002,
      "step": 4418
    },
    {
      "epoch": 7.60258064516129,
      "grad_norm": 1.7270289749200007,
      "learning_rate": 2.8593051358102062e-05,
      "loss": 0.0034,
      "step": 4419
    },
    {
      "epoch": 7.604301075268817,
      "grad_norm": 0.00099542503691311,
      "learning_rate": 2.855403228993877e-05,
      "loss": 0.0,
      "step": 4420
    },
    {
      "epoch": 7.6060215053763445,
      "grad_norm": 0.00017761793491392436,
      "learning_rate": 2.8515035428761315e-05,
      "loss": 0.0,
      "step": 4421
    },
    {
      "epoch": 7.607741935483871,
      "grad_norm": 0.06009746077459332,
      "learning_rate": 2.8476060786690815e-05,
      "loss": 0.0001,
      "step": 4422
    },
    {
      "epoch": 7.609462365591398,
      "grad_norm": 0.0009620248306413617,
      "learning_rate": 2.8437108375841503e-05,
      "loss": 0.0,
      "step": 4423
    },
    {
      "epoch": 7.611182795698925,
      "grad_norm": 0.001679803773379635,
      "learning_rate": 2.839817820832056e-05,
      "loss": 0.0,
      "step": 4424
    },
    {
      "epoch": 7.612903225806452,
      "grad_norm": 0.011210710964801222,
      "learning_rate": 2.8359270296228424e-05,
      "loss": 0.0,
      "step": 4425
    },
    {
      "epoch": 7.614623655913978,
      "grad_norm": 0.0008374257630853499,
      "learning_rate": 2.8320384651658493e-05,
      "loss": 0.0,
      "step": 4426
    },
    {
      "epoch": 7.616344086021505,
      "grad_norm": 0.08307024476060446,
      "learning_rate": 2.8281521286697265e-05,
      "loss": 0.0003,
      "step": 4427
    },
    {
      "epoch": 7.618064516129032,
      "grad_norm": 0.001934226665268483,
      "learning_rate": 2.8242680213424376e-05,
      "loss": 0.0,
      "step": 4428
    },
    {
      "epoch": 7.619784946236559,
      "grad_norm": 0.0003728279003060437,
      "learning_rate": 2.820386144391247e-05,
      "loss": 0.0,
      "step": 4429
    },
    {
      "epoch": 7.621505376344086,
      "grad_norm": 0.287929547079887,
      "learning_rate": 2.8165064990227252e-05,
      "loss": 0.0004,
      "step": 4430
    },
    {
      "epoch": 7.623225806451613,
      "grad_norm": 0.036250187643852884,
      "learning_rate": 2.812629086442754e-05,
      "loss": 0.0001,
      "step": 4431
    },
    {
      "epoch": 7.62494623655914,
      "grad_norm": 0.0013841516150554386,
      "learning_rate": 2.8087539078565228e-05,
      "loss": 0.0,
      "step": 4432
    },
    {
      "epoch": 7.626666666666667,
      "grad_norm": 0.0006616112769649926,
      "learning_rate": 2.8048809644685158e-05,
      "loss": 0.0,
      "step": 4433
    },
    {
      "epoch": 7.628387096774194,
      "grad_norm": 1.1777398594122799,
      "learning_rate": 2.801010257482537e-05,
      "loss": 0.0022,
      "step": 4434
    },
    {
      "epoch": 7.63010752688172,
      "grad_norm": 0.00303375139688107,
      "learning_rate": 2.7971417881016825e-05,
      "loss": 0.0,
      "step": 4435
    },
    {
      "epoch": 7.631827956989247,
      "grad_norm": 0.009276393093690773,
      "learning_rate": 2.7932755575283566e-05,
      "loss": 0.0,
      "step": 4436
    },
    {
      "epoch": 7.633548387096774,
      "grad_norm": 0.01776380355483693,
      "learning_rate": 2.789411566964274e-05,
      "loss": 0.0001,
      "step": 4437
    },
    {
      "epoch": 7.635268817204301,
      "grad_norm": 0.0025981072467324393,
      "learning_rate": 2.7855498176104434e-05,
      "loss": 0.0,
      "step": 4438
    },
    {
      "epoch": 7.636989247311828,
      "grad_norm": 0.006257769586471198,
      "learning_rate": 2.7816903106671876e-05,
      "loss": 0.0,
      "step": 4439
    },
    {
      "epoch": 7.638709677419355,
      "grad_norm": 0.03800951169989904,
      "learning_rate": 2.7778330473341208e-05,
      "loss": 0.0001,
      "step": 4440
    },
    {
      "epoch": 7.640430107526882,
      "grad_norm": 0.002273688088072059,
      "learning_rate": 2.773978028810168e-05,
      "loss": 0.0,
      "step": 4441
    },
    {
      "epoch": 7.642150537634409,
      "grad_norm": 0.002227848778172664,
      "learning_rate": 2.7701252562935587e-05,
      "loss": 0.0,
      "step": 4442
    },
    {
      "epoch": 7.643870967741935,
      "grad_norm": 0.0012838680108838364,
      "learning_rate": 2.7662747309818147e-05,
      "loss": 0.0,
      "step": 4443
    },
    {
      "epoch": 7.645591397849462,
      "grad_norm": 0.02955936054511474,
      "learning_rate": 2.7624264540717625e-05,
      "loss": 0.0001,
      "step": 4444
    },
    {
      "epoch": 7.647311827956989,
      "grad_norm": 0.005041879010978752,
      "learning_rate": 2.7585804267595384e-05,
      "loss": 0.0,
      "step": 4445
    },
    {
      "epoch": 7.6490322580645165,
      "grad_norm": 0.3494709131881684,
      "learning_rate": 2.754736650240568e-05,
      "loss": 0.0008,
      "step": 4446
    },
    {
      "epoch": 7.650752688172043,
      "grad_norm": 2.4703614849961104,
      "learning_rate": 2.7508951257095794e-05,
      "loss": 0.0271,
      "step": 4447
    },
    {
      "epoch": 7.65247311827957,
      "grad_norm": 0.0008631414959616458,
      "learning_rate": 2.7470558543606107e-05,
      "loss": 0.0,
      "step": 4448
    },
    {
      "epoch": 7.654193548387097,
      "grad_norm": 0.000964813783885557,
      "learning_rate": 2.743218837386985e-05,
      "loss": 0.0,
      "step": 4449
    },
    {
      "epoch": 7.655913978494624,
      "grad_norm": 0.2999261118077479,
      "learning_rate": 2.739384075981335e-05,
      "loss": 0.0005,
      "step": 4450
    },
    {
      "epoch": 7.65763440860215,
      "grad_norm": 0.007918812842761741,
      "learning_rate": 2.735551571335593e-05,
      "loss": 0.0,
      "step": 4451
    },
    {
      "epoch": 7.659354838709677,
      "grad_norm": 0.003865865290902576,
      "learning_rate": 2.731721324640982e-05,
      "loss": 0.0,
      "step": 4452
    },
    {
      "epoch": 7.661075268817204,
      "grad_norm": 0.004836390958637766,
      "learning_rate": 2.7278933370880265e-05,
      "loss": 0.0,
      "step": 4453
    },
    {
      "epoch": 7.6627956989247314,
      "grad_norm": 0.0004362818941537153,
      "learning_rate": 2.724067609866554e-05,
      "loss": 0.0,
      "step": 4454
    },
    {
      "epoch": 7.664516129032258,
      "grad_norm": 0.0030979097157431117,
      "learning_rate": 2.720244144165678e-05,
      "loss": 0.0,
      "step": 4455
    },
    {
      "epoch": 7.666236559139785,
      "grad_norm": 0.01054887051026766,
      "learning_rate": 2.7164229411738253e-05,
      "loss": 0.0,
      "step": 4456
    },
    {
      "epoch": 7.667956989247312,
      "grad_norm": 0.08118112115691829,
      "learning_rate": 2.7126040020787036e-05,
      "loss": 0.0002,
      "step": 4457
    },
    {
      "epoch": 7.669677419354839,
      "grad_norm": 0.04020550317135873,
      "learning_rate": 2.7087873280673205e-05,
      "loss": 0.0001,
      "step": 4458
    },
    {
      "epoch": 7.671397849462366,
      "grad_norm": 0.005867905404579799,
      "learning_rate": 2.7049729203259934e-05,
      "loss": 0.0,
      "step": 4459
    },
    {
      "epoch": 7.673118279569892,
      "grad_norm": 0.0029024615894674448,
      "learning_rate": 2.7011607800403184e-05,
      "loss": 0.0,
      "step": 4460
    },
    {
      "epoch": 7.674838709677419,
      "grad_norm": 0.812839402516522,
      "learning_rate": 2.69735090839519e-05,
      "loss": 0.002,
      "step": 4461
    },
    {
      "epoch": 7.676559139784946,
      "grad_norm": 0.059483519318516045,
      "learning_rate": 2.6935433065748063e-05,
      "loss": 0.0001,
      "step": 4462
    },
    {
      "epoch": 7.678279569892473,
      "grad_norm": 0.010673988600226055,
      "learning_rate": 2.689737975762653e-05,
      "loss": 0.0,
      "step": 4463
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.00613498689831539,
      "learning_rate": 2.685934917141505e-05,
      "loss": 0.0,
      "step": 4464
    },
    {
      "epoch": 7.681720430107527,
      "grad_norm": 0.04523330421680042,
      "learning_rate": 2.6821341318934456e-05,
      "loss": 0.0001,
      "step": 4465
    },
    {
      "epoch": 7.683440860215054,
      "grad_norm": 0.0038998707097422443,
      "learning_rate": 2.6783356211998355e-05,
      "loss": 0.0,
      "step": 4466
    },
    {
      "epoch": 7.685161290322581,
      "grad_norm": 0.0031142503656833576,
      "learning_rate": 2.6745393862413392e-05,
      "loss": 0.0,
      "step": 4467
    },
    {
      "epoch": 7.686881720430107,
      "grad_norm": 0.004139279026729028,
      "learning_rate": 2.6707454281979127e-05,
      "loss": 0.0,
      "step": 4468
    },
    {
      "epoch": 7.688602150537634,
      "grad_norm": 0.0029987160052895884,
      "learning_rate": 2.6669537482488006e-05,
      "loss": 0.0,
      "step": 4469
    },
    {
      "epoch": 7.690322580645161,
      "grad_norm": 0.00875921581115393,
      "learning_rate": 2.6631643475725354e-05,
      "loss": 0.0,
      "step": 4470
    },
    {
      "epoch": 7.6920430107526885,
      "grad_norm": 0.021062232890781282,
      "learning_rate": 2.6593772273469553e-05,
      "loss": 0.0,
      "step": 4471
    },
    {
      "epoch": 7.693763440860215,
      "grad_norm": 0.008579922854328023,
      "learning_rate": 2.655592388749173e-05,
      "loss": 0.0,
      "step": 4472
    },
    {
      "epoch": 7.695483870967742,
      "grad_norm": 0.00024110655799143522,
      "learning_rate": 2.6518098329556075e-05,
      "loss": 0.0,
      "step": 4473
    },
    {
      "epoch": 7.697204301075269,
      "grad_norm": 0.10767230433608178,
      "learning_rate": 2.648029561141956e-05,
      "loss": 0.0002,
      "step": 4474
    },
    {
      "epoch": 7.698924731182796,
      "grad_norm": 1.5119703025949318,
      "learning_rate": 2.6442515744832087e-05,
      "loss": 0.0087,
      "step": 4475
    },
    {
      "epoch": 7.700645161290323,
      "grad_norm": 0.02085286247041908,
      "learning_rate": 2.6404758741536505e-05,
      "loss": 0.0001,
      "step": 4476
    },
    {
      "epoch": 7.702365591397849,
      "grad_norm": 0.000981088482651804,
      "learning_rate": 2.6367024613268543e-05,
      "loss": 0.0,
      "step": 4477
    },
    {
      "epoch": 7.704086021505376,
      "grad_norm": 2.0227635096262535,
      "learning_rate": 2.6329313371756758e-05,
      "loss": 0.0063,
      "step": 4478
    },
    {
      "epoch": 7.7058064516129035,
      "grad_norm": 0.0034439303347017693,
      "learning_rate": 2.629162502872269e-05,
      "loss": 0.0,
      "step": 4479
    },
    {
      "epoch": 7.70752688172043,
      "grad_norm": 0.0012181080551983468,
      "learning_rate": 2.6253959595880673e-05,
      "loss": 0.0,
      "step": 4480
    },
    {
      "epoch": 7.709247311827957,
      "grad_norm": 6.706796853933878e-05,
      "learning_rate": 2.6216317084937935e-05,
      "loss": 0.0,
      "step": 4481
    },
    {
      "epoch": 7.710967741935484,
      "grad_norm": 0.0003813343450533443,
      "learning_rate": 2.6178697507594664e-05,
      "loss": 0.0,
      "step": 4482
    },
    {
      "epoch": 7.712688172043011,
      "grad_norm": 0.0018315016764359083,
      "learning_rate": 2.6141100875543778e-05,
      "loss": 0.0,
      "step": 4483
    },
    {
      "epoch": 7.714408602150538,
      "grad_norm": 0.04874675709158619,
      "learning_rate": 2.6103527200471224e-05,
      "loss": 0.0002,
      "step": 4484
    },
    {
      "epoch": 7.716129032258064,
      "grad_norm": 0.3693818367691917,
      "learning_rate": 2.6065976494055645e-05,
      "loss": 0.0008,
      "step": 4485
    },
    {
      "epoch": 7.717849462365591,
      "grad_norm": 0.03646644358713137,
      "learning_rate": 2.6028448767968718e-05,
      "loss": 0.0001,
      "step": 4486
    },
    {
      "epoch": 7.719569892473118,
      "grad_norm": 0.00021900805860167972,
      "learning_rate": 2.599094403387481e-05,
      "loss": 0.0,
      "step": 4487
    },
    {
      "epoch": 7.7212903225806455,
      "grad_norm": 0.23446763308015578,
      "learning_rate": 2.5953462303431285e-05,
      "loss": 0.0012,
      "step": 4488
    },
    {
      "epoch": 7.723010752688172,
      "grad_norm": 0.013371615867781792,
      "learning_rate": 2.591600358828824e-05,
      "loss": 0.0,
      "step": 4489
    },
    {
      "epoch": 7.724731182795699,
      "grad_norm": 0.0010380209355690532,
      "learning_rate": 2.5878567900088722e-05,
      "loss": 0.0,
      "step": 4490
    },
    {
      "epoch": 7.726451612903226,
      "grad_norm": 0.0031343792757458286,
      "learning_rate": 2.5841155250468553e-05,
      "loss": 0.0,
      "step": 4491
    },
    {
      "epoch": 7.728172043010753,
      "grad_norm": 0.015279530755541166,
      "learning_rate": 2.5803765651056377e-05,
      "loss": 0.0,
      "step": 4492
    },
    {
      "epoch": 7.729892473118279,
      "grad_norm": 0.001830160556076639,
      "learning_rate": 2.576639911347376e-05,
      "loss": 0.0,
      "step": 4493
    },
    {
      "epoch": 7.731612903225806,
      "grad_norm": 0.003073537993899236,
      "learning_rate": 2.5729055649334987e-05,
      "loss": 0.0,
      "step": 4494
    },
    {
      "epoch": 7.733333333333333,
      "grad_norm": 0.03507061297165781,
      "learning_rate": 2.5691735270247274e-05,
      "loss": 0.0001,
      "step": 4495
    },
    {
      "epoch": 7.7350537634408605,
      "grad_norm": 0.005095682493980854,
      "learning_rate": 2.5654437987810644e-05,
      "loss": 0.0,
      "step": 4496
    },
    {
      "epoch": 7.736774193548387,
      "grad_norm": 0.0042519507544720855,
      "learning_rate": 2.5617163813617885e-05,
      "loss": 0.0,
      "step": 4497
    },
    {
      "epoch": 7.738494623655914,
      "grad_norm": 1.2097318392607301,
      "learning_rate": 2.557991275925461e-05,
      "loss": 0.0086,
      "step": 4498
    },
    {
      "epoch": 7.740215053763441,
      "grad_norm": 0.0027879560660134806,
      "learning_rate": 2.5542684836299313e-05,
      "loss": 0.0,
      "step": 4499
    },
    {
      "epoch": 7.741935483870968,
      "grad_norm": 0.031788237107846756,
      "learning_rate": 2.5505480056323216e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 7.743655913978495,
      "grad_norm": 0.00247680910108021,
      "learning_rate": 2.5468298430890437e-05,
      "loss": 0.0,
      "step": 4501
    },
    {
      "epoch": 7.745376344086021,
      "grad_norm": 0.18082672275962558,
      "learning_rate": 2.5431139971557827e-05,
      "loss": 0.0002,
      "step": 4502
    },
    {
      "epoch": 7.747096774193548,
      "grad_norm": 0.10251928710230448,
      "learning_rate": 2.5394004689875005e-05,
      "loss": 0.0002,
      "step": 4503
    },
    {
      "epoch": 7.7488172043010755,
      "grad_norm": 0.07252342438336562,
      "learning_rate": 2.5356892597384486e-05,
      "loss": 0.0002,
      "step": 4504
    },
    {
      "epoch": 7.750537634408602,
      "grad_norm": 0.003990938609612134,
      "learning_rate": 2.5319803705621558e-05,
      "loss": 0.0,
      "step": 4505
    },
    {
      "epoch": 7.752258064516129,
      "grad_norm": 0.007641294494030791,
      "learning_rate": 2.5282738026114193e-05,
      "loss": 0.0,
      "step": 4506
    },
    {
      "epoch": 7.753978494623656,
      "grad_norm": 0.09583181563767777,
      "learning_rate": 2.524569557038331e-05,
      "loss": 0.0002,
      "step": 4507
    },
    {
      "epoch": 7.755698924731183,
      "grad_norm": 0.0166818175539753,
      "learning_rate": 2.5208676349942462e-05,
      "loss": 0.0001,
      "step": 4508
    },
    {
      "epoch": 7.75741935483871,
      "grad_norm": 0.06229653352783206,
      "learning_rate": 2.5171680376298022e-05,
      "loss": 0.0001,
      "step": 4509
    },
    {
      "epoch": 7.759139784946236,
      "grad_norm": 0.0004832604468069371,
      "learning_rate": 2.5134707660949232e-05,
      "loss": 0.0,
      "step": 4510
    },
    {
      "epoch": 7.760860215053763,
      "grad_norm": 0.05460874071547192,
      "learning_rate": 2.5097758215387957e-05,
      "loss": 0.0001,
      "step": 4511
    },
    {
      "epoch": 7.76258064516129,
      "grad_norm": 0.029260185902555774,
      "learning_rate": 2.5060832051098926e-05,
      "loss": 0.0001,
      "step": 4512
    },
    {
      "epoch": 7.7643010752688175,
      "grad_norm": 0.000952696704296208,
      "learning_rate": 2.5023929179559647e-05,
      "loss": 0.0,
      "step": 4513
    },
    {
      "epoch": 7.766021505376344,
      "grad_norm": 0.014466183083222468,
      "learning_rate": 2.498704961224031e-05,
      "loss": 0.0,
      "step": 4514
    },
    {
      "epoch": 7.767741935483871,
      "grad_norm": 0.007401271029641583,
      "learning_rate": 2.495019336060387e-05,
      "loss": 0.0,
      "step": 4515
    },
    {
      "epoch": 7.769462365591398,
      "grad_norm": 0.06557764612119171,
      "learning_rate": 2.4913360436106126e-05,
      "loss": 0.0001,
      "step": 4516
    },
    {
      "epoch": 7.771182795698925,
      "grad_norm": 0.008333978456058449,
      "learning_rate": 2.4876550850195512e-05,
      "loss": 0.0,
      "step": 4517
    },
    {
      "epoch": 7.772903225806452,
      "grad_norm": 0.01974801179325066,
      "learning_rate": 2.4839764614313322e-05,
      "loss": 0.0001,
      "step": 4518
    },
    {
      "epoch": 7.774623655913978,
      "grad_norm": 0.046139777082099584,
      "learning_rate": 2.4803001739893483e-05,
      "loss": 0.0001,
      "step": 4519
    },
    {
      "epoch": 7.776344086021505,
      "grad_norm": 0.014449023656133257,
      "learning_rate": 2.4766262238362705e-05,
      "loss": 0.0,
      "step": 4520
    },
    {
      "epoch": 7.7780645161290325,
      "grad_norm": 0.006842930047228823,
      "learning_rate": 2.4729546121140433e-05,
      "loss": 0.0,
      "step": 4521
    },
    {
      "epoch": 7.779784946236559,
      "grad_norm": 0.002169133973156437,
      "learning_rate": 2.4692853399638917e-05,
      "loss": 0.0,
      "step": 4522
    },
    {
      "epoch": 7.781505376344086,
      "grad_norm": 0.005868034602047982,
      "learning_rate": 2.465618408526298e-05,
      "loss": 0.0,
      "step": 4523
    },
    {
      "epoch": 7.783225806451613,
      "grad_norm": 0.09259282284834731,
      "learning_rate": 2.4619538189410317e-05,
      "loss": 0.0002,
      "step": 4524
    },
    {
      "epoch": 7.78494623655914,
      "grad_norm": 0.0052441096598974625,
      "learning_rate": 2.4582915723471256e-05,
      "loss": 0.0,
      "step": 4525
    },
    {
      "epoch": 7.786666666666667,
      "grad_norm": 0.009447132012536332,
      "learning_rate": 2.4546316698828842e-05,
      "loss": 0.0,
      "step": 4526
    },
    {
      "epoch": 7.788387096774193,
      "grad_norm": 0.005721401977673662,
      "learning_rate": 2.450974112685892e-05,
      "loss": 0.0,
      "step": 4527
    },
    {
      "epoch": 7.79010752688172,
      "grad_norm": 0.0028490549465127178,
      "learning_rate": 2.447318901892993e-05,
      "loss": 0.0,
      "step": 4528
    },
    {
      "epoch": 7.7918279569892475,
      "grad_norm": 0.000715392842932356,
      "learning_rate": 2.4436660386403122e-05,
      "loss": 0.0,
      "step": 4529
    },
    {
      "epoch": 7.7935483870967746,
      "grad_norm": 0.03718510015289531,
      "learning_rate": 2.440015524063236e-05,
      "loss": 0.0002,
      "step": 4530
    },
    {
      "epoch": 7.795268817204301,
      "grad_norm": 0.017165356147336205,
      "learning_rate": 2.4363673592964288e-05,
      "loss": 0.0001,
      "step": 4531
    },
    {
      "epoch": 7.796989247311828,
      "grad_norm": 0.014892832418137828,
      "learning_rate": 2.4327215454738173e-05,
      "loss": 0.0001,
      "step": 4532
    },
    {
      "epoch": 7.798709677419355,
      "grad_norm": 0.052135082309655315,
      "learning_rate": 2.4290780837286054e-05,
      "loss": 0.0001,
      "step": 4533
    },
    {
      "epoch": 7.800430107526882,
      "grad_norm": 0.0015417782486346183,
      "learning_rate": 2.4254369751932548e-05,
      "loss": 0.0,
      "step": 4534
    },
    {
      "epoch": 7.802150537634408,
      "grad_norm": 0.05714399936705813,
      "learning_rate": 2.4217982209995116e-05,
      "loss": 0.0004,
      "step": 4535
    },
    {
      "epoch": 7.803870967741935,
      "grad_norm": 0.35909918836591004,
      "learning_rate": 2.418161822278374e-05,
      "loss": 0.0008,
      "step": 4536
    },
    {
      "epoch": 7.805591397849462,
      "grad_norm": 0.007498011215880112,
      "learning_rate": 2.4145277801601164e-05,
      "loss": 0.0,
      "step": 4537
    },
    {
      "epoch": 7.8073118279569895,
      "grad_norm": 0.01948199617279461,
      "learning_rate": 2.410896095774281e-05,
      "loss": 0.0001,
      "step": 4538
    },
    {
      "epoch": 7.809032258064516,
      "grad_norm": 0.00386407849474122,
      "learning_rate": 2.4072667702496733e-05,
      "loss": 0.0,
      "step": 4539
    },
    {
      "epoch": 7.810752688172043,
      "grad_norm": 0.001499236705783484,
      "learning_rate": 2.4036398047143693e-05,
      "loss": 0.0,
      "step": 4540
    },
    {
      "epoch": 7.81247311827957,
      "grad_norm": 0.012446104913674347,
      "learning_rate": 2.400015200295712e-05,
      "loss": 0.0,
      "step": 4541
    },
    {
      "epoch": 7.814193548387097,
      "grad_norm": 0.24986013199349746,
      "learning_rate": 2.396392958120307e-05,
      "loss": 0.0004,
      "step": 4542
    },
    {
      "epoch": 7.815913978494624,
      "grad_norm": 0.005820020080435954,
      "learning_rate": 2.3927730793140246e-05,
      "loss": 0.0,
      "step": 4543
    },
    {
      "epoch": 7.81763440860215,
      "grad_norm": 0.003976529029226463,
      "learning_rate": 2.389155565002008e-05,
      "loss": 0.0,
      "step": 4544
    },
    {
      "epoch": 7.819354838709677,
      "grad_norm": 0.7069614372934584,
      "learning_rate": 2.3855404163086558e-05,
      "loss": 0.0021,
      "step": 4545
    },
    {
      "epoch": 7.8210752688172045,
      "grad_norm": 0.05780318649346072,
      "learning_rate": 2.3819276343576403e-05,
      "loss": 0.0002,
      "step": 4546
    },
    {
      "epoch": 7.822795698924731,
      "grad_norm": 0.014996324848450978,
      "learning_rate": 2.3783172202718928e-05,
      "loss": 0.0,
      "step": 4547
    },
    {
      "epoch": 7.824516129032258,
      "grad_norm": 0.0013686574536681845,
      "learning_rate": 2.374709175173605e-05,
      "loss": 0.0,
      "step": 4548
    },
    {
      "epoch": 7.826236559139785,
      "grad_norm": 1.3931107683978745,
      "learning_rate": 2.3711035001842418e-05,
      "loss": 0.0013,
      "step": 4549
    },
    {
      "epoch": 7.827956989247312,
      "grad_norm": 0.04212899821490553,
      "learning_rate": 2.367500196424529e-05,
      "loss": 0.0,
      "step": 4550
    },
    {
      "epoch": 7.829677419354839,
      "grad_norm": 0.00177980781869618,
      "learning_rate": 2.3638992650144475e-05,
      "loss": 0.0,
      "step": 4551
    },
    {
      "epoch": 7.831397849462365,
      "grad_norm": 0.0014131475055271098,
      "learning_rate": 2.360300707073251e-05,
      "loss": 0.0,
      "step": 4552
    },
    {
      "epoch": 7.833118279569892,
      "grad_norm": 0.004234295641540062,
      "learning_rate": 2.3567045237194497e-05,
      "loss": 0.0,
      "step": 4553
    },
    {
      "epoch": 7.8348387096774195,
      "grad_norm": 0.8648105032096244,
      "learning_rate": 2.3531107160708122e-05,
      "loss": 0.003,
      "step": 4554
    },
    {
      "epoch": 7.836559139784947,
      "grad_norm": 0.05227901177055278,
      "learning_rate": 2.3495192852443793e-05,
      "loss": 0.0001,
      "step": 4555
    },
    {
      "epoch": 7.838279569892473,
      "grad_norm": 4.8362425690383173e-05,
      "learning_rate": 2.3459302323564458e-05,
      "loss": 0.0,
      "step": 4556
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.003967399923508598,
      "learning_rate": 2.3423435585225616e-05,
      "loss": 0.0,
      "step": 4557
    },
    {
      "epoch": 7.841720430107527,
      "grad_norm": 0.0029830047217415706,
      "learning_rate": 2.338759264857556e-05,
      "loss": 0.0,
      "step": 4558
    },
    {
      "epoch": 7.843440860215054,
      "grad_norm": 0.0026507814613451843,
      "learning_rate": 2.3351773524755015e-05,
      "loss": 0.0,
      "step": 4559
    },
    {
      "epoch": 7.845161290322581,
      "grad_norm": 0.0999334796956195,
      "learning_rate": 2.331597822489733e-05,
      "loss": 0.0002,
      "step": 4560
    },
    {
      "epoch": 7.846881720430107,
      "grad_norm": 0.0009130529497444308,
      "learning_rate": 2.328020676012851e-05,
      "loss": 0.0,
      "step": 4561
    },
    {
      "epoch": 7.848602150537634,
      "grad_norm": 0.01065830743368443,
      "learning_rate": 2.3244459141567075e-05,
      "loss": 0.0001,
      "step": 4562
    },
    {
      "epoch": 7.8503225806451615,
      "grad_norm": 0.0021047099246126575,
      "learning_rate": 2.3208735380324244e-05,
      "loss": 0.0,
      "step": 4563
    },
    {
      "epoch": 7.852043010752688,
      "grad_norm": 0.06544006817383208,
      "learning_rate": 2.3173035487503703e-05,
      "loss": 0.0001,
      "step": 4564
    },
    {
      "epoch": 7.853763440860215,
      "grad_norm": 0.009188977796380799,
      "learning_rate": 2.3137359474201747e-05,
      "loss": 0.0,
      "step": 4565
    },
    {
      "epoch": 7.855483870967742,
      "grad_norm": 1.6862415308482208,
      "learning_rate": 2.3101707351507294e-05,
      "loss": 0.0032,
      "step": 4566
    },
    {
      "epoch": 7.857204301075269,
      "grad_norm": 0.4487303786520439,
      "learning_rate": 2.306607913050185e-05,
      "loss": 0.0011,
      "step": 4567
    },
    {
      "epoch": 7.858924731182796,
      "grad_norm": 0.004942030971147617,
      "learning_rate": 2.3030474822259397e-05,
      "loss": 0.0,
      "step": 4568
    },
    {
      "epoch": 7.860645161290322,
      "grad_norm": 0.1781454563835802,
      "learning_rate": 2.2994894437846583e-05,
      "loss": 0.0004,
      "step": 4569
    },
    {
      "epoch": 7.862365591397849,
      "grad_norm": 0.05560705399842398,
      "learning_rate": 2.295933798832256e-05,
      "loss": 0.0001,
      "step": 4570
    },
    {
      "epoch": 7.8640860215053765,
      "grad_norm": 0.00420843423214843,
      "learning_rate": 2.2923805484739035e-05,
      "loss": 0.0,
      "step": 4571
    },
    {
      "epoch": 7.865806451612904,
      "grad_norm": 0.010075539709822182,
      "learning_rate": 2.288829693814034e-05,
      "loss": 0.0,
      "step": 4572
    },
    {
      "epoch": 7.86752688172043,
      "grad_norm": 0.022349961193682797,
      "learning_rate": 2.2852812359563293e-05,
      "loss": 0.0001,
      "step": 4573
    },
    {
      "epoch": 7.869247311827957,
      "grad_norm": 0.015499354740611685,
      "learning_rate": 2.2817351760037255e-05,
      "loss": 0.0001,
      "step": 4574
    },
    {
      "epoch": 7.870967741935484,
      "grad_norm": 0.0046292988616619905,
      "learning_rate": 2.27819151505842e-05,
      "loss": 0.0,
      "step": 4575
    },
    {
      "epoch": 7.872688172043011,
      "grad_norm": 0.03244687072216866,
      "learning_rate": 2.274650254221863e-05,
      "loss": 0.0001,
      "step": 4576
    },
    {
      "epoch": 7.874408602150537,
      "grad_norm": 0.0008060448049538874,
      "learning_rate": 2.2711113945947506e-05,
      "loss": 0.0,
      "step": 4577
    },
    {
      "epoch": 7.876129032258064,
      "grad_norm": 0.010676210304259613,
      "learning_rate": 2.267574937277046e-05,
      "loss": 0.0,
      "step": 4578
    },
    {
      "epoch": 7.8778494623655915,
      "grad_norm": 0.017815918319115005,
      "learning_rate": 2.2640408833679506e-05,
      "loss": 0.0001,
      "step": 4579
    },
    {
      "epoch": 7.879569892473119,
      "grad_norm": 0.0009414025475782737,
      "learning_rate": 2.260509233965934e-05,
      "loss": 0.0,
      "step": 4580
    },
    {
      "epoch": 7.881290322580645,
      "grad_norm": 0.0007099056496671711,
      "learning_rate": 2.256979990168706e-05,
      "loss": 0.0,
      "step": 4581
    },
    {
      "epoch": 7.883010752688172,
      "grad_norm": 0.05250282776426283,
      "learning_rate": 2.2534531530732316e-05,
      "loss": 0.0002,
      "step": 4582
    },
    {
      "epoch": 7.884731182795699,
      "grad_norm": 0.09284112896795145,
      "learning_rate": 2.2499287237757372e-05,
      "loss": 0.0001,
      "step": 4583
    },
    {
      "epoch": 7.886451612903226,
      "grad_norm": 0.14291629890803864,
      "learning_rate": 2.246406703371685e-05,
      "loss": 0.0003,
      "step": 4584
    },
    {
      "epoch": 7.888172043010753,
      "grad_norm": 0.14114909411983137,
      "learning_rate": 2.242887092955801e-05,
      "loss": 0.0002,
      "step": 4585
    },
    {
      "epoch": 7.889892473118279,
      "grad_norm": 0.001112597384501,
      "learning_rate": 2.2393698936220597e-05,
      "loss": 0.0,
      "step": 4586
    },
    {
      "epoch": 7.891612903225806,
      "grad_norm": 0.009553969106196436,
      "learning_rate": 2.2358551064636836e-05,
      "loss": 0.0,
      "step": 4587
    },
    {
      "epoch": 7.8933333333333335,
      "grad_norm": 0.0009446554776529246,
      "learning_rate": 2.2323427325731417e-05,
      "loss": 0.0,
      "step": 4588
    },
    {
      "epoch": 7.89505376344086,
      "grad_norm": 0.0018238577668149892,
      "learning_rate": 2.2288327730421632e-05,
      "loss": 0.0,
      "step": 4589
    },
    {
      "epoch": 7.896774193548387,
      "grad_norm": 0.00855455226728403,
      "learning_rate": 2.2253252289617178e-05,
      "loss": 0.0,
      "step": 4590
    },
    {
      "epoch": 7.898494623655914,
      "grad_norm": 0.0015098115923003154,
      "learning_rate": 2.2218201014220263e-05,
      "loss": 0.0,
      "step": 4591
    },
    {
      "epoch": 7.900215053763441,
      "grad_norm": 0.0013109270006009925,
      "learning_rate": 2.2183173915125656e-05,
      "loss": 0.0,
      "step": 4592
    },
    {
      "epoch": 7.901935483870968,
      "grad_norm": 0.013843573707200393,
      "learning_rate": 2.2148171003220487e-05,
      "loss": 0.0,
      "step": 4593
    },
    {
      "epoch": 7.903655913978494,
      "grad_norm": 0.07184705252245077,
      "learning_rate": 2.2113192289384454e-05,
      "loss": 0.0002,
      "step": 4594
    },
    {
      "epoch": 7.905376344086021,
      "grad_norm": 0.006067874830867651,
      "learning_rate": 2.2078237784489765e-05,
      "loss": 0.0,
      "step": 4595
    },
    {
      "epoch": 7.9070967741935485,
      "grad_norm": 0.0013953217565417283,
      "learning_rate": 2.204330749940098e-05,
      "loss": 0.0,
      "step": 4596
    },
    {
      "epoch": 7.908817204301076,
      "grad_norm": 0.001390214578647927,
      "learning_rate": 2.2008401444975268e-05,
      "loss": 0.0,
      "step": 4597
    },
    {
      "epoch": 7.910537634408602,
      "grad_norm": 0.02704270308490345,
      "learning_rate": 2.1973519632062166e-05,
      "loss": 0.0001,
      "step": 4598
    },
    {
      "epoch": 7.912258064516129,
      "grad_norm": 0.016804075779318545,
      "learning_rate": 2.1938662071503692e-05,
      "loss": 0.0,
      "step": 4599
    },
    {
      "epoch": 7.913978494623656,
      "grad_norm": 0.024738770151022216,
      "learning_rate": 2.1903828774134404e-05,
      "loss": 0.0001,
      "step": 4600
    },
    {
      "epoch": 7.915698924731183,
      "grad_norm": 0.004832377359801752,
      "learning_rate": 2.1869019750781218e-05,
      "loss": 0.0,
      "step": 4601
    },
    {
      "epoch": 7.917419354838709,
      "grad_norm": 0.0007208645914354637,
      "learning_rate": 2.1834235012263517e-05,
      "loss": 0.0,
      "step": 4602
    },
    {
      "epoch": 7.919139784946236,
      "grad_norm": 0.0003811259144140932,
      "learning_rate": 2.1799474569393253e-05,
      "loss": 0.0,
      "step": 4603
    },
    {
      "epoch": 7.9208602150537635,
      "grad_norm": 0.0016403954638580525,
      "learning_rate": 2.1764738432974697e-05,
      "loss": 0.0,
      "step": 4604
    },
    {
      "epoch": 7.922580645161291,
      "grad_norm": 0.004651593099872121,
      "learning_rate": 2.1730026613804578e-05,
      "loss": 0.0,
      "step": 4605
    },
    {
      "epoch": 7.924301075268817,
      "grad_norm": 0.0005001441657457012,
      "learning_rate": 2.1695339122672155e-05,
      "loss": 0.0,
      "step": 4606
    },
    {
      "epoch": 7.926021505376344,
      "grad_norm": 0.00649220441486317,
      "learning_rate": 2.1660675970359036e-05,
      "loss": 0.0,
      "step": 4607
    },
    {
      "epoch": 7.927741935483871,
      "grad_norm": 0.0026208434864319063,
      "learning_rate": 2.162603716763927e-05,
      "loss": 0.0,
      "step": 4608
    },
    {
      "epoch": 7.929462365591398,
      "grad_norm": 0.0011396506965787659,
      "learning_rate": 2.159142272527941e-05,
      "loss": 0.0,
      "step": 4609
    },
    {
      "epoch": 7.931182795698925,
      "grad_norm": 0.0006424165397233696,
      "learning_rate": 2.1556832654038338e-05,
      "loss": 0.0,
      "step": 4610
    },
    {
      "epoch": 7.932903225806451,
      "grad_norm": 0.2591233037917195,
      "learning_rate": 2.152226696466745e-05,
      "loss": 0.0003,
      "step": 4611
    },
    {
      "epoch": 7.9346236559139784,
      "grad_norm": 0.001831283580400088,
      "learning_rate": 2.148772566791053e-05,
      "loss": 0.0,
      "step": 4612
    },
    {
      "epoch": 7.9363440860215055,
      "grad_norm": 0.007006101627153537,
      "learning_rate": 2.1453208774503754e-05,
      "loss": 0.0,
      "step": 4613
    },
    {
      "epoch": 7.938064516129033,
      "grad_norm": 0.0021615137589706527,
      "learning_rate": 2.141871629517577e-05,
      "loss": 0.0,
      "step": 4614
    },
    {
      "epoch": 7.939784946236559,
      "grad_norm": 0.0016907109337997881,
      "learning_rate": 2.1384248240647575e-05,
      "loss": 0.0,
      "step": 4615
    },
    {
      "epoch": 7.941505376344086,
      "grad_norm": 0.006620517836385906,
      "learning_rate": 2.1349804621632575e-05,
      "loss": 0.0,
      "step": 4616
    },
    {
      "epoch": 7.943225806451613,
      "grad_norm": 0.3288372455640924,
      "learning_rate": 2.131538544883668e-05,
      "loss": 0.0006,
      "step": 4617
    },
    {
      "epoch": 7.94494623655914,
      "grad_norm": 0.07446937711652381,
      "learning_rate": 2.128099073295807e-05,
      "loss": 0.0001,
      "step": 4618
    },
    {
      "epoch": 7.946666666666666,
      "grad_norm": 0.0014531177504919278,
      "learning_rate": 2.1246620484687386e-05,
      "loss": 0.0,
      "step": 4619
    },
    {
      "epoch": 7.948387096774193,
      "grad_norm": 0.0006911026181316049,
      "learning_rate": 2.121227471470768e-05,
      "loss": 0.0,
      "step": 4620
    },
    {
      "epoch": 7.9501075268817205,
      "grad_norm": 0.04773023859092641,
      "learning_rate": 2.11779534336944e-05,
      "loss": 0.0001,
      "step": 4621
    },
    {
      "epoch": 7.951827956989248,
      "grad_norm": 0.4544133927810681,
      "learning_rate": 2.114365665231529e-05,
      "loss": 0.001,
      "step": 4622
    },
    {
      "epoch": 7.953548387096774,
      "grad_norm": 0.0032680793367158554,
      "learning_rate": 2.1109384381230635e-05,
      "loss": 0.0,
      "step": 4623
    },
    {
      "epoch": 7.955268817204301,
      "grad_norm": 0.0020892951402887356,
      "learning_rate": 2.1075136631092962e-05,
      "loss": 0.0,
      "step": 4624
    },
    {
      "epoch": 7.956989247311828,
      "grad_norm": 0.12761757442421734,
      "learning_rate": 2.1040913412547203e-05,
      "loss": 0.0003,
      "step": 4625
    },
    {
      "epoch": 7.958709677419355,
      "grad_norm": 0.0672932501106501,
      "learning_rate": 2.100671473623076e-05,
      "loss": 0.0001,
      "step": 4626
    },
    {
      "epoch": 7.960430107526882,
      "grad_norm": 0.06851442329563358,
      "learning_rate": 2.0972540612773262e-05,
      "loss": 0.0002,
      "step": 4627
    },
    {
      "epoch": 7.962150537634408,
      "grad_norm": 0.01190842871746824,
      "learning_rate": 2.0938391052796856e-05,
      "loss": 0.0001,
      "step": 4628
    },
    {
      "epoch": 7.9638709677419355,
      "grad_norm": 0.019385168504128174,
      "learning_rate": 2.090426606691591e-05,
      "loss": 0.0,
      "step": 4629
    },
    {
      "epoch": 7.965591397849463,
      "grad_norm": 0.00030873364597491234,
      "learning_rate": 2.0870165665737274e-05,
      "loss": 0.0,
      "step": 4630
    },
    {
      "epoch": 7.967311827956989,
      "grad_norm": 0.0008887886758559002,
      "learning_rate": 2.0836089859860108e-05,
      "loss": 0.0,
      "step": 4631
    },
    {
      "epoch": 7.969032258064516,
      "grad_norm": 0.03372745867071396,
      "learning_rate": 2.08020386598759e-05,
      "loss": 0.0001,
      "step": 4632
    },
    {
      "epoch": 7.970752688172043,
      "grad_norm": 0.0022681414231816824,
      "learning_rate": 2.0768012076368515e-05,
      "loss": 0.0,
      "step": 4633
    },
    {
      "epoch": 7.97247311827957,
      "grad_norm": 0.00032571972494521413,
      "learning_rate": 2.0734010119914192e-05,
      "loss": 0.0,
      "step": 4634
    },
    {
      "epoch": 7.974193548387097,
      "grad_norm": 0.00031895494266265354,
      "learning_rate": 2.070003280108147e-05,
      "loss": 0.0,
      "step": 4635
    },
    {
      "epoch": 7.975913978494623,
      "grad_norm": 0.00022811258095854593,
      "learning_rate": 2.0666080130431243e-05,
      "loss": 0.0,
      "step": 4636
    },
    {
      "epoch": 7.9776344086021505,
      "grad_norm": 8.716159621506796e-06,
      "learning_rate": 2.063215211851678e-05,
      "loss": 0.0,
      "step": 4637
    },
    {
      "epoch": 7.9793548387096775,
      "grad_norm": 5.8649457195863606e-05,
      "learning_rate": 2.059824877588361e-05,
      "loss": 0.0,
      "step": 4638
    },
    {
      "epoch": 7.981075268817205,
      "grad_norm": 0.00197228547103061,
      "learning_rate": 2.0564370113069687e-05,
      "loss": 0.0,
      "step": 4639
    },
    {
      "epoch": 7.982795698924731,
      "grad_norm": 0.0029137799529804975,
      "learning_rate": 2.053051614060525e-05,
      "loss": 0.0,
      "step": 4640
    },
    {
      "epoch": 7.984516129032258,
      "grad_norm": 0.04537517232323088,
      "learning_rate": 2.0496686869012847e-05,
      "loss": 0.0001,
      "step": 4641
    },
    {
      "epoch": 7.986236559139785,
      "grad_norm": 0.002238299357677633,
      "learning_rate": 2.046288230880733e-05,
      "loss": 0.0,
      "step": 4642
    },
    {
      "epoch": 7.987956989247312,
      "grad_norm": 0.0005138021563384435,
      "learning_rate": 2.0429102470495963e-05,
      "loss": 0.0,
      "step": 4643
    },
    {
      "epoch": 7.989677419354838,
      "grad_norm": 0.0015847391889760453,
      "learning_rate": 2.039534736457822e-05,
      "loss": 0.0,
      "step": 4644
    },
    {
      "epoch": 7.991397849462365,
      "grad_norm": 0.04791687879367014,
      "learning_rate": 2.0361617001545976e-05,
      "loss": 0.0001,
      "step": 4645
    },
    {
      "epoch": 7.9931182795698925,
      "grad_norm": 2.4281830257294525,
      "learning_rate": 2.0327911391883346e-05,
      "loss": 0.0135,
      "step": 4646
    },
    {
      "epoch": 7.99483870967742,
      "grad_norm": 0.0001527094229245938,
      "learning_rate": 2.0294230546066727e-05,
      "loss": 0.0,
      "step": 4647
    },
    {
      "epoch": 7.996559139784946,
      "grad_norm": 0.000383031991749801,
      "learning_rate": 2.0260574474564987e-05,
      "loss": 0.0,
      "step": 4648
    },
    {
      "epoch": 7.998279569892473,
      "grad_norm": 0.00046960559377041874,
      "learning_rate": 2.022694318783911e-05,
      "loss": 0.0,
      "step": 4649
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0003155561606433644,
      "learning_rate": 2.0193336696342425e-05,
      "loss": 0.0,
      "step": 4650
    },
    {
      "epoch": 8.001720430107527,
      "grad_norm": 0.00026787447517675485,
      "learning_rate": 2.015975501052062e-05,
      "loss": 0.0,
      "step": 4651
    },
    {
      "epoch": 8.003440860215054,
      "grad_norm": 0.0002743676287786816,
      "learning_rate": 2.0126198140811603e-05,
      "loss": 0.0,
      "step": 4652
    },
    {
      "epoch": 8.005161290322581,
      "grad_norm": 0.015564227877254472,
      "learning_rate": 2.0092666097645564e-05,
      "loss": 0.0,
      "step": 4653
    },
    {
      "epoch": 8.006881720430108,
      "grad_norm": 0.002986708002812214,
      "learning_rate": 2.005915889144504e-05,
      "loss": 0.0,
      "step": 4654
    },
    {
      "epoch": 8.008602150537634,
      "grad_norm": 0.04017491104534791,
      "learning_rate": 2.002567653262479e-05,
      "loss": 0.0001,
      "step": 4655
    },
    {
      "epoch": 8.01032258064516,
      "grad_norm": 0.0010147812463352722,
      "learning_rate": 1.9992219031591876e-05,
      "loss": 0.0,
      "step": 4656
    },
    {
      "epoch": 8.012043010752688,
      "grad_norm": 0.010319581735293222,
      "learning_rate": 1.9958786398745654e-05,
      "loss": 0.0,
      "step": 4657
    },
    {
      "epoch": 8.013763440860215,
      "grad_norm": 0.003956041908676444,
      "learning_rate": 1.992537864447771e-05,
      "loss": 0.0,
      "step": 4658
    },
    {
      "epoch": 8.015483870967742,
      "grad_norm": 0.00011018513159807687,
      "learning_rate": 1.9891995779171878e-05,
      "loss": 0.0,
      "step": 4659
    },
    {
      "epoch": 8.01720430107527,
      "grad_norm": 0.00013912663531024004,
      "learning_rate": 1.985863781320435e-05,
      "loss": 0.0,
      "step": 4660
    },
    {
      "epoch": 8.018924731182796,
      "grad_norm": 0.022437062921640077,
      "learning_rate": 1.9825304756943454e-05,
      "loss": 0.0,
      "step": 4661
    },
    {
      "epoch": 8.020645161290323,
      "grad_norm": 0.0007240321884079478,
      "learning_rate": 1.979199662074991e-05,
      "loss": 0.0,
      "step": 4662
    },
    {
      "epoch": 8.022365591397849,
      "grad_norm": 7.85478815017829e-05,
      "learning_rate": 1.9758713414976582e-05,
      "loss": 0.0,
      "step": 4663
    },
    {
      "epoch": 8.024086021505376,
      "grad_norm": 0.004094192303932624,
      "learning_rate": 1.972545514996861e-05,
      "loss": 0.0,
      "step": 4664
    },
    {
      "epoch": 8.025806451612903,
      "grad_norm": 0.006435801736746063,
      "learning_rate": 1.969222183606342e-05,
      "loss": 0.0,
      "step": 4665
    },
    {
      "epoch": 8.02752688172043,
      "grad_norm": 0.037388715547973884,
      "learning_rate": 1.965901348359068e-05,
      "loss": 0.0001,
      "step": 4666
    },
    {
      "epoch": 8.029247311827957,
      "grad_norm": 0.0006127671922905433,
      "learning_rate": 1.9625830102872233e-05,
      "loss": 0.0,
      "step": 4667
    },
    {
      "epoch": 8.030967741935484,
      "grad_norm": 0.0009051879081168609,
      "learning_rate": 1.9592671704222264e-05,
      "loss": 0.0,
      "step": 4668
    },
    {
      "epoch": 8.032688172043011,
      "grad_norm": 0.00012630605719008624,
      "learning_rate": 1.955953829794711e-05,
      "loss": 0.0,
      "step": 4669
    },
    {
      "epoch": 8.034408602150538,
      "grad_norm": 0.0011280750247717275,
      "learning_rate": 1.9526429894345334e-05,
      "loss": 0.0,
      "step": 4670
    },
    {
      "epoch": 8.036129032258064,
      "grad_norm": 0.00022149896888789479,
      "learning_rate": 1.949334650370782e-05,
      "loss": 0.0,
      "step": 4671
    },
    {
      "epoch": 8.03784946236559,
      "grad_norm": 0.012462597446882898,
      "learning_rate": 1.946028813631755e-05,
      "loss": 0.0,
      "step": 4672
    },
    {
      "epoch": 8.039569892473118,
      "grad_norm": 0.0005067629548726313,
      "learning_rate": 1.9427254802449856e-05,
      "loss": 0.0,
      "step": 4673
    },
    {
      "epoch": 8.041290322580645,
      "grad_norm": 0.0005093542294787057,
      "learning_rate": 1.9394246512372182e-05,
      "loss": 0.0,
      "step": 4674
    },
    {
      "epoch": 8.043010752688172,
      "grad_norm": 0.15564359087740443,
      "learning_rate": 1.9361263276344254e-05,
      "loss": 0.0002,
      "step": 4675
    },
    {
      "epoch": 8.044731182795699,
      "grad_norm": 0.0038699778189810272,
      "learning_rate": 1.9328305104618015e-05,
      "loss": 0.0,
      "step": 4676
    },
    {
      "epoch": 8.046451612903226,
      "grad_norm": 0.0001536451511342165,
      "learning_rate": 1.9295372007437574e-05,
      "loss": 0.0,
      "step": 4677
    },
    {
      "epoch": 8.048172043010753,
      "grad_norm": 0.005268669791564149,
      "learning_rate": 1.9262463995039225e-05,
      "loss": 0.0,
      "step": 4678
    },
    {
      "epoch": 8.04989247311828,
      "grad_norm": 0.022572069062850607,
      "learning_rate": 1.922958107765158e-05,
      "loss": 0.0001,
      "step": 4679
    },
    {
      "epoch": 8.051612903225806,
      "grad_norm": 0.001668262838855089,
      "learning_rate": 1.919672326549533e-05,
      "loss": 0.0,
      "step": 4680
    },
    {
      "epoch": 8.053333333333333,
      "grad_norm": 0.010105470999567255,
      "learning_rate": 1.9163890568783394e-05,
      "loss": 0.0,
      "step": 4681
    },
    {
      "epoch": 8.05505376344086,
      "grad_norm": 0.0018665020999727,
      "learning_rate": 1.913108299772095e-05,
      "loss": 0.0,
      "step": 4682
    },
    {
      "epoch": 8.056774193548387,
      "grad_norm": 0.00509323399351329,
      "learning_rate": 1.9098300562505266e-05,
      "loss": 0.0,
      "step": 4683
    },
    {
      "epoch": 8.058494623655914,
      "grad_norm": 0.0016032025698968114,
      "learning_rate": 1.906554327332587e-05,
      "loss": 0.0,
      "step": 4684
    },
    {
      "epoch": 8.060215053763441,
      "grad_norm": 0.005299934790094691,
      "learning_rate": 1.903281114036447e-05,
      "loss": 0.0,
      "step": 4685
    },
    {
      "epoch": 8.061935483870968,
      "grad_norm": 0.00029333092791283203,
      "learning_rate": 1.900010417379493e-05,
      "loss": 0.0,
      "step": 4686
    },
    {
      "epoch": 8.063655913978495,
      "grad_norm": 0.0005327794194911725,
      "learning_rate": 1.896742238378325e-05,
      "loss": 0.0,
      "step": 4687
    },
    {
      "epoch": 8.06537634408602,
      "grad_norm": 0.04278069637118494,
      "learning_rate": 1.893476578048773e-05,
      "loss": 0.0,
      "step": 4688
    },
    {
      "epoch": 8.067096774193548,
      "grad_norm": 0.0009981126577732974,
      "learning_rate": 1.890213437405869e-05,
      "loss": 0.0,
      "step": 4689
    },
    {
      "epoch": 8.068817204301075,
      "grad_norm": 0.0008535943310221432,
      "learning_rate": 1.8869528174638752e-05,
      "loss": 0.0,
      "step": 4690
    },
    {
      "epoch": 8.070537634408602,
      "grad_norm": 0.004300391934191029,
      "learning_rate": 1.883694719236262e-05,
      "loss": 0.0,
      "step": 4691
    },
    {
      "epoch": 8.072258064516129,
      "grad_norm": 0.0018327226560616665,
      "learning_rate": 1.880439143735713e-05,
      "loss": 0.0,
      "step": 4692
    },
    {
      "epoch": 8.073978494623656,
      "grad_norm": 0.006699379016079786,
      "learning_rate": 1.8771860919741425e-05,
      "loss": 0.0,
      "step": 4693
    },
    {
      "epoch": 8.075698924731183,
      "grad_norm": 0.0013559543218958656,
      "learning_rate": 1.8739355649626666e-05,
      "loss": 0.0,
      "step": 4694
    },
    {
      "epoch": 8.07741935483871,
      "grad_norm": 0.00016869387455616022,
      "learning_rate": 1.8706875637116184e-05,
      "loss": 0.0,
      "step": 4695
    },
    {
      "epoch": 8.079139784946237,
      "grad_norm": 0.0001219912901341163,
      "learning_rate": 1.8674420892305544e-05,
      "loss": 0.0,
      "step": 4696
    },
    {
      "epoch": 8.080860215053763,
      "grad_norm": 0.0003737946195354134,
      "learning_rate": 1.8641991425282345e-05,
      "loss": 0.0,
      "step": 4697
    },
    {
      "epoch": 8.08258064516129,
      "grad_norm": 0.00017929849088037182,
      "learning_rate": 1.8609587246126392e-05,
      "loss": 0.0,
      "step": 4698
    },
    {
      "epoch": 8.084301075268817,
      "grad_norm": 3.396584023831774e-05,
      "learning_rate": 1.8577208364909648e-05,
      "loss": 0.0,
      "step": 4699
    },
    {
      "epoch": 8.086021505376344,
      "grad_norm": 0.00823290230979624,
      "learning_rate": 1.8544854791696143e-05,
      "loss": 0.0,
      "step": 4700
    },
    {
      "epoch": 8.087741935483871,
      "grad_norm": 0.0044150673309323344,
      "learning_rate": 1.8512526536542098e-05,
      "loss": 0.0,
      "step": 4701
    },
    {
      "epoch": 8.089462365591398,
      "grad_norm": 0.00016247490635818625,
      "learning_rate": 1.8480223609495882e-05,
      "loss": 0.0,
      "step": 4702
    },
    {
      "epoch": 8.091182795698925,
      "grad_norm": 0.00011524893311143277,
      "learning_rate": 1.844794602059794e-05,
      "loss": 0.0,
      "step": 4703
    },
    {
      "epoch": 8.092903225806452,
      "grad_norm": 0.0082569475016424,
      "learning_rate": 1.8415693779880817e-05,
      "loss": 0.0,
      "step": 4704
    },
    {
      "epoch": 8.094623655913978,
      "grad_norm": 0.02010680794203852,
      "learning_rate": 1.8383466897369294e-05,
      "loss": 0.0,
      "step": 4705
    },
    {
      "epoch": 8.096344086021505,
      "grad_norm": 0.0018999237830487586,
      "learning_rate": 1.835126538308013e-05,
      "loss": 0.0,
      "step": 4706
    },
    {
      "epoch": 8.098064516129032,
      "grad_norm": 0.0013789396234440887,
      "learning_rate": 1.8319089247022325e-05,
      "loss": 0.0,
      "step": 4707
    },
    {
      "epoch": 8.099784946236559,
      "grad_norm": 0.0007643687830894946,
      "learning_rate": 1.8286938499196916e-05,
      "loss": 0.0,
      "step": 4708
    },
    {
      "epoch": 8.101505376344086,
      "grad_norm": 0.006743431343362325,
      "learning_rate": 1.825481314959703e-05,
      "loss": 0.0,
      "step": 4709
    },
    {
      "epoch": 8.103225806451613,
      "grad_norm": 0.0006758254931456926,
      "learning_rate": 1.8222713208207952e-05,
      "loss": 0.0,
      "step": 4710
    },
    {
      "epoch": 8.10494623655914,
      "grad_norm": 0.14909688897877152,
      "learning_rate": 1.819063868500711e-05,
      "loss": 0.0002,
      "step": 4711
    },
    {
      "epoch": 8.106666666666667,
      "grad_norm": 0.00015571205779256288,
      "learning_rate": 1.815858958996389e-05,
      "loss": 0.0,
      "step": 4712
    },
    {
      "epoch": 8.108387096774193,
      "grad_norm": 0.005007716882891418,
      "learning_rate": 1.812656593303993e-05,
      "loss": 0.0,
      "step": 4713
    },
    {
      "epoch": 8.11010752688172,
      "grad_norm": 0.0001909276652967088,
      "learning_rate": 1.809456772418886e-05,
      "loss": 0.0,
      "step": 4714
    },
    {
      "epoch": 8.111827956989247,
      "grad_norm": 0.0034180863469208803,
      "learning_rate": 1.8062594973356394e-05,
      "loss": 0.0,
      "step": 4715
    },
    {
      "epoch": 8.113548387096774,
      "grad_norm": 0.001094244865025407,
      "learning_rate": 1.803064769048044e-05,
      "loss": 0.0,
      "step": 4716
    },
    {
      "epoch": 8.115268817204301,
      "grad_norm": 0.0013848647434635364,
      "learning_rate": 1.7998725885490865e-05,
      "loss": 0.0,
      "step": 4717
    },
    {
      "epoch": 8.116989247311828,
      "grad_norm": 0.010629845917302467,
      "learning_rate": 1.7966829568309707e-05,
      "loss": 0.0,
      "step": 4718
    },
    {
      "epoch": 8.118709677419355,
      "grad_norm": 0.0040984951377584,
      "learning_rate": 1.7934958748851016e-05,
      "loss": 0.0,
      "step": 4719
    },
    {
      "epoch": 8.120430107526882,
      "grad_norm": 0.0023281857786270157,
      "learning_rate": 1.790311343702098e-05,
      "loss": 0.0,
      "step": 4720
    },
    {
      "epoch": 8.12215053763441,
      "grad_norm": 4.972450436517962e-05,
      "learning_rate": 1.787129364271778e-05,
      "loss": 0.0,
      "step": 4721
    },
    {
      "epoch": 8.123870967741935,
      "grad_norm": 0.0001269543322310234,
      "learning_rate": 1.783949937583177e-05,
      "loss": 0.0,
      "step": 4722
    },
    {
      "epoch": 8.125591397849462,
      "grad_norm": 0.00016509814012636114,
      "learning_rate": 1.7807730646245245e-05,
      "loss": 0.0,
      "step": 4723
    },
    {
      "epoch": 8.127311827956989,
      "grad_norm": 0.0008686521442242666,
      "learning_rate": 1.77759874638327e-05,
      "loss": 0.0,
      "step": 4724
    },
    {
      "epoch": 8.129032258064516,
      "grad_norm": 0.021875834790682877,
      "learning_rate": 1.774426983846058e-05,
      "loss": 0.0001,
      "step": 4725
    },
    {
      "epoch": 8.130752688172043,
      "grad_norm": 9.388272087116743e-05,
      "learning_rate": 1.7712577779987394e-05,
      "loss": 0.0,
      "step": 4726
    },
    {
      "epoch": 8.13247311827957,
      "grad_norm": 0.051979884851655986,
      "learning_rate": 1.7680911298263793e-05,
      "loss": 0.0001,
      "step": 4727
    },
    {
      "epoch": 8.134193548387097,
      "grad_norm": 0.0001877624524122324,
      "learning_rate": 1.7649270403132367e-05,
      "loss": 0.0,
      "step": 4728
    },
    {
      "epoch": 8.135913978494624,
      "grad_norm": 6.147939302392815e-05,
      "learning_rate": 1.7617655104427832e-05,
      "loss": 0.0,
      "step": 4729
    },
    {
      "epoch": 8.13763440860215,
      "grad_norm": 0.1199638964608985,
      "learning_rate": 1.758606541197695e-05,
      "loss": 0.0002,
      "step": 4730
    },
    {
      "epoch": 8.139354838709677,
      "grad_norm": 0.0067408624697134385,
      "learning_rate": 1.755450133559845e-05,
      "loss": 0.0,
      "step": 4731
    },
    {
      "epoch": 8.141075268817204,
      "grad_norm": 0.0010537787042248072,
      "learning_rate": 1.7522962885103145e-05,
      "loss": 0.0,
      "step": 4732
    },
    {
      "epoch": 8.142795698924731,
      "grad_norm": 0.004114940082804135,
      "learning_rate": 1.7491450070293926e-05,
      "loss": 0.0,
      "step": 4733
    },
    {
      "epoch": 8.144516129032258,
      "grad_norm": 0.004007436427624303,
      "learning_rate": 1.745996290096561e-05,
      "loss": 0.0,
      "step": 4734
    },
    {
      "epoch": 8.146236559139785,
      "grad_norm": 0.001294488445157961,
      "learning_rate": 1.7428501386905172e-05,
      "loss": 0.0,
      "step": 4735
    },
    {
      "epoch": 8.147956989247312,
      "grad_norm": 0.0005629063565841319,
      "learning_rate": 1.739706553789151e-05,
      "loss": 0.0,
      "step": 4736
    },
    {
      "epoch": 8.14967741935484,
      "grad_norm": 5.701845130089093e-05,
      "learning_rate": 1.7365655363695553e-05,
      "loss": 0.0,
      "step": 4737
    },
    {
      "epoch": 8.151397849462366,
      "grad_norm": 0.00017447932327059221,
      "learning_rate": 1.7334270874080318e-05,
      "loss": 0.0,
      "step": 4738
    },
    {
      "epoch": 8.153118279569892,
      "grad_norm": 0.00011353616415181637,
      "learning_rate": 1.7302912078800803e-05,
      "loss": 0.0,
      "step": 4739
    },
    {
      "epoch": 8.154838709677419,
      "grad_norm": 0.020506154002462276,
      "learning_rate": 1.7271578987603976e-05,
      "loss": 0.0,
      "step": 4740
    },
    {
      "epoch": 8.156559139784946,
      "grad_norm": 0.0006704201367080363,
      "learning_rate": 1.7240271610228907e-05,
      "loss": 0.0,
      "step": 4741
    },
    {
      "epoch": 8.158279569892473,
      "grad_norm": 0.004526811486522222,
      "learning_rate": 1.7208989956406596e-05,
      "loss": 0.0,
      "step": 4742
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.013575466301855514,
      "learning_rate": 1.7177734035860037e-05,
      "loss": 0.0,
      "step": 4743
    },
    {
      "epoch": 8.161720430107527,
      "grad_norm": 0.020451222097922255,
      "learning_rate": 1.714650385830432e-05,
      "loss": 0.0,
      "step": 4744
    },
    {
      "epoch": 8.163440860215054,
      "grad_norm": 0.00031462660336568335,
      "learning_rate": 1.711529943344644e-05,
      "loss": 0.0,
      "step": 4745
    },
    {
      "epoch": 8.165161290322581,
      "grad_norm": 0.011862352094909124,
      "learning_rate": 1.708412077098539e-05,
      "loss": 0.0,
      "step": 4746
    },
    {
      "epoch": 8.166881720430107,
      "grad_norm": 0.0007328944939246946,
      "learning_rate": 1.7052967880612268e-05,
      "loss": 0.0,
      "step": 4747
    },
    {
      "epoch": 8.168602150537634,
      "grad_norm": 0.0007663113162082489,
      "learning_rate": 1.7021840772010046e-05,
      "loss": 0.0,
      "step": 4748
    },
    {
      "epoch": 8.170322580645161,
      "grad_norm": 0.027833891423192075,
      "learning_rate": 1.6990739454853677e-05,
      "loss": 0.0001,
      "step": 4749
    },
    {
      "epoch": 8.172043010752688,
      "grad_norm": 0.0019998230709765137,
      "learning_rate": 1.69596639388102e-05,
      "loss": 0.0,
      "step": 4750
    },
    {
      "epoch": 8.173763440860215,
      "grad_norm": 0.1563363313872102,
      "learning_rate": 1.6928614233538507e-05,
      "loss": 0.0002,
      "step": 4751
    },
    {
      "epoch": 8.175483870967742,
      "grad_norm": 7.09744365277372e-05,
      "learning_rate": 1.689759034868961e-05,
      "loss": 0.0,
      "step": 4752
    },
    {
      "epoch": 8.17720430107527,
      "grad_norm": 7.964505472791301e-05,
      "learning_rate": 1.686659229390637e-05,
      "loss": 0.0,
      "step": 4753
    },
    {
      "epoch": 8.178924731182796,
      "grad_norm": 0.0004532172214782058,
      "learning_rate": 1.6835620078823643e-05,
      "loss": 0.0,
      "step": 4754
    },
    {
      "epoch": 8.180645161290322,
      "grad_norm": 1.6084899545426046e-05,
      "learning_rate": 1.680467371306832e-05,
      "loss": 0.0,
      "step": 4755
    },
    {
      "epoch": 8.182365591397849,
      "grad_norm": 0.0010094845039378864,
      "learning_rate": 1.6773753206259224e-05,
      "loss": 0.0,
      "step": 4756
    },
    {
      "epoch": 8.184086021505376,
      "grad_norm": 0.03345449273342722,
      "learning_rate": 1.674285856800709e-05,
      "loss": 0.0001,
      "step": 4757
    },
    {
      "epoch": 8.185806451612903,
      "grad_norm": 0.001460481368525749,
      "learning_rate": 1.6711989807914708e-05,
      "loss": 0.0,
      "step": 4758
    },
    {
      "epoch": 8.18752688172043,
      "grad_norm": 0.0523181486830438,
      "learning_rate": 1.668114693557673e-05,
      "loss": 0.0001,
      "step": 4759
    },
    {
      "epoch": 8.189247311827957,
      "grad_norm": 0.0001389821258808055,
      "learning_rate": 1.6650329960579792e-05,
      "loss": 0.0,
      "step": 4760
    },
    {
      "epoch": 8.190967741935484,
      "grad_norm": 0.0009377396890290876,
      "learning_rate": 1.661953889250254e-05,
      "loss": 0.0,
      "step": 4761
    },
    {
      "epoch": 8.192688172043011,
      "grad_norm": 0.0009929426220667559,
      "learning_rate": 1.6588773740915486e-05,
      "loss": 0.0,
      "step": 4762
    },
    {
      "epoch": 8.194408602150538,
      "grad_norm": 0.00044006186401323433,
      "learning_rate": 1.6558034515381072e-05,
      "loss": 0.0,
      "step": 4763
    },
    {
      "epoch": 8.196129032258064,
      "grad_norm": 0.008644233704747432,
      "learning_rate": 1.652732122545384e-05,
      "loss": 0.0,
      "step": 4764
    },
    {
      "epoch": 8.19784946236559,
      "grad_norm": 0.0034260366672372667,
      "learning_rate": 1.649663388068009e-05,
      "loss": 0.0,
      "step": 4765
    },
    {
      "epoch": 8.199569892473118,
      "grad_norm": 0.03706220317379844,
      "learning_rate": 1.6465972490598113e-05,
      "loss": 0.0001,
      "step": 4766
    },
    {
      "epoch": 8.201290322580645,
      "grad_norm": 0.0045800406462083556,
      "learning_rate": 1.643533706473819e-05,
      "loss": 0.0,
      "step": 4767
    },
    {
      "epoch": 8.203010752688172,
      "grad_norm": 0.011100273890204784,
      "learning_rate": 1.640472761262245e-05,
      "loss": 0.0,
      "step": 4768
    },
    {
      "epoch": 8.2047311827957,
      "grad_norm": 0.0004894165084026052,
      "learning_rate": 1.6374144143765025e-05,
      "loss": 0.0,
      "step": 4769
    },
    {
      "epoch": 8.206451612903226,
      "grad_norm": 0.00028979759892601084,
      "learning_rate": 1.6343586667671917e-05,
      "loss": 0.0,
      "step": 4770
    },
    {
      "epoch": 8.208172043010753,
      "grad_norm": 0.030971585936487026,
      "learning_rate": 1.6313055193841042e-05,
      "loss": 0.0,
      "step": 4771
    },
    {
      "epoch": 8.209892473118279,
      "grad_norm": 0.017137463367130845,
      "learning_rate": 1.6282549731762266e-05,
      "loss": 0.0,
      "step": 4772
    },
    {
      "epoch": 8.211612903225806,
      "grad_norm": 0.0013967943204722675,
      "learning_rate": 1.6252070290917397e-05,
      "loss": 0.0,
      "step": 4773
    },
    {
      "epoch": 8.213333333333333,
      "grad_norm": 0.00015776563537956188,
      "learning_rate": 1.6221616880780076e-05,
      "loss": 0.0,
      "step": 4774
    },
    {
      "epoch": 8.21505376344086,
      "grad_norm": 0.31757497841582627,
      "learning_rate": 1.619118951081594e-05,
      "loss": 0.0011,
      "step": 4775
    },
    {
      "epoch": 8.216774193548387,
      "grad_norm": 0.05695998504752533,
      "learning_rate": 1.6160788190482456e-05,
      "loss": 0.0004,
      "step": 4776
    },
    {
      "epoch": 8.218494623655914,
      "grad_norm": 0.0027383632611893568,
      "learning_rate": 1.6130412929229e-05,
      "loss": 0.0,
      "step": 4777
    },
    {
      "epoch": 8.220215053763441,
      "grad_norm": 0.0016598072173352192,
      "learning_rate": 1.610006373649694e-05,
      "loss": 0.0,
      "step": 4778
    },
    {
      "epoch": 8.221935483870968,
      "grad_norm": 0.008145205079422374,
      "learning_rate": 1.606974062171944e-05,
      "loss": 0.0,
      "step": 4779
    },
    {
      "epoch": 8.223655913978495,
      "grad_norm": 0.007902584787123973,
      "learning_rate": 1.603944359432158e-05,
      "loss": 0.0,
      "step": 4780
    },
    {
      "epoch": 8.22537634408602,
      "grad_norm": 0.002934662835586282,
      "learning_rate": 1.600917266372035e-05,
      "loss": 0.0,
      "step": 4781
    },
    {
      "epoch": 8.227096774193548,
      "grad_norm": 6.706307856243353e-05,
      "learning_rate": 1.5978927839324664e-05,
      "loss": 0.0,
      "step": 4782
    },
    {
      "epoch": 8.228817204301075,
      "grad_norm": 0.0002324620225839778,
      "learning_rate": 1.5948709130535234e-05,
      "loss": 0.0,
      "step": 4783
    },
    {
      "epoch": 8.230537634408602,
      "grad_norm": 0.0030903458241402604,
      "learning_rate": 1.5918516546744745e-05,
      "loss": 0.0,
      "step": 4784
    },
    {
      "epoch": 8.23225806451613,
      "grad_norm": 0.0036032188213877543,
      "learning_rate": 1.5888350097337667e-05,
      "loss": 0.0,
      "step": 4785
    },
    {
      "epoch": 8.233978494623656,
      "grad_norm": 0.0004842726019721733,
      "learning_rate": 1.585820979169046e-05,
      "loss": 0.0,
      "step": 4786
    },
    {
      "epoch": 8.235698924731183,
      "grad_norm": 0.0001155836757415742,
      "learning_rate": 1.5828095639171358e-05,
      "loss": 0.0,
      "step": 4787
    },
    {
      "epoch": 8.23741935483871,
      "grad_norm": 0.0013138674719912816,
      "learning_rate": 1.57980076491405e-05,
      "loss": 0.0,
      "step": 4788
    },
    {
      "epoch": 8.239139784946236,
      "grad_norm": 0.0009050613712156666,
      "learning_rate": 1.5767945830949938e-05,
      "loss": 0.0,
      "step": 4789
    },
    {
      "epoch": 8.240860215053763,
      "grad_norm": 0.0016338683381627718,
      "learning_rate": 1.5737910193943495e-05,
      "loss": 0.0,
      "step": 4790
    },
    {
      "epoch": 8.24258064516129,
      "grad_norm": 0.006167881912244132,
      "learning_rate": 1.570790074745694e-05,
      "loss": 0.0,
      "step": 4791
    },
    {
      "epoch": 8.244301075268817,
      "grad_norm": 0.00027727751512376264,
      "learning_rate": 1.5677917500817884e-05,
      "loss": 0.0,
      "step": 4792
    },
    {
      "epoch": 8.246021505376344,
      "grad_norm": 0.0009421522444340381,
      "learning_rate": 1.564796046334579e-05,
      "loss": 0.0,
      "step": 4793
    },
    {
      "epoch": 8.247741935483871,
      "grad_norm": 0.006391831997005213,
      "learning_rate": 1.5618029644351917e-05,
      "loss": 0.0,
      "step": 4794
    },
    {
      "epoch": 8.249462365591398,
      "grad_norm": 0.002158549918255129,
      "learning_rate": 1.5588125053139468e-05,
      "loss": 0.0,
      "step": 4795
    },
    {
      "epoch": 8.251182795698925,
      "grad_norm": 0.0001409528660384426,
      "learning_rate": 1.5558246699003432e-05,
      "loss": 0.0,
      "step": 4796
    },
    {
      "epoch": 8.252903225806453,
      "grad_norm": 0.00030091165605697964,
      "learning_rate": 1.5528394591230687e-05,
      "loss": 0.0,
      "step": 4797
    },
    {
      "epoch": 8.254623655913978,
      "grad_norm": 5.063857222876381e-05,
      "learning_rate": 1.5498568739099906e-05,
      "loss": 0.0,
      "step": 4798
    },
    {
      "epoch": 8.256344086021505,
      "grad_norm": 0.00292045964626647,
      "learning_rate": 1.54687691518816e-05,
      "loss": 0.0,
      "step": 4799
    },
    {
      "epoch": 8.258064516129032,
      "grad_norm": 0.00018625264343021588,
      "learning_rate": 1.5438995838838177e-05,
      "loss": 0.0,
      "step": 4800
    },
    {
      "epoch": 8.25978494623656,
      "grad_norm": 0.0003526398761412977,
      "learning_rate": 1.5409248809223842e-05,
      "loss": 0.0,
      "step": 4801
    },
    {
      "epoch": 8.261505376344086,
      "grad_norm": 0.00023552965014601979,
      "learning_rate": 1.53795280722846e-05,
      "loss": 0.0,
      "step": 4802
    },
    {
      "epoch": 8.263225806451613,
      "grad_norm": 0.0019035189067818608,
      "learning_rate": 1.534983363725835e-05,
      "loss": 0.0,
      "step": 4803
    },
    {
      "epoch": 8.26494623655914,
      "grad_norm": 0.0001300126274906805,
      "learning_rate": 1.5320165513374764e-05,
      "loss": 0.0,
      "step": 4804
    },
    {
      "epoch": 8.266666666666667,
      "grad_norm": 0.0021716165516491763,
      "learning_rate": 1.529052370985532e-05,
      "loss": 0.0,
      "step": 4805
    },
    {
      "epoch": 8.268387096774193,
      "grad_norm": 7.502278433897073e-05,
      "learning_rate": 1.5260908235913384e-05,
      "loss": 0.0,
      "step": 4806
    },
    {
      "epoch": 8.27010752688172,
      "grad_norm": 0.0008462082415911453,
      "learning_rate": 1.5231319100754105e-05,
      "loss": 0.0,
      "step": 4807
    },
    {
      "epoch": 8.271827956989247,
      "grad_norm": 0.0008001965588845227,
      "learning_rate": 1.5201756313574367e-05,
      "loss": 0.0,
      "step": 4808
    },
    {
      "epoch": 8.273548387096774,
      "grad_norm": 0.006957207210312806,
      "learning_rate": 1.5172219883563033e-05,
      "loss": 0.0,
      "step": 4809
    },
    {
      "epoch": 8.275268817204301,
      "grad_norm": 0.0001776029926873336,
      "learning_rate": 1.5142709819900647e-05,
      "loss": 0.0,
      "step": 4810
    },
    {
      "epoch": 8.276989247311828,
      "grad_norm": 0.0001445314774219932,
      "learning_rate": 1.511322613175955e-05,
      "loss": 0.0,
      "step": 4811
    },
    {
      "epoch": 8.278709677419355,
      "grad_norm": 0.008676361506731489,
      "learning_rate": 1.5083768828303978e-05,
      "loss": 0.0,
      "step": 4812
    },
    {
      "epoch": 8.280430107526882,
      "grad_norm": 7.833894615931899e-05,
      "learning_rate": 1.5054337918689865e-05,
      "loss": 0.0,
      "step": 4813
    },
    {
      "epoch": 8.282150537634408,
      "grad_norm": 0.18128968454166283,
      "learning_rate": 1.5024933412065035e-05,
      "loss": 0.0002,
      "step": 4814
    },
    {
      "epoch": 8.283870967741935,
      "grad_norm": 0.0036649953645594047,
      "learning_rate": 1.4995555317569043e-05,
      "loss": 0.0,
      "step": 4815
    },
    {
      "epoch": 8.285591397849462,
      "grad_norm": 0.001049612470750883,
      "learning_rate": 1.496620364433321e-05,
      "loss": 0.0,
      "step": 4816
    },
    {
      "epoch": 8.287311827956989,
      "grad_norm": 0.0010625848902963723,
      "learning_rate": 1.4936878401480714e-05,
      "loss": 0.0,
      "step": 4817
    },
    {
      "epoch": 8.289032258064516,
      "grad_norm": 0.0009794541830330666,
      "learning_rate": 1.490757959812652e-05,
      "loss": 0.0,
      "step": 4818
    },
    {
      "epoch": 8.290752688172043,
      "grad_norm": 0.001134569731969682,
      "learning_rate": 1.4878307243377288e-05,
      "loss": 0.0,
      "step": 4819
    },
    {
      "epoch": 8.29247311827957,
      "grad_norm": 0.0010139451839280174,
      "learning_rate": 1.484906134633156e-05,
      "loss": 0.0,
      "step": 4820
    },
    {
      "epoch": 8.294193548387097,
      "grad_norm": 0.0008422756618985886,
      "learning_rate": 1.481984191607959e-05,
      "loss": 0.0,
      "step": 4821
    },
    {
      "epoch": 8.295913978494625,
      "grad_norm": 0.0007276335065376296,
      "learning_rate": 1.4790648961703402e-05,
      "loss": 0.0,
      "step": 4822
    },
    {
      "epoch": 8.29763440860215,
      "grad_norm": 6.48925603576924e-05,
      "learning_rate": 1.4761482492276846e-05,
      "loss": 0.0,
      "step": 4823
    },
    {
      "epoch": 8.299354838709677,
      "grad_norm": 0.00040456087650071585,
      "learning_rate": 1.4732342516865494e-05,
      "loss": 0.0,
      "step": 4824
    },
    {
      "epoch": 8.301075268817204,
      "grad_norm": 0.022560536153391555,
      "learning_rate": 1.4703229044526656e-05,
      "loss": 0.0,
      "step": 4825
    },
    {
      "epoch": 8.302795698924731,
      "grad_norm": 0.009553738672383315,
      "learning_rate": 1.4674142084309484e-05,
      "loss": 0.0,
      "step": 4826
    },
    {
      "epoch": 8.304516129032258,
      "grad_norm": 0.004237522253426824,
      "learning_rate": 1.4645081645254855e-05,
      "loss": 0.0,
      "step": 4827
    },
    {
      "epoch": 8.306236559139785,
      "grad_norm": 0.04105815375709892,
      "learning_rate": 1.4616047736395366e-05,
      "loss": 0.0002,
      "step": 4828
    },
    {
      "epoch": 8.307956989247312,
      "grad_norm": 0.00013447346328552274,
      "learning_rate": 1.4587040366755433e-05,
      "loss": 0.0,
      "step": 4829
    },
    {
      "epoch": 8.30967741935484,
      "grad_norm": 0.0021450529815853904,
      "learning_rate": 1.4558059545351143e-05,
      "loss": 0.0,
      "step": 4830
    },
    {
      "epoch": 8.311397849462365,
      "grad_norm": 0.005164412450296484,
      "learning_rate": 1.4529105281190413e-05,
      "loss": 0.0,
      "step": 4831
    },
    {
      "epoch": 8.313118279569892,
      "grad_norm": 0.07194685174962422,
      "learning_rate": 1.4500177583272867e-05,
      "loss": 0.0001,
      "step": 4832
    },
    {
      "epoch": 8.314838709677419,
      "grad_norm": 0.006761101296617996,
      "learning_rate": 1.4471276460589833e-05,
      "loss": 0.0,
      "step": 4833
    },
    {
      "epoch": 8.316559139784946,
      "grad_norm": 8.02308901181661e-05,
      "learning_rate": 1.4442401922124471e-05,
      "loss": 0.0,
      "step": 4834
    },
    {
      "epoch": 8.318279569892473,
      "grad_norm": 0.00019294313396638993,
      "learning_rate": 1.4413553976851568e-05,
      "loss": 0.0,
      "step": 4835
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.007665000322743675,
      "learning_rate": 1.4384732633737751e-05,
      "loss": 0.0,
      "step": 4836
    },
    {
      "epoch": 8.321720430107527,
      "grad_norm": 1.4403399209113433e-05,
      "learning_rate": 1.4355937901741323e-05,
      "loss": 0.0,
      "step": 4837
    },
    {
      "epoch": 8.323440860215054,
      "grad_norm": 0.0038910302891874667,
      "learning_rate": 1.4327169789812322e-05,
      "loss": 0.0,
      "step": 4838
    },
    {
      "epoch": 8.32516129032258,
      "grad_norm": 0.001802449355593506,
      "learning_rate": 1.4298428306892487e-05,
      "loss": 0.0,
      "step": 4839
    },
    {
      "epoch": 8.326881720430107,
      "grad_norm": 0.0007127627764689155,
      "learning_rate": 1.4269713461915346e-05,
      "loss": 0.0,
      "step": 4840
    },
    {
      "epoch": 8.328602150537634,
      "grad_norm": 0.0008529334077858094,
      "learning_rate": 1.4241025263806095e-05,
      "loss": 0.0,
      "step": 4841
    },
    {
      "epoch": 8.330322580645161,
      "grad_norm": 0.002073904791026648,
      "learning_rate": 1.4212363721481614e-05,
      "loss": 0.0,
      "step": 4842
    },
    {
      "epoch": 8.332043010752688,
      "grad_norm": 0.0008252114180642055,
      "learning_rate": 1.4183728843850618e-05,
      "loss": 0.0,
      "step": 4843
    },
    {
      "epoch": 8.333763440860215,
      "grad_norm": 0.00012705819692829357,
      "learning_rate": 1.415512063981339e-05,
      "loss": 0.0,
      "step": 4844
    },
    {
      "epoch": 8.335483870967742,
      "grad_norm": 0.0006011207481835973,
      "learning_rate": 1.4126539118262038e-05,
      "loss": 0.0,
      "step": 4845
    },
    {
      "epoch": 8.33720430107527,
      "grad_norm": 9.397469897884604e-05,
      "learning_rate": 1.4097984288080334e-05,
      "loss": 0.0,
      "step": 4846
    },
    {
      "epoch": 8.338924731182797,
      "grad_norm": 5.9145506047305565e-05,
      "learning_rate": 1.4069456158143712e-05,
      "loss": 0.0,
      "step": 4847
    },
    {
      "epoch": 8.340645161290322,
      "grad_norm": 0.0008067984248583354,
      "learning_rate": 1.404095473731939e-05,
      "loss": 0.0,
      "step": 4848
    },
    {
      "epoch": 8.342365591397849,
      "grad_norm": 0.001405817680530953,
      "learning_rate": 1.4012480034466225e-05,
      "loss": 0.0,
      "step": 4849
    },
    {
      "epoch": 8.344086021505376,
      "grad_norm": 0.0019904763967489273,
      "learning_rate": 1.3984032058434748e-05,
      "loss": 0.0,
      "step": 4850
    },
    {
      "epoch": 8.345806451612903,
      "grad_norm": 0.0006521187196258087,
      "learning_rate": 1.3955610818067266e-05,
      "loss": 0.0,
      "step": 4851
    },
    {
      "epoch": 8.34752688172043,
      "grad_norm": 0.0002721509629792376,
      "learning_rate": 1.3927216322197723e-05,
      "loss": 0.0,
      "step": 4852
    },
    {
      "epoch": 8.349247311827957,
      "grad_norm": 5.7826890153198403e-05,
      "learning_rate": 1.3898848579651691e-05,
      "loss": 0.0,
      "step": 4853
    },
    {
      "epoch": 8.350967741935484,
      "grad_norm": 0.0005168614651394562,
      "learning_rate": 1.3870507599246585e-05,
      "loss": 0.0,
      "step": 4854
    },
    {
      "epoch": 8.352688172043012,
      "grad_norm": 0.008432970550400931,
      "learning_rate": 1.384219338979137e-05,
      "loss": 0.0,
      "step": 4855
    },
    {
      "epoch": 8.354408602150537,
      "grad_norm": 0.0015261126683628762,
      "learning_rate": 1.3813905960086704e-05,
      "loss": 0.0,
      "step": 4856
    },
    {
      "epoch": 8.356129032258064,
      "grad_norm": 0.00011197158387960686,
      "learning_rate": 1.378564531892499e-05,
      "loss": 0.0,
      "step": 4857
    },
    {
      "epoch": 8.357849462365591,
      "grad_norm": 0.0018959640212368757,
      "learning_rate": 1.3757411475090231e-05,
      "loss": 0.0,
      "step": 4858
    },
    {
      "epoch": 8.359569892473118,
      "grad_norm": 0.0001850079660923166,
      "learning_rate": 1.3729204437358112e-05,
      "loss": 0.0,
      "step": 4859
    },
    {
      "epoch": 8.361290322580645,
      "grad_norm": 6.845639284057112e-05,
      "learning_rate": 1.370102421449605e-05,
      "loss": 0.0,
      "step": 4860
    },
    {
      "epoch": 8.363010752688172,
      "grad_norm": 0.0032139994702480366,
      "learning_rate": 1.3672870815263039e-05,
      "loss": 0.0,
      "step": 4861
    },
    {
      "epoch": 8.3647311827957,
      "grad_norm": 0.0024112051279587304,
      "learning_rate": 1.3644744248409792e-05,
      "loss": 0.0,
      "step": 4862
    },
    {
      "epoch": 8.366451612903226,
      "grad_norm": 0.00036962122031755727,
      "learning_rate": 1.361664452267869e-05,
      "loss": 0.0,
      "step": 4863
    },
    {
      "epoch": 8.368172043010752,
      "grad_norm": 4.782792160492753e-05,
      "learning_rate": 1.3588571646803716e-05,
      "loss": 0.0,
      "step": 4864
    },
    {
      "epoch": 8.369892473118279,
      "grad_norm": 0.1369377734997732,
      "learning_rate": 1.3560525629510568e-05,
      "loss": 0.0003,
      "step": 4865
    },
    {
      "epoch": 8.371612903225806,
      "grad_norm": 0.00047622973330619826,
      "learning_rate": 1.353250647951657e-05,
      "loss": 0.0,
      "step": 4866
    },
    {
      "epoch": 8.373333333333333,
      "grad_norm": 7.633746641532039e-05,
      "learning_rate": 1.350451420553065e-05,
      "loss": 0.0,
      "step": 4867
    },
    {
      "epoch": 8.37505376344086,
      "grad_norm": 0.0002463087649153728,
      "learning_rate": 1.3476548816253464e-05,
      "loss": 0.0,
      "step": 4868
    },
    {
      "epoch": 8.376774193548387,
      "grad_norm": 0.0024792784975235494,
      "learning_rate": 1.3448610320377276e-05,
      "loss": 0.0,
      "step": 4869
    },
    {
      "epoch": 8.378494623655914,
      "grad_norm": 0.0041172525615794,
      "learning_rate": 1.3420698726585946e-05,
      "loss": 0.0,
      "step": 4870
    },
    {
      "epoch": 8.380215053763441,
      "grad_norm": 0.00035413271606151315,
      "learning_rate": 1.3392814043555047e-05,
      "loss": 0.0,
      "step": 4871
    },
    {
      "epoch": 8.381935483870969,
      "grad_norm": 0.0013969889434165609,
      "learning_rate": 1.3364956279951768e-05,
      "loss": 0.0,
      "step": 4872
    },
    {
      "epoch": 8.383655913978494,
      "grad_norm": 0.02564246031130909,
      "learning_rate": 1.3337125444434884e-05,
      "loss": 0.0001,
      "step": 4873
    },
    {
      "epoch": 8.385376344086021,
      "grad_norm": 0.09717795159418866,
      "learning_rate": 1.3309321545654873e-05,
      "loss": 0.0002,
      "step": 4874
    },
    {
      "epoch": 8.387096774193548,
      "grad_norm": 0.0007771739448244867,
      "learning_rate": 1.328154459225377e-05,
      "loss": 0.0,
      "step": 4875
    },
    {
      "epoch": 8.388817204301075,
      "grad_norm": 0.0006524434203173635,
      "learning_rate": 1.3253794592865265e-05,
      "loss": 0.0,
      "step": 4876
    },
    {
      "epoch": 8.390537634408602,
      "grad_norm": 0.029536805281491413,
      "learning_rate": 1.3226071556114693e-05,
      "loss": 0.0,
      "step": 4877
    },
    {
      "epoch": 8.39225806451613,
      "grad_norm": 0.0002982733193926083,
      "learning_rate": 1.3198375490618953e-05,
      "loss": 0.0,
      "step": 4878
    },
    {
      "epoch": 8.393978494623656,
      "grad_norm": 0.0014348127204667047,
      "learning_rate": 1.3170706404986644e-05,
      "loss": 0.0,
      "step": 4879
    },
    {
      "epoch": 8.395698924731184,
      "grad_norm": 0.002839847287286999,
      "learning_rate": 1.3143064307817876e-05,
      "loss": 0.0,
      "step": 4880
    },
    {
      "epoch": 8.397419354838709,
      "grad_norm": 0.003877249504462586,
      "learning_rate": 1.3115449207704444e-05,
      "loss": 0.0,
      "step": 4881
    },
    {
      "epoch": 8.399139784946236,
      "grad_norm": 0.002045792217179316,
      "learning_rate": 1.308786111322976e-05,
      "loss": 0.0,
      "step": 4882
    },
    {
      "epoch": 8.400860215053763,
      "grad_norm": 0.0006483414055999074,
      "learning_rate": 1.3060300032968787e-05,
      "loss": 0.0,
      "step": 4883
    },
    {
      "epoch": 8.40258064516129,
      "grad_norm": 0.0006361081651904491,
      "learning_rate": 1.3032765975488103e-05,
      "loss": 0.0,
      "step": 4884
    },
    {
      "epoch": 8.404301075268817,
      "grad_norm": 0.022573628365370656,
      "learning_rate": 1.3005258949345944e-05,
      "loss": 0.0001,
      "step": 4885
    },
    {
      "epoch": 8.406021505376344,
      "grad_norm": 0.0001957072576619884,
      "learning_rate": 1.2977778963092068e-05,
      "loss": 0.0,
      "step": 4886
    },
    {
      "epoch": 8.407741935483871,
      "grad_norm": 0.08886408407930528,
      "learning_rate": 1.2950326025267857e-05,
      "loss": 0.0001,
      "step": 4887
    },
    {
      "epoch": 8.409462365591398,
      "grad_norm": 3.2737375080876516e-05,
      "learning_rate": 1.2922900144406325e-05,
      "loss": 0.0,
      "step": 4888
    },
    {
      "epoch": 8.411182795698926,
      "grad_norm": 0.00016451867875640945,
      "learning_rate": 1.2895501329032e-05,
      "loss": 0.0,
      "step": 4889
    },
    {
      "epoch": 8.412903225806451,
      "grad_norm": 9.968433550357273e-06,
      "learning_rate": 1.286812958766106e-05,
      "loss": 0.0,
      "step": 4890
    },
    {
      "epoch": 8.414623655913978,
      "grad_norm": 0.00021228842347477715,
      "learning_rate": 1.2840784928801263e-05,
      "loss": 0.0,
      "step": 4891
    },
    {
      "epoch": 8.416344086021505,
      "grad_norm": 0.00042664576051958466,
      "learning_rate": 1.2813467360951925e-05,
      "loss": 0.0,
      "step": 4892
    },
    {
      "epoch": 8.418064516129032,
      "grad_norm": 0.00029472062709299585,
      "learning_rate": 1.2786176892603929e-05,
      "loss": 0.0,
      "step": 4893
    },
    {
      "epoch": 8.41978494623656,
      "grad_norm": 0.00017295143810447137,
      "learning_rate": 1.2758913532239781e-05,
      "loss": 0.0,
      "step": 4894
    },
    {
      "epoch": 8.421505376344086,
      "grad_norm": 0.0005037970910279459,
      "learning_rate": 1.273167728833351e-05,
      "loss": 0.0,
      "step": 4895
    },
    {
      "epoch": 8.423225806451613,
      "grad_norm": 0.0005143341601427461,
      "learning_rate": 1.2704468169350781e-05,
      "loss": 0.0,
      "step": 4896
    },
    {
      "epoch": 8.42494623655914,
      "grad_norm": 0.005378086922276444,
      "learning_rate": 1.267728618374876e-05,
      "loss": 0.0,
      "step": 4897
    },
    {
      "epoch": 8.426666666666666,
      "grad_norm": 0.00020339099983045643,
      "learning_rate": 1.265013133997618e-05,
      "loss": 0.0,
      "step": 4898
    },
    {
      "epoch": 8.428387096774193,
      "grad_norm": 1.831546837864337e-05,
      "learning_rate": 1.262300364647343e-05,
      "loss": 0.0,
      "step": 4899
    },
    {
      "epoch": 8.43010752688172,
      "grad_norm": 0.006500893800532297,
      "learning_rate": 1.259590311167238e-05,
      "loss": 0.0,
      "step": 4900
    },
    {
      "epoch": 8.431827956989247,
      "grad_norm": 0.00360419946356538,
      "learning_rate": 1.2568829743996446e-05,
      "loss": 0.0,
      "step": 4901
    },
    {
      "epoch": 8.433548387096774,
      "grad_norm": 0.002801547134157245,
      "learning_rate": 1.2541783551860663e-05,
      "loss": 0.0,
      "step": 4902
    },
    {
      "epoch": 8.435268817204301,
      "grad_norm": 0.00248875672913502,
      "learning_rate": 1.2514764543671564e-05,
      "loss": 0.0,
      "step": 4903
    },
    {
      "epoch": 8.436989247311828,
      "grad_norm": 0.00457523492872202,
      "learning_rate": 1.2487772727827252e-05,
      "loss": 0.0,
      "step": 4904
    },
    {
      "epoch": 8.438709677419356,
      "grad_norm": 0.0005978995345814193,
      "learning_rate": 1.2460808112717393e-05,
      "loss": 0.0,
      "step": 4905
    },
    {
      "epoch": 8.440430107526883,
      "grad_norm": 0.0026660094822821595,
      "learning_rate": 1.2433870706723172e-05,
      "loss": 0.0,
      "step": 4906
    },
    {
      "epoch": 8.442150537634408,
      "grad_norm": 0.00011976858013557251,
      "learning_rate": 1.2406960518217326e-05,
      "loss": 0.0,
      "step": 4907
    },
    {
      "epoch": 8.443870967741935,
      "grad_norm": 0.00038247402437859,
      "learning_rate": 1.2380077555564174e-05,
      "loss": 0.0,
      "step": 4908
    },
    {
      "epoch": 8.445591397849462,
      "grad_norm": 9.115571455936389e-05,
      "learning_rate": 1.235322182711951e-05,
      "loss": 0.0,
      "step": 4909
    },
    {
      "epoch": 8.44731182795699,
      "grad_norm": 0.00015834035119986423,
      "learning_rate": 1.2326393341230657e-05,
      "loss": 0.0,
      "step": 4910
    },
    {
      "epoch": 8.449032258064516,
      "grad_norm": 4.624632170538066e-06,
      "learning_rate": 1.2299592106236568e-05,
      "loss": 0.0,
      "step": 4911
    },
    {
      "epoch": 8.450752688172043,
      "grad_norm": 0.0017541013747416798,
      "learning_rate": 1.227281813046759e-05,
      "loss": 0.0,
      "step": 4912
    },
    {
      "epoch": 8.45247311827957,
      "grad_norm": 0.0017969341096041728,
      "learning_rate": 1.224607142224572e-05,
      "loss": 0.0,
      "step": 4913
    },
    {
      "epoch": 8.454193548387098,
      "grad_norm": 0.031103312432196634,
      "learning_rate": 1.221935198988441e-05,
      "loss": 0.0001,
      "step": 4914
    },
    {
      "epoch": 8.455913978494623,
      "grad_norm": 0.0014542430431578543,
      "learning_rate": 1.2192659841688626e-05,
      "loss": 0.0,
      "step": 4915
    },
    {
      "epoch": 8.45763440860215,
      "grad_norm": 0.05816868245284388,
      "learning_rate": 1.2165994985954887e-05,
      "loss": 0.0001,
      "step": 4916
    },
    {
      "epoch": 8.459354838709677,
      "grad_norm": 0.007735427073229991,
      "learning_rate": 1.2139357430971255e-05,
      "loss": 0.0,
      "step": 4917
    },
    {
      "epoch": 8.461075268817204,
      "grad_norm": 0.0011429244615563017,
      "learning_rate": 1.2112747185017226e-05,
      "loss": 0.0,
      "step": 4918
    },
    {
      "epoch": 8.462795698924731,
      "grad_norm": 0.0033786424563585662,
      "learning_rate": 1.2086164256363896e-05,
      "loss": 0.0,
      "step": 4919
    },
    {
      "epoch": 8.464516129032258,
      "grad_norm": 0.0007256274646235374,
      "learning_rate": 1.205960865327379e-05,
      "loss": 0.0,
      "step": 4920
    },
    {
      "epoch": 8.466236559139785,
      "grad_norm": 0.0002136093905885108,
      "learning_rate": 1.2033080384000983e-05,
      "loss": 0.0,
      "step": 4921
    },
    {
      "epoch": 8.467956989247313,
      "grad_norm": 0.002669568295928397,
      "learning_rate": 1.2006579456791067e-05,
      "loss": 0.0,
      "step": 4922
    },
    {
      "epoch": 8.469677419354838,
      "grad_norm": 6.503015608018059e-05,
      "learning_rate": 1.1980105879881076e-05,
      "loss": 0.0,
      "step": 4923
    },
    {
      "epoch": 8.471397849462365,
      "grad_norm": 0.04957211499102419,
      "learning_rate": 1.1953659661499638e-05,
      "loss": 0.0001,
      "step": 4924
    },
    {
      "epoch": 8.473118279569892,
      "grad_norm": 3.0739807320375825e-05,
      "learning_rate": 1.1927240809866769e-05,
      "loss": 0.0,
      "step": 4925
    },
    {
      "epoch": 8.47483870967742,
      "grad_norm": 0.002803811192129204,
      "learning_rate": 1.1900849333194074e-05,
      "loss": 0.0,
      "step": 4926
    },
    {
      "epoch": 8.476559139784946,
      "grad_norm": 0.0005022087641454923,
      "learning_rate": 1.1874485239684574e-05,
      "loss": 0.0,
      "step": 4927
    },
    {
      "epoch": 8.478279569892473,
      "grad_norm": 0.0259901739560574,
      "learning_rate": 1.1848148537532843e-05,
      "loss": 0.0,
      "step": 4928
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.0007764979820832781,
      "learning_rate": 1.182183923492488e-05,
      "loss": 0.0,
      "step": 4929
    },
    {
      "epoch": 8.481720430107528,
      "grad_norm": 0.00020537414533270884,
      "learning_rate": 1.1795557340038233e-05,
      "loss": 0.0,
      "step": 4930
    },
    {
      "epoch": 8.483440860215055,
      "grad_norm": 0.0034325321436673773,
      "learning_rate": 1.1769302861041864e-05,
      "loss": 0.0,
      "step": 4931
    },
    {
      "epoch": 8.48516129032258,
      "grad_norm": 0.009428586638198715,
      "learning_rate": 1.174307580609625e-05,
      "loss": 0.0,
      "step": 4932
    },
    {
      "epoch": 8.486881720430107,
      "grad_norm": 0.001188619045376505,
      "learning_rate": 1.1716876183353353e-05,
      "loss": 0.0,
      "step": 4933
    },
    {
      "epoch": 8.488602150537634,
      "grad_norm": 0.0044133433999966115,
      "learning_rate": 1.1690704000956575e-05,
      "loss": 0.0,
      "step": 4934
    },
    {
      "epoch": 8.490322580645161,
      "grad_norm": 0.011082054776242389,
      "learning_rate": 1.166455926704082e-05,
      "loss": 0.0,
      "step": 4935
    },
    {
      "epoch": 8.492043010752688,
      "grad_norm": 0.0004834060083211042,
      "learning_rate": 1.1638441989732473e-05,
      "loss": 0.0,
      "step": 4936
    },
    {
      "epoch": 8.493763440860215,
      "grad_norm": 0.001113477855371229,
      "learning_rate": 1.1612352177149332e-05,
      "loss": 0.0,
      "step": 4937
    },
    {
      "epoch": 8.495483870967742,
      "grad_norm": 0.0008886854105007055,
      "learning_rate": 1.1586289837400688e-05,
      "loss": 0.0,
      "step": 4938
    },
    {
      "epoch": 8.49720430107527,
      "grad_norm": 0.002741494505143324,
      "learning_rate": 1.1560254978587304e-05,
      "loss": 0.0,
      "step": 4939
    },
    {
      "epoch": 8.498924731182795,
      "grad_norm": 0.00018183382161178613,
      "learning_rate": 1.1534247608801374e-05,
      "loss": 0.0,
      "step": 4940
    },
    {
      "epoch": 8.500645161290322,
      "grad_norm": 0.0007190135733158404,
      "learning_rate": 1.1508267736126588e-05,
      "loss": 0.0,
      "step": 4941
    },
    {
      "epoch": 8.502365591397849,
      "grad_norm": 0.0007315123117805689,
      "learning_rate": 1.1482315368638042e-05,
      "loss": 0.0,
      "step": 4942
    },
    {
      "epoch": 8.504086021505376,
      "grad_norm": 5.544354990505466e-05,
      "learning_rate": 1.1456390514402304e-05,
      "loss": 0.0,
      "step": 4943
    },
    {
      "epoch": 8.505806451612903,
      "grad_norm": 0.011955295753760054,
      "learning_rate": 1.1430493181477398e-05,
      "loss": 0.0,
      "step": 4944
    },
    {
      "epoch": 8.50752688172043,
      "grad_norm": 0.00028085242324391984,
      "learning_rate": 1.1404623377912805e-05,
      "loss": 0.0,
      "step": 4945
    },
    {
      "epoch": 8.509247311827957,
      "grad_norm": 6.166306259368303e-05,
      "learning_rate": 1.1378781111749404e-05,
      "loss": 0.0,
      "step": 4946
    },
    {
      "epoch": 8.510967741935485,
      "grad_norm": 0.0008105693088906228,
      "learning_rate": 1.135296639101957e-05,
      "loss": 0.0,
      "step": 4947
    },
    {
      "epoch": 8.51268817204301,
      "grad_norm": 0.00010520636882193756,
      "learning_rate": 1.1327179223747075e-05,
      "loss": 0.0,
      "step": 4948
    },
    {
      "epoch": 8.514408602150537,
      "grad_norm": 0.00014607759547050991,
      "learning_rate": 1.1301419617947117e-05,
      "loss": 0.0,
      "step": 4949
    },
    {
      "epoch": 8.516129032258064,
      "grad_norm": 1.807525006255568e-05,
      "learning_rate": 1.1275687581626404e-05,
      "loss": 0.0,
      "step": 4950
    },
    {
      "epoch": 8.517849462365591,
      "grad_norm": 0.00027081395854261313,
      "learning_rate": 1.124998312278297e-05,
      "loss": 0.0,
      "step": 4951
    },
    {
      "epoch": 8.519569892473118,
      "grad_norm": 0.00010593030150779965,
      "learning_rate": 1.1224306249406336e-05,
      "loss": 0.0,
      "step": 4952
    },
    {
      "epoch": 8.521290322580645,
      "grad_norm": 6.491765864360099e-05,
      "learning_rate": 1.1198656969477494e-05,
      "loss": 0.0,
      "step": 4953
    },
    {
      "epoch": 8.523010752688172,
      "grad_norm": 1.543573120956206e-05,
      "learning_rate": 1.1173035290968759e-05,
      "loss": 0.0,
      "step": 4954
    },
    {
      "epoch": 8.5247311827957,
      "grad_norm": 0.0013432011330767016,
      "learning_rate": 1.1147441221843902e-05,
      "loss": 0.0,
      "step": 4955
    },
    {
      "epoch": 8.526451612903227,
      "grad_norm": 0.00021738894313331312,
      "learning_rate": 1.112187477005817e-05,
      "loss": 0.0,
      "step": 4956
    },
    {
      "epoch": 8.528172043010752,
      "grad_norm": 0.003618757450012519,
      "learning_rate": 1.1096335943558145e-05,
      "loss": 0.0,
      "step": 4957
    },
    {
      "epoch": 8.529892473118279,
      "grad_norm": 4.733527963896363e-05,
      "learning_rate": 1.1070824750281894e-05,
      "loss": 0.0,
      "step": 4958
    },
    {
      "epoch": 8.531612903225806,
      "grad_norm": 0.0002094155980428929,
      "learning_rate": 1.1045341198158831e-05,
      "loss": 0.0,
      "step": 4959
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 0.0031329867021821353,
      "learning_rate": 1.1019885295109799e-05,
      "loss": 0.0,
      "step": 4960
    },
    {
      "epoch": 8.53505376344086,
      "grad_norm": 8.93476116933007e-05,
      "learning_rate": 1.099445704904708e-05,
      "loss": 0.0,
      "step": 4961
    },
    {
      "epoch": 8.536774193548387,
      "grad_norm": 0.00029355354821103446,
      "learning_rate": 1.0969056467874338e-05,
      "loss": 0.0,
      "step": 4962
    },
    {
      "epoch": 8.538494623655914,
      "grad_norm": 0.01793594627664393,
      "learning_rate": 1.0943683559486605e-05,
      "loss": 0.0,
      "step": 4963
    },
    {
      "epoch": 8.540215053763442,
      "grad_norm": 0.000587569415500689,
      "learning_rate": 1.0918338331770384e-05,
      "loss": 0.0,
      "step": 4964
    },
    {
      "epoch": 8.541935483870969,
      "grad_norm": 0.10241201144927214,
      "learning_rate": 1.0893020792603503e-05,
      "loss": 0.0002,
      "step": 4965
    },
    {
      "epoch": 8.543655913978494,
      "grad_norm": 0.00020763613846006606,
      "learning_rate": 1.0867730949855203e-05,
      "loss": 0.0,
      "step": 4966
    },
    {
      "epoch": 8.545376344086021,
      "grad_norm": 0.03413540119564188,
      "learning_rate": 1.0842468811386153e-05,
      "loss": 0.0,
      "step": 4967
    },
    {
      "epoch": 8.547096774193548,
      "grad_norm": 0.00015516641621770582,
      "learning_rate": 1.0817234385048359e-05,
      "loss": 0.0,
      "step": 4968
    },
    {
      "epoch": 8.548817204301075,
      "grad_norm": 0.0001707100683739615,
      "learning_rate": 1.0792027678685267e-05,
      "loss": 0.0,
      "step": 4969
    },
    {
      "epoch": 8.550537634408602,
      "grad_norm": 0.01324132752659002,
      "learning_rate": 1.0766848700131648e-05,
      "loss": 0.0,
      "step": 4970
    },
    {
      "epoch": 8.55225806451613,
      "grad_norm": 7.096571227975758e-05,
      "learning_rate": 1.0741697457213717e-05,
      "loss": 0.0,
      "step": 4971
    },
    {
      "epoch": 8.553978494623657,
      "grad_norm": 0.000368586469786795,
      "learning_rate": 1.0716573957749e-05,
      "loss": 0.0,
      "step": 4972
    },
    {
      "epoch": 8.555698924731182,
      "grad_norm": 0.0003846628622332126,
      "learning_rate": 1.0691478209546479e-05,
      "loss": 0.0,
      "step": 4973
    },
    {
      "epoch": 8.557419354838709,
      "grad_norm": 0.0023869613085666136,
      "learning_rate": 1.066641022040642e-05,
      "loss": 0.0,
      "step": 4974
    },
    {
      "epoch": 8.559139784946236,
      "grad_norm": 0.006365255964165472,
      "learning_rate": 1.0641369998120543e-05,
      "loss": 0.0,
      "step": 4975
    },
    {
      "epoch": 8.560860215053763,
      "grad_norm": 0.0001288001860418067,
      "learning_rate": 1.06163575504719e-05,
      "loss": 0.0,
      "step": 4976
    },
    {
      "epoch": 8.56258064516129,
      "grad_norm": 0.0002496470946880045,
      "learning_rate": 1.0591372885234885e-05,
      "loss": 0.0,
      "step": 4977
    },
    {
      "epoch": 8.564301075268817,
      "grad_norm": 0.004938696801610741,
      "learning_rate": 1.0566416010175317e-05,
      "loss": 0.0,
      "step": 4978
    },
    {
      "epoch": 8.566021505376344,
      "grad_norm": 0.002319746393701147,
      "learning_rate": 1.0541486933050316e-05,
      "loss": 0.0,
      "step": 4979
    },
    {
      "epoch": 8.567741935483872,
      "grad_norm": 5.288745780758685e-05,
      "learning_rate": 1.0516585661608403e-05,
      "loss": 0.0,
      "step": 4980
    },
    {
      "epoch": 8.569462365591399,
      "grad_norm": 0.007378989473001319,
      "learning_rate": 1.0491712203589466e-05,
      "loss": 0.0,
      "step": 4981
    },
    {
      "epoch": 8.571182795698924,
      "grad_norm": 0.00011989709174805613,
      "learning_rate": 1.0466866566724698e-05,
      "loss": 0.0,
      "step": 4982
    },
    {
      "epoch": 8.572903225806451,
      "grad_norm": 0.0015077567663000742,
      "learning_rate": 1.0442048758736656e-05,
      "loss": 0.0,
      "step": 4983
    },
    {
      "epoch": 8.574623655913978,
      "grad_norm": 0.0034694928185927884,
      "learning_rate": 1.0417258787339313e-05,
      "loss": 0.0,
      "step": 4984
    },
    {
      "epoch": 8.576344086021505,
      "grad_norm": 0.001144674658706137,
      "learning_rate": 1.0392496660237894e-05,
      "loss": 0.0,
      "step": 4985
    },
    {
      "epoch": 8.578064516129032,
      "grad_norm": 0.0007409167840246872,
      "learning_rate": 1.0367762385129054e-05,
      "loss": 0.0,
      "step": 4986
    },
    {
      "epoch": 8.57978494623656,
      "grad_norm": 0.002312608523248404,
      "learning_rate": 1.034305596970072e-05,
      "loss": 0.0,
      "step": 4987
    },
    {
      "epoch": 8.581505376344086,
      "grad_norm": 0.008724401524966246,
      "learning_rate": 1.0318377421632198e-05,
      "loss": 0.0,
      "step": 4988
    },
    {
      "epoch": 8.583225806451614,
      "grad_norm": 3.2760099795020756e-05,
      "learning_rate": 1.0293726748594135e-05,
      "loss": 0.0,
      "step": 4989
    },
    {
      "epoch": 8.58494623655914,
      "grad_norm": 0.020308412639832452,
      "learning_rate": 1.0269103958248517e-05,
      "loss": 0.0,
      "step": 4990
    },
    {
      "epoch": 8.586666666666666,
      "grad_norm": 0.00012009232349534884,
      "learning_rate": 1.0244509058248609e-05,
      "loss": 0.0,
      "step": 4991
    },
    {
      "epoch": 8.588387096774193,
      "grad_norm": 1.166978329791748e-05,
      "learning_rate": 1.0219942056239107e-05,
      "loss": 0.0,
      "step": 4992
    },
    {
      "epoch": 8.59010752688172,
      "grad_norm": 0.0003267837776845623,
      "learning_rate": 1.0195402959855948e-05,
      "loss": 0.0,
      "step": 4993
    },
    {
      "epoch": 8.591827956989247,
      "grad_norm": 2.116269032277903e-05,
      "learning_rate": 1.0170891776726399e-05,
      "loss": 0.0,
      "step": 4994
    },
    {
      "epoch": 8.593548387096774,
      "grad_norm": 0.00037003944847078184,
      "learning_rate": 1.014640851446913e-05,
      "loss": 0.0,
      "step": 4995
    },
    {
      "epoch": 8.595268817204301,
      "grad_norm": 0.004135115134610606,
      "learning_rate": 1.0121953180694054e-05,
      "loss": 0.0,
      "step": 4996
    },
    {
      "epoch": 8.596989247311829,
      "grad_norm": 0.0017875139069257592,
      "learning_rate": 1.0097525783002392e-05,
      "loss": 0.0,
      "step": 4997
    },
    {
      "epoch": 8.598709677419356,
      "grad_norm": 0.0030203524078478263,
      "learning_rate": 1.0073126328986804e-05,
      "loss": 0.0,
      "step": 4998
    },
    {
      "epoch": 8.600430107526881,
      "grad_norm": 0.028845373145402288,
      "learning_rate": 1.0048754826231121e-05,
      "loss": 0.0001,
      "step": 4999
    },
    {
      "epoch": 8.602150537634408,
      "grad_norm": 2.7570387340012216e-05,
      "learning_rate": 1.0024411282310542e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 8.603870967741935,
      "grad_norm": 0.006827114494469421,
      "learning_rate": 1.0000095704791611e-05,
      "loss": 0.0,
      "step": 5001
    },
    {
      "epoch": 8.605591397849462,
      "grad_norm": 0.003244133384876612,
      "learning_rate": 9.97580810123211e-06,
      "loss": 0.0,
      "step": 5002
    },
    {
      "epoch": 8.60731182795699,
      "grad_norm": 0.04035871984992385,
      "learning_rate": 9.951548479181205e-06,
      "loss": 0.0001,
      "step": 5003
    },
    {
      "epoch": 8.609032258064516,
      "grad_norm": 0.0011486906737754668,
      "learning_rate": 9.927316846179292e-06,
      "loss": 0.0,
      "step": 5004
    },
    {
      "epoch": 8.610752688172044,
      "grad_norm": 1.7103003301274844e-05,
      "learning_rate": 9.903113209758096e-06,
      "loss": 0.0,
      "step": 5005
    },
    {
      "epoch": 8.61247311827957,
      "grad_norm": 0.0029511529833261304,
      "learning_rate": 9.878937577440638e-06,
      "loss": 0.0,
      "step": 5006
    },
    {
      "epoch": 8.614193548387096,
      "grad_norm": 0.0001118113472771864,
      "learning_rate": 9.854789956741284e-06,
      "loss": 0.0,
      "step": 5007
    },
    {
      "epoch": 8.615913978494623,
      "grad_norm": 0.0009485111213269041,
      "learning_rate": 9.830670355165594e-06,
      "loss": 0.0,
      "step": 5008
    },
    {
      "epoch": 8.61763440860215,
      "grad_norm": 0.0009272509052267539,
      "learning_rate": 9.806578780210518e-06,
      "loss": 0.0,
      "step": 5009
    },
    {
      "epoch": 8.619354838709677,
      "grad_norm": 0.0047972864174432115,
      "learning_rate": 9.78251523936422e-06,
      "loss": 0.0,
      "step": 5010
    },
    {
      "epoch": 8.621075268817204,
      "grad_norm": 0.0034268571822740107,
      "learning_rate": 9.758479740106175e-06,
      "loss": 0.0,
      "step": 5011
    },
    {
      "epoch": 8.622795698924731,
      "grad_norm": 2.7923169142476602e-05,
      "learning_rate": 9.734472289907182e-06,
      "loss": 0.0,
      "step": 5012
    },
    {
      "epoch": 8.624516129032259,
      "grad_norm": 9.78082980283142e-05,
      "learning_rate": 9.710492896229262e-06,
      "loss": 0.0,
      "step": 5013
    },
    {
      "epoch": 8.626236559139786,
      "grad_norm": 9.578289527161173e-05,
      "learning_rate": 9.68654156652573e-06,
      "loss": 0.0,
      "step": 5014
    },
    {
      "epoch": 8.627956989247313,
      "grad_norm": 0.00039787232705605754,
      "learning_rate": 9.6626183082412e-06,
      "loss": 0.0,
      "step": 5015
    },
    {
      "epoch": 8.629677419354838,
      "grad_norm": 0.001574824176658985,
      "learning_rate": 9.638723128811578e-06,
      "loss": 0.0,
      "step": 5016
    },
    {
      "epoch": 8.631397849462365,
      "grad_norm": 0.0001908851079742027,
      "learning_rate": 9.614856035663966e-06,
      "loss": 0.0,
      "step": 5017
    },
    {
      "epoch": 8.633118279569892,
      "grad_norm": 6.028888990834889e-05,
      "learning_rate": 9.59101703621682e-06,
      "loss": 0.0,
      "step": 5018
    },
    {
      "epoch": 8.63483870967742,
      "grad_norm": 0.002631548684033746,
      "learning_rate": 9.567206137879803e-06,
      "loss": 0.0,
      "step": 5019
    },
    {
      "epoch": 8.636559139784946,
      "grad_norm": 0.0001318883893435903,
      "learning_rate": 9.543423348053892e-06,
      "loss": 0.0,
      "step": 5020
    },
    {
      "epoch": 8.638279569892473,
      "grad_norm": 0.0025142843480447587,
      "learning_rate": 9.519668674131299e-06,
      "loss": 0.0,
      "step": 5021
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.4571610255909255e-05,
      "learning_rate": 9.495942123495472e-06,
      "loss": 0.0,
      "step": 5022
    },
    {
      "epoch": 8.641720430107528,
      "grad_norm": 0.0007063762688095423,
      "learning_rate": 9.472243703521188e-06,
      "loss": 0.0,
      "step": 5023
    },
    {
      "epoch": 8.643440860215053,
      "grad_norm": 0.0004115232853068216,
      "learning_rate": 9.448573421574402e-06,
      "loss": 0.0,
      "step": 5024
    },
    {
      "epoch": 8.64516129032258,
      "grad_norm": 0.01203856144501525,
      "learning_rate": 9.424931285012384e-06,
      "loss": 0.0,
      "step": 5025
    },
    {
      "epoch": 8.646881720430107,
      "grad_norm": 0.0001636461423101794,
      "learning_rate": 9.401317301183655e-06,
      "loss": 0.0,
      "step": 5026
    },
    {
      "epoch": 8.648602150537634,
      "grad_norm": 0.015878098387114247,
      "learning_rate": 9.37773147742792e-06,
      "loss": 0.0,
      "step": 5027
    },
    {
      "epoch": 8.650322580645161,
      "grad_norm": 0.0014314855789593376,
      "learning_rate": 9.354173821076184e-06,
      "loss": 0.0,
      "step": 5028
    },
    {
      "epoch": 8.652043010752688,
      "grad_norm": 0.004814538142938381,
      "learning_rate": 9.330644339450712e-06,
      "loss": 0.0,
      "step": 5029
    },
    {
      "epoch": 8.653763440860216,
      "grad_norm": 0.07261214174686606,
      "learning_rate": 9.307143039864962e-06,
      "loss": 0.0,
      "step": 5030
    },
    {
      "epoch": 8.655483870967743,
      "grad_norm": 0.0003189136017608995,
      "learning_rate": 9.283669929623651e-06,
      "loss": 0.0,
      "step": 5031
    },
    {
      "epoch": 8.657204301075268,
      "grad_norm": 0.000245832542007658,
      "learning_rate": 9.260225016022772e-06,
      "loss": 0.0,
      "step": 5032
    },
    {
      "epoch": 8.658924731182795,
      "grad_norm": 0.00010562908017985175,
      "learning_rate": 9.236808306349497e-06,
      "loss": 0.0,
      "step": 5033
    },
    {
      "epoch": 8.660645161290322,
      "grad_norm": 7.679866634322741e-05,
      "learning_rate": 9.21341980788225e-06,
      "loss": 0.0,
      "step": 5034
    },
    {
      "epoch": 8.66236559139785,
      "grad_norm": 0.0002348614889354271,
      "learning_rate": 9.190059527890738e-06,
      "loss": 0.0,
      "step": 5035
    },
    {
      "epoch": 8.664086021505376,
      "grad_norm": 0.00028833671133399603,
      "learning_rate": 9.166727473635795e-06,
      "loss": 0.0,
      "step": 5036
    },
    {
      "epoch": 8.665806451612903,
      "grad_norm": 0.00851830297567017,
      "learning_rate": 9.143423652369588e-06,
      "loss": 0.0,
      "step": 5037
    },
    {
      "epoch": 8.66752688172043,
      "grad_norm": 0.4221458181862162,
      "learning_rate": 9.120148071335433e-06,
      "loss": 0.0001,
      "step": 5038
    },
    {
      "epoch": 8.669247311827958,
      "grad_norm": 4.348239763908122e-05,
      "learning_rate": 9.096900737767888e-06,
      "loss": 0.0,
      "step": 5039
    },
    {
      "epoch": 8.670967741935485,
      "grad_norm": 0.002115249344199006,
      "learning_rate": 9.073681658892775e-06,
      "loss": 0.0,
      "step": 5040
    },
    {
      "epoch": 8.67268817204301,
      "grad_norm": 0.0019207198848828848,
      "learning_rate": 9.050490841927062e-06,
      "loss": 0.0,
      "step": 5041
    },
    {
      "epoch": 8.674408602150537,
      "grad_norm": 0.0007369770525694768,
      "learning_rate": 9.02732829407894e-06,
      "loss": 0.0,
      "step": 5042
    },
    {
      "epoch": 8.676129032258064,
      "grad_norm": 0.002201358718220653,
      "learning_rate": 9.004194022547918e-06,
      "loss": 0.0,
      "step": 5043
    },
    {
      "epoch": 8.677849462365591,
      "grad_norm": 0.0005127496053835242,
      "learning_rate": 8.981088034524599e-06,
      "loss": 0.0,
      "step": 5044
    },
    {
      "epoch": 8.679569892473118,
      "grad_norm": 0.05083611666037894,
      "learning_rate": 8.958010337190825e-06,
      "loss": 0.0002,
      "step": 5045
    },
    {
      "epoch": 8.681290322580645,
      "grad_norm": 0.0003493660929701574,
      "learning_rate": 8.934960937719671e-06,
      "loss": 0.0,
      "step": 5046
    },
    {
      "epoch": 8.683010752688173,
      "grad_norm": 0.025010721847593523,
      "learning_rate": 8.911939843275396e-06,
      "loss": 0.0,
      "step": 5047
    },
    {
      "epoch": 8.6847311827957,
      "grad_norm": 7.849567374592777e-05,
      "learning_rate": 8.888947061013453e-06,
      "loss": 0.0,
      "step": 5048
    },
    {
      "epoch": 8.686451612903225,
      "grad_norm": 5.9487794129201513e-05,
      "learning_rate": 8.865982598080525e-06,
      "loss": 0.0,
      "step": 5049
    },
    {
      "epoch": 8.688172043010752,
      "grad_norm": 0.00012099786279344057,
      "learning_rate": 8.843046461614446e-06,
      "loss": 0.0,
      "step": 5050
    },
    {
      "epoch": 8.68989247311828,
      "grad_norm": 0.0002584096329282733,
      "learning_rate": 8.820138658744304e-06,
      "loss": 0.0,
      "step": 5051
    },
    {
      "epoch": 8.691612903225806,
      "grad_norm": 0.0006591709616924122,
      "learning_rate": 8.797259196590346e-06,
      "loss": 0.0,
      "step": 5052
    },
    {
      "epoch": 8.693333333333333,
      "grad_norm": 1.578535662612428e-05,
      "learning_rate": 8.774408082263996e-06,
      "loss": 0.0,
      "step": 5053
    },
    {
      "epoch": 8.69505376344086,
      "grad_norm": 7.641668373649293e-05,
      "learning_rate": 8.751585322867917e-06,
      "loss": 0.0,
      "step": 5054
    },
    {
      "epoch": 8.696774193548388,
      "grad_norm": 0.000317504366343829,
      "learning_rate": 8.728790925495911e-06,
      "loss": 0.0,
      "step": 5055
    },
    {
      "epoch": 8.698494623655915,
      "grad_norm": 6.757650116746998e-05,
      "learning_rate": 8.706024897232956e-06,
      "loss": 0.0,
      "step": 5056
    },
    {
      "epoch": 8.70021505376344,
      "grad_norm": 0.0009959379864101633,
      "learning_rate": 8.68328724515528e-06,
      "loss": 0.0,
      "step": 5057
    },
    {
      "epoch": 8.701935483870967,
      "grad_norm": 4.6514611916723864e-05,
      "learning_rate": 8.660577976330231e-06,
      "loss": 0.0,
      "step": 5058
    },
    {
      "epoch": 8.703655913978494,
      "grad_norm": 0.003999551301760678,
      "learning_rate": 8.637897097816316e-06,
      "loss": 0.0,
      "step": 5059
    },
    {
      "epoch": 8.705376344086021,
      "grad_norm": 1.2630592514848046e-05,
      "learning_rate": 8.615244616663298e-06,
      "loss": 0.0,
      "step": 5060
    },
    {
      "epoch": 8.707096774193548,
      "grad_norm": 0.0008615679552466548,
      "learning_rate": 8.592620539912066e-06,
      "loss": 0.0,
      "step": 5061
    },
    {
      "epoch": 8.708817204301075,
      "grad_norm": 0.0008531601030662452,
      "learning_rate": 8.57002487459465e-06,
      "loss": 0.0,
      "step": 5062
    },
    {
      "epoch": 8.710537634408603,
      "grad_norm": 0.0019801197663512275,
      "learning_rate": 8.547457627734335e-06,
      "loss": 0.0,
      "step": 5063
    },
    {
      "epoch": 8.71225806451613,
      "grad_norm": 0.0014501639640758322,
      "learning_rate": 8.524918806345484e-06,
      "loss": 0.0,
      "step": 5064
    },
    {
      "epoch": 8.713978494623657,
      "grad_norm": 0.00011162566187679498,
      "learning_rate": 8.502408417433649e-06,
      "loss": 0.0,
      "step": 5065
    },
    {
      "epoch": 8.715698924731182,
      "grad_norm": 0.0001336602818171381,
      "learning_rate": 8.47992646799558e-06,
      "loss": 0.0,
      "step": 5066
    },
    {
      "epoch": 8.717419354838709,
      "grad_norm": 5.016399091525298e-05,
      "learning_rate": 8.457472965019153e-06,
      "loss": 0.0,
      "step": 5067
    },
    {
      "epoch": 8.719139784946236,
      "grad_norm": 0.0002955260069227734,
      "learning_rate": 8.43504791548344e-06,
      "loss": 0.0,
      "step": 5068
    },
    {
      "epoch": 8.720860215053763,
      "grad_norm": 0.0013996289760234227,
      "learning_rate": 8.412651326358589e-06,
      "loss": 0.0,
      "step": 5069
    },
    {
      "epoch": 8.72258064516129,
      "grad_norm": 0.00045001043401791426,
      "learning_rate": 8.390283204605997e-06,
      "loss": 0.0,
      "step": 5070
    },
    {
      "epoch": 8.724301075268817,
      "grad_norm": 0.0005276238982216721,
      "learning_rate": 8.36794355717817e-06,
      "loss": 0.0,
      "step": 5071
    },
    {
      "epoch": 8.726021505376345,
      "grad_norm": 0.0008533217300807206,
      "learning_rate": 8.345632391018755e-06,
      "loss": 0.0,
      "step": 5072
    },
    {
      "epoch": 8.727741935483872,
      "grad_norm": 0.0012174405559875322,
      "learning_rate": 8.323349713062535e-06,
      "loss": 0.0,
      "step": 5073
    },
    {
      "epoch": 8.729462365591399,
      "grad_norm": 0.00013339476132130112,
      "learning_rate": 8.301095530235492e-06,
      "loss": 0.0,
      "step": 5074
    },
    {
      "epoch": 8.731182795698924,
      "grad_norm": 2.631261778503478,
      "learning_rate": 8.278869849454718e-06,
      "loss": 0.0529,
      "step": 5075
    },
    {
      "epoch": 8.732903225806451,
      "grad_norm": 0.0005892190707473994,
      "learning_rate": 8.256672677628396e-06,
      "loss": 0.0,
      "step": 5076
    },
    {
      "epoch": 8.734623655913978,
      "grad_norm": 0.0874328385777075,
      "learning_rate": 8.234504021655964e-06,
      "loss": 0.0,
      "step": 5077
    },
    {
      "epoch": 8.736344086021505,
      "grad_norm": 0.00010097925529105994,
      "learning_rate": 8.212363888427876e-06,
      "loss": 0.0,
      "step": 5078
    },
    {
      "epoch": 8.738064516129032,
      "grad_norm": 0.0004740436677228451,
      "learning_rate": 8.190252284825805e-06,
      "loss": 0.0,
      "step": 5079
    },
    {
      "epoch": 8.73978494623656,
      "grad_norm": 1.914192029274296e-05,
      "learning_rate": 8.168169217722532e-06,
      "loss": 0.0,
      "step": 5080
    },
    {
      "epoch": 8.741505376344087,
      "grad_norm": 6.348478541301699e-06,
      "learning_rate": 8.146114693981944e-06,
      "loss": 0.0,
      "step": 5081
    },
    {
      "epoch": 8.743225806451614,
      "grad_norm": 0.02475085942722158,
      "learning_rate": 8.124088720459067e-06,
      "loss": 0.0,
      "step": 5082
    },
    {
      "epoch": 8.744946236559139,
      "grad_norm": 0.0010370817329951644,
      "learning_rate": 8.102091304000093e-06,
      "loss": 0.0,
      "step": 5083
    },
    {
      "epoch": 8.746666666666666,
      "grad_norm": 0.0022319452799802984,
      "learning_rate": 8.080122451442263e-06,
      "loss": 0.0,
      "step": 5084
    },
    {
      "epoch": 8.748387096774193,
      "grad_norm": 6.713189627896945e-05,
      "learning_rate": 8.058182169614025e-06,
      "loss": 0.0,
      "step": 5085
    },
    {
      "epoch": 8.75010752688172,
      "grad_norm": 2.9857932349109744e-05,
      "learning_rate": 8.036270465334894e-06,
      "loss": 0.0,
      "step": 5086
    },
    {
      "epoch": 8.751827956989247,
      "grad_norm": 3.079631644574148e-05,
      "learning_rate": 8.014387345415454e-06,
      "loss": 0.0,
      "step": 5087
    },
    {
      "epoch": 8.753548387096775,
      "grad_norm": 0.0003625232248828943,
      "learning_rate": 7.992532816657549e-06,
      "loss": 0.0,
      "step": 5088
    },
    {
      "epoch": 8.755268817204302,
      "grad_norm": 0.0017508083107891017,
      "learning_rate": 7.970706885854007e-06,
      "loss": 0.0,
      "step": 5089
    },
    {
      "epoch": 8.756989247311829,
      "grad_norm": 0.024587009765667286,
      "learning_rate": 7.948909559788797e-06,
      "loss": 0.0,
      "step": 5090
    },
    {
      "epoch": 8.758709677419354,
      "grad_norm": 2.1037394097431174e-05,
      "learning_rate": 7.927140845237036e-06,
      "loss": 0.0,
      "step": 5091
    },
    {
      "epoch": 8.760430107526881,
      "grad_norm": 2.10512655854887e-05,
      "learning_rate": 7.90540074896492e-06,
      "loss": 0.0,
      "step": 5092
    },
    {
      "epoch": 8.762150537634408,
      "grad_norm": 2.1714909954199023e-05,
      "learning_rate": 7.883689277729722e-06,
      "loss": 0.0,
      "step": 5093
    },
    {
      "epoch": 8.763870967741935,
      "grad_norm": 0.10562333317367843,
      "learning_rate": 7.86200643827989e-06,
      "loss": 0.0001,
      "step": 5094
    },
    {
      "epoch": 8.765591397849462,
      "grad_norm": 0.0008401194524531017,
      "learning_rate": 7.840352237354875e-06,
      "loss": 0.0,
      "step": 5095
    },
    {
      "epoch": 8.76731182795699,
      "grad_norm": 0.0001777214314409404,
      "learning_rate": 7.81872668168533e-06,
      "loss": 0.0,
      "step": 5096
    },
    {
      "epoch": 8.769032258064517,
      "grad_norm": 0.0032382982980200276,
      "learning_rate": 7.797129777992952e-06,
      "loss": 0.0,
      "step": 5097
    },
    {
      "epoch": 8.770752688172044,
      "grad_norm": 0.00037674519575298516,
      "learning_rate": 7.775561532990516e-06,
      "loss": 0.0,
      "step": 5098
    },
    {
      "epoch": 8.77247311827957,
      "grad_norm": 3.1369930899075364e-05,
      "learning_rate": 7.754021953381908e-06,
      "loss": 0.0,
      "step": 5099
    },
    {
      "epoch": 8.774193548387096,
      "grad_norm": 0.00042344768998127847,
      "learning_rate": 7.732511045862122e-06,
      "loss": 0.0,
      "step": 5100
    },
    {
      "epoch": 8.775913978494623,
      "grad_norm": 0.0002564925019146525,
      "learning_rate": 7.711028817117205e-06,
      "loss": 0.0,
      "step": 5101
    },
    {
      "epoch": 8.77763440860215,
      "grad_norm": 0.00213278247116812,
      "learning_rate": 7.689575273824346e-06,
      "loss": 0.0,
      "step": 5102
    },
    {
      "epoch": 8.779354838709677,
      "grad_norm": 0.009544840489303088,
      "learning_rate": 7.668150422651743e-06,
      "loss": 0.0,
      "step": 5103
    },
    {
      "epoch": 8.781075268817204,
      "grad_norm": 0.0004970506564350812,
      "learning_rate": 7.646754270258705e-06,
      "loss": 0.0,
      "step": 5104
    },
    {
      "epoch": 8.782795698924732,
      "grad_norm": 0.0032853407069562014,
      "learning_rate": 7.625386823295644e-06,
      "loss": 0.0,
      "step": 5105
    },
    {
      "epoch": 8.784516129032259,
      "grad_norm": 1.691669334074718e-05,
      "learning_rate": 7.604048088404059e-06,
      "loss": 0.0,
      "step": 5106
    },
    {
      "epoch": 8.786236559139786,
      "grad_norm": 8.001679787648025e-05,
      "learning_rate": 7.582738072216466e-06,
      "loss": 0.0,
      "step": 5107
    },
    {
      "epoch": 8.787956989247311,
      "grad_norm": 4.505328097241844e-05,
      "learning_rate": 7.561456781356524e-06,
      "loss": 0.0,
      "step": 5108
    },
    {
      "epoch": 8.789677419354838,
      "grad_norm": 0.0558286620181359,
      "learning_rate": 7.540204222438896e-06,
      "loss": 0.0001,
      "step": 5109
    },
    {
      "epoch": 8.791397849462365,
      "grad_norm": 0.08673871486730722,
      "learning_rate": 7.5189804020693536e-06,
      "loss": 0.0001,
      "step": 5110
    },
    {
      "epoch": 8.793118279569892,
      "grad_norm": 0.0002982236579080634,
      "learning_rate": 7.497785326844742e-06,
      "loss": 0.0,
      "step": 5111
    },
    {
      "epoch": 8.79483870967742,
      "grad_norm": 0.009560245791699435,
      "learning_rate": 7.476619003352936e-06,
      "loss": 0.0,
      "step": 5112
    },
    {
      "epoch": 8.796559139784947,
      "grad_norm": 0.00027938100373016704,
      "learning_rate": 7.45548143817294e-06,
      "loss": 0.0,
      "step": 5113
    },
    {
      "epoch": 8.798279569892474,
      "grad_norm": 0.00045233312743600003,
      "learning_rate": 7.43437263787472e-06,
      "loss": 0.0,
      "step": 5114
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.0031244869360138746,
      "learning_rate": 7.413292609019385e-06,
      "loss": 0.0,
      "step": 5115
    },
    {
      "epoch": 8.801720430107526,
      "grad_norm": 0.00020390814906983025,
      "learning_rate": 7.392241358159091e-06,
      "loss": 0.0,
      "step": 5116
    },
    {
      "epoch": 8.803440860215053,
      "grad_norm": 0.00015316733843814882,
      "learning_rate": 7.3712188918370285e-06,
      "loss": 0.0,
      "step": 5117
    },
    {
      "epoch": 8.80516129032258,
      "grad_norm": 0.0008534481370330874,
      "learning_rate": 7.350225216587403e-06,
      "loss": 0.0,
      "step": 5118
    },
    {
      "epoch": 8.806881720430107,
      "grad_norm": 0.002463386831507328,
      "learning_rate": 7.329260338935562e-06,
      "loss": 0.0,
      "step": 5119
    },
    {
      "epoch": 8.808602150537634,
      "grad_norm": 0.000350980477436804,
      "learning_rate": 7.308324265397836e-06,
      "loss": 0.0,
      "step": 5120
    },
    {
      "epoch": 8.810322580645161,
      "grad_norm": 4.6910854886746615e-05,
      "learning_rate": 7.2874170024816004e-06,
      "loss": 0.0,
      "step": 5121
    },
    {
      "epoch": 8.812043010752689,
      "grad_norm": 0.00030154643490246,
      "learning_rate": 7.26653855668532e-06,
      "loss": 0.0,
      "step": 5122
    },
    {
      "epoch": 8.813763440860216,
      "grad_norm": 1.240745296683418e-05,
      "learning_rate": 7.245688934498463e-06,
      "loss": 0.0,
      "step": 5123
    },
    {
      "epoch": 8.815483870967743,
      "grad_norm": 0.00044893259449925855,
      "learning_rate": 7.224868142401542e-06,
      "loss": 0.0,
      "step": 5124
    },
    {
      "epoch": 8.817204301075268,
      "grad_norm": 0.00303198583467295,
      "learning_rate": 7.20407618686616e-06,
      "loss": 0.0,
      "step": 5125
    },
    {
      "epoch": 8.818924731182795,
      "grad_norm": 0.00022531633161373106,
      "learning_rate": 7.183313074354892e-06,
      "loss": 0.0,
      "step": 5126
    },
    {
      "epoch": 8.820645161290322,
      "grad_norm": 0.0004098705998605726,
      "learning_rate": 7.162578811321352e-06,
      "loss": 0.0,
      "step": 5127
    },
    {
      "epoch": 8.82236559139785,
      "grad_norm": 0.0016890142613513249,
      "learning_rate": 7.141873404210253e-06,
      "loss": 0.0,
      "step": 5128
    },
    {
      "epoch": 8.824086021505376,
      "grad_norm": 0.00014171649270970212,
      "learning_rate": 7.121196859457235e-06,
      "loss": 0.0,
      "step": 5129
    },
    {
      "epoch": 8.825806451612904,
      "grad_norm": 0.0013901417027059547,
      "learning_rate": 7.1005491834890805e-06,
      "loss": 0.0,
      "step": 5130
    },
    {
      "epoch": 8.82752688172043,
      "grad_norm": 0.008687483245574515,
      "learning_rate": 7.079930382723521e-06,
      "loss": 0.0,
      "step": 5131
    },
    {
      "epoch": 8.829247311827958,
      "grad_norm": 0.00013503760154973243,
      "learning_rate": 7.059340463569308e-06,
      "loss": 0.0,
      "step": 5132
    },
    {
      "epoch": 8.830967741935483,
      "grad_norm": 0.0005064039900801304,
      "learning_rate": 7.03877943242629e-06,
      "loss": 0.0,
      "step": 5133
    },
    {
      "epoch": 8.83268817204301,
      "grad_norm": 8.435146557006024e-05,
      "learning_rate": 7.018247295685276e-06,
      "loss": 0.0,
      "step": 5134
    },
    {
      "epoch": 8.834408602150537,
      "grad_norm": 0.001322381720253582,
      "learning_rate": 6.997744059728084e-06,
      "loss": 0.0,
      "step": 5135
    },
    {
      "epoch": 8.836129032258064,
      "grad_norm": 0.0009862031765475422,
      "learning_rate": 6.977269730927616e-06,
      "loss": 0.0,
      "step": 5136
    },
    {
      "epoch": 8.837849462365591,
      "grad_norm": 0.0006382478344467388,
      "learning_rate": 6.9568243156477145e-06,
      "loss": 0.0,
      "step": 5137
    },
    {
      "epoch": 8.839569892473119,
      "grad_norm": 0.000182158224773573,
      "learning_rate": 6.936407820243251e-06,
      "loss": 0.0,
      "step": 5138
    },
    {
      "epoch": 8.841290322580646,
      "grad_norm": 0.001768298786558275,
      "learning_rate": 6.9160202510601624e-06,
      "loss": 0.0,
      "step": 5139
    },
    {
      "epoch": 8.843010752688173,
      "grad_norm": 0.017704286859680365,
      "learning_rate": 6.895661614435322e-06,
      "loss": 0.0,
      "step": 5140
    },
    {
      "epoch": 8.844731182795698,
      "grad_norm": 0.002953809488529537,
      "learning_rate": 6.87533191669667e-06,
      "loss": 0.0,
      "step": 5141
    },
    {
      "epoch": 8.846451612903225,
      "grad_norm": 0.0008872769461480789,
      "learning_rate": 6.855031164163117e-06,
      "loss": 0.0,
      "step": 5142
    },
    {
      "epoch": 8.848172043010752,
      "grad_norm": 0.0008480566251662572,
      "learning_rate": 6.834759363144594e-06,
      "loss": 0.0,
      "step": 5143
    },
    {
      "epoch": 8.84989247311828,
      "grad_norm": 3.556697235946265e-05,
      "learning_rate": 6.814516519942005e-06,
      "loss": 0.0,
      "step": 5144
    },
    {
      "epoch": 8.851612903225806,
      "grad_norm": 0.00019626948023282651,
      "learning_rate": 6.794302640847294e-06,
      "loss": 0.0,
      "step": 5145
    },
    {
      "epoch": 8.853333333333333,
      "grad_norm": 0.00012555774605171765,
      "learning_rate": 6.774117732143359e-06,
      "loss": 0.0,
      "step": 5146
    },
    {
      "epoch": 8.85505376344086,
      "grad_norm": 0.0004020159749127913,
      "learning_rate": 6.753961800104136e-06,
      "loss": 0.0,
      "step": 5147
    },
    {
      "epoch": 8.856774193548388,
      "grad_norm": 9.902802118634786e-05,
      "learning_rate": 6.733834850994536e-06,
      "loss": 0.0,
      "step": 5148
    },
    {
      "epoch": 8.858494623655915,
      "grad_norm": 0.0005054792999004696,
      "learning_rate": 6.713736891070421e-06,
      "loss": 0.0,
      "step": 5149
    },
    {
      "epoch": 8.86021505376344,
      "grad_norm": 2.4942731744139473e-05,
      "learning_rate": 6.693667926578717e-06,
      "loss": 0.0,
      "step": 5150
    },
    {
      "epoch": 8.861935483870967,
      "grad_norm": 0.0062960307759730464,
      "learning_rate": 6.673627963757312e-06,
      "loss": 0.0,
      "step": 5151
    },
    {
      "epoch": 8.863655913978494,
      "grad_norm": 0.002091773831306037,
      "learning_rate": 6.653617008835034e-06,
      "loss": 0.0,
      "step": 5152
    },
    {
      "epoch": 8.865376344086021,
      "grad_norm": 0.00045005123901018483,
      "learning_rate": 6.633635068031763e-06,
      "loss": 0.0,
      "step": 5153
    },
    {
      "epoch": 8.867096774193548,
      "grad_norm": 0.0004873857498333775,
      "learning_rate": 6.61368214755832e-06,
      "loss": 0.0,
      "step": 5154
    },
    {
      "epoch": 8.868817204301076,
      "grad_norm": 7.626684803388135e-05,
      "learning_rate": 6.593758253616489e-06,
      "loss": 0.0,
      "step": 5155
    },
    {
      "epoch": 8.870537634408603,
      "grad_norm": 2.9057843856231623e-05,
      "learning_rate": 6.573863392399082e-06,
      "loss": 0.0,
      "step": 5156
    },
    {
      "epoch": 8.87225806451613,
      "grad_norm": 2.1732463682265887e-05,
      "learning_rate": 6.553997570089843e-06,
      "loss": 0.0,
      "step": 5157
    },
    {
      "epoch": 8.873978494623657,
      "grad_norm": 0.0013685622150769348,
      "learning_rate": 6.534160792863531e-06,
      "loss": 0.0,
      "step": 5158
    },
    {
      "epoch": 8.875698924731182,
      "grad_norm": 0.00042600393496615283,
      "learning_rate": 6.514353066885837e-06,
      "loss": 0.0,
      "step": 5159
    },
    {
      "epoch": 8.87741935483871,
      "grad_norm": 0.004095636084609173,
      "learning_rate": 6.494574398313457e-06,
      "loss": 0.0,
      "step": 5160
    },
    {
      "epoch": 8.879139784946236,
      "grad_norm": 0.015984458304954513,
      "learning_rate": 6.47482479329401e-06,
      "loss": 0.0,
      "step": 5161
    },
    {
      "epoch": 8.880860215053763,
      "grad_norm": 0.00039910588198130496,
      "learning_rate": 6.455104257966138e-06,
      "loss": 0.0,
      "step": 5162
    },
    {
      "epoch": 8.88258064516129,
      "grad_norm": 0.0005866255882613631,
      "learning_rate": 6.4354127984594056e-06,
      "loss": 0.0,
      "step": 5163
    },
    {
      "epoch": 8.884301075268818,
      "grad_norm": 0.12901803600482553,
      "learning_rate": 6.415750420894362e-06,
      "loss": 0.0003,
      "step": 5164
    },
    {
      "epoch": 8.886021505376345,
      "grad_norm": 4.705676465990429e-05,
      "learning_rate": 6.3961171313825066e-06,
      "loss": 0.0,
      "step": 5165
    },
    {
      "epoch": 8.88774193548387,
      "grad_norm": 0.001043772362615174,
      "learning_rate": 6.37651293602628e-06,
      "loss": 0.0,
      "step": 5166
    },
    {
      "epoch": 8.889462365591397,
      "grad_norm": 0.007955591998320237,
      "learning_rate": 6.356937840919142e-06,
      "loss": 0.0,
      "step": 5167
    },
    {
      "epoch": 8.891182795698924,
      "grad_norm": 2.2243371229237282e-05,
      "learning_rate": 6.337391852145414e-06,
      "loss": 0.0,
      "step": 5168
    },
    {
      "epoch": 8.892903225806451,
      "grad_norm": 0.0003575383374273463,
      "learning_rate": 6.3178749757804355e-06,
      "loss": 0.0,
      "step": 5169
    },
    {
      "epoch": 8.894623655913978,
      "grad_norm": 0.021009234387746805,
      "learning_rate": 6.298387217890522e-06,
      "loss": 0.0,
      "step": 5170
    },
    {
      "epoch": 8.896344086021506,
      "grad_norm": 0.0005532604841013018,
      "learning_rate": 6.278928584532872e-06,
      "loss": 0.0,
      "step": 5171
    },
    {
      "epoch": 8.898064516129033,
      "grad_norm": 0.00033396664095170897,
      "learning_rate": 6.2594990817556376e-06,
      "loss": 0.0,
      "step": 5172
    },
    {
      "epoch": 8.89978494623656,
      "grad_norm": 2.6930458582228334e-05,
      "learning_rate": 6.240098715597975e-06,
      "loss": 0.0,
      "step": 5173
    },
    {
      "epoch": 8.901505376344087,
      "grad_norm": 0.000332412174331413,
      "learning_rate": 6.220727492089917e-06,
      "loss": 0.0,
      "step": 5174
    },
    {
      "epoch": 8.903225806451612,
      "grad_norm": 0.00019195208794341214,
      "learning_rate": 6.2013854172524924e-06,
      "loss": 0.0,
      "step": 5175
    },
    {
      "epoch": 8.90494623655914,
      "grad_norm": 0.003435324153101001,
      "learning_rate": 6.182072497097635e-06,
      "loss": 0.0,
      "step": 5176
    },
    {
      "epoch": 8.906666666666666,
      "grad_norm": 0.0009119228197680191,
      "learning_rate": 6.162788737628211e-06,
      "loss": 0.0,
      "step": 5177
    },
    {
      "epoch": 8.908387096774193,
      "grad_norm": 4.077947906338432e-05,
      "learning_rate": 6.1435341448380475e-06,
      "loss": 0.0,
      "step": 5178
    },
    {
      "epoch": 8.91010752688172,
      "grad_norm": 0.0024027925187438616,
      "learning_rate": 6.124308724711924e-06,
      "loss": 0.0,
      "step": 5179
    },
    {
      "epoch": 8.911827956989248,
      "grad_norm": 6.937102787502729e-05,
      "learning_rate": 6.1051124832254944e-06,
      "loss": 0.0,
      "step": 5180
    },
    {
      "epoch": 8.913548387096775,
      "grad_norm": 0.0002273051375371496,
      "learning_rate": 6.085945426345407e-06,
      "loss": 0.0,
      "step": 5181
    },
    {
      "epoch": 8.915268817204302,
      "grad_norm": 0.00152261376282861,
      "learning_rate": 6.066807560029175e-06,
      "loss": 0.0,
      "step": 5182
    },
    {
      "epoch": 8.916989247311829,
      "grad_norm": 0.0001243455806056121,
      "learning_rate": 6.047698890225273e-06,
      "loss": 0.0,
      "step": 5183
    },
    {
      "epoch": 8.918709677419354,
      "grad_norm": 0.000543950191488852,
      "learning_rate": 6.028619422873116e-06,
      "loss": 0.0,
      "step": 5184
    },
    {
      "epoch": 8.920430107526881,
      "grad_norm": 0.00042901606925563226,
      "learning_rate": 6.009569163903017e-06,
      "loss": 0.0,
      "step": 5185
    },
    {
      "epoch": 8.922150537634408,
      "grad_norm": 0.0010049319871357533,
      "learning_rate": 5.9905481192361835e-06,
      "loss": 0.0,
      "step": 5186
    },
    {
      "epoch": 8.923870967741935,
      "grad_norm": 0.004716078192413423,
      "learning_rate": 5.971556294784841e-06,
      "loss": 0.0,
      "step": 5187
    },
    {
      "epoch": 8.925591397849463,
      "grad_norm": 0.012726879906495334,
      "learning_rate": 5.952593696452036e-06,
      "loss": 0.0,
      "step": 5188
    },
    {
      "epoch": 8.92731182795699,
      "grad_norm": 0.07439208678405751,
      "learning_rate": 5.933660330131752e-06,
      "loss": 0.0,
      "step": 5189
    },
    {
      "epoch": 8.929032258064517,
      "grad_norm": 0.00015409528858937902,
      "learning_rate": 5.914756201708915e-06,
      "loss": 0.0,
      "step": 5190
    },
    {
      "epoch": 8.930752688172044,
      "grad_norm": 0.0024169281264862707,
      "learning_rate": 5.895881317059327e-06,
      "loss": 0.0,
      "step": 5191
    },
    {
      "epoch": 8.93247311827957,
      "grad_norm": 0.0016749514286145996,
      "learning_rate": 5.877035682049747e-06,
      "loss": 0.0,
      "step": 5192
    },
    {
      "epoch": 8.934193548387096,
      "grad_norm": 0.0003449447335985232,
      "learning_rate": 5.858219302537793e-06,
      "loss": 0.0,
      "step": 5193
    },
    {
      "epoch": 8.935913978494623,
      "grad_norm": 0.0007466112814227716,
      "learning_rate": 5.839432184372018e-06,
      "loss": 0.0,
      "step": 5194
    },
    {
      "epoch": 8.93763440860215,
      "grad_norm": 7.330201824007123e-05,
      "learning_rate": 5.820674333391862e-06,
      "loss": 0.0,
      "step": 5195
    },
    {
      "epoch": 8.939354838709678,
      "grad_norm": 0.00029909724737467333,
      "learning_rate": 5.801945755427707e-06,
      "loss": 0.0,
      "step": 5196
    },
    {
      "epoch": 8.941075268817205,
      "grad_norm": 0.0015576691179250142,
      "learning_rate": 5.783246456300784e-06,
      "loss": 0.0,
      "step": 5197
    },
    {
      "epoch": 8.942795698924732,
      "grad_norm": 0.00030650502856719683,
      "learning_rate": 5.764576441823266e-06,
      "loss": 0.0,
      "step": 5198
    },
    {
      "epoch": 8.944516129032259,
      "grad_norm": 0.002204114526477576,
      "learning_rate": 5.745935717798212e-06,
      "loss": 0.0,
      "step": 5199
    },
    {
      "epoch": 8.946236559139784,
      "grad_norm": 5.2184248047241696e-05,
      "learning_rate": 5.727324290019531e-06,
      "loss": 0.0,
      "step": 5200
    },
    {
      "epoch": 8.947956989247311,
      "grad_norm": 0.019492945229047064,
      "learning_rate": 5.708742164272107e-06,
      "loss": 0.0001,
      "step": 5201
    },
    {
      "epoch": 8.949677419354838,
      "grad_norm": 0.0008454163771391206,
      "learning_rate": 5.6901893463316645e-06,
      "loss": 0.0,
      "step": 5202
    },
    {
      "epoch": 8.951397849462365,
      "grad_norm": 0.0006196630250733709,
      "learning_rate": 5.671665841964801e-06,
      "loss": 0.0,
      "step": 5203
    },
    {
      "epoch": 8.953118279569892,
      "grad_norm": 0.0006712176544123003,
      "learning_rate": 5.653171656929068e-06,
      "loss": 0.0,
      "step": 5204
    },
    {
      "epoch": 8.95483870967742,
      "grad_norm": 0.0062856608493324214,
      "learning_rate": 5.634706796972867e-06,
      "loss": 0.0,
      "step": 5205
    },
    {
      "epoch": 8.956559139784947,
      "grad_norm": 0.0007938940039538874,
      "learning_rate": 5.616271267835449e-06,
      "loss": 0.0,
      "step": 5206
    },
    {
      "epoch": 8.958279569892474,
      "grad_norm": 0.0001786947005256921,
      "learning_rate": 5.597865075247033e-06,
      "loss": 0.0,
      "step": 5207
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.016663596391542735,
      "learning_rate": 5.579488224928619e-06,
      "loss": 0.0,
      "step": 5208
    },
    {
      "epoch": 8.961720430107526,
      "grad_norm": 4.952340405655344e-05,
      "learning_rate": 5.561140722592184e-06,
      "loss": 0.0,
      "step": 5209
    },
    {
      "epoch": 8.963440860215053,
      "grad_norm": 0.0005181044481094062,
      "learning_rate": 5.54282257394052e-06,
      "loss": 0.0,
      "step": 5210
    },
    {
      "epoch": 8.96516129032258,
      "grad_norm": 0.00010923023417949227,
      "learning_rate": 5.524533784667285e-06,
      "loss": 0.0,
      "step": 5211
    },
    {
      "epoch": 8.966881720430107,
      "grad_norm": 8.534405576909414e-05,
      "learning_rate": 5.506274360457086e-06,
      "loss": 0.0,
      "step": 5212
    },
    {
      "epoch": 8.968602150537635,
      "grad_norm": 0.0029758442577457827,
      "learning_rate": 5.488044306985318e-06,
      "loss": 0.0,
      "step": 5213
    },
    {
      "epoch": 8.970322580645162,
      "grad_norm": 0.00018683282124035036,
      "learning_rate": 5.469843629918292e-06,
      "loss": 0.0,
      "step": 5214
    },
    {
      "epoch": 8.972043010752689,
      "grad_norm": 0.0027961130598470807,
      "learning_rate": 5.451672334913216e-06,
      "loss": 0.0,
      "step": 5215
    },
    {
      "epoch": 8.973763440860216,
      "grad_norm": 0.002761518316109107,
      "learning_rate": 5.4335304276180944e-06,
      "loss": 0.0,
      "step": 5216
    },
    {
      "epoch": 8.975483870967741,
      "grad_norm": 0.003322860154707139,
      "learning_rate": 5.4154179136718275e-06,
      "loss": 0.0,
      "step": 5217
    },
    {
      "epoch": 8.977204301075268,
      "grad_norm": 5.4891900791985186e-05,
      "learning_rate": 5.397334798704212e-06,
      "loss": 0.0,
      "step": 5218
    },
    {
      "epoch": 8.978924731182795,
      "grad_norm": 2.161627728863032e-05,
      "learning_rate": 5.379281088335852e-06,
      "loss": 0.0,
      "step": 5219
    },
    {
      "epoch": 8.980645161290322,
      "grad_norm": 0.0001436129281363504,
      "learning_rate": 5.361256788178259e-06,
      "loss": 0.0,
      "step": 5220
    },
    {
      "epoch": 8.98236559139785,
      "grad_norm": 0.001001036172079279,
      "learning_rate": 5.343261903833796e-06,
      "loss": 0.0,
      "step": 5221
    },
    {
      "epoch": 8.984086021505377,
      "grad_norm": 0.002407854975662358,
      "learning_rate": 5.325296440895622e-06,
      "loss": 0.0,
      "step": 5222
    },
    {
      "epoch": 8.985806451612904,
      "grad_norm": 0.00021906588118386443,
      "learning_rate": 5.307360404947848e-06,
      "loss": 0.0,
      "step": 5223
    },
    {
      "epoch": 8.98752688172043,
      "grad_norm": 0.0007651474188755735,
      "learning_rate": 5.2894538015653805e-06,
      "loss": 0.0,
      "step": 5224
    },
    {
      "epoch": 8.989247311827956,
      "grad_norm": 0.032375735270141634,
      "learning_rate": 5.271576636313969e-06,
      "loss": 0.0,
      "step": 5225
    },
    {
      "epoch": 8.990967741935483,
      "grad_norm": 4.7159886561342575e-05,
      "learning_rate": 5.253728914750244e-06,
      "loss": 0.0,
      "step": 5226
    },
    {
      "epoch": 8.99268817204301,
      "grad_norm": 0.4941654315549094,
      "learning_rate": 5.235910642421682e-06,
      "loss": 0.0006,
      "step": 5227
    },
    {
      "epoch": 8.994408602150537,
      "grad_norm": 0.00012983392520867222,
      "learning_rate": 5.218121824866573e-06,
      "loss": 0.0,
      "step": 5228
    },
    {
      "epoch": 8.996129032258064,
      "grad_norm": 0.0023720982190442753,
      "learning_rate": 5.200362467614106e-06,
      "loss": 0.0,
      "step": 5229
    },
    {
      "epoch": 8.997849462365592,
      "grad_norm": 0.003710100385303531,
      "learning_rate": 5.182632576184254e-06,
      "loss": 0.0,
      "step": 5230
    },
    {
      "epoch": 8.999569892473119,
      "grad_norm": 0.0020574050436131196,
      "learning_rate": 5.164932156087843e-06,
      "loss": 0.0,
      "step": 5231
    },
    {
      "epoch": 9.001290322580646,
      "grad_norm": 2.7015490644017302e-05,
      "learning_rate": 5.147261212826604e-06,
      "loss": 0.0,
      "step": 5232
    },
    {
      "epoch": 9.003010752688173,
      "grad_norm": 0.0029004500032538826,
      "learning_rate": 5.129619751893033e-06,
      "loss": 0.0,
      "step": 5233
    },
    {
      "epoch": 9.004731182795698,
      "grad_norm": 0.0003541325718698817,
      "learning_rate": 5.112007778770467e-06,
      "loss": 0.0,
      "step": 5234
    },
    {
      "epoch": 9.006451612903225,
      "grad_norm": 4.217760309280284e-05,
      "learning_rate": 5.094425298933136e-06,
      "loss": 0.0,
      "step": 5235
    },
    {
      "epoch": 9.008172043010752,
      "grad_norm": 0.0011611246967559352,
      "learning_rate": 5.0768723178460266e-06,
      "loss": 0.0,
      "step": 5236
    },
    {
      "epoch": 9.00989247311828,
      "grad_norm": 1.7967215674640964e-05,
      "learning_rate": 5.059348840965028e-06,
      "loss": 0.0,
      "step": 5237
    },
    {
      "epoch": 9.011612903225807,
      "grad_norm": 0.001507252240820832,
      "learning_rate": 5.041854873736795e-06,
      "loss": 0.0,
      "step": 5238
    },
    {
      "epoch": 9.013333333333334,
      "grad_norm": 3.310922949871412e-05,
      "learning_rate": 5.024390421598835e-06,
      "loss": 0.0,
      "step": 5239
    },
    {
      "epoch": 9.01505376344086,
      "grad_norm": 5.9916661701859694e-05,
      "learning_rate": 5.006955489979503e-06,
      "loss": 0.0,
      "step": 5240
    },
    {
      "epoch": 9.016774193548388,
      "grad_norm": 0.00042453185017657824,
      "learning_rate": 4.989550084297978e-06,
      "loss": 0.0,
      "step": 5241
    },
    {
      "epoch": 9.018494623655913,
      "grad_norm": 0.001706179950609439,
      "learning_rate": 4.9721742099642085e-06,
      "loss": 0.0,
      "step": 5242
    },
    {
      "epoch": 9.02021505376344,
      "grad_norm": 0.00015653295754276844,
      "learning_rate": 4.954827872379031e-06,
      "loss": 0.0,
      "step": 5243
    },
    {
      "epoch": 9.021935483870967,
      "grad_norm": 0.00011047540515738585,
      "learning_rate": 4.937511076934042e-06,
      "loss": 0.0,
      "step": 5244
    },
    {
      "epoch": 9.023655913978494,
      "grad_norm": 0.0002473692725755659,
      "learning_rate": 4.920223829011705e-06,
      "loss": 0.0,
      "step": 5245
    },
    {
      "epoch": 9.025376344086022,
      "grad_norm": 0.0009496684348658576,
      "learning_rate": 4.9029661339852765e-06,
      "loss": 0.0,
      "step": 5246
    },
    {
      "epoch": 9.027096774193549,
      "grad_norm": 0.0007761664568809366,
      "learning_rate": 4.88573799721882e-06,
      "loss": 0.0,
      "step": 5247
    },
    {
      "epoch": 9.028817204301076,
      "grad_norm": 0.00011364626072324665,
      "learning_rate": 4.86853942406722e-06,
      "loss": 0.0,
      "step": 5248
    },
    {
      "epoch": 9.030537634408603,
      "grad_norm": 0.0002483341156207793,
      "learning_rate": 4.851370419876178e-06,
      "loss": 0.0,
      "step": 5249
    },
    {
      "epoch": 9.03225806451613,
      "grad_norm": 9.539366338811657e-05,
      "learning_rate": 4.834230989982213e-06,
      "loss": 0.0,
      "step": 5250
    },
    {
      "epoch": 9.033978494623655,
      "grad_norm": 7.380302324034214e-06,
      "learning_rate": 4.81712113971261e-06,
      "loss": 0.0,
      "step": 5251
    },
    {
      "epoch": 9.035698924731182,
      "grad_norm": 0.0003016664359723913,
      "learning_rate": 4.800040874385525e-06,
      "loss": 0.0,
      "step": 5252
    },
    {
      "epoch": 9.03741935483871,
      "grad_norm": 0.0010122741176708965,
      "learning_rate": 4.782990199309856e-06,
      "loss": 0.0,
      "step": 5253
    },
    {
      "epoch": 9.039139784946236,
      "grad_norm": 0.0020466423212409405,
      "learning_rate": 4.765969119785341e-06,
      "loss": 0.0,
      "step": 5254
    },
    {
      "epoch": 9.040860215053764,
      "grad_norm": 0.000578146715170977,
      "learning_rate": 4.748977641102503e-06,
      "loss": 0.0,
      "step": 5255
    },
    {
      "epoch": 9.04258064516129,
      "grad_norm": 8.551603975963085e-05,
      "learning_rate": 4.732015768542653e-06,
      "loss": 0.0,
      "step": 5256
    },
    {
      "epoch": 9.044301075268818,
      "grad_norm": 0.002283689723915097,
      "learning_rate": 4.715083507377949e-06,
      "loss": 0.0,
      "step": 5257
    },
    {
      "epoch": 9.046021505376345,
      "grad_norm": 0.011142763428930846,
      "learning_rate": 4.698180862871282e-06,
      "loss": 0.0,
      "step": 5258
    },
    {
      "epoch": 9.04774193548387,
      "grad_norm": 0.000230769057395747,
      "learning_rate": 4.6813078402763835e-06,
      "loss": 0.0,
      "step": 5259
    },
    {
      "epoch": 9.049462365591397,
      "grad_norm": 0.005227016349055898,
      "learning_rate": 4.664464444837768e-06,
      "loss": 0.0,
      "step": 5260
    },
    {
      "epoch": 9.051182795698924,
      "grad_norm": 0.000211599087471267,
      "learning_rate": 4.647650681790727e-06,
      "loss": 0.0,
      "step": 5261
    },
    {
      "epoch": 9.052903225806451,
      "grad_norm": 2.32843929236989e-05,
      "learning_rate": 4.630866556361335e-06,
      "loss": 0.0,
      "step": 5262
    },
    {
      "epoch": 9.054623655913979,
      "grad_norm": 0.00024012334714211154,
      "learning_rate": 4.614112073766497e-06,
      "loss": 0.0,
      "step": 5263
    },
    {
      "epoch": 9.056344086021506,
      "grad_norm": 9.948273946157603e-05,
      "learning_rate": 4.597387239213868e-06,
      "loss": 0.0,
      "step": 5264
    },
    {
      "epoch": 9.058064516129033,
      "grad_norm": 0.00042395982039817866,
      "learning_rate": 4.580692057901869e-06,
      "loss": 0.0,
      "step": 5265
    },
    {
      "epoch": 9.05978494623656,
      "grad_norm": 0.018925543275461254,
      "learning_rate": 4.564026535019772e-06,
      "loss": 0.0,
      "step": 5266
    },
    {
      "epoch": 9.061505376344085,
      "grad_norm": 2.8620018396391632e-05,
      "learning_rate": 4.547390675747554e-06,
      "loss": 0.0,
      "step": 5267
    },
    {
      "epoch": 9.063225806451612,
      "grad_norm": 0.0002997996324764313,
      "learning_rate": 4.530784485256024e-06,
      "loss": 0.0,
      "step": 5268
    },
    {
      "epoch": 9.06494623655914,
      "grad_norm": 0.00010721744763056036,
      "learning_rate": 4.514207968706774e-06,
      "loss": 0.0,
      "step": 5269
    },
    {
      "epoch": 9.066666666666666,
      "grad_norm": 4.847026357817799e-05,
      "learning_rate": 4.4976611312521065e-06,
      "loss": 0.0,
      "step": 5270
    },
    {
      "epoch": 9.068387096774194,
      "grad_norm": 4.611756188086759e-05,
      "learning_rate": 4.481143978035196e-06,
      "loss": 0.0,
      "step": 5271
    },
    {
      "epoch": 9.07010752688172,
      "grad_norm": 0.00036177573905635827,
      "learning_rate": 4.4646565141899025e-06,
      "loss": 0.0,
      "step": 5272
    },
    {
      "epoch": 9.071827956989248,
      "grad_norm": 0.0011838216953917265,
      "learning_rate": 4.4481987448408925e-06,
      "loss": 0.0,
      "step": 5273
    },
    {
      "epoch": 9.073548387096775,
      "grad_norm": 0.0010920867686866744,
      "learning_rate": 4.43177067510363e-06,
      "loss": 0.0,
      "step": 5274
    },
    {
      "epoch": 9.075268817204302,
      "grad_norm": 0.002113367123302093,
      "learning_rate": 4.415372310084309e-06,
      "loss": 0.0,
      "step": 5275
    },
    {
      "epoch": 9.076989247311827,
      "grad_norm": 0.0018151151959099811,
      "learning_rate": 4.399003654879874e-06,
      "loss": 0.0,
      "step": 5276
    },
    {
      "epoch": 9.078709677419354,
      "grad_norm": 0.00033432652664703704,
      "learning_rate": 4.382664714578111e-06,
      "loss": 0.0,
      "step": 5277
    },
    {
      "epoch": 9.080430107526881,
      "grad_norm": 0.002899048510438784,
      "learning_rate": 4.366355494257523e-06,
      "loss": 0.0,
      "step": 5278
    },
    {
      "epoch": 9.082150537634408,
      "grad_norm": 2.1635319424531956e-05,
      "learning_rate": 4.350075998987335e-06,
      "loss": 0.0,
      "step": 5279
    },
    {
      "epoch": 9.083870967741936,
      "grad_norm": 0.00032437815766741315,
      "learning_rate": 4.333826233827609e-06,
      "loss": 0.0,
      "step": 5280
    },
    {
      "epoch": 9.085591397849463,
      "grad_norm": 1.711424258598394e-05,
      "learning_rate": 4.317606203829127e-06,
      "loss": 0.0,
      "step": 5281
    },
    {
      "epoch": 9.08731182795699,
      "grad_norm": 0.0006804715975555903,
      "learning_rate": 4.301415914033413e-06,
      "loss": 0.0,
      "step": 5282
    },
    {
      "epoch": 9.089032258064517,
      "grad_norm": 0.0004674905069507194,
      "learning_rate": 4.285255369472796e-06,
      "loss": 0.0,
      "step": 5283
    },
    {
      "epoch": 9.090752688172042,
      "grad_norm": 9.792781243782261e-05,
      "learning_rate": 4.269124575170291e-06,
      "loss": 0.0,
      "step": 5284
    },
    {
      "epoch": 9.09247311827957,
      "grad_norm": 0.0009078364074837839,
      "learning_rate": 4.253023536139733e-06,
      "loss": 0.0,
      "step": 5285
    },
    {
      "epoch": 9.094193548387096,
      "grad_norm": 0.0020942648127622566,
      "learning_rate": 4.236952257385696e-06,
      "loss": 0.0,
      "step": 5286
    },
    {
      "epoch": 9.095913978494623,
      "grad_norm": 0.00018201239993032684,
      "learning_rate": 4.22091074390345e-06,
      "loss": 0.0,
      "step": 5287
    },
    {
      "epoch": 9.09763440860215,
      "grad_norm": 0.0009183666277385117,
      "learning_rate": 4.204899000679086e-06,
      "loss": 0.0,
      "step": 5288
    },
    {
      "epoch": 9.099354838709678,
      "grad_norm": 9.316977431089138e-05,
      "learning_rate": 4.188917032689399e-06,
      "loss": 0.0,
      "step": 5289
    },
    {
      "epoch": 9.101075268817205,
      "grad_norm": 0.00016461468657524318,
      "learning_rate": 4.172964844901917e-06,
      "loss": 0.0,
      "step": 5290
    },
    {
      "epoch": 9.102795698924732,
      "grad_norm": 0.00019048566650566381,
      "learning_rate": 4.15704244227495e-06,
      "loss": 0.0,
      "step": 5291
    },
    {
      "epoch": 9.104516129032259,
      "grad_norm": 1.0650961727292723e-05,
      "learning_rate": 4.14114982975754e-06,
      "loss": 0.0,
      "step": 5292
    },
    {
      "epoch": 9.106236559139784,
      "grad_norm": 0.0024307926882064573,
      "learning_rate": 4.125287012289436e-06,
      "loss": 0.0,
      "step": 5293
    },
    {
      "epoch": 9.107956989247311,
      "grad_norm": 0.0020100777421355105,
      "learning_rate": 4.109453994801171e-06,
      "loss": 0.0,
      "step": 5294
    },
    {
      "epoch": 9.109677419354838,
      "grad_norm": 0.0002465647300667148,
      "learning_rate": 4.093650782213998e-06,
      "loss": 0.0,
      "step": 5295
    },
    {
      "epoch": 9.111397849462366,
      "grad_norm": 0.0008104957397133431,
      "learning_rate": 4.077877379439899e-06,
      "loss": 0.0,
      "step": 5296
    },
    {
      "epoch": 9.113118279569893,
      "grad_norm": 9.938652816303098e-05,
      "learning_rate": 4.062133791381606e-06,
      "loss": 0.0,
      "step": 5297
    },
    {
      "epoch": 9.11483870967742,
      "grad_norm": 0.00011047316811097125,
      "learning_rate": 4.046420022932573e-06,
      "loss": 0.0,
      "step": 5298
    },
    {
      "epoch": 9.116559139784947,
      "grad_norm": 0.005050597620783388,
      "learning_rate": 4.03073607897696e-06,
      "loss": 0.0,
      "step": 5299
    },
    {
      "epoch": 9.118279569892474,
      "grad_norm": 0.0002992417949281919,
      "learning_rate": 4.015081964389722e-06,
      "loss": 0.0,
      "step": 5300
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.0001728274577356295,
      "learning_rate": 3.999457684036467e-06,
      "loss": 0.0,
      "step": 5301
    },
    {
      "epoch": 9.121720430107526,
      "grad_norm": 0.0009412832249094313,
      "learning_rate": 3.9838632427736e-06,
      "loss": 0.0,
      "step": 5302
    },
    {
      "epoch": 9.123440860215053,
      "grad_norm": 0.04150972085430673,
      "learning_rate": 3.968298645448188e-06,
      "loss": 0.0,
      "step": 5303
    },
    {
      "epoch": 9.12516129032258,
      "grad_norm": 0.00048489412542724317,
      "learning_rate": 3.952763896898071e-06,
      "loss": 0.0,
      "step": 5304
    },
    {
      "epoch": 9.126881720430108,
      "grad_norm": 0.00016430287836489776,
      "learning_rate": 3.9372590019517984e-06,
      "loss": 0.0,
      "step": 5305
    },
    {
      "epoch": 9.128602150537635,
      "grad_norm": 0.001419643145977645,
      "learning_rate": 3.921783965428627e-06,
      "loss": 0.0,
      "step": 5306
    },
    {
      "epoch": 9.130322580645162,
      "grad_norm": 0.0005882699654952599,
      "learning_rate": 3.90633879213852e-06,
      "loss": 0.0,
      "step": 5307
    },
    {
      "epoch": 9.132043010752689,
      "grad_norm": 1.7771569697960945e-05,
      "learning_rate": 3.890923486882203e-06,
      "loss": 0.0,
      "step": 5308
    },
    {
      "epoch": 9.133763440860214,
      "grad_norm": 3.1191094703466e-05,
      "learning_rate": 3.8755380544511e-06,
      "loss": 0.0,
      "step": 5309
    },
    {
      "epoch": 9.135483870967741,
      "grad_norm": 0.0023691516054348493,
      "learning_rate": 3.8601824996273076e-06,
      "loss": 0.0,
      "step": 5310
    },
    {
      "epoch": 9.137204301075268,
      "grad_norm": 0.0028035756080483803,
      "learning_rate": 3.8448568271837075e-06,
      "loss": 0.0,
      "step": 5311
    },
    {
      "epoch": 9.138924731182795,
      "grad_norm": 1.421617160692816e-05,
      "learning_rate": 3.829561041883833e-06,
      "loss": 0.0,
      "step": 5312
    },
    {
      "epoch": 9.140645161290323,
      "grad_norm": 0.0005856186031842817,
      "learning_rate": 3.814295148481961e-06,
      "loss": 0.0,
      "step": 5313
    },
    {
      "epoch": 9.14236559139785,
      "grad_norm": 0.0012252224646863465,
      "learning_rate": 3.799059151723083e-06,
      "loss": 0.0,
      "step": 5314
    },
    {
      "epoch": 9.144086021505377,
      "grad_norm": 0.0003662114480048941,
      "learning_rate": 3.783853056342879e-06,
      "loss": 0.0,
      "step": 5315
    },
    {
      "epoch": 9.145806451612904,
      "grad_norm": 0.0016028528246388872,
      "learning_rate": 3.768676867067711e-06,
      "loss": 0.0,
      "step": 5316
    },
    {
      "epoch": 9.147526881720431,
      "grad_norm": 2.0658069079197198e-05,
      "learning_rate": 3.7535305886147064e-06,
      "loss": 0.0,
      "step": 5317
    },
    {
      "epoch": 9.149247311827956,
      "grad_norm": 0.0006611042165759112,
      "learning_rate": 3.7384142256916442e-06,
      "loss": 0.0,
      "step": 5318
    },
    {
      "epoch": 9.150967741935483,
      "grad_norm": 0.0005465670906547903,
      "learning_rate": 3.7233277829970325e-06,
      "loss": 0.0,
      "step": 5319
    },
    {
      "epoch": 9.15268817204301,
      "grad_norm": 0.0037852928298935467,
      "learning_rate": 3.7082712652200867e-06,
      "loss": 0.0,
      "step": 5320
    },
    {
      "epoch": 9.154408602150538,
      "grad_norm": 0.0013896125558733828,
      "learning_rate": 3.6932446770406527e-06,
      "loss": 0.0,
      "step": 5321
    },
    {
      "epoch": 9.156129032258065,
      "grad_norm": 0.001273879088264612,
      "learning_rate": 3.6782480231293936e-06,
      "loss": 0.0,
      "step": 5322
    },
    {
      "epoch": 9.157849462365592,
      "grad_norm": 0.00045164207905064584,
      "learning_rate": 3.663281308147559e-06,
      "loss": 0.0,
      "step": 5323
    },
    {
      "epoch": 9.159569892473119,
      "grad_norm": 0.0007728019756166049,
      "learning_rate": 3.648344536747139e-06,
      "loss": 0.0,
      "step": 5324
    },
    {
      "epoch": 9.161290322580646,
      "grad_norm": 0.0011026634537166932,
      "learning_rate": 3.633437713570831e-06,
      "loss": 0.0,
      "step": 5325
    },
    {
      "epoch": 9.163010752688171,
      "grad_norm": 0.0005808403918124037,
      "learning_rate": 3.6185608432519947e-06,
      "loss": 0.0,
      "step": 5326
    },
    {
      "epoch": 9.164731182795698,
      "grad_norm": 0.0003630940873362457,
      "learning_rate": 3.6037139304146762e-06,
      "loss": 0.0,
      "step": 5327
    },
    {
      "epoch": 9.166451612903225,
      "grad_norm": 0.00031774820702451507,
      "learning_rate": 3.588896979673639e-06,
      "loss": 0.0,
      "step": 5328
    },
    {
      "epoch": 9.168172043010753,
      "grad_norm": 9.508725116326773e-05,
      "learning_rate": 3.574109995634312e-06,
      "loss": 0.0,
      "step": 5329
    },
    {
      "epoch": 9.16989247311828,
      "grad_norm": 0.0006640081886858869,
      "learning_rate": 3.5593529828928274e-06,
      "loss": 0.0,
      "step": 5330
    },
    {
      "epoch": 9.171612903225807,
      "grad_norm": 0.00044895454956028416,
      "learning_rate": 3.5446259460359843e-06,
      "loss": 0.0,
      "step": 5331
    },
    {
      "epoch": 9.173333333333334,
      "grad_norm": 0.00037953134914610917,
      "learning_rate": 3.5299288896412763e-06,
      "loss": 0.0,
      "step": 5332
    },
    {
      "epoch": 9.17505376344086,
      "grad_norm": 0.002674318216454293,
      "learning_rate": 3.515261818276849e-06,
      "loss": 0.0,
      "step": 5333
    },
    {
      "epoch": 9.176774193548388,
      "grad_norm": 0.00046130349550785636,
      "learning_rate": 3.50062473650159e-06,
      "loss": 0.0,
      "step": 5334
    },
    {
      "epoch": 9.178494623655913,
      "grad_norm": 0.019319513444682784,
      "learning_rate": 3.486017648865003e-06,
      "loss": 0.0,
      "step": 5335
    },
    {
      "epoch": 9.18021505376344,
      "grad_norm": 0.0005414372391948124,
      "learning_rate": 3.471440559907302e-06,
      "loss": 0.0,
      "step": 5336
    },
    {
      "epoch": 9.181935483870967,
      "grad_norm": 0.0019125829198649211,
      "learning_rate": 3.4568934741593728e-06,
      "loss": 0.0,
      "step": 5337
    },
    {
      "epoch": 9.183655913978495,
      "grad_norm": 0.00013274196000038563,
      "learning_rate": 3.4423763961427435e-06,
      "loss": 0.0,
      "step": 5338
    },
    {
      "epoch": 9.185376344086022,
      "grad_norm": 4.49048412205415e-05,
      "learning_rate": 3.4278893303696713e-06,
      "loss": 0.0,
      "step": 5339
    },
    {
      "epoch": 9.187096774193549,
      "grad_norm": 0.0002693950937482956,
      "learning_rate": 3.413432281343065e-06,
      "loss": 0.0,
      "step": 5340
    },
    {
      "epoch": 9.188817204301076,
      "grad_norm": 0.0003451316084120504,
      "learning_rate": 3.399005253556464e-06,
      "loss": 0.0,
      "step": 5341
    },
    {
      "epoch": 9.190537634408603,
      "grad_norm": 0.0021784821659461074,
      "learning_rate": 3.3846082514941257e-06,
      "loss": 0.0,
      "step": 5342
    },
    {
      "epoch": 9.192258064516128,
      "grad_norm": 1.2698223727562995e-05,
      "learning_rate": 3.37024127963097e-06,
      "loss": 0.0,
      "step": 5343
    },
    {
      "epoch": 9.193978494623655,
      "grad_norm": 0.0019001895639386701,
      "learning_rate": 3.3559043424325253e-06,
      "loss": 0.0,
      "step": 5344
    },
    {
      "epoch": 9.195698924731182,
      "grad_norm": 8.380784431619761e-05,
      "learning_rate": 3.3415974443550825e-06,
      "loss": 0.0,
      "step": 5345
    },
    {
      "epoch": 9.19741935483871,
      "grad_norm": 0.00018668330925962799,
      "learning_rate": 3.327320589845495e-06,
      "loss": 0.0,
      "step": 5346
    },
    {
      "epoch": 9.199139784946237,
      "grad_norm": 0.0015118787666265872,
      "learning_rate": 3.313073783341347e-06,
      "loss": 0.0,
      "step": 5347
    },
    {
      "epoch": 9.200860215053764,
      "grad_norm": 0.00012947030410864201,
      "learning_rate": 3.298857029270863e-06,
      "loss": 0.0,
      "step": 5348
    },
    {
      "epoch": 9.20258064516129,
      "grad_norm": 0.00036722944312597456,
      "learning_rate": 3.2846703320529303e-06,
      "loss": 0.0,
      "step": 5349
    },
    {
      "epoch": 9.204301075268818,
      "grad_norm": 0.006176404419487274,
      "learning_rate": 3.270513696097055e-06,
      "loss": 0.0,
      "step": 5350
    },
    {
      "epoch": 9.206021505376343,
      "grad_norm": 6.181664652235077e-05,
      "learning_rate": 3.2563871258034726e-06,
      "loss": 0.0,
      "step": 5351
    },
    {
      "epoch": 9.20774193548387,
      "grad_norm": 0.006897989644416507,
      "learning_rate": 3.242290625563016e-06,
      "loss": 0.0,
      "step": 5352
    },
    {
      "epoch": 9.209462365591397,
      "grad_norm": 4.073026518253489e-05,
      "learning_rate": 3.2282241997571904e-06,
      "loss": 0.0,
      "step": 5353
    },
    {
      "epoch": 9.211182795698925,
      "grad_norm": 0.0012034290856948098,
      "learning_rate": 3.2141878527581437e-06,
      "loss": 0.0,
      "step": 5354
    },
    {
      "epoch": 9.212903225806452,
      "grad_norm": 0.0016877975732641699,
      "learning_rate": 3.2001815889286856e-06,
      "loss": 0.0,
      "step": 5355
    },
    {
      "epoch": 9.214623655913979,
      "grad_norm": 0.0006151126144706383,
      "learning_rate": 3.1862054126222895e-06,
      "loss": 0.0,
      "step": 5356
    },
    {
      "epoch": 9.216344086021506,
      "grad_norm": 0.001130740433375938,
      "learning_rate": 3.172259328183036e-06,
      "loss": 0.0,
      "step": 5357
    },
    {
      "epoch": 9.218064516129033,
      "grad_norm": 0.0001335970486973747,
      "learning_rate": 3.1583433399456798e-06,
      "loss": 0.0,
      "step": 5358
    },
    {
      "epoch": 9.21978494623656,
      "grad_norm": 1.3782252637508247e-05,
      "learning_rate": 3.1444574522356496e-06,
      "loss": 0.0,
      "step": 5359
    },
    {
      "epoch": 9.221505376344085,
      "grad_norm": 0.0011459372691747308,
      "learning_rate": 3.1306016693689487e-06,
      "loss": 0.0,
      "step": 5360
    },
    {
      "epoch": 9.223225806451612,
      "grad_norm": 0.0009395627455512427,
      "learning_rate": 3.1167759956522656e-06,
      "loss": 0.0,
      "step": 5361
    },
    {
      "epoch": 9.22494623655914,
      "grad_norm": 0.00143900373096238,
      "learning_rate": 3.1029804353829517e-06,
      "loss": 0.0,
      "step": 5362
    },
    {
      "epoch": 9.226666666666667,
      "grad_norm": 0.00015147307938565019,
      "learning_rate": 3.089214992848932e-06,
      "loss": 0.0,
      "step": 5363
    },
    {
      "epoch": 9.228387096774194,
      "grad_norm": 1.352217204996978e-05,
      "learning_rate": 3.0754796723288516e-06,
      "loss": 0.0,
      "step": 5364
    },
    {
      "epoch": 9.23010752688172,
      "grad_norm": 3.0306398250061825e-05,
      "learning_rate": 3.0617744780919277e-06,
      "loss": 0.0,
      "step": 5365
    },
    {
      "epoch": 9.231827956989248,
      "grad_norm": 0.00140883947443151,
      "learning_rate": 3.0480994143980312e-06,
      "loss": 0.0,
      "step": 5366
    },
    {
      "epoch": 9.233548387096775,
      "grad_norm": 9.960932026132928e-05,
      "learning_rate": 3.0344544854976953e-06,
      "loss": 0.0,
      "step": 5367
    },
    {
      "epoch": 9.2352688172043,
      "grad_norm": 3.786295252096524e-05,
      "learning_rate": 3.0208396956320497e-06,
      "loss": 0.0,
      "step": 5368
    },
    {
      "epoch": 9.236989247311827,
      "grad_norm": 0.0009542992759097409,
      "learning_rate": 3.0072550490328753e-06,
      "loss": 0.0,
      "step": 5369
    },
    {
      "epoch": 9.238709677419354,
      "grad_norm": 0.0003099680152819807,
      "learning_rate": 2.9937005499225955e-06,
      "loss": 0.0,
      "step": 5370
    },
    {
      "epoch": 9.240430107526882,
      "grad_norm": 0.0014141830518696165,
      "learning_rate": 2.9801762025142288e-06,
      "loss": 0.0,
      "step": 5371
    },
    {
      "epoch": 9.242150537634409,
      "grad_norm": 0.00013473771565901142,
      "learning_rate": 2.9666820110114455e-06,
      "loss": 0.0,
      "step": 5372
    },
    {
      "epoch": 9.243870967741936,
      "grad_norm": 0.0001747609638020817,
      "learning_rate": 2.9532179796085356e-06,
      "loss": 0.0,
      "step": 5373
    },
    {
      "epoch": 9.245591397849463,
      "grad_norm": 0.00018052956295444754,
      "learning_rate": 2.939784112490429e-06,
      "loss": 0.0,
      "step": 5374
    },
    {
      "epoch": 9.24731182795699,
      "grad_norm": 7.276643207011573e-05,
      "learning_rate": 2.926380413832652e-06,
      "loss": 0.0,
      "step": 5375
    },
    {
      "epoch": 9.249032258064517,
      "grad_norm": 9.545731838842313e-05,
      "learning_rate": 2.913006887801395e-06,
      "loss": 0.0,
      "step": 5376
    },
    {
      "epoch": 9.250752688172042,
      "grad_norm": 1.588378512293745e-05,
      "learning_rate": 2.899663538553432e-06,
      "loss": 0.0,
      "step": 5377
    },
    {
      "epoch": 9.25247311827957,
      "grad_norm": 0.0003777406735566198,
      "learning_rate": 2.8863503702361682e-06,
      "loss": 0.0,
      "step": 5378
    },
    {
      "epoch": 9.254193548387097,
      "grad_norm": 0.006884065751225991,
      "learning_rate": 2.8730673869876266e-06,
      "loss": 0.0,
      "step": 5379
    },
    {
      "epoch": 9.255913978494624,
      "grad_norm": 0.00012301667571786116,
      "learning_rate": 2.8598145929364607e-06,
      "loss": 0.0,
      "step": 5380
    },
    {
      "epoch": 9.25763440860215,
      "grad_norm": 0.00043254523622670557,
      "learning_rate": 2.8465919922019303e-06,
      "loss": 0.0,
      "step": 5381
    },
    {
      "epoch": 9.259354838709678,
      "grad_norm": 4.620989547696013e-05,
      "learning_rate": 2.8333995888939146e-06,
      "loss": 0.0,
      "step": 5382
    },
    {
      "epoch": 9.261075268817205,
      "grad_norm": 2.851492951698384e-05,
      "learning_rate": 2.8202373871128895e-06,
      "loss": 0.0,
      "step": 5383
    },
    {
      "epoch": 9.262795698924732,
      "grad_norm": 0.00023566403606303332,
      "learning_rate": 2.8071053909499712e-06,
      "loss": 0.0,
      "step": 5384
    },
    {
      "epoch": 9.264516129032257,
      "grad_norm": 0.0009939826140940259,
      "learning_rate": 2.7940036044868832e-06,
      "loss": 0.0,
      "step": 5385
    },
    {
      "epoch": 9.266236559139784,
      "grad_norm": 0.00016945425515336608,
      "learning_rate": 2.780932031795924e-06,
      "loss": 0.0,
      "step": 5386
    },
    {
      "epoch": 9.267956989247311,
      "grad_norm": 0.0005280368475839159,
      "learning_rate": 2.767890676940055e-06,
      "loss": 0.0,
      "step": 5387
    },
    {
      "epoch": 9.269677419354839,
      "grad_norm": 5.0847669796934675e-05,
      "learning_rate": 2.7548795439728102e-06,
      "loss": 0.0,
      "step": 5388
    },
    {
      "epoch": 9.271397849462366,
      "grad_norm": 6.56722493221338e-05,
      "learning_rate": 2.7418986369383114e-06,
      "loss": 0.0,
      "step": 5389
    },
    {
      "epoch": 9.273118279569893,
      "grad_norm": 6.0778874404684475e-05,
      "learning_rate": 2.728947959871353e-06,
      "loss": 0.0,
      "step": 5390
    },
    {
      "epoch": 9.27483870967742,
      "grad_norm": 0.0016268454261296938,
      "learning_rate": 2.7160275167972484e-06,
      "loss": 0.0,
      "step": 5391
    },
    {
      "epoch": 9.276559139784947,
      "grad_norm": 0.00019531222473426717,
      "learning_rate": 2.7031373117319956e-06,
      "loss": 0.0,
      "step": 5392
    },
    {
      "epoch": 9.278279569892472,
      "grad_norm": 0.0011579781703925168,
      "learning_rate": 2.6902773486821354e-06,
      "loss": 0.0,
      "step": 5393
    },
    {
      "epoch": 9.28,
      "grad_norm": 2.125908337973106e-05,
      "learning_rate": 2.677447631644836e-06,
      "loss": 0.0,
      "step": 5394
    },
    {
      "epoch": 9.281720430107526,
      "grad_norm": 0.0004144803685325634,
      "learning_rate": 2.6646481646078415e-06,
      "loss": 0.0,
      "step": 5395
    },
    {
      "epoch": 9.283440860215054,
      "grad_norm": 0.0008858119453336424,
      "learning_rate": 2.651878951549536e-06,
      "loss": 0.0,
      "step": 5396
    },
    {
      "epoch": 9.28516129032258,
      "grad_norm": 0.0012555875209908788,
      "learning_rate": 2.639139996438844e-06,
      "loss": 0.0,
      "step": 5397
    },
    {
      "epoch": 9.286881720430108,
      "grad_norm": 0.0002530601119572002,
      "learning_rate": 2.6264313032353325e-06,
      "loss": 0.0,
      "step": 5398
    },
    {
      "epoch": 9.288602150537635,
      "grad_norm": 0.00010856769919746157,
      "learning_rate": 2.6137528758891526e-06,
      "loss": 0.0,
      "step": 5399
    },
    {
      "epoch": 9.290322580645162,
      "grad_norm": 0.00696007362647682,
      "learning_rate": 2.6011047183410073e-06,
      "loss": 0.0,
      "step": 5400
    },
    {
      "epoch": 9.292043010752689,
      "grad_norm": 1.0596041771785165e-05,
      "learning_rate": 2.5884868345222523e-06,
      "loss": 0.0,
      "step": 5401
    },
    {
      "epoch": 9.293763440860214,
      "grad_norm": 0.00039429991760435993,
      "learning_rate": 2.5758992283547945e-06,
      "loss": 0.0,
      "step": 5402
    },
    {
      "epoch": 9.295483870967741,
      "grad_norm": 0.007840580919488483,
      "learning_rate": 2.5633419037511375e-06,
      "loss": 0.0,
      "step": 5403
    },
    {
      "epoch": 9.297204301075269,
      "grad_norm": 0.0007552853817898549,
      "learning_rate": 2.5508148646143927e-06,
      "loss": 0.0,
      "step": 5404
    },
    {
      "epoch": 9.298924731182796,
      "grad_norm": 0.0032455557143942063,
      "learning_rate": 2.5383181148382227e-06,
      "loss": 0.0,
      "step": 5405
    },
    {
      "epoch": 9.300645161290323,
      "grad_norm": 0.0003909851725081469,
      "learning_rate": 2.525851658306888e-06,
      "loss": 0.0,
      "step": 5406
    },
    {
      "epoch": 9.30236559139785,
      "grad_norm": 1.3282091140206956e-05,
      "learning_rate": 2.513415498895255e-06,
      "loss": 0.0,
      "step": 5407
    },
    {
      "epoch": 9.304086021505377,
      "grad_norm": 8.504635540424614e-06,
      "learning_rate": 2.5010096404687545e-06,
      "loss": 0.0,
      "step": 5408
    },
    {
      "epoch": 9.305806451612904,
      "grad_norm": 0.00010221943570403526,
      "learning_rate": 2.48863408688339e-06,
      "loss": 0.0,
      "step": 5409
    },
    {
      "epoch": 9.30752688172043,
      "grad_norm": 0.00015878143842562063,
      "learning_rate": 2.4762888419857744e-06,
      "loss": 0.0,
      "step": 5410
    },
    {
      "epoch": 9.309247311827956,
      "grad_norm": 0.0018554318687291104,
      "learning_rate": 2.4639739096130707e-06,
      "loss": 0.0,
      "step": 5411
    },
    {
      "epoch": 9.310967741935483,
      "grad_norm": 0.00024824430106345417,
      "learning_rate": 2.451689293593018e-06,
      "loss": 0.0,
      "step": 5412
    },
    {
      "epoch": 9.31268817204301,
      "grad_norm": 0.0003164583279796937,
      "learning_rate": 2.4394349977439834e-06,
      "loss": 0.0,
      "step": 5413
    },
    {
      "epoch": 9.314408602150538,
      "grad_norm": 8.640449538796459e-06,
      "learning_rate": 2.4272110258748426e-06,
      "loss": 0.0,
      "step": 5414
    },
    {
      "epoch": 9.316129032258065,
      "grad_norm": 0.0011775823782584516,
      "learning_rate": 2.415017381785101e-06,
      "loss": 0.0,
      "step": 5415
    },
    {
      "epoch": 9.317849462365592,
      "grad_norm": 0.0005825771531221846,
      "learning_rate": 2.4028540692647817e-06,
      "loss": 0.0,
      "step": 5416
    },
    {
      "epoch": 9.319569892473119,
      "grad_norm": 0.0002127171918272144,
      "learning_rate": 2.3907210920945277e-06,
      "loss": 0.0,
      "step": 5417
    },
    {
      "epoch": 9.321290322580644,
      "grad_norm": 0.0005524470329426,
      "learning_rate": 2.3786184540455448e-06,
      "loss": 0.0,
      "step": 5418
    },
    {
      "epoch": 9.323010752688171,
      "grad_norm": 0.010209287181669864,
      "learning_rate": 2.36654615887959e-06,
      "loss": 0.0,
      "step": 5419
    },
    {
      "epoch": 9.324731182795698,
      "grad_norm": 0.00031092462225648025,
      "learning_rate": 2.3545042103489847e-06,
      "loss": 0.0,
      "step": 5420
    },
    {
      "epoch": 9.326451612903226,
      "grad_norm": 0.00034569172139939554,
      "learning_rate": 2.3424926121966674e-06,
      "loss": 0.0,
      "step": 5421
    },
    {
      "epoch": 9.328172043010753,
      "grad_norm": 7.362522035073047e-05,
      "learning_rate": 2.3305113681560964e-06,
      "loss": 0.0,
      "step": 5422
    },
    {
      "epoch": 9.32989247311828,
      "grad_norm": 0.0004444413046310491,
      "learning_rate": 2.3185604819512818e-06,
      "loss": 0.0,
      "step": 5423
    },
    {
      "epoch": 9.331612903225807,
      "grad_norm": 2.7464426444347547e-05,
      "learning_rate": 2.306639957296852e-06,
      "loss": 0.0,
      "step": 5424
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 0.0008425337558923141,
      "learning_rate": 2.294749797897955e-06,
      "loss": 0.0,
      "step": 5425
    },
    {
      "epoch": 9.335053763440861,
      "grad_norm": 3.976265190654969e-05,
      "learning_rate": 2.282890007450322e-06,
      "loss": 0.0,
      "step": 5426
    },
    {
      "epoch": 9.336774193548386,
      "grad_norm": 0.00041821024365538734,
      "learning_rate": 2.2710605896402394e-06,
      "loss": 0.0,
      "step": 5427
    },
    {
      "epoch": 9.338494623655913,
      "grad_norm": 0.00032212911097624956,
      "learning_rate": 2.2592615481445423e-06,
      "loss": 0.0,
      "step": 5428
    },
    {
      "epoch": 9.34021505376344,
      "grad_norm": 9.752228818741923e-06,
      "learning_rate": 2.247492886630631e-06,
      "loss": 0.0,
      "step": 5429
    },
    {
      "epoch": 9.341935483870968,
      "grad_norm": 4.0599456928042876e-05,
      "learning_rate": 2.2357546087564906e-06,
      "loss": 0.0,
      "step": 5430
    },
    {
      "epoch": 9.343655913978495,
      "grad_norm": 0.00030492987596204336,
      "learning_rate": 2.2240467181706137e-06,
      "loss": 0.0,
      "step": 5431
    },
    {
      "epoch": 9.345376344086022,
      "grad_norm": 0.0009493982439728411,
      "learning_rate": 2.212369218512078e-06,
      "loss": 0.0,
      "step": 5432
    },
    {
      "epoch": 9.347096774193549,
      "grad_norm": 0.0003332213273253382,
      "learning_rate": 2.2007221134105137e-06,
      "loss": 0.0,
      "step": 5433
    },
    {
      "epoch": 9.348817204301076,
      "grad_norm": 5.332390257363601e-05,
      "learning_rate": 2.1891054064860917e-06,
      "loss": 0.0,
      "step": 5434
    },
    {
      "epoch": 9.350537634408601,
      "grad_norm": 0.0002655591043586807,
      "learning_rate": 2.1775191013495456e-06,
      "loss": 0.0,
      "step": 5435
    },
    {
      "epoch": 9.352258064516128,
      "grad_norm": 0.0004689823915352891,
      "learning_rate": 2.16596320160215e-06,
      "loss": 0.0,
      "step": 5436
    },
    {
      "epoch": 9.353978494623655,
      "grad_norm": 0.0017887808072933728,
      "learning_rate": 2.1544377108357215e-06,
      "loss": 0.0,
      "step": 5437
    },
    {
      "epoch": 9.355698924731183,
      "grad_norm": 7.000162603972571e-05,
      "learning_rate": 2.1429426326326717e-06,
      "loss": 0.0,
      "step": 5438
    },
    {
      "epoch": 9.35741935483871,
      "grad_norm": 1.3304792450565847e-05,
      "learning_rate": 2.1314779705658982e-06,
      "loss": 0.0,
      "step": 5439
    },
    {
      "epoch": 9.359139784946237,
      "grad_norm": 0.001191951875529482,
      "learning_rate": 2.1200437281988726e-06,
      "loss": 0.0,
      "step": 5440
    },
    {
      "epoch": 9.360860215053764,
      "grad_norm": 5.118149942472743e-05,
      "learning_rate": 2.1086399090856302e-06,
      "loss": 0.0,
      "step": 5441
    },
    {
      "epoch": 9.362580645161291,
      "grad_norm": 0.0038512168151092997,
      "learning_rate": 2.0972665167707126e-06,
      "loss": 0.0,
      "step": 5442
    },
    {
      "epoch": 9.364301075268818,
      "grad_norm": 9.140300127277214e-05,
      "learning_rate": 2.0859235547892262e-06,
      "loss": 0.0,
      "step": 5443
    },
    {
      "epoch": 9.366021505376343,
      "grad_norm": 0.002958497637033952,
      "learning_rate": 2.0746110266668174e-06,
      "loss": 0.0,
      "step": 5444
    },
    {
      "epoch": 9.36774193548387,
      "grad_norm": 0.00040460639110858536,
      "learning_rate": 2.0633289359196506e-06,
      "loss": 0.0,
      "step": 5445
    },
    {
      "epoch": 9.369462365591398,
      "grad_norm": 0.001235202412221704,
      "learning_rate": 2.0520772860544767e-06,
      "loss": 0.0,
      "step": 5446
    },
    {
      "epoch": 9.371182795698925,
      "grad_norm": 0.0004233816160271998,
      "learning_rate": 2.0408560805685316e-06,
      "loss": 0.0,
      "step": 5447
    },
    {
      "epoch": 9.372903225806452,
      "grad_norm": 2.7701095659145455e-05,
      "learning_rate": 2.0296653229496366e-06,
      "loss": 0.0,
      "step": 5448
    },
    {
      "epoch": 9.374623655913979,
      "grad_norm": 4.115631277464816e-05,
      "learning_rate": 2.0185050166761197e-06,
      "loss": 0.0,
      "step": 5449
    },
    {
      "epoch": 9.376344086021506,
      "grad_norm": 0.002774800942513584,
      "learning_rate": 2.0073751652168515e-06,
      "loss": 0.0,
      "step": 5450
    },
    {
      "epoch": 9.378064516129033,
      "grad_norm": 0.0003793304426536769,
      "learning_rate": 1.9962757720312196e-06,
      "loss": 0.0,
      "step": 5451
    },
    {
      "epoch": 9.379784946236558,
      "grad_norm": 0.0004944968353426236,
      "learning_rate": 1.985206840569187e-06,
      "loss": 0.0,
      "step": 5452
    },
    {
      "epoch": 9.381505376344085,
      "grad_norm": 7.249595653677964e-05,
      "learning_rate": 1.9741683742712012e-06,
      "loss": 0.0,
      "step": 5453
    },
    {
      "epoch": 9.383225806451613,
      "grad_norm": 0.002003420453533292,
      "learning_rate": 1.963160376568274e-06,
      "loss": 0.0,
      "step": 5454
    },
    {
      "epoch": 9.38494623655914,
      "grad_norm": 0.0018850540205644305,
      "learning_rate": 1.952182850881923e-06,
      "loss": 0.0,
      "step": 5455
    },
    {
      "epoch": 9.386666666666667,
      "grad_norm": 0.0010908075325508856,
      "learning_rate": 1.9412358006242082e-06,
      "loss": 0.0,
      "step": 5456
    },
    {
      "epoch": 9.388387096774194,
      "grad_norm": 0.00020493553916908148,
      "learning_rate": 1.9303192291977303e-06,
      "loss": 0.0,
      "step": 5457
    },
    {
      "epoch": 9.390107526881721,
      "grad_norm": 8.638787141344379e-05,
      "learning_rate": 1.9194331399955854e-06,
      "loss": 0.0,
      "step": 5458
    },
    {
      "epoch": 9.391827956989248,
      "grad_norm": 0.0008773992091088701,
      "learning_rate": 1.9085775364014124e-06,
      "loss": 0.0,
      "step": 5459
    },
    {
      "epoch": 9.393548387096775,
      "grad_norm": 0.004019932811040988,
      "learning_rate": 1.8977524217893783e-06,
      "loss": 0.0,
      "step": 5460
    },
    {
      "epoch": 9.3952688172043,
      "grad_norm": 0.00023120180009535078,
      "learning_rate": 1.8869577995241694e-06,
      "loss": 0.0,
      "step": 5461
    },
    {
      "epoch": 9.396989247311827,
      "grad_norm": 0.00205480117303734,
      "learning_rate": 1.8761936729609797e-06,
      "loss": 0.0,
      "step": 5462
    },
    {
      "epoch": 9.398709677419355,
      "grad_norm": 0.00018083485184107868,
      "learning_rate": 1.865460045445544e-06,
      "loss": 0.0,
      "step": 5463
    },
    {
      "epoch": 9.400430107526882,
      "grad_norm": 0.0003509094353897873,
      "learning_rate": 1.8547569203141158e-06,
      "loss": 0.0,
      "step": 5464
    },
    {
      "epoch": 9.402150537634409,
      "grad_norm": 0.0006571517922886787,
      "learning_rate": 1.8440843008934561e-06,
      "loss": 0.0,
      "step": 5465
    },
    {
      "epoch": 9.403870967741936,
      "grad_norm": 3.412409701735354e-05,
      "learning_rate": 1.833442190500867e-06,
      "loss": 0.0,
      "step": 5466
    },
    {
      "epoch": 9.405591397849463,
      "grad_norm": 0.00018020525931767612,
      "learning_rate": 1.822830592444147e-06,
      "loss": 0.0,
      "step": 5467
    },
    {
      "epoch": 9.40731182795699,
      "grad_norm": 0.00013782429746420357,
      "learning_rate": 1.8122495100215909e-06,
      "loss": 0.0,
      "step": 5468
    },
    {
      "epoch": 9.409032258064515,
      "grad_norm": 3.48607528482992e-05,
      "learning_rate": 1.801698946522057e-06,
      "loss": 0.0,
      "step": 5469
    },
    {
      "epoch": 9.410752688172042,
      "grad_norm": 0.002052933969021613,
      "learning_rate": 1.7911789052248884e-06,
      "loss": 0.0,
      "step": 5470
    },
    {
      "epoch": 9.41247311827957,
      "grad_norm": 0.0013234378515150959,
      "learning_rate": 1.7806893893999367e-06,
      "loss": 0.0,
      "step": 5471
    },
    {
      "epoch": 9.414193548387097,
      "grad_norm": 0.0004947711405154995,
      "learning_rate": 1.7702304023075932e-06,
      "loss": 0.0,
      "step": 5472
    },
    {
      "epoch": 9.415913978494624,
      "grad_norm": 0.0005438165181249415,
      "learning_rate": 1.7598019471987248e-06,
      "loss": 0.0,
      "step": 5473
    },
    {
      "epoch": 9.41763440860215,
      "grad_norm": 0.00015201623078101899,
      "learning_rate": 1.7494040273147382e-06,
      "loss": 0.0,
      "step": 5474
    },
    {
      "epoch": 9.419354838709678,
      "grad_norm": 0.00011250969663493481,
      "learning_rate": 1.7390366458875262e-06,
      "loss": 0.0,
      "step": 5475
    },
    {
      "epoch": 9.421075268817205,
      "grad_norm": 0.0002302861528944815,
      "learning_rate": 1.728699806139511e-06,
      "loss": 0.0,
      "step": 5476
    },
    {
      "epoch": 9.42279569892473,
      "grad_norm": 7.27559914892328e-05,
      "learning_rate": 1.7183935112836114e-06,
      "loss": 0.0,
      "step": 5477
    },
    {
      "epoch": 9.424516129032257,
      "grad_norm": 0.000645566846036438,
      "learning_rate": 1.7081177645232426e-06,
      "loss": 0.0,
      "step": 5478
    },
    {
      "epoch": 9.426236559139785,
      "grad_norm": 0.0006425249289340523,
      "learning_rate": 1.6978725690523278e-06,
      "loss": 0.0,
      "step": 5479
    },
    {
      "epoch": 9.427956989247312,
      "grad_norm": 0.00041767318764844623,
      "learning_rate": 1.6876579280553195e-06,
      "loss": 0.0,
      "step": 5480
    },
    {
      "epoch": 9.429677419354839,
      "grad_norm": 0.00025859158765955455,
      "learning_rate": 1.6774738447071559e-06,
      "loss": 0.0,
      "step": 5481
    },
    {
      "epoch": 9.431397849462366,
      "grad_norm": 7.406968140234798e-05,
      "learning_rate": 1.667320322173227e-06,
      "loss": 0.0,
      "step": 5482
    },
    {
      "epoch": 9.433118279569893,
      "grad_norm": 0.0004966412245383269,
      "learning_rate": 1.6571973636095417e-06,
      "loss": 0.0,
      "step": 5483
    },
    {
      "epoch": 9.43483870967742,
      "grad_norm": 0.0008927321164894618,
      "learning_rate": 1.6471049721624943e-06,
      "loss": 0.0,
      "step": 5484
    },
    {
      "epoch": 9.436559139784947,
      "grad_norm": 0.00017510434068822224,
      "learning_rate": 1.6370431509690309e-06,
      "loss": 0.0,
      "step": 5485
    },
    {
      "epoch": 9.438279569892472,
      "grad_norm": 0.0006145344557417314,
      "learning_rate": 1.6270119031566055e-06,
      "loss": 0.0,
      "step": 5486
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.00010788028923239871,
      "learning_rate": 1.6170112318431352e-06,
      "loss": 0.0,
      "step": 5487
    },
    {
      "epoch": 9.441720430107527,
      "grad_norm": 0.002393362354726456,
      "learning_rate": 1.6070411401370334e-06,
      "loss": 0.0,
      "step": 5488
    },
    {
      "epoch": 9.443440860215054,
      "grad_norm": 0.0017684196738953866,
      "learning_rate": 1.5971016311372655e-06,
      "loss": 0.0,
      "step": 5489
    },
    {
      "epoch": 9.44516129032258,
      "grad_norm": 3.614955712770208e-05,
      "learning_rate": 1.5871927079332162e-06,
      "loss": 0.0,
      "step": 5490
    },
    {
      "epoch": 9.446881720430108,
      "grad_norm": 0.0004161599244816903,
      "learning_rate": 1.5773143736048102e-06,
      "loss": 0.0,
      "step": 5491
    },
    {
      "epoch": 9.448602150537635,
      "grad_norm": 0.002979738358173013,
      "learning_rate": 1.5674666312224584e-06,
      "loss": 0.0,
      "step": 5492
    },
    {
      "epoch": 9.450322580645162,
      "grad_norm": 0.001201163904467037,
      "learning_rate": 1.5576494838470456e-06,
      "loss": 0.0,
      "step": 5493
    },
    {
      "epoch": 9.452043010752687,
      "grad_norm": 0.08253238104211394,
      "learning_rate": 1.5478629345299756e-06,
      "loss": 0.0,
      "step": 5494
    },
    {
      "epoch": 9.453763440860214,
      "grad_norm": 0.000116017338176172,
      "learning_rate": 1.5381069863131037e-06,
      "loss": 0.0,
      "step": 5495
    },
    {
      "epoch": 9.455483870967742,
      "grad_norm": 0.0028399287278194295,
      "learning_rate": 1.5283816422288045e-06,
      "loss": 0.0,
      "step": 5496
    },
    {
      "epoch": 9.457204301075269,
      "grad_norm": 4.892552151492263e-05,
      "learning_rate": 1.5186869052999263e-06,
      "loss": 0.0,
      "step": 5497
    },
    {
      "epoch": 9.458924731182796,
      "grad_norm": 0.0009711084412607875,
      "learning_rate": 1.5090227785398149e-06,
      "loss": 0.0,
      "step": 5498
    },
    {
      "epoch": 9.460645161290323,
      "grad_norm": 0.005333471710626568,
      "learning_rate": 1.4993892649522779e-06,
      "loss": 0.0,
      "step": 5499
    },
    {
      "epoch": 9.46236559139785,
      "grad_norm": 1.3259570570969106e-05,
      "learning_rate": 1.4897863675316427e-06,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 9.464086021505377,
      "grad_norm": 6.961725545827149e-05,
      "learning_rate": 1.4802140892626992e-06,
      "loss": 0.0,
      "step": 5501
    },
    {
      "epoch": 9.465806451612902,
      "grad_norm": 0.0008415198187905204,
      "learning_rate": 1.4706724331207122e-06,
      "loss": 0.0,
      "step": 5502
    },
    {
      "epoch": 9.46752688172043,
      "grad_norm": 0.0004422418923461922,
      "learning_rate": 1.4611614020714426e-06,
      "loss": 0.0,
      "step": 5503
    },
    {
      "epoch": 9.469247311827957,
      "grad_norm": 0.000742139694180453,
      "learning_rate": 1.4516809990711478e-06,
      "loss": 0.0,
      "step": 5504
    },
    {
      "epoch": 9.470967741935484,
      "grad_norm": 0.00023550911400387918,
      "learning_rate": 1.442231227066515e-06,
      "loss": 0.0,
      "step": 5505
    },
    {
      "epoch": 9.47268817204301,
      "grad_norm": 0.00016382003700968987,
      "learning_rate": 1.4328120889947615e-06,
      "loss": 0.0,
      "step": 5506
    },
    {
      "epoch": 9.474408602150538,
      "grad_norm": 4.3805046712663575e-05,
      "learning_rate": 1.4234235877835566e-06,
      "loss": 0.0,
      "step": 5507
    },
    {
      "epoch": 9.476129032258065,
      "grad_norm": 1.401292192593233e-05,
      "learning_rate": 1.4140657263510658e-06,
      "loss": 0.0,
      "step": 5508
    },
    {
      "epoch": 9.477849462365592,
      "grad_norm": 7.94344559942246e-05,
      "learning_rate": 1.4047385076059071e-06,
      "loss": 0.0,
      "step": 5509
    },
    {
      "epoch": 9.479569892473119,
      "grad_norm": 0.0006741789632042609,
      "learning_rate": 1.3954419344471947e-06,
      "loss": 0.0,
      "step": 5510
    },
    {
      "epoch": 9.481290322580644,
      "grad_norm": 0.0018610880707776321,
      "learning_rate": 1.386176009764506e-06,
      "loss": 0.0,
      "step": 5511
    },
    {
      "epoch": 9.483010752688172,
      "grad_norm": 0.0011055779066648421,
      "learning_rate": 1.3769407364378928e-06,
      "loss": 0.0,
      "step": 5512
    },
    {
      "epoch": 9.484731182795699,
      "grad_norm": 0.0015292166846978044,
      "learning_rate": 1.3677361173378699e-06,
      "loss": 0.0,
      "step": 5513
    },
    {
      "epoch": 9.486451612903226,
      "grad_norm": 0.00046155233538698837,
      "learning_rate": 1.3585621553254712e-06,
      "loss": 0.0,
      "step": 5514
    },
    {
      "epoch": 9.488172043010753,
      "grad_norm": 0.0016277973105974816,
      "learning_rate": 1.3494188532521268e-06,
      "loss": 0.0,
      "step": 5515
    },
    {
      "epoch": 9.48989247311828,
      "grad_norm": 0.003910704959882777,
      "learning_rate": 1.3403062139598076e-06,
      "loss": 0.0,
      "step": 5516
    },
    {
      "epoch": 9.491612903225807,
      "grad_norm": 7.882732226066212e-05,
      "learning_rate": 1.3312242402809038e-06,
      "loss": 0.0,
      "step": 5517
    },
    {
      "epoch": 9.493333333333334,
      "grad_norm": 0.00016732730459083887,
      "learning_rate": 1.3221729350383016e-06,
      "loss": 0.0,
      "step": 5518
    },
    {
      "epoch": 9.49505376344086,
      "grad_norm": 0.0032962936935939523,
      "learning_rate": 1.3131523010453394e-06,
      "loss": 0.0,
      "step": 5519
    },
    {
      "epoch": 9.496774193548386,
      "grad_norm": 0.0003185856006584021,
      "learning_rate": 1.3041623411058522e-06,
      "loss": 0.0,
      "step": 5520
    },
    {
      "epoch": 9.498494623655914,
      "grad_norm": 2.9955195877548577e-05,
      "learning_rate": 1.295203058014105e-06,
      "loss": 0.0,
      "step": 5521
    },
    {
      "epoch": 9.50021505376344,
      "grad_norm": 2.4792299055423653e-05,
      "learning_rate": 1.2862744545548256e-06,
      "loss": 0.0,
      "step": 5522
    },
    {
      "epoch": 9.501935483870968,
      "grad_norm": 1.624038515612352e-05,
      "learning_rate": 1.2773765335032383e-06,
      "loss": 0.0,
      "step": 5523
    },
    {
      "epoch": 9.503655913978495,
      "grad_norm": 0.010731892914338811,
      "learning_rate": 1.2685092976249978e-06,
      "loss": 0.0,
      "step": 5524
    },
    {
      "epoch": 9.505376344086022,
      "grad_norm": 4.4479480216252504e-05,
      "learning_rate": 1.2596727496762662e-06,
      "loss": 0.0,
      "step": 5525
    },
    {
      "epoch": 9.507096774193549,
      "grad_norm": 0.0006421280833107932,
      "learning_rate": 1.2508668924036126e-06,
      "loss": 0.0,
      "step": 5526
    },
    {
      "epoch": 9.508817204301074,
      "grad_norm": 0.00021539907457757295,
      "learning_rate": 1.2420917285440925e-06,
      "loss": 0.0,
      "step": 5527
    },
    {
      "epoch": 9.510537634408601,
      "grad_norm": 0.00023769172160885568,
      "learning_rate": 1.233347260825246e-06,
      "loss": 0.0,
      "step": 5528
    },
    {
      "epoch": 9.512258064516129,
      "grad_norm": 0.0016518101442884671,
      "learning_rate": 1.2246334919650216e-06,
      "loss": 0.0,
      "step": 5529
    },
    {
      "epoch": 9.513978494623656,
      "grad_norm": 0.0009297675033187195,
      "learning_rate": 1.2159504246718522e-06,
      "loss": 0.0,
      "step": 5530
    },
    {
      "epoch": 9.515698924731183,
      "grad_norm": 0.003149817675937444,
      "learning_rate": 1.207298061644635e-06,
      "loss": 0.0,
      "step": 5531
    },
    {
      "epoch": 9.51741935483871,
      "grad_norm": 0.0048033183818714945,
      "learning_rate": 1.1986764055727185e-06,
      "loss": 0.0,
      "step": 5532
    },
    {
      "epoch": 9.519139784946237,
      "grad_norm": 8.341221880325283e-05,
      "learning_rate": 1.1900854591359034e-06,
      "loss": 0.0,
      "step": 5533
    },
    {
      "epoch": 9.520860215053764,
      "grad_norm": 7.79896092264025e-06,
      "learning_rate": 1.1815252250044318e-06,
      "loss": 0.0,
      "step": 5534
    },
    {
      "epoch": 9.522580645161291,
      "grad_norm": 0.00028658591153015887,
      "learning_rate": 1.1729957058390306e-06,
      "loss": 0.0,
      "step": 5535
    },
    {
      "epoch": 9.524301075268816,
      "grad_norm": 0.00015440921188461328,
      "learning_rate": 1.164496904290846e-06,
      "loss": 0.0,
      "step": 5536
    },
    {
      "epoch": 9.526021505376344,
      "grad_norm": 0.00016991070478647425,
      "learning_rate": 1.1560288230015203e-06,
      "loss": 0.0,
      "step": 5537
    },
    {
      "epoch": 9.52774193548387,
      "grad_norm": 0.0013114980074585172,
      "learning_rate": 1.1475914646030817e-06,
      "loss": 0.0,
      "step": 5538
    },
    {
      "epoch": 9.529462365591398,
      "grad_norm": 0.0012664059458115762,
      "learning_rate": 1.1391848317180876e-06,
      "loss": 0.0,
      "step": 5539
    },
    {
      "epoch": 9.531182795698925,
      "grad_norm": 0.0006135183657390366,
      "learning_rate": 1.1308089269594923e-06,
      "loss": 0.0,
      "step": 5540
    },
    {
      "epoch": 9.532903225806452,
      "grad_norm": 0.0005993822225972799,
      "learning_rate": 1.1224637529306915e-06,
      "loss": 0.0,
      "step": 5541
    },
    {
      "epoch": 9.534623655913979,
      "grad_norm": 0.00011678506627702541,
      "learning_rate": 1.1141493122255763e-06,
      "loss": 0.0,
      "step": 5542
    },
    {
      "epoch": 9.536344086021506,
      "grad_norm": 5.86654310889505e-05,
      "learning_rate": 1.1058656074284358e-06,
      "loss": 0.0,
      "step": 5543
    },
    {
      "epoch": 9.538064516129033,
      "grad_norm": 6.312811551570705e-05,
      "learning_rate": 1.0976126411140431e-06,
      "loss": 0.0,
      "step": 5544
    },
    {
      "epoch": 9.539784946236558,
      "grad_norm": 6.087236686362676e-06,
      "learning_rate": 1.0893904158476021e-06,
      "loss": 0.0,
      "step": 5545
    },
    {
      "epoch": 9.541505376344086,
      "grad_norm": 0.00042232243569884895,
      "learning_rate": 1.0811989341847684e-06,
      "loss": 0.0,
      "step": 5546
    },
    {
      "epoch": 9.543225806451613,
      "grad_norm": 5.609573787661669e-05,
      "learning_rate": 1.0730381986716165e-06,
      "loss": 0.0,
      "step": 5547
    },
    {
      "epoch": 9.54494623655914,
      "grad_norm": 0.005191596560953486,
      "learning_rate": 1.0649082118446951e-06,
      "loss": 0.0,
      "step": 5548
    },
    {
      "epoch": 9.546666666666667,
      "grad_norm": 3.9387346780529715e-05,
      "learning_rate": 1.0568089762309829e-06,
      "loss": 0.0,
      "step": 5549
    },
    {
      "epoch": 9.548387096774194,
      "grad_norm": 0.008472397151280925,
      "learning_rate": 1.0487404943478995e-06,
      "loss": 0.0,
      "step": 5550
    },
    {
      "epoch": 9.550107526881721,
      "grad_norm": 0.0006791596941602181,
      "learning_rate": 1.0407027687033166e-06,
      "loss": 0.0,
      "step": 5551
    },
    {
      "epoch": 9.551827956989248,
      "grad_norm": 0.0005254368657335865,
      "learning_rate": 1.0326958017955247e-06,
      "loss": 0.0,
      "step": 5552
    },
    {
      "epoch": 9.553548387096773,
      "grad_norm": 0.0009578972554134208,
      "learning_rate": 1.0247195961132661e-06,
      "loss": 0.0,
      "step": 5553
    },
    {
      "epoch": 9.5552688172043,
      "grad_norm": 0.00039179610219867837,
      "learning_rate": 1.0167741541357355e-06,
      "loss": 0.0,
      "step": 5554
    },
    {
      "epoch": 9.556989247311828,
      "grad_norm": 0.0010532792190876786,
      "learning_rate": 1.0088594783325356e-06,
      "loss": 0.0,
      "step": 5555
    },
    {
      "epoch": 9.558709677419355,
      "grad_norm": 0.0007942234321793434,
      "learning_rate": 1.0009755711637315e-06,
      "loss": 0.0,
      "step": 5556
    },
    {
      "epoch": 9.560430107526882,
      "grad_norm": 4.3665176411803313e-05,
      "learning_rate": 9.931224350798185e-07,
      "loss": 0.0,
      "step": 5557
    },
    {
      "epoch": 9.562150537634409,
      "grad_norm": 1.2566496907984577e-05,
      "learning_rate": 9.85300072521711e-07,
      "loss": 0.0,
      "step": 5558
    },
    {
      "epoch": 9.563870967741936,
      "grad_norm": 7.850981005422769e-06,
      "learning_rate": 9.775084859207862e-07,
      "loss": 0.0,
      "step": 5559
    },
    {
      "epoch": 9.565591397849463,
      "grad_norm": 0.0003362744340505082,
      "learning_rate": 9.697476776988401e-07,
      "loss": 0.0,
      "step": 5560
    },
    {
      "epoch": 9.567311827956988,
      "grad_norm": 0.0002637219763875864,
      "learning_rate": 9.620176502680988e-07,
      "loss": 0.0,
      "step": 5561
    },
    {
      "epoch": 9.569032258064516,
      "grad_norm": 0.00014903616064923736,
      "learning_rate": 9.543184060312294e-07,
      "loss": 0.0,
      "step": 5562
    },
    {
      "epoch": 9.570752688172043,
      "grad_norm": 0.00028996412454657285,
      "learning_rate": 9.466499473813173e-07,
      "loss": 0.0,
      "step": 5563
    },
    {
      "epoch": 9.57247311827957,
      "grad_norm": 0.0005823967700457726,
      "learning_rate": 9.390122767018894e-07,
      "loss": 0.0,
      "step": 5564
    },
    {
      "epoch": 9.574193548387097,
      "grad_norm": 0.00042012454686280153,
      "learning_rate": 9.314053963669245e-07,
      "loss": 0.0,
      "step": 5565
    },
    {
      "epoch": 9.575913978494624,
      "grad_norm": 0.0008621969336809436,
      "learning_rate": 9.238293087407978e-07,
      "loss": 0.0,
      "step": 5566
    },
    {
      "epoch": 9.577634408602151,
      "grad_norm": 0.0005715299186258012,
      "learning_rate": 9.162840161783038e-07,
      "loss": 0.0,
      "step": 5567
    },
    {
      "epoch": 9.579354838709678,
      "grad_norm": 0.00016250882169677771,
      "learning_rate": 9.087695210247216e-07,
      "loss": 0.0,
      "step": 5568
    },
    {
      "epoch": 9.581075268817205,
      "grad_norm": 0.00040785460984284845,
      "learning_rate": 9.01285825615683e-07,
      "loss": 0.0,
      "step": 5569
    },
    {
      "epoch": 9.58279569892473,
      "grad_norm": 1.2299027019083458e-05,
      "learning_rate": 8.938329322773275e-07,
      "loss": 0.0,
      "step": 5570
    },
    {
      "epoch": 9.584516129032258,
      "grad_norm": 0.00012128935349166442,
      "learning_rate": 8.864108433261575e-07,
      "loss": 0.0,
      "step": 5571
    },
    {
      "epoch": 9.586236559139785,
      "grad_norm": 0.0036917034493674627,
      "learning_rate": 8.790195610691054e-07,
      "loss": 0.0,
      "step": 5572
    },
    {
      "epoch": 9.587956989247312,
      "grad_norm": 0.001133253933814912,
      "learning_rate": 8.716590878035779e-07,
      "loss": 0.0,
      "step": 5573
    },
    {
      "epoch": 9.589677419354839,
      "grad_norm": 0.0004346566322534216,
      "learning_rate": 8.643294258173562e-07,
      "loss": 0.0,
      "step": 5574
    },
    {
      "epoch": 9.591397849462366,
      "grad_norm": 3.1345360246579894e-05,
      "learning_rate": 8.570305773886622e-07,
      "loss": 0.0,
      "step": 5575
    },
    {
      "epoch": 9.593118279569893,
      "grad_norm": 0.0003590568521089746,
      "learning_rate": 8.497625447861369e-07,
      "loss": 0.0,
      "step": 5576
    },
    {
      "epoch": 9.59483870967742,
      "grad_norm": 0.0003146695022809558,
      "learning_rate": 8.425253302688618e-07,
      "loss": 0.0,
      "step": 5577
    },
    {
      "epoch": 9.596559139784945,
      "grad_norm": 0.0005148116091465892,
      "learning_rate": 8.353189360862934e-07,
      "loss": 0.0,
      "step": 5578
    },
    {
      "epoch": 9.598279569892473,
      "grad_norm": 0.00017141772229940205,
      "learning_rate": 8.281433644783621e-07,
      "loss": 0.0,
      "step": 5579
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.8635840566318593e-05,
      "learning_rate": 8.209986176753948e-07,
      "loss": 0.0,
      "step": 5580
    },
    {
      "epoch": 9.601720430107527,
      "grad_norm": 0.00034366424773956723,
      "learning_rate": 8.138846978981152e-07,
      "loss": 0.0,
      "step": 5581
    },
    {
      "epoch": 9.603440860215054,
      "grad_norm": 0.00030219073307720607,
      "learning_rate": 8.0680160735771e-07,
      "loss": 0.0,
      "step": 5582
    },
    {
      "epoch": 9.605161290322581,
      "grad_norm": 0.0009165775958630022,
      "learning_rate": 7.997493482557517e-07,
      "loss": 0.0,
      "step": 5583
    },
    {
      "epoch": 9.606881720430108,
      "grad_norm": 0.00013869184712048523,
      "learning_rate": 7.927279227842311e-07,
      "loss": 0.0,
      "step": 5584
    },
    {
      "epoch": 9.608602150537635,
      "grad_norm": 0.0008006662640566686,
      "learning_rate": 7.857373331255802e-07,
      "loss": 0.0,
      "step": 5585
    },
    {
      "epoch": 9.61032258064516,
      "grad_norm": 9.484607641286911e-06,
      "learning_rate": 7.787775814526054e-07,
      "loss": 0.0,
      "step": 5586
    },
    {
      "epoch": 9.612043010752688,
      "grad_norm": 0.0003208972818207683,
      "learning_rate": 7.718486699285654e-07,
      "loss": 0.0,
      "step": 5587
    },
    {
      "epoch": 9.613763440860215,
      "grad_norm": 0.0006262857021744446,
      "learning_rate": 7.649506007071261e-07,
      "loss": 0.0,
      "step": 5588
    },
    {
      "epoch": 9.615483870967742,
      "grad_norm": 0.00013659810615342346,
      "learning_rate": 7.580833759323392e-07,
      "loss": 0.0,
      "step": 5589
    },
    {
      "epoch": 9.617204301075269,
      "grad_norm": 0.00033250641624592357,
      "learning_rate": 7.512469977387083e-07,
      "loss": 0.0,
      "step": 5590
    },
    {
      "epoch": 9.618924731182796,
      "grad_norm": 0.0020184682498726896,
      "learning_rate": 7.444414682511225e-07,
      "loss": 0.0,
      "step": 5591
    },
    {
      "epoch": 9.620645161290323,
      "grad_norm": 3.9612679860778574e-05,
      "learning_rate": 7.376667895848899e-07,
      "loss": 0.0,
      "step": 5592
    },
    {
      "epoch": 9.62236559139785,
      "grad_norm": 0.007832719943031915,
      "learning_rate": 7.309229638457371e-07,
      "loss": 0.0,
      "step": 5593
    },
    {
      "epoch": 9.624086021505377,
      "grad_norm": 0.0006717051474897897,
      "learning_rate": 7.242099931297874e-07,
      "loss": 0.0,
      "step": 5594
    },
    {
      "epoch": 9.625806451612902,
      "grad_norm": 0.00015250784900260986,
      "learning_rate": 7.17527879523583e-07,
      "loss": 0.0,
      "step": 5595
    },
    {
      "epoch": 9.62752688172043,
      "grad_norm": 9.034602610157581e-05,
      "learning_rate": 7.108766251040733e-07,
      "loss": 0.0,
      "step": 5596
    },
    {
      "epoch": 9.629247311827957,
      "grad_norm": 0.0002386587161111326,
      "learning_rate": 7.042562319386159e-07,
      "loss": 0.0,
      "step": 5597
    },
    {
      "epoch": 9.630967741935484,
      "grad_norm": 0.0010351517552181309,
      "learning_rate": 6.976667020849759e-07,
      "loss": 0.0,
      "step": 5598
    },
    {
      "epoch": 9.63268817204301,
      "grad_norm": 5.179892321830343e-05,
      "learning_rate": 6.911080375913148e-07,
      "loss": 0.0,
      "step": 5599
    },
    {
      "epoch": 9.634408602150538,
      "grad_norm": 0.0016870596810396998,
      "learning_rate": 6.845802404962243e-07,
      "loss": 0.0,
      "step": 5600
    },
    {
      "epoch": 9.636129032258065,
      "grad_norm": 0.0020156196797897104,
      "learning_rate": 6.780833128286812e-07,
      "loss": 0.0,
      "step": 5601
    },
    {
      "epoch": 9.637849462365592,
      "grad_norm": 0.0003065490165107671,
      "learning_rate": 6.716172566080814e-07,
      "loss": 0.0,
      "step": 5602
    },
    {
      "epoch": 9.639569892473117,
      "grad_norm": 5.8129360934584526e-05,
      "learning_rate": 6.651820738441949e-07,
      "loss": 0.0,
      "step": 5603
    },
    {
      "epoch": 9.641290322580645,
      "grad_norm": 0.006652217436435434,
      "learning_rate": 6.587777665372552e-07,
      "loss": 0.0,
      "step": 5604
    },
    {
      "epoch": 9.643010752688172,
      "grad_norm": 0.0013171150597587348,
      "learning_rate": 6.524043366778365e-07,
      "loss": 0.0,
      "step": 5605
    },
    {
      "epoch": 9.644731182795699,
      "grad_norm": 0.0011975343373976264,
      "learning_rate": 6.460617862469432e-07,
      "loss": 0.0,
      "step": 5606
    },
    {
      "epoch": 9.646451612903226,
      "grad_norm": 0.0007989467449769112,
      "learning_rate": 6.397501172159869e-07,
      "loss": 0.0,
      "step": 5607
    },
    {
      "epoch": 9.648172043010753,
      "grad_norm": 0.00026429310367645525,
      "learning_rate": 6.334693315467766e-07,
      "loss": 0.0,
      "step": 5608
    },
    {
      "epoch": 9.64989247311828,
      "grad_norm": 0.00047751287458594217,
      "learning_rate": 6.272194311915059e-07,
      "loss": 0.0,
      "step": 5609
    },
    {
      "epoch": 9.651612903225807,
      "grad_norm": 0.00012534018310386602,
      "learning_rate": 6.210004180927986e-07,
      "loss": 0.0,
      "step": 5610
    },
    {
      "epoch": 9.653333333333332,
      "grad_norm": 5.9793626236275166e-05,
      "learning_rate": 6.148122941836532e-07,
      "loss": 0.0,
      "step": 5611
    },
    {
      "epoch": 9.65505376344086,
      "grad_norm": 0.004735194689802538,
      "learning_rate": 6.086550613874753e-07,
      "loss": 0.0,
      "step": 5612
    },
    {
      "epoch": 9.656774193548387,
      "grad_norm": 0.00030010899171389204,
      "learning_rate": 6.025287216180675e-07,
      "loss": 0.0,
      "step": 5613
    },
    {
      "epoch": 9.658494623655914,
      "grad_norm": 0.0017652894803965179,
      "learning_rate": 5.964332767796399e-07,
      "loss": 0.0,
      "step": 5614
    },
    {
      "epoch": 9.66021505376344,
      "grad_norm": 0.001008282049056722,
      "learning_rate": 5.90368728766777e-07,
      "loss": 0.0,
      "step": 5615
    },
    {
      "epoch": 9.661935483870968,
      "grad_norm": 0.0013510701864930168,
      "learning_rate": 5.843350794644931e-07,
      "loss": 0.0,
      "step": 5616
    },
    {
      "epoch": 9.663655913978495,
      "grad_norm": 1.9741019906611447e-05,
      "learning_rate": 5.783323307481548e-07,
      "loss": 0.0,
      "step": 5617
    },
    {
      "epoch": 9.665376344086022,
      "grad_norm": 5.5684317034619156e-05,
      "learning_rate": 5.723604844835694e-07,
      "loss": 0.0,
      "step": 5618
    },
    {
      "epoch": 9.66709677419355,
      "grad_norm": 4.610096780218469e-05,
      "learning_rate": 5.664195425269192e-07,
      "loss": 0.0,
      "step": 5619
    },
    {
      "epoch": 9.668817204301074,
      "grad_norm": 3.7416362566032456e-05,
      "learning_rate": 5.605095067247601e-07,
      "loss": 0.0,
      "step": 5620
    },
    {
      "epoch": 9.670537634408602,
      "grad_norm": 7.987114478524595e-05,
      "learning_rate": 5.546303789140894e-07,
      "loss": 0.0,
      "step": 5621
    },
    {
      "epoch": 9.672258064516129,
      "grad_norm": 0.0011383061581626602,
      "learning_rate": 5.487821609222566e-07,
      "loss": 0.0,
      "step": 5622
    },
    {
      "epoch": 9.673978494623656,
      "grad_norm": 8.393131051811924e-05,
      "learning_rate": 5.429648545670074e-07,
      "loss": 0.0,
      "step": 5623
    },
    {
      "epoch": 9.675698924731183,
      "grad_norm": 0.0002577669300431131,
      "learning_rate": 5.371784616565068e-07,
      "loss": 0.0,
      "step": 5624
    },
    {
      "epoch": 9.67741935483871,
      "grad_norm": 0.0013753168660119526,
      "learning_rate": 5.314229839892825e-07,
      "loss": 0.0,
      "step": 5625
    },
    {
      "epoch": 9.679139784946237,
      "grad_norm": 0.0005845857535683896,
      "learning_rate": 5.256984233542595e-07,
      "loss": 0.0,
      "step": 5626
    },
    {
      "epoch": 9.680860215053764,
      "grad_norm": 0.0004062788307985221,
      "learning_rate": 5.200047815307807e-07,
      "loss": 0.0,
      "step": 5627
    },
    {
      "epoch": 9.682580645161291,
      "grad_norm": 0.0014415425104922221,
      "learning_rate": 5.143420602885308e-07,
      "loss": 0.0,
      "step": 5628
    },
    {
      "epoch": 9.684301075268817,
      "grad_norm": 0.0003246273980369536,
      "learning_rate": 5.087102613876127e-07,
      "loss": 0.0,
      "step": 5629
    },
    {
      "epoch": 9.686021505376344,
      "grad_norm": 0.0006239942087859506,
      "learning_rate": 5.031093865785263e-07,
      "loss": 0.0,
      "step": 5630
    },
    {
      "epoch": 9.68774193548387,
      "grad_norm": 1.670567183459273e-05,
      "learning_rate": 4.975394376021458e-07,
      "loss": 0.0,
      "step": 5631
    },
    {
      "epoch": 9.689462365591398,
      "grad_norm": 8.20029068923718e-05,
      "learning_rate": 4.920004161897196e-07,
      "loss": 0.0,
      "step": 5632
    },
    {
      "epoch": 9.691182795698925,
      "grad_norm": 0.0007685426989264808,
      "learning_rate": 4.864923240629149e-07,
      "loss": 0.0,
      "step": 5633
    },
    {
      "epoch": 9.692903225806452,
      "grad_norm": 1.4948489542768759e-05,
      "learning_rate": 4.810151629337622e-07,
      "loss": 0.0,
      "step": 5634
    },
    {
      "epoch": 9.69462365591398,
      "grad_norm": 0.00011856661592499908,
      "learning_rate": 4.7556893450466653e-07,
      "loss": 0.0,
      "step": 5635
    },
    {
      "epoch": 9.696344086021504,
      "grad_norm": 0.00016565155219107984,
      "learning_rate": 4.701536404684737e-07,
      "loss": 0.0,
      "step": 5636
    },
    {
      "epoch": 9.698064516129032,
      "grad_norm": 9.794270980136828e-05,
      "learning_rate": 4.647692825083483e-07,
      "loss": 0.0,
      "step": 5637
    },
    {
      "epoch": 9.699784946236559,
      "grad_norm": 0.0006643348148646976,
      "learning_rate": 4.594158622978739e-07,
      "loss": 0.0,
      "step": 5638
    },
    {
      "epoch": 9.701505376344086,
      "grad_norm": 0.006847591267541099,
      "learning_rate": 4.5409338150101956e-07,
      "loss": 0.0,
      "step": 5639
    },
    {
      "epoch": 9.703225806451613,
      "grad_norm": 7.592114951445397e-05,
      "learning_rate": 4.4880184177210627e-07,
      "loss": 0.0,
      "step": 5640
    },
    {
      "epoch": 9.70494623655914,
      "grad_norm": 0.0018081905492899305,
      "learning_rate": 4.435412447558962e-07,
      "loss": 0.0,
      "step": 5641
    },
    {
      "epoch": 9.706666666666667,
      "grad_norm": 6.197949579035038e-05,
      "learning_rate": 4.383115920874814e-07,
      "loss": 0.0,
      "step": 5642
    },
    {
      "epoch": 9.708387096774194,
      "grad_norm": 1.0179531003847782e-05,
      "learning_rate": 4.331128853923394e-07,
      "loss": 0.0,
      "step": 5643
    },
    {
      "epoch": 9.710107526881721,
      "grad_norm": 0.0021883785101375047,
      "learning_rate": 4.279451262863665e-07,
      "loss": 0.0,
      "step": 5644
    },
    {
      "epoch": 9.711827956989247,
      "grad_norm": 4.763603825674427e-05,
      "learning_rate": 4.228083163758112e-07,
      "loss": 0.0,
      "step": 5645
    },
    {
      "epoch": 9.713548387096774,
      "grad_norm": 0.000855829402587787,
      "learning_rate": 4.177024572573074e-07,
      "loss": 0.0,
      "step": 5646
    },
    {
      "epoch": 9.7152688172043,
      "grad_norm": 0.00019302482729463254,
      "learning_rate": 4.126275505178523e-07,
      "loss": 0.0,
      "step": 5647
    },
    {
      "epoch": 9.716989247311828,
      "grad_norm": 0.0015160220979271123,
      "learning_rate": 4.075835977348619e-07,
      "loss": 0.0,
      "step": 5648
    },
    {
      "epoch": 9.718709677419355,
      "grad_norm": 8.673490358882973e-06,
      "learning_rate": 4.025706004760932e-07,
      "loss": 0.0,
      "step": 5649
    },
    {
      "epoch": 9.720430107526882,
      "grad_norm": 0.0018431674611604579,
      "learning_rate": 3.9758856029971093e-07,
      "loss": 0.0,
      "step": 5650
    },
    {
      "epoch": 9.722150537634409,
      "grad_norm": 0.00022672215614016097,
      "learning_rate": 3.92637478754232e-07,
      "loss": 0.0,
      "step": 5651
    },
    {
      "epoch": 9.723870967741936,
      "grad_norm": 0.00018147300230279747,
      "learning_rate": 3.8771735737855864e-07,
      "loss": 0.0,
      "step": 5652
    },
    {
      "epoch": 9.725591397849463,
      "grad_norm": 0.0007683670488771529,
      "learning_rate": 3.8282819770197873e-07,
      "loss": 0.0,
      "step": 5653
    },
    {
      "epoch": 9.727311827956989,
      "grad_norm": 0.003670695443108741,
      "learning_rate": 3.779700012441545e-07,
      "loss": 0.0,
      "step": 5654
    },
    {
      "epoch": 9.729032258064516,
      "grad_norm": 0.001408215074665973,
      "learning_rate": 3.731427695151224e-07,
      "loss": 0.0,
      "step": 5655
    },
    {
      "epoch": 9.730752688172043,
      "grad_norm": 6.579822623658408e-05,
      "learning_rate": 3.6834650401528223e-07,
      "loss": 0.0,
      "step": 5656
    },
    {
      "epoch": 9.73247311827957,
      "grad_norm": 0.0002111050300867874,
      "learning_rate": 3.6358120623541937e-07,
      "loss": 0.0,
      "step": 5657
    },
    {
      "epoch": 9.734193548387097,
      "grad_norm": 7.21078616323711e-05,
      "learning_rate": 3.5884687765671556e-07,
      "loss": 0.0,
      "step": 5658
    },
    {
      "epoch": 9.735913978494624,
      "grad_norm": 0.00041656588029330866,
      "learning_rate": 3.541435197506715e-07,
      "loss": 0.0,
      "step": 5659
    },
    {
      "epoch": 9.737634408602151,
      "grad_norm": 2.56223175366811e-05,
      "learning_rate": 3.494711339792289e-07,
      "loss": 0.0,
      "step": 5660
    },
    {
      "epoch": 9.739354838709678,
      "grad_norm": 4.639620145669875e-05,
      "learning_rate": 3.4482972179463723e-07,
      "loss": 0.0,
      "step": 5661
    },
    {
      "epoch": 9.741075268817204,
      "grad_norm": 3.9887284666725655e-06,
      "learning_rate": 3.4021928463957574e-07,
      "loss": 0.0,
      "step": 5662
    },
    {
      "epoch": 9.74279569892473,
      "grad_norm": 0.00023556956749913157,
      "learning_rate": 3.3563982394704266e-07,
      "loss": 0.0,
      "step": 5663
    },
    {
      "epoch": 9.744516129032258,
      "grad_norm": 0.002434505585024453,
      "learning_rate": 3.3109134114046594e-07,
      "loss": 0.0,
      "step": 5664
    },
    {
      "epoch": 9.746236559139785,
      "grad_norm": 0.001005452659195614,
      "learning_rate": 3.265738376335925e-07,
      "loss": 0.0,
      "step": 5665
    },
    {
      "epoch": 9.747956989247312,
      "grad_norm": 8.525679489718087e-05,
      "learning_rate": 3.22087314830577e-07,
      "loss": 0.0,
      "step": 5666
    },
    {
      "epoch": 9.749677419354839,
      "grad_norm": 0.004101701026170693,
      "learning_rate": 3.1763177412592605e-07,
      "loss": 0.0,
      "step": 5667
    },
    {
      "epoch": 9.751397849462366,
      "grad_norm": 0.00012999108335348715,
      "learning_rate": 3.1320721690450974e-07,
      "loss": 0.0,
      "step": 5668
    },
    {
      "epoch": 9.753118279569893,
      "grad_norm": 0.0006079552684108722,
      "learning_rate": 3.0881364454158345e-07,
      "loss": 0.0,
      "step": 5669
    },
    {
      "epoch": 9.754838709677419,
      "grad_norm": 0.0006289391915920672,
      "learning_rate": 3.044510584027771e-07,
      "loss": 0.0,
      "step": 5670
    },
    {
      "epoch": 9.756559139784946,
      "grad_norm": 0.0008073600242778644,
      "learning_rate": 3.001194598440615e-07,
      "loss": 0.0,
      "step": 5671
    },
    {
      "epoch": 9.758279569892473,
      "grad_norm": 0.0002815722660486838,
      "learning_rate": 2.9581885021181533e-07,
      "loss": 0.0,
      "step": 5672
    },
    {
      "epoch": 9.76,
      "grad_norm": 7.090166810821731e-05,
      "learning_rate": 2.915492308427359e-07,
      "loss": 0.0,
      "step": 5673
    },
    {
      "epoch": 9.761720430107527,
      "grad_norm": 3.568245670107274e-05,
      "learning_rate": 2.873106030639394e-07,
      "loss": 0.0,
      "step": 5674
    },
    {
      "epoch": 9.763440860215054,
      "grad_norm": 5.4022088458619606e-05,
      "learning_rate": 2.8310296819287206e-07,
      "loss": 0.0,
      "step": 5675
    },
    {
      "epoch": 9.765161290322581,
      "grad_norm": 0.0002419593488126208,
      "learning_rate": 2.7892632753735435e-07,
      "loss": 0.0,
      "step": 5676
    },
    {
      "epoch": 9.766881720430108,
      "grad_norm": 0.00028737110629220076,
      "learning_rate": 2.747806823956034e-07,
      "loss": 0.0,
      "step": 5677
    },
    {
      "epoch": 9.768602150537635,
      "grad_norm": 0.002374038150621662,
      "learning_rate": 2.706660340561551e-07,
      "loss": 0.0,
      "step": 5678
    },
    {
      "epoch": 9.77032258064516,
      "grad_norm": 0.000688238184256325,
      "learning_rate": 2.665823837979309e-07,
      "loss": 0.0,
      "step": 5679
    },
    {
      "epoch": 9.772043010752688,
      "grad_norm": 0.000617864670907334,
      "learning_rate": 2.6252973289022654e-07,
      "loss": 0.0,
      "step": 5680
    },
    {
      "epoch": 9.773763440860215,
      "grad_norm": 7.996056402617658e-06,
      "learning_rate": 2.585080825927122e-07,
      "loss": 0.0,
      "step": 5681
    },
    {
      "epoch": 9.775483870967742,
      "grad_norm": 0.0004385624440009584,
      "learning_rate": 2.5451743415537685e-07,
      "loss": 0.0,
      "step": 5682
    },
    {
      "epoch": 9.777204301075269,
      "grad_norm": 0.00022639080690799233,
      "learning_rate": 2.5055778881861723e-07,
      "loss": 0.0,
      "step": 5683
    },
    {
      "epoch": 9.778924731182796,
      "grad_norm": 0.006297386107929962,
      "learning_rate": 2.4662914781318213e-07,
      "loss": 0.0,
      "step": 5684
    },
    {
      "epoch": 9.780645161290323,
      "grad_norm": 7.707824093435227e-06,
      "learning_rate": 2.4273151236017253e-07,
      "loss": 0.0,
      "step": 5685
    },
    {
      "epoch": 9.78236559139785,
      "grad_norm": 0.00035854910159924616,
      "learning_rate": 2.3886488367106385e-07,
      "loss": 0.0,
      "step": 5686
    },
    {
      "epoch": 9.784086021505376,
      "grad_norm": 0.0001602875339777211,
      "learning_rate": 2.3502926294768357e-07,
      "loss": 0.0,
      "step": 5687
    },
    {
      "epoch": 9.785806451612903,
      "grad_norm": 0.0006001549487287333,
      "learning_rate": 2.3122465138223358e-07,
      "loss": 0.0,
      "step": 5688
    },
    {
      "epoch": 9.78752688172043,
      "grad_norm": 0.0007367673949703429,
      "learning_rate": 2.2745105015726798e-07,
      "loss": 0.0,
      "step": 5689
    },
    {
      "epoch": 9.789247311827957,
      "grad_norm": 0.001028024952783947,
      "learning_rate": 2.2370846044570403e-07,
      "loss": 0.0,
      "step": 5690
    },
    {
      "epoch": 9.790967741935484,
      "grad_norm": 0.0004893855254233932,
      "learning_rate": 2.1999688341083346e-07,
      "loss": 0.0,
      "step": 5691
    },
    {
      "epoch": 9.792688172043011,
      "grad_norm": 9.492358956344515e-05,
      "learning_rate": 2.163163202062779e-07,
      "loss": 0.0,
      "step": 5692
    },
    {
      "epoch": 9.794408602150538,
      "grad_norm": 0.0012317458684651267,
      "learning_rate": 2.1266677197604445e-07,
      "loss": 0.0,
      "step": 5693
    },
    {
      "epoch": 9.796129032258065,
      "grad_norm": 3.35467557401865e-05,
      "learning_rate": 2.0904823985450351e-07,
      "loss": 0.0,
      "step": 5694
    },
    {
      "epoch": 9.79784946236559,
      "grad_norm": 0.0003413086995924012,
      "learning_rate": 2.054607249663665e-07,
      "loss": 0.0,
      "step": 5695
    },
    {
      "epoch": 9.799569892473118,
      "grad_norm": 0.0008662848475181256,
      "learning_rate": 2.0190422842670808e-07,
      "loss": 0.0,
      "step": 5696
    },
    {
      "epoch": 9.801290322580645,
      "grad_norm": 0.0007406239431064353,
      "learning_rate": 1.9837875134097738e-07,
      "loss": 0.0,
      "step": 5697
    },
    {
      "epoch": 9.803010752688172,
      "grad_norm": 0.0005243433300044419,
      "learning_rate": 1.948842948049534e-07,
      "loss": 0.0,
      "step": 5698
    },
    {
      "epoch": 9.804731182795699,
      "grad_norm": 0.002319005818780934,
      "learning_rate": 1.9142085990481173e-07,
      "loss": 0.0,
      "step": 5699
    },
    {
      "epoch": 9.806451612903226,
      "grad_norm": 0.000582403718829345,
      "learning_rate": 1.8798844771704683e-07,
      "loss": 0.0,
      "step": 5700
    },
    {
      "epoch": 9.808172043010753,
      "grad_norm": 1.8605666222672203e-05,
      "learning_rate": 1.8458705930854968e-07,
      "loss": 0.0,
      "step": 5701
    },
    {
      "epoch": 9.80989247311828,
      "grad_norm": 0.0023716267593518123,
      "learning_rate": 1.812166957365191e-07,
      "loss": 0.0,
      "step": 5702
    },
    {
      "epoch": 9.811612903225807,
      "grad_norm": 0.00433272153501803,
      "learning_rate": 1.7787735804855045e-07,
      "loss": 0.0,
      "step": 5703
    },
    {
      "epoch": 9.813333333333333,
      "grad_norm": 0.0032573651841615587,
      "learning_rate": 1.7456904728259115e-07,
      "loss": 0.0,
      "step": 5704
    },
    {
      "epoch": 9.81505376344086,
      "grad_norm": 0.0002796180443463861,
      "learning_rate": 1.7129176446692984e-07,
      "loss": 0.0,
      "step": 5705
    },
    {
      "epoch": 9.816774193548387,
      "grad_norm": 0.0003809662713119375,
      "learning_rate": 1.6804551062021835e-07,
      "loss": 0.0,
      "step": 5706
    },
    {
      "epoch": 9.818494623655914,
      "grad_norm": 0.00011628954945750154,
      "learning_rate": 1.6483028675147173e-07,
      "loss": 0.0,
      "step": 5707
    },
    {
      "epoch": 9.820215053763441,
      "grad_norm": 0.02010481283550274,
      "learning_rate": 1.6164609386003505e-07,
      "loss": 0.0,
      "step": 5708
    },
    {
      "epoch": 9.821935483870968,
      "grad_norm": 0.0008656076506676051,
      "learning_rate": 1.5849293293564994e-07,
      "loss": 0.0,
      "step": 5709
    },
    {
      "epoch": 9.823655913978495,
      "grad_norm": 0.0008686559835450369,
      "learning_rate": 1.5537080495836577e-07,
      "loss": 0.0,
      "step": 5710
    },
    {
      "epoch": 9.825376344086022,
      "grad_norm": 0.00016643450528683708,
      "learning_rate": 1.5227971089862847e-07,
      "loss": 0.0,
      "step": 5711
    },
    {
      "epoch": 9.82709677419355,
      "grad_norm": 0.00015794989593057208,
      "learning_rate": 1.4921965171720287e-07,
      "loss": 0.0,
      "step": 5712
    },
    {
      "epoch": 9.828817204301075,
      "grad_norm": 9.816218107284961e-05,
      "learning_rate": 1.4619062836522813e-07,
      "loss": 0.0,
      "step": 5713
    },
    {
      "epoch": 9.830537634408602,
      "grad_norm": 0.002075518734742875,
      "learning_rate": 1.4319264178419557e-07,
      "loss": 0.0,
      "step": 5714
    },
    {
      "epoch": 9.832258064516129,
      "grad_norm": 9.135214760894806e-05,
      "learning_rate": 1.4022569290594866e-07,
      "loss": 0.0,
      "step": 5715
    },
    {
      "epoch": 9.833978494623656,
      "grad_norm": 7.248906371351084e-05,
      "learning_rate": 1.372897826526609e-07,
      "loss": 0.0,
      "step": 5716
    },
    {
      "epoch": 9.835698924731183,
      "grad_norm": 0.0001979445450645633,
      "learning_rate": 1.3438491193690229e-07,
      "loss": 0.0,
      "step": 5717
    },
    {
      "epoch": 9.83741935483871,
      "grad_norm": 0.00027412632208786373,
      "learning_rate": 1.3151108166156168e-07,
      "loss": 0.0,
      "step": 5718
    },
    {
      "epoch": 9.839139784946237,
      "grad_norm": 0.0006459335259271181,
      "learning_rate": 1.2866829271989124e-07,
      "loss": 0.0,
      "step": 5719
    },
    {
      "epoch": 9.840860215053763,
      "grad_norm": 0.000322443985996611,
      "learning_rate": 1.2585654599548413e-07,
      "loss": 0.0,
      "step": 5720
    },
    {
      "epoch": 9.84258064516129,
      "grad_norm": 8.725959348437433e-05,
      "learning_rate": 1.2307584236229687e-07,
      "loss": 0.0,
      "step": 5721
    },
    {
      "epoch": 9.844301075268817,
      "grad_norm": 1.4539841903024857e-05,
      "learning_rate": 1.2032618268463803e-07,
      "loss": 0.0,
      "step": 5722
    },
    {
      "epoch": 9.846021505376344,
      "grad_norm": 1.5036268724697652e-05,
      "learning_rate": 1.1760756781715732e-07,
      "loss": 0.0,
      "step": 5723
    },
    {
      "epoch": 9.847741935483871,
      "grad_norm": 0.0035488738066815195,
      "learning_rate": 1.1491999860486769e-07,
      "loss": 0.0,
      "step": 5724
    },
    {
      "epoch": 9.849462365591398,
      "grad_norm": 0.0025893269132057023,
      "learning_rate": 1.1226347588311203e-07,
      "loss": 0.0,
      "step": 5725
    },
    {
      "epoch": 9.851182795698925,
      "grad_norm": 0.0009234264766575298,
      "learning_rate": 1.0963800047760763e-07,
      "loss": 0.0,
      "step": 5726
    },
    {
      "epoch": 9.852903225806452,
      "grad_norm": 8.184498533601747e-05,
      "learning_rate": 1.0704357320441282e-07,
      "loss": 0.0,
      "step": 5727
    },
    {
      "epoch": 9.85462365591398,
      "grad_norm": 0.0008036943814431769,
      "learning_rate": 1.04480194869927e-07,
      "loss": 0.0,
      "step": 5728
    },
    {
      "epoch": 9.856344086021505,
      "grad_norm": 0.0016602763161148652,
      "learning_rate": 1.0194786627090169e-07,
      "loss": 0.0,
      "step": 5729
    },
    {
      "epoch": 9.858064516129032,
      "grad_norm": 0.007247980274489249,
      "learning_rate": 9.944658819444064e-08,
      "loss": 0.0,
      "step": 5730
    },
    {
      "epoch": 9.859784946236559,
      "grad_norm": 8.935294253045595e-06,
      "learning_rate": 9.69763614180108e-08,
      "loss": 0.0,
      "step": 5731
    },
    {
      "epoch": 9.861505376344086,
      "grad_norm": 7.183229687289633e-05,
      "learning_rate": 9.453718670939804e-08,
      "loss": 0.0,
      "step": 5732
    },
    {
      "epoch": 9.863225806451613,
      "grad_norm": 0.000985252332068912,
      "learning_rate": 9.212906482675143e-08,
      "loss": 0.0,
      "step": 5733
    },
    {
      "epoch": 9.86494623655914,
      "grad_norm": 0.00036995854047863346,
      "learning_rate": 8.975199651857225e-08,
      "loss": 0.0,
      "step": 5734
    },
    {
      "epoch": 9.866666666666667,
      "grad_norm": 0.0042404727817020905,
      "learning_rate": 8.74059825237139e-08,
      "loss": 0.0,
      "step": 5735
    },
    {
      "epoch": 9.868387096774194,
      "grad_norm": 3.186604279027624e-05,
      "learning_rate": 8.509102357134868e-08,
      "loss": 0.0,
      "step": 5736
    },
    {
      "epoch": 9.870107526881721,
      "grad_norm": 6.279306623058778e-05,
      "learning_rate": 8.280712038104543e-08,
      "loss": 0.0,
      "step": 5737
    },
    {
      "epoch": 9.871827956989247,
      "grad_norm": 0.002475936011924737,
      "learning_rate": 8.055427366266965e-08,
      "loss": 0.0,
      "step": 5738
    },
    {
      "epoch": 9.873548387096774,
      "grad_norm": 0.0016643592989276014,
      "learning_rate": 7.833248411646122e-08,
      "loss": 0.0,
      "step": 5739
    },
    {
      "epoch": 9.8752688172043,
      "grad_norm": 1.8221385535549094e-05,
      "learning_rate": 7.614175243301213e-08,
      "loss": 0.0,
      "step": 5740
    },
    {
      "epoch": 9.876989247311828,
      "grad_norm": 0.0010833290482802382,
      "learning_rate": 7.39820792932333e-08,
      "loss": 0.0,
      "step": 5741
    },
    {
      "epoch": 9.878709677419355,
      "grad_norm": 0.0004830101850914681,
      "learning_rate": 7.185346536840997e-08,
      "loss": 0.0,
      "step": 5742
    },
    {
      "epoch": 9.880430107526882,
      "grad_norm": 0.0008495944583665276,
      "learning_rate": 6.975591132015736e-08,
      "loss": 0.0,
      "step": 5743
    },
    {
      "epoch": 9.88215053763441,
      "grad_norm": 0.0007804698014722075,
      "learning_rate": 6.76894178004428e-08,
      "loss": 0.0,
      "step": 5744
    },
    {
      "epoch": 9.883870967741936,
      "grad_norm": 8.520675092038196e-05,
      "learning_rate": 6.565398545158585e-08,
      "loss": 0.0,
      "step": 5745
    },
    {
      "epoch": 9.885591397849462,
      "grad_norm": 0.00017849428836082376,
      "learning_rate": 6.3649614906236e-08,
      "loss": 0.0,
      "step": 5746
    },
    {
      "epoch": 9.887311827956989,
      "grad_norm": 0.0005068661216671192,
      "learning_rate": 6.16763067873949e-08,
      "loss": 0.0,
      "step": 5747
    },
    {
      "epoch": 9.889032258064516,
      "grad_norm": 4.72590265357472e-05,
      "learning_rate": 5.973406170840523e-08,
      "loss": 0.0,
      "step": 5748
    },
    {
      "epoch": 9.890752688172043,
      "grad_norm": 0.0004356496204352524,
      "learning_rate": 5.7822880272973e-08,
      "loss": 0.0,
      "step": 5749
    },
    {
      "epoch": 9.89247311827957,
      "grad_norm": 5.06050768603663e-05,
      "learning_rate": 5.594276307513413e-08,
      "loss": 0.0,
      "step": 5750
    },
    {
      "epoch": 9.894193548387097,
      "grad_norm": 0.0002157887814824039,
      "learning_rate": 5.4093710699254505e-08,
      "loss": 0.0,
      "step": 5751
    },
    {
      "epoch": 9.895913978494624,
      "grad_norm": 0.0016078061571073675,
      "learning_rate": 5.227572372007439e-08,
      "loss": 0.0,
      "step": 5752
    },
    {
      "epoch": 9.897634408602151,
      "grad_norm": 0.0012109982373493672,
      "learning_rate": 5.048880270266398e-08,
      "loss": 0.0,
      "step": 5753
    },
    {
      "epoch": 9.899354838709677,
      "grad_norm": 0.00030858725586731023,
      "learning_rate": 4.873294820244567e-08,
      "loss": 0.0,
      "step": 5754
    },
    {
      "epoch": 9.901075268817204,
      "grad_norm": 6.39968484505861e-05,
      "learning_rate": 4.700816076516068e-08,
      "loss": 0.0,
      "step": 5755
    },
    {
      "epoch": 9.90279569892473,
      "grad_norm": 0.000698984711733072,
      "learning_rate": 4.531444092691351e-08,
      "loss": 0.0,
      "step": 5756
    },
    {
      "epoch": 9.904516129032258,
      "grad_norm": 0.0003618925803491216,
      "learning_rate": 4.36517892141608e-08,
      "loss": 0.0,
      "step": 5757
    },
    {
      "epoch": 9.906236559139785,
      "grad_norm": 0.0002233409244287211,
      "learning_rate": 4.202020614367808e-08,
      "loss": 0.0,
      "step": 5758
    },
    {
      "epoch": 9.907956989247312,
      "grad_norm": 0.006755526523271631,
      "learning_rate": 4.041969222260411e-08,
      "loss": 0.0,
      "step": 5759
    },
    {
      "epoch": 9.90967741935484,
      "grad_norm": 0.00031171712113810376,
      "learning_rate": 3.885024794841874e-08,
      "loss": 0.0,
      "step": 5760
    },
    {
      "epoch": 9.911397849462366,
      "grad_norm": 2.8129599571070406e-05,
      "learning_rate": 3.731187380893175e-08,
      "loss": 0.0,
      "step": 5761
    },
    {
      "epoch": 9.913118279569893,
      "grad_norm": 0.0008170105003106285,
      "learning_rate": 3.580457028231621e-08,
      "loss": 0.0,
      "step": 5762
    },
    {
      "epoch": 9.914838709677419,
      "grad_norm": 0.006103971773853701,
      "learning_rate": 3.432833783706402e-08,
      "loss": 0.0,
      "step": 5763
    },
    {
      "epoch": 9.916559139784946,
      "grad_norm": 0.00021431067491492928,
      "learning_rate": 3.288317693201926e-08,
      "loss": 0.0,
      "step": 5764
    },
    {
      "epoch": 9.918279569892473,
      "grad_norm": 0.0005496181032649397,
      "learning_rate": 3.1469088016378153e-08,
      "loss": 0.0,
      "step": 5765
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.0023343287070209558,
      "learning_rate": 3.008607152965581e-08,
      "loss": 0.0,
      "step": 5766
    },
    {
      "epoch": 9.921720430107527,
      "grad_norm": 3.670933087149034e-05,
      "learning_rate": 2.8734127901752783e-08,
      "loss": 0.0,
      "step": 5767
    },
    {
      "epoch": 9.923440860215054,
      "grad_norm": 0.0009537261994437909,
      "learning_rate": 2.7413257552855177e-08,
      "loss": 0.0,
      "step": 5768
    },
    {
      "epoch": 9.925161290322581,
      "grad_norm": 0.0007188265360987358,
      "learning_rate": 2.6123460893523465e-08,
      "loss": 0.0,
      "step": 5769
    },
    {
      "epoch": 9.926881720430108,
      "grad_norm": 5.206675289669583e-05,
      "learning_rate": 2.486473832467029e-08,
      "loss": 0.0,
      "step": 5770
    },
    {
      "epoch": 9.928602150537634,
      "grad_norm": 0.0010007156867408366,
      "learning_rate": 2.3637090237527137e-08,
      "loss": 0.0,
      "step": 5771
    },
    {
      "epoch": 9.93032258064516,
      "grad_norm": 0.0002598897129754847,
      "learning_rate": 2.2440517013666563e-08,
      "loss": 0.0,
      "step": 5772
    },
    {
      "epoch": 9.932043010752688,
      "grad_norm": 0.00889751440034111,
      "learning_rate": 2.1275019025013276e-08,
      "loss": 0.0,
      "step": 5773
    },
    {
      "epoch": 9.933763440860215,
      "grad_norm": 0.0025177945280411467,
      "learning_rate": 2.0140596633833052e-08,
      "loss": 0.0,
      "step": 5774
    },
    {
      "epoch": 9.935483870967742,
      "grad_norm": 0.0004898053100322321,
      "learning_rate": 1.9037250192732726e-08,
      "loss": 0.0,
      "step": 5775
    },
    {
      "epoch": 9.937204301075269,
      "grad_norm": 0.0001493832816238789,
      "learning_rate": 1.796498004463798e-08,
      "loss": 0.0,
      "step": 5776
    },
    {
      "epoch": 9.938924731182796,
      "grad_norm": 0.00026903667790857254,
      "learning_rate": 1.6923786522859973e-08,
      "loss": 0.0,
      "step": 5777
    },
    {
      "epoch": 9.940645161290323,
      "grad_norm": 0.0006319545852868547,
      "learning_rate": 1.5913669951017617e-08,
      "loss": 0.0,
      "step": 5778
    },
    {
      "epoch": 9.942365591397849,
      "grad_norm": 0.0010603264556427417,
      "learning_rate": 1.4934630643059776e-08,
      "loss": 0.0,
      "step": 5779
    },
    {
      "epoch": 9.944086021505376,
      "grad_norm": 0.001580103675354115,
      "learning_rate": 1.3986668903320788e-08,
      "loss": 0.0,
      "step": 5780
    },
    {
      "epoch": 9.945806451612903,
      "grad_norm": 0.0006220825779110196,
      "learning_rate": 1.3069785026420534e-08,
      "loss": 0.0,
      "step": 5781
    },
    {
      "epoch": 9.94752688172043,
      "grad_norm": 0.00029099590936144053,
      "learning_rate": 1.2183979297364368e-08,
      "loss": 0.0,
      "step": 5782
    },
    {
      "epoch": 9.949247311827957,
      "grad_norm": 0.00014950346677895622,
      "learning_rate": 1.1329251991476497e-08,
      "loss": 0.0,
      "step": 5783
    },
    {
      "epoch": 9.950967741935484,
      "grad_norm": 0.0003198420134455054,
      "learning_rate": 1.0505603374433292e-08,
      "loss": 0.0,
      "step": 5784
    },
    {
      "epoch": 9.952688172043011,
      "grad_norm": 0.0006866217098096313,
      "learning_rate": 9.713033702218877e-09,
      "loss": 0.0,
      "step": 5785
    },
    {
      "epoch": 9.954408602150538,
      "grad_norm": 1.559642533603103e-05,
      "learning_rate": 8.951543221213943e-09,
      "loss": 0.0,
      "step": 5786
    },
    {
      "epoch": 9.956129032258065,
      "grad_norm": 0.0006812450357325989,
      "learning_rate": 8.221132168073631e-09,
      "loss": 0.0,
      "step": 5787
    },
    {
      "epoch": 9.95784946236559,
      "grad_norm": 0.00016211568413099613,
      "learning_rate": 7.521800769849651e-09,
      "loss": 0.0,
      "step": 5788
    },
    {
      "epoch": 9.959569892473118,
      "grad_norm": 0.00037632316315821493,
      "learning_rate": 6.8535492439014694e-09,
      "loss": 0.0,
      "step": 5789
    },
    {
      "epoch": 9.961290322580645,
      "grad_norm": 0.0023491776058271615,
      "learning_rate": 6.216377797929606e-09,
      "loss": 0.0,
      "step": 5790
    },
    {
      "epoch": 9.963010752688172,
      "grad_norm": 3.459094435122699e-05,
      "learning_rate": 5.610286629997852e-09,
      "loss": 0.0,
      "step": 5791
    },
    {
      "epoch": 9.964731182795699,
      "grad_norm": 0.00019690547912107635,
      "learning_rate": 5.035275928477745e-09,
      "loss": 0.0,
      "step": 5792
    },
    {
      "epoch": 9.966451612903226,
      "grad_norm": 0.0006423764895902823,
      "learning_rate": 4.491345872104091e-09,
      "loss": 0.0,
      "step": 5793
    },
    {
      "epoch": 9.968172043010753,
      "grad_norm": 0.0002693569011301418,
      "learning_rate": 3.978496629930551e-09,
      "loss": 0.0,
      "step": 5794
    },
    {
      "epoch": 9.96989247311828,
      "grad_norm": 0.0006395877424090557,
      "learning_rate": 3.4967283613740466e-09,
      "loss": 0.0,
      "step": 5795
    },
    {
      "epoch": 9.971612903225806,
      "grad_norm": 4.032682920066029e-05,
      "learning_rate": 3.046041216181461e-09,
      "loss": 0.0,
      "step": 5796
    },
    {
      "epoch": 9.973333333333333,
      "grad_norm": 2.6989239040855573e-05,
      "learning_rate": 2.626435334418531e-09,
      "loss": 0.0,
      "step": 5797
    },
    {
      "epoch": 9.97505376344086,
      "grad_norm": 0.0027055213837083093,
      "learning_rate": 2.2379108465253596e-09,
      "loss": 0.0,
      "step": 5798
    },
    {
      "epoch": 9.976774193548387,
      "grad_norm": 0.0020787327830240517,
      "learning_rate": 1.880467873260905e-09,
      "loss": 0.0,
      "step": 5799
    },
    {
      "epoch": 9.978494623655914,
      "grad_norm": 9.383464005870117e-05,
      "learning_rate": 1.554106525714083e-09,
      "loss": 0.0,
      "step": 5800
    },
    {
      "epoch": 9.980215053763441,
      "grad_norm": 0.0004346073766726723,
      "learning_rate": 1.258826905348176e-09,
      "loss": 0.0,
      "step": 5801
    },
    {
      "epoch": 9.981935483870968,
      "grad_norm": 0.003495410032615055,
      "learning_rate": 9.94629103923117e-10,
      "loss": 0.0,
      "step": 5802
    },
    {
      "epoch": 9.983655913978495,
      "grad_norm": 0.0014560433102548422,
      "learning_rate": 7.615132035510008e-10,
      "loss": 0.0,
      "step": 5803
    },
    {
      "epoch": 9.98537634408602,
      "grad_norm": 0.0010392693013401726,
      "learning_rate": 5.594792767182888e-10,
      "loss": 0.0,
      "step": 5804
    },
    {
      "epoch": 9.987096774193548,
      "grad_norm": 3.589540635777949e-05,
      "learning_rate": 3.885273861969907e-10,
      "loss": 0.0,
      "step": 5805
    },
    {
      "epoch": 9.988817204301075,
      "grad_norm": 0.0002185528096698761,
      "learning_rate": 2.486575851334827e-10,
      "loss": 0.0,
      "step": 5806
    },
    {
      "epoch": 9.990537634408602,
      "grad_norm": 0.00031571295879969345,
      "learning_rate": 1.3986991699299624e-10,
      "loss": 0.0,
      "step": 5807
    },
    {
      "epoch": 9.992258064516129,
      "grad_norm": 0.004863154552950571,
      "learning_rate": 6.216441560402686e-11,
      "loss": 0.0,
      "step": 5808
    },
    {
      "epoch": 9.993978494623656,
      "grad_norm": 0.0018278422603552067,
      "learning_rate": 1.554110511392537e-11,
      "loss": 0.0,
      "step": 5809
    },
    {
      "epoch": 9.995698924731183,
      "grad_norm": 0.00043244496258817403,
      "learning_rate": 0.0,
      "loss": 0.0,
      "step": 5810
    },
    {
      "epoch": 9.995698924731183,
      "step": 5810,
      "total_flos": 2968457249259520.0,
      "train_loss": 0.04289107832662156,
      "train_runtime": 132398.7914,
      "train_samples_per_second": 1.404,
      "train_steps_per_second": 0.044
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 5810,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2968457249259520.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
