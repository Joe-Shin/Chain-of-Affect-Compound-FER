{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/station_01/anaconda3/envs/phi3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoProcessor, AutoConfig\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "setattr(torch.nn.Linear, \"reset_parameters\", lambda self: None)\n",
    "setattr(torch.nn.LayerNorm, \"reset_parameters\", lambda self: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'output/lora_vision_all_ft_only'\n",
    "model_base = 'microsoft/Phi-3.5-vision-instruct'\n",
    "\n",
    "model_paths = model_path.split(\"/\")\n",
    "model_name = model_paths[-1]\n",
    "\n",
    "load_8bit=False\n",
    "load_4bit=False\n",
    "device_map=\"auto\"\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoProcessor, AutoConfig\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "def disable_torch_init():\n",
    "    \"\"\"\n",
    "    Disable the redundant torch default initialization to accelerate model creation.\n",
    "    \"\"\"\n",
    "    setattr(torch.nn.Linear, \"reset_parameters\", lambda self: None)\n",
    "    setattr(torch.nn.LayerNorm, \"reset_parameters\", lambda self: None)\n",
    "\n",
    "# This code is borrowed from LLaVA\n",
    "def load_pretrained_model(model_path, model_base, model_name, load_8bit=False, load_4bit=False, \n",
    "                          device_map=\"auto\", device=\"cuda\", use_flash_attn=False, **kwargs):\n",
    "    kwargs = {\"device_map\": device_map}\n",
    "    \n",
    "    if device != \"cuda\":\n",
    "        kwargs['device_map'] = {\"\":device}\n",
    "    \n",
    "    if load_8bit:\n",
    "        kwargs['load_in_8bit'] = True\n",
    "    elif load_4bit:\n",
    "        kwargs['quantization_config'] = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type='nf4'\n",
    "        )\n",
    "    else:\n",
    "        kwargs['torch_dtype'] = torch.float16\n",
    "\n",
    "    #if use_flash_attn:\n",
    "    #    kwargs['_attn_implementation'] = 'flash_attention_2'\n",
    "\n",
    "    if 'lora' in model_name.lower() and model_base is None:\n",
    "        warnings.warn('There is `lora` in model name but no `model_base` is provided. If you are loading a LoRA model, please provide the `model_base` argument.')\n",
    "    if 'lora' in model_name.lower() and model_base is not None:\n",
    "        lora_cfg_pretrained = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "        if hasattr(lora_cfg_pretrained, 'quantization_config'):\n",
    "            del lora_cfg_pretrained.quantization_config\n",
    "        processor = AutoProcessor.from_pretrained(model_base, trust_remote_code=True)\n",
    "        print('Loading Phi3-Vision from base model...')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_base, low_cpu_mem_usage=True, config=lora_cfg_pretrained, trust_remote_code=True, **kwargs)\n",
    "        token_num, tokem_dim = model.lm_head.out_features, model.lm_head.in_features\n",
    "        if model.lm_head.weight.shape[0] != token_num:\n",
    "            model.lm_head.weight = torch.nn.Parameter(torch.empty(token_num, tokem_dim, device=model.device, dtype=model.dtype))\n",
    "            model.model.embed_tokens.weight = torch.nn.Parameter(torch.empty(token_num, tokem_dim, device=model.device, dtype=model.dtype))\n",
    "\n",
    "        print('Loading additional Phi3-Vision weights...')\n",
    "        non_lora_trainables = torch.load(os.path.join(model_path, 'non_lora_state_dict.bin'), map_location='cpu')\n",
    "        non_lora_trainables = {(k[11:] if k.startswith('base_model.') else k): v for k, v in non_lora_trainables.items()}\n",
    "        if any(k.startswith('model.model.') for k in non_lora_trainables):\n",
    "            non_lora_trainables = {(k[6:] if k.startswith('model.') else k): v for k, v in non_lora_trainables.items()}\n",
    "        model.load_state_dict(non_lora_trainables, strict=False)\n",
    "    \n",
    "        print('Loading LoRA weights...')\n",
    "        model = PeftModel.from_pretrained(model, model_path)\n",
    "\n",
    "        print('Merging LoRA weights...')\n",
    "        \n",
    "        model = model.merge_and_unload()\n",
    "        \n",
    "        print('Model Loaded!!!')\n",
    "    \n",
    "    else:\n",
    "        processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, trust_remote_code=True, **kwargs)\n",
    "\n",
    "    return processor, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Phi3-Vision from base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading additional Phi3-Vision weights...\n",
      "Loading LoRA weights...\n",
      "Merging LoRA weights...\n",
      "Model Loaded!!!\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "\n",
    "    # Model\n",
    "    disable_torch_init()\n",
    "\n",
    "processor, model = load_pretrained_model(model_path = model_path, model_base=model_base, \n",
    "                                            model_name=model_name, device_map=device, \n",
    "                                            load_4bit=load_4bit, load_8bit=load_8bit,\n",
    "                                            device=device, use_flash_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 첫 번째 JSON 파일 읽기\n",
    "with open('RAF-DB/all_ft_valid.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "basic_data =[]\n",
    "cmpd_data = []\n",
    "\n",
    "for d in data:\n",
    "    \n",
    "    if len(d['id']) == 4:\n",
    "        basic_data.append(d)\n",
    "    else:\n",
    "        cmpd_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [17:49<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness\n",
      "0.8870292887029289\n",
      "Surprise\n",
      "0.8936170212765957\n",
      "Happiness\n",
      "0.9620253164556962\n",
      "Disgust\n",
      "0.76875\n",
      "Anger\n",
      "0.8148148148148148\n",
      "Fear\n",
      "0.7432432432432432\n",
      "Neutral\n",
      "0.8808823529411764\n",
      "0.901890482398957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BASIC INFERENCE\n",
    "\n",
    "from transformers import TextStreamer\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "def do_basic(imagepath):\n",
    "    \n",
    "    image = Image.open(imagepath).convert(\"RGB\")\n",
    "\n",
    "    inp = f\"<|image_1|>\\nSelect an emotion label from the following options: 'Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', or 'Neutral'.\"\n",
    "    messages =[ {\"role\": \"user\", \"content\": inp} ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt, [image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generate_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens= 1000,\n",
    "            temperature= 0,\n",
    "            repetition_penalty= 1.0,\n",
    "            use_cache=True,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    outputs = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    \n",
    "    return outputs\n",
    "    \n",
    "    \n",
    "# epoch 5 : 65.4\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "cnt = 0\n",
    "hit = 0\n",
    "res_dic = {}\n",
    "res_dic2 = {}\n",
    "\n",
    "res_lb = []\n",
    "\n",
    "for r in tqdm(basic_data):\n",
    "\n",
    "    \n",
    "    tr_lb = r['conversations'][1]['value']\n",
    "    print('[', tr_lb, ']')\n",
    "\n",
    "    lb = do_basic( 'RAF-DB/all/valid/'+ r['image']).strip()\n",
    "    print(lb)\n",
    "    res_lb.append(lb)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    if lb.lower() ==  tr_lb.lower():\n",
    "        hit +=1 \n",
    "        res_dic[tr_lb] = res_dic.get(tr_lb, 0) + 1\n",
    "    \n",
    "    cnt +=1\n",
    "    res_dic2[tr_lb] = res_dic2.get(tr_lb, 0) + 1\n",
    "    \n",
    "        \n",
    "    for k in res_dic:\n",
    "        print(k)\n",
    "        print(res_dic[k]/res_dic2[k])\n",
    "    print(hit/cnt)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "      <th>cmpd_label</th>\n",
       "      <th>basic_pred_top1</th>\n",
       "      <th>basic_pred_top2</th>\n",
       "      <th>basic_pred_top3</th>\n",
       "      <th>basic_pred_top4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Happily Surprised</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Sadly Disgusted</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Sadly Disgusted</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Happily Disgusted</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Sadly Disgusted</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Sadly Fearful</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Angrily Surprised</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Angrily Disgusted</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Angrily Surprised</td>\n",
       "      <td>Anger</td>\n",
       "      <td>Fear</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>/mnt/storage1/Research/vlm_research/Phi3-Visio...</td>\n",
       "      <td>Sadly Disgusted</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 fpath         cmpd_label  \\\n",
       "0    /mnt/storage1/Research/vlm_research/Phi3-Visio...  Happily Surprised   \n",
       "1    /mnt/storage1/Research/vlm_research/Phi3-Visio...    Sadly Disgusted   \n",
       "2    /mnt/storage1/Research/vlm_research/Phi3-Visio...    Sadly Disgusted   \n",
       "3    /mnt/storage1/Research/vlm_research/Phi3-Visio...  Happily Disgusted   \n",
       "4    /mnt/storage1/Research/vlm_research/Phi3-Visio...    Sadly Disgusted   \n",
       "..                                                 ...                ...   \n",
       "787  /mnt/storage1/Research/vlm_research/Phi3-Visio...      Sadly Fearful   \n",
       "788  /mnt/storage1/Research/vlm_research/Phi3-Visio...  Angrily Surprised   \n",
       "789  /mnt/storage1/Research/vlm_research/Phi3-Visio...  Angrily Disgusted   \n",
       "790  /mnt/storage1/Research/vlm_research/Phi3-Visio...  Angrily Surprised   \n",
       "791  /mnt/storage1/Research/vlm_research/Phi3-Visio...    Sadly Disgusted   \n",
       "\n",
       "    basic_pred_top1 basic_pred_top2 basic_pred_top3 basic_pred_top4  \n",
       "0         Happiness        Surprise         Sadness            Fear  \n",
       "1           Sadness         Disgust            Fear         Neutral  \n",
       "2         Happiness         Disgust         Sadness           Anger  \n",
       "3         Happiness         Sadness            Fear         Disgust  \n",
       "4           Neutral         Sadness         Disgust            Fear  \n",
       "..              ...             ...             ...             ...  \n",
       "787         Sadness         Neutral            Fear         Disgust  \n",
       "788           Anger         Disgust        Surprise            Fear  \n",
       "789         Disgust           Anger         Sadness            Fear  \n",
       "790           Anger            Fear         Sadness       Happiness  \n",
       "791         Disgust         Neutral         Sadness           Anger  \n",
       "\n",
       "[792 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "df = pd.read_csv('RAF-DB/poster_cmpd_valid.csv')\n",
    "\n",
    "edic_cmpd = {'Happily Surprised':['Happiness', 'Surprise'],\n",
    "             'Happily Disgusted':['Happiness', 'Disgust'],\n",
    "             'Sadly Fearful': ['Sadness', 'Fear'],\n",
    "             'Sadly Angry': ['Sadness', 'Anger'],\n",
    "             'Sadly Surprised': ['Sadness', 'Surprise'],\n",
    "             'Sadly Disgusted': ['Sadness', 'Disgust'],\n",
    "             'Fearfully Angry': ['Fear','Anger'],\n",
    "             'Fearfully Surprised': ['Fear','Surprise'],\n",
    "             'Angrily Surprised': ['Anger','Surprise'],\n",
    "             'Angrily Disgusted': ['Anger','Disgust'],\n",
    "             'Disgustedly Surprised': ['Disgust', 'Surprise']}\n",
    "\n",
    "\n",
    "edic_basic = ['Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', 'Neutral']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cmpd(imagepath):\n",
    "    \n",
    "    image = Image.open(imagepath).convert(\"RGB\")\n",
    "\n",
    "    inp = f\"<|image_1|>\\nSelect an emotion label from the following options: 'Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger' or 'Neutral'.\"\n",
    "    messages =[ {\"role\": \"user\", \"content\": inp} ]\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt, [image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generate_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens= 1000,\n",
    "            temperature= 0,\n",
    "            repetition_penalty= 1.0,\n",
    "            use_cache=True,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    lb1 = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0].strip()\n",
    "    \n",
    "\n",
    "    lb_cand = [e for e in edic_basic if e != lb1]\n",
    "    lb_cand = ', '.join( lb_cand[:-1] ) + ', or ' + lb_cand[-1]\n",
    "    \n",
    "    inp = f\"<|image_1|>\\nThe primary emotion conveyed by this image was {lb1}. Please select the next most strongly felt emotion from the following options: {lb_cand}.\"\n",
    "    messages =[ {\"role\": \"user\", \"content\": inp} ]\n",
    "    \n",
    "    print(inp)\n",
    "\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt, [image], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generate_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens= 1000,\n",
    "            temperature= 0,\n",
    "            repetition_penalty= 1.0,\n",
    "            use_cache=True,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    lb2 = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0].strip()\n",
    "    \n",
    "    return lb1, lb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happily Surprised\n",
      "0.8740740740740741\n",
      "Sadly Disgusted\n",
      "0.7588652482269503\n",
      "Happily Disgusted\n",
      "0.6170212765957447\n",
      "Angrily Disgusted\n",
      "0.7413793103448276\n",
      "Angrily Surprised\n",
      "0.6578947368421053\n",
      "Fearfully Surprised\n",
      "0.7672413793103449\n",
      "Disgustedly Surprised\n",
      "0.4\n",
      "Sadly Fearful\n",
      "0.3181818181818182\n",
      "Fearfully Angry\n",
      "0.7272727272727273\n",
      "Sadly Surprised\n",
      "0.5\n",
      "Sadly Angry\n",
      "0.3333333333333333\n",
      "0.7095959595959596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMPOUND INFERENCE\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "cnt = 0\n",
    "hit = 0\n",
    "res_dic = {}\n",
    "res_dic2 = {}\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "\n",
    "    tr_lb = r['cmpd_label']\n",
    "    print('[', tr_lb, ']')\n",
    "\n",
    "    lb1, lb2 = do_cmpd( r['fpath'] )\n",
    "    \n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if lb1 != lb2 and lb1 in  edic_cmpd[tr_lb] and lb2 in  edic_cmpd[tr_lb]:\n",
    "        hit +=1 \n",
    "        res_dic[tr_lb] = res_dic.get(tr_lb, 0) + 1\n",
    "    \n",
    "    cnt +=1\n",
    "    res_dic2[tr_lb] = res_dic2.get(tr_lb, 0) + 1\n",
    "    \n",
    "        \n",
    "    for k in res_dic:\n",
    "        print(k)\n",
    "        print(res_dic[k]/res_dic2[k])\n",
    "    print(hit/cnt)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
